{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch import optim as optim\n",
    "import torch.distributed as dist\n",
    "\n",
    "from timm.scheduler.cosine_lr import CosineLRScheduler\n",
    "from timm.utils import accuracy, AverageMeter\n",
    "\n",
    "from utils import NativeScalerWithGradNormCount, reduce_tensor\n",
    "from models.swin_transformer import SwinTransformer\n",
    "# import train_val_func as tvfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 및 변환 정의\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# 학습 및 검증 데이터셋으로 분할\n",
    "train_length = int(0.8 * len(train_dataset))\n",
    "val_length = len(train_dataset) - train_length\n",
    "train_subset, val_subset = random_split(train_dataset, [train_length, val_length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device check: cuda\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 100\n",
    "lr = 1e-3\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device check:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "val_iterator = DataLoader(val_subset, batch_size=batch_size, shuffle=True)\n",
    "test_iterator = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SwinTransformer(img_size=32,\n",
    "                        patch_size=2,\n",
    "                        in_chans=3,\n",
    "                        num_classes=10,\n",
    "                        embed_dim=64, # 잠재 공간의 차원\n",
    "                        depths=[2, 2, 2, 2], # 각 스테이지에서의 블록 수\n",
    "                        num_heads=[2, 4, 8, 16], # 각 스테이지에서의 어텐션 헤드 수\n",
    "                        window_size=4, # 로컬 윈도우 크기\n",
    "                        mlp_ratio=3, # MLP 레이어의 확장 비율\n",
    "                        qkv_bias=True, # default, 자가 어텐션 메커니즘의 선형 변환에 편향(bias) 항 추가 여부\n",
    "                        qk_scale=None, # default, Query (Q)와 Key (K) 행렬의 내적(dot product)을 정규화하는 데 사용되는 스케일링 계수\n",
    "                        drop_rate=0.1, # 드롭아웃 비율\n",
    "                        drop_path_rate=0.1, # 드롭 경로 비율\n",
    "                        ape=False, # default, absolute position embedding이 patch embedding에 추가\n",
    "                        norm_layer=nn.LayerNorm, # default\n",
    "                        patch_norm=True, # default\n",
    "                        use_checkpoint=False, # defult\n",
    "                        fused_window_process=False # deafult\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), eps=1e-8, betas=(0.9, 0.999), lr=lr, weight_decay=1e-2) # 개발자 설정 weight_decay=0.05\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss_scaler = NativeScalerWithGradNormCount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = int(epochs * len(train_iterator))\n",
    "warmup_steps = int(3 * len(train_iterator))\n",
    "\n",
    "lr_scheduler = CosineLRScheduler(\n",
    "            optimizer,\n",
    "            t_initial=(num_steps - warmup_steps) if True else num_steps, # config.TRAIN.LR_SCHEDULER.WARMUP_PREFIX\n",
    "            cycle_mul=1.,\n",
    "            lr_min=1e-5, # config.TRAIN.MIN_LR\n",
    "            warmup_lr_init=1e-4, # config.TRAIN.WARMUP_LR\n",
    "            warmup_t=warmup_steps,\n",
    "            cycle_limit=1,\n",
    "            t_in_epochs=False,\n",
    "            warmup_prefix=True, # TRAIN.LR_SCHEDULER.WARMUP_PREFIX\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = './model_save'\n",
    "\n",
    "def save_checkpoint(epoch, model, max_accuracy, optimizer, lr_scheduler, loss_scaler):\n",
    "    save_state = {'model': model.state_dict(),\n",
    "                  'optimizer': optimizer.state_dict(),\n",
    "                  'lr_scheduler': lr_scheduler.state_dict(),\n",
    "                  'max_accuracy': max_accuracy,\n",
    "                  'scaler': loss_scaler.state_dict(),\n",
    "                  'epoch': epoch,\n",
    "                  }\n",
    "\n",
    "    save_path = os.path.join(output, f'ckpt_epoch_{epoch}.pth')\n",
    "    print(f\"{save_path} saving......\")\n",
    "    torch.save(save_state, save_path)\n",
    "    print(f\"{save_path} saved !!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epochs, model, criterion, data_loader, optimizer, epoch, lr_scheduler, loss_scaler): # mixedup_fn 제외\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    num_steps = len(data_loader)\n",
    "    batch_time = AverageMeter()\n",
    "    loss_meter = AverageMeter()\n",
    "    norm_meter = AverageMeter()\n",
    "    scaler_meter = AverageMeter()\n",
    "\n",
    "    start = time.time()\n",
    "    end = time.time()\n",
    "    for idx, (samples, targets) in enumerate(data_loader):\n",
    "        samples = samples.cuda(non_blocking=True)\n",
    "        targets = targets.cuda(non_blocking=True)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=True): # Enable Pytorch automatic mixed precision (amp)\n",
    "            outputs = model(samples)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss = loss / 1 # config.TRAIN.ACCUMULATION_STEPS - could be overwritten by command line argument\n",
    "\n",
    "        # this attribute is added by timm on one optimizer (adahessian)\n",
    "        is_second_order = hasattr(optimizer, 'is_second_order') and optimizer.is_second_order\n",
    "        grad_norm = loss_scaler(loss, optimizer, clip_grad=5.0, # gradient 크기 제한\n",
    "                                parameters=model.parameters(), create_graph=is_second_order,\n",
    "                                update_grad=(idx + 1) % 1 == 0)\n",
    "        if (idx + 1) % 1 == 0:\n",
    "            optimizer.zero_grad()\n",
    "            lr_scheduler.step_update((epoch * num_steps + idx) // 1)\n",
    "        loss_scale_value = loss_scaler.state_dict()[\"scale\"]\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        loss_meter.update(loss.item(), targets.size(0))\n",
    "        if grad_norm is not None:  # loss_scaler return None if not update\n",
    "            norm_meter.update(grad_norm)\n",
    "        scaler_meter.update(loss_scale_value)\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if idx % 10 == 0:\n",
    "            lr = optimizer.param_groups[0]['lr']\n",
    "            wd = optimizer.param_groups[0]['weight_decay']\n",
    "            memory_used = torch.cuda.max_memory_allocated() / (1024.0 * 1024.0)\n",
    "            etas = batch_time.avg * (num_steps - idx)\n",
    "            print(\n",
    "                f'Train: [{epoch}/{epochs}][{idx}/{num_steps}]\\t'\n",
    "                f'eta {datetime.timedelta(seconds=int(etas))} lr {lr:.6f}\\t wd {wd:.4f}\\t'\n",
    "                f'time {batch_time.val:.4f} ({batch_time.avg:.4f})\\t'\n",
    "                f'loss {loss_meter.val:.4f} ({loss_meter.avg:.4f})\\t'\n",
    "                f'grad_norm {norm_meter.val:.4f} ({norm_meter.avg:.4f})\\t'\n",
    "                f'loss_scale {scaler_meter.val:.4f} ({scaler_meter.avg:.4f})\\t'\n",
    "                f'mem {memory_used:.0f}MB')\n",
    "    epoch_time = time.time() - start\n",
    "    print(f\"EPOCH {epoch} training takes {datetime.timedelta(seconds=int(epoch_time))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate(data_loader, model):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "\n",
    "    batch_time = AverageMeter()\n",
    "    loss_meter = AverageMeter()\n",
    "    acc1_meter = AverageMeter()\n",
    "    acc5_meter = AverageMeter()\n",
    "\n",
    "    end = time.time()\n",
    "    for idx, (images, target) in enumerate(data_loader):\n",
    "        images = images.cuda(non_blocking=True)\n",
    "        target = target.cuda(non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        with torch.cuda.amp.autocast(enabled=True): # config.AMP_ENABLE\n",
    "            output = model(images)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        loss = criterion(output, target)\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "\n",
    "        # acc1 = reduce_tensor(acc1)\n",
    "        # acc5 = reduce_tensor(acc5)\n",
    "        # loss = reduce_tensor(loss)\n",
    "\n",
    "        loss_meter.update(loss.item(), target.size(0))\n",
    "        acc1_meter.update(acc1.item(), target.size(0))\n",
    "        acc5_meter.update(acc5.item(), target.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if idx % 10 == 0: # config.PRINT_FREQ\n",
    "            memory_used = torch.cuda.max_memory_allocated() / (1024.0 * 1024.0)\n",
    "            print(\n",
    "                f'Test: [{idx}/{len(data_loader)}]\\t'\n",
    "                f'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                f'Loss {loss_meter.val:.4f} ({loss_meter.avg:.4f})\\t'\n",
    "                f'Acc@1 {acc1_meter.val:.3f} ({acc1_meter.avg:.3f})\\t'\n",
    "                f'Acc@5 {acc5_meter.val:.3f} ({acc5_meter.avg:.3f})\\t'\n",
    "                f'Mem {memory_used:.0f}MB')\n",
    "    print(f' * Acc@1 {acc1_meter.avg:.3f} Acc@5 {acc5_meter.avg:.3f}')\n",
    "    return acc1_meter.avg, acc5_meter.avg, loss_meter.avg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training\n",
      "Train: [0/100][0/625]\teta 0:00:30 lr 0.000100\t wd 0.0100\ttime 0.0491 (0.0491)\tloss 2.2734 (2.2734)\tgrad_norm nan (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 370MB\n",
      "Train: [0/100][10/625]\teta 0:00:23 lr 0.000105\t wd 0.0100\ttime 0.0392 (0.0380)\tloss 2.0879 (2.2360)\tgrad_norm 4.1512 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][20/625]\teta 0:00:22 lr 0.000110\t wd 0.0100\ttime 0.0374 (0.0372)\tloss 2.1484 (2.2181)\tgrad_norm 6.4588 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][30/625]\teta 0:00:22 lr 0.000114\t wd 0.0100\ttime 0.0337 (0.0372)\tloss 2.2031 (2.1926)\tgrad_norm 4.6669 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][40/625]\teta 0:00:21 lr 0.000119\t wd 0.0100\ttime 0.0327 (0.0371)\tloss 2.1211 (2.1562)\tgrad_norm 5.0497 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][50/625]\teta 0:00:21 lr 0.000124\t wd 0.0100\ttime 0.0392 (0.0371)\tloss 2.1152 (2.1419)\tgrad_norm 6.1506 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][60/625]\teta 0:00:20 lr 0.000129\t wd 0.0100\ttime 0.0336 (0.0370)\tloss 2.0332 (2.1261)\tgrad_norm 3.4605 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][70/625]\teta 0:00:20 lr 0.000134\t wd 0.0100\ttime 0.0332 (0.0367)\tloss 2.0801 (2.1102)\tgrad_norm 4.8504 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][80/625]\teta 0:00:19 lr 0.000138\t wd 0.0100\ttime 0.0335 (0.0364)\tloss 1.9600 (2.1045)\tgrad_norm 5.7150 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][90/625]\teta 0:00:19 lr 0.000143\t wd 0.0100\ttime 0.0333 (0.0364)\tloss 2.0195 (2.0976)\tgrad_norm 5.0328 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][100/625]\teta 0:00:19 lr 0.000148\t wd 0.0100\ttime 0.0368 (0.0363)\tloss 2.0078 (2.0853)\tgrad_norm 4.4040 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][110/625]\teta 0:00:18 lr 0.000153\t wd 0.0100\ttime 0.0341 (0.0362)\tloss 1.9541 (2.0689)\tgrad_norm 3.1808 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][120/625]\teta 0:00:18 lr 0.000158\t wd 0.0100\ttime 0.0397 (0.0362)\tloss 1.8916 (2.0635)\tgrad_norm 2.7096 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][130/625]\teta 0:00:17 lr 0.000162\t wd 0.0100\ttime 0.0360 (0.0362)\tloss 1.9434 (2.0514)\tgrad_norm 3.1785 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][140/625]\teta 0:00:17 lr 0.000167\t wd 0.0100\ttime 0.0327 (0.0362)\tloss 2.1113 (2.0435)\tgrad_norm 3.7515 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][150/625]\teta 0:00:17 lr 0.000172\t wd 0.0100\ttime 0.0333 (0.0362)\tloss 1.8408 (2.0361)\tgrad_norm 2.7686 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][160/625]\teta 0:00:16 lr 0.000177\t wd 0.0100\ttime 0.0394 (0.0362)\tloss 1.8789 (2.0330)\tgrad_norm 3.9338 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][170/625]\teta 0:00:16 lr 0.000182\t wd 0.0100\ttime 0.0400 (0.0362)\tloss 2.0625 (2.0267)\tgrad_norm 3.9462 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][180/625]\teta 0:00:16 lr 0.000186\t wd 0.0100\ttime 0.0388 (0.0362)\tloss 1.6885 (2.0212)\tgrad_norm 3.2967 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][190/625]\teta 0:00:15 lr 0.000191\t wd 0.0100\ttime 0.0326 (0.0362)\tloss 1.8008 (2.0156)\tgrad_norm 3.9267 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][200/625]\teta 0:00:15 lr 0.000196\t wd 0.0100\ttime 0.0407 (0.0362)\tloss 1.9150 (2.0090)\tgrad_norm 6.8982 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][210/625]\teta 0:00:14 lr 0.000201\t wd 0.0100\ttime 0.0325 (0.0361)\tloss 2.0547 (2.0050)\tgrad_norm 3.5296 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][220/625]\teta 0:00:14 lr 0.000206\t wd 0.0100\ttime 0.0333 (0.0360)\tloss 1.8242 (1.9977)\tgrad_norm 3.4860 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][230/625]\teta 0:00:14 lr 0.000210\t wd 0.0100\ttime 0.0326 (0.0360)\tloss 1.7656 (1.9904)\tgrad_norm 3.3116 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][240/625]\teta 0:00:13 lr 0.000215\t wd 0.0100\ttime 0.0357 (0.0359)\tloss 2.0391 (1.9862)\tgrad_norm 3.4892 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][250/625]\teta 0:00:13 lr 0.000220\t wd 0.0100\ttime 0.0401 (0.0358)\tloss 1.8281 (1.9807)\tgrad_norm 4.0257 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][260/625]\teta 0:00:13 lr 0.000225\t wd 0.0100\ttime 0.0383 (0.0359)\tloss 2.1406 (1.9766)\tgrad_norm 5.6928 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][270/625]\teta 0:00:12 lr 0.000230\t wd 0.0100\ttime 0.0326 (0.0358)\tloss 1.8584 (1.9708)\tgrad_norm 3.6058 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][280/625]\teta 0:00:12 lr 0.000234\t wd 0.0100\ttime 0.0408 (0.0358)\tloss 1.6709 (1.9657)\tgrad_norm 3.8178 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][290/625]\teta 0:00:12 lr 0.000239\t wd 0.0100\ttime 0.0357 (0.0359)\tloss 1.5977 (1.9620)\tgrad_norm 2.9758 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][300/625]\teta 0:00:11 lr 0.000244\t wd 0.0100\ttime 0.0330 (0.0358)\tloss 1.7393 (1.9570)\tgrad_norm 4.2500 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][310/625]\teta 0:00:11 lr 0.000249\t wd 0.0100\ttime 0.0324 (0.0358)\tloss 1.8564 (1.9536)\tgrad_norm 3.5289 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][320/625]\teta 0:00:10 lr 0.000254\t wd 0.0100\ttime 0.0331 (0.0358)\tloss 1.8945 (1.9457)\tgrad_norm 4.3057 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][330/625]\teta 0:00:10 lr 0.000258\t wd 0.0100\ttime 0.0344 (0.0358)\tloss 1.7549 (1.9415)\tgrad_norm 3.5092 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][340/625]\teta 0:00:10 lr 0.000263\t wd 0.0100\ttime 0.0359 (0.0358)\tloss 1.6387 (1.9364)\tgrad_norm 2.8654 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][350/625]\teta 0:00:09 lr 0.000268\t wd 0.0100\ttime 0.0330 (0.0358)\tloss 1.7090 (1.9328)\tgrad_norm 5.1380 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][360/625]\teta 0:00:09 lr 0.000273\t wd 0.0100\ttime 0.0375 (0.0357)\tloss 1.8291 (1.9289)\tgrad_norm 4.8238 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][370/625]\teta 0:00:09 lr 0.000278\t wd 0.0100\ttime 0.0330 (0.0357)\tloss 1.7773 (1.9253)\tgrad_norm 2.9726 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][380/625]\teta 0:00:08 lr 0.000282\t wd 0.0100\ttime 0.0391 (0.0357)\tloss 1.5693 (1.9206)\tgrad_norm 3.1015 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][390/625]\teta 0:00:08 lr 0.000287\t wd 0.0100\ttime 0.0397 (0.0357)\tloss 2.0801 (1.9179)\tgrad_norm 3.9028 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][400/625]\teta 0:00:08 lr 0.000292\t wd 0.0100\ttime 0.0345 (0.0357)\tloss 1.5986 (1.9133)\tgrad_norm 2.9831 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][410/625]\teta 0:00:07 lr 0.000297\t wd 0.0100\ttime 0.0395 (0.0357)\tloss 1.9102 (1.9102)\tgrad_norm 4.5029 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][420/625]\teta 0:00:07 lr 0.000302\t wd 0.0100\ttime 0.0374 (0.0358)\tloss 1.8545 (1.9071)\tgrad_norm 3.3241 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][430/625]\teta 0:00:06 lr 0.000306\t wd 0.0100\ttime 0.0397 (0.0358)\tloss 1.5996 (1.9041)\tgrad_norm 2.8874 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][440/625]\teta 0:00:06 lr 0.000311\t wd 0.0100\ttime 0.0329 (0.0359)\tloss 1.8535 (1.9013)\tgrad_norm 3.7346 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][450/625]\teta 0:00:06 lr 0.000316\t wd 0.0100\ttime 0.0327 (0.0359)\tloss 1.7637 (1.8971)\tgrad_norm 3.7122 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][460/625]\teta 0:00:05 lr 0.000321\t wd 0.0100\ttime 0.0331 (0.0359)\tloss 1.7939 (1.8941)\tgrad_norm 2.7396 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][470/625]\teta 0:00:05 lr 0.000326\t wd 0.0100\ttime 0.0392 (0.0358)\tloss 1.7324 (1.8900)\tgrad_norm 4.1091 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][480/625]\teta 0:00:05 lr 0.000330\t wd 0.0100\ttime 0.0334 (0.0358)\tloss 1.8379 (1.8873)\tgrad_norm 4.6611 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][490/625]\teta 0:00:04 lr 0.000335\t wd 0.0100\ttime 0.0389 (0.0358)\tloss 2.0039 (1.8840)\tgrad_norm 2.9567 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][500/625]\teta 0:00:04 lr 0.000340\t wd 0.0100\ttime 0.0393 (0.0358)\tloss 1.7197 (1.8805)\tgrad_norm 2.9647 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][510/625]\teta 0:00:04 lr 0.000345\t wd 0.0100\ttime 0.0331 (0.0358)\tloss 1.7549 (1.8775)\tgrad_norm 3.7712 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][520/625]\teta 0:00:03 lr 0.000350\t wd 0.0100\ttime 0.0332 (0.0358)\tloss 1.5889 (1.8747)\tgrad_norm 2.6265 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][530/625]\teta 0:00:03 lr 0.000354\t wd 0.0100\ttime 0.0361 (0.0358)\tloss 1.6279 (1.8720)\tgrad_norm 2.8754 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][540/625]\teta 0:00:03 lr 0.000359\t wd 0.0100\ttime 0.0367 (0.0358)\tloss 1.8115 (1.8691)\tgrad_norm 2.8776 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][550/625]\teta 0:00:02 lr 0.000364\t wd 0.0100\ttime 0.0355 (0.0359)\tloss 1.7852 (1.8659)\tgrad_norm 2.6539 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][560/625]\teta 0:00:02 lr 0.000369\t wd 0.0100\ttime 0.0391 (0.0359)\tloss 1.7441 (1.8616)\tgrad_norm 2.9949 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][570/625]\teta 0:00:01 lr 0.000374\t wd 0.0100\ttime 0.0336 (0.0359)\tloss 1.6758 (1.8600)\tgrad_norm 2.6811 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][580/625]\teta 0:00:01 lr 0.000378\t wd 0.0100\ttime 0.0371 (0.0359)\tloss 1.7070 (1.8582)\tgrad_norm 3.1331 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][590/625]\teta 0:00:01 lr 0.000383\t wd 0.0100\ttime 0.0329 (0.0359)\tloss 1.6104 (1.8554)\tgrad_norm 4.3408 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][600/625]\teta 0:00:00 lr 0.000388\t wd 0.0100\ttime 0.0386 (0.0359)\tloss 1.6523 (1.8533)\tgrad_norm 3.2959 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][610/625]\teta 0:00:00 lr 0.000393\t wd 0.0100\ttime 0.0406 (0.0359)\tloss 1.8115 (1.8509)\tgrad_norm 3.2941 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [0/100][620/625]\teta 0:00:00 lr 0.000398\t wd 0.0100\ttime 0.0368 (0.0360)\tloss 1.5820 (1.8482)\tgrad_norm 3.4973 (nan)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 0 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_0.pth saving......\n",
      "./model_save/ckpt_epoch_0.pth saved !!!\n",
      "Test: [0/157]\tTime 0.020 (0.020)\tLoss 1.5459 (1.5459)\tAcc@1 43.750 (43.750)\tAcc@5 85.938 (85.938)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 1.6396 (1.6394)\tAcc@1 46.875 (42.614)\tAcc@5 87.500 (88.068)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 1.6533 (1.6423)\tAcc@1 40.625 (41.443)\tAcc@5 93.750 (88.170)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 1.4150 (1.6331)\tAcc@1 46.875 (40.675)\tAcc@5 90.625 (88.558)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 1.6182 (1.6482)\tAcc@1 40.625 (39.748)\tAcc@5 89.062 (88.186)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 1.5508 (1.6412)\tAcc@1 37.500 (39.920)\tAcc@5 89.062 (88.419)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 1.6885 (1.6372)\tAcc@1 39.062 (40.241)\tAcc@5 87.500 (88.448)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 1.6006 (1.6307)\tAcc@1 42.188 (40.471)\tAcc@5 92.188 (88.600)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 1.6680 (1.6390)\tAcc@1 39.062 (40.258)\tAcc@5 85.938 (88.349)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 1.8916 (1.6450)\tAcc@1 25.000 (39.870)\tAcc@5 85.938 (88.479)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 1.7480 (1.6406)\tAcc@1 39.062 (39.836)\tAcc@5 87.500 (88.660)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 1.6396 (1.6399)\tAcc@1 34.375 (39.809)\tAcc@5 92.188 (88.626)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 1.6982 (1.6423)\tAcc@1 42.188 (39.631)\tAcc@5 81.250 (88.611)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 1.8232 (1.6436)\tAcc@1 29.688 (39.587)\tAcc@5 82.812 (88.585)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 1.6865 (1.6445)\tAcc@1 45.312 (39.705)\tAcc@5 85.938 (88.520)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 1.9971 (1.6479)\tAcc@1 23.438 (39.476)\tAcc@5 81.250 (88.462)\tMem 455MB\n",
      " * Acc@1 39.450 Acc@5 88.510\n",
      "Accuracy of the network on the 10000 test images: 39.5%\n",
      "Max accuracy: 39.45%\n",
      "Train: [1/100][0/625]\teta 0:00:24 lr 0.000400\t wd 0.0100\ttime 0.0388 (0.0388)\tloss 1.7109 (1.7109)\tgrad_norm 2.7069 (2.7069)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][10/625]\teta 0:00:22 lr 0.000405\t wd 0.0100\ttime 0.0359 (0.0366)\tloss 1.5312 (1.5786)\tgrad_norm 2.5457 (2.7863)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][20/625]\teta 0:00:22 lr 0.000410\t wd 0.0100\ttime 0.0402 (0.0364)\tloss 1.6396 (1.6173)\tgrad_norm 3.5696 (2.8844)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][30/625]\teta 0:00:21 lr 0.000414\t wd 0.0100\ttime 0.0356 (0.0362)\tloss 1.6348 (1.6389)\tgrad_norm 2.2278 (3.0310)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][40/625]\teta 0:00:21 lr 0.000419\t wd 0.0100\ttime 0.0331 (0.0361)\tloss 1.8975 (1.6549)\tgrad_norm 3.9369 (3.0858)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][50/625]\teta 0:00:20 lr 0.000424\t wd 0.0100\ttime 0.0338 (0.0361)\tloss 1.6572 (1.6692)\tgrad_norm 3.2197 (3.0934)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][60/625]\teta 0:00:20 lr 0.000429\t wd 0.0100\ttime 0.0409 (0.0362)\tloss 1.5156 (1.6696)\tgrad_norm 3.4327 (3.1463)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][70/625]\teta 0:00:20 lr 0.000434\t wd 0.0100\ttime 0.0362 (0.0363)\tloss 1.7363 (1.6762)\tgrad_norm 3.6166 (3.1825)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][80/625]\teta 0:00:19 lr 0.000438\t wd 0.0100\ttime 0.0335 (0.0361)\tloss 1.8760 (1.6740)\tgrad_norm 3.7485 (3.1880)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][90/625]\teta 0:00:19 lr 0.000443\t wd 0.0100\ttime 0.0338 (0.0360)\tloss 1.7002 (1.6844)\tgrad_norm 3.1954 (3.2035)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][100/625]\teta 0:00:18 lr 0.000448\t wd 0.0100\ttime 0.0372 (0.0360)\tloss 1.6182 (1.6834)\tgrad_norm 2.5482 (3.1613)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][110/625]\teta 0:00:18 lr 0.000453\t wd 0.0100\ttime 0.0386 (0.0362)\tloss 1.6807 (1.6792)\tgrad_norm 2.6059 (3.1177)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][120/625]\teta 0:00:18 lr 0.000458\t wd 0.0100\ttime 0.0330 (0.0362)\tloss 1.6670 (1.6695)\tgrad_norm 2.7293 (3.1064)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][130/625]\teta 0:00:17 lr 0.000462\t wd 0.0100\ttime 0.0333 (0.0361)\tloss 1.7363 (1.6680)\tgrad_norm 2.5962 (3.0797)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][140/625]\teta 0:00:17 lr 0.000467\t wd 0.0100\ttime 0.0342 (0.0361)\tloss 1.4756 (1.6641)\tgrad_norm 2.7493 (3.0572)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][150/625]\teta 0:00:17 lr 0.000472\t wd 0.0100\ttime 0.0328 (0.0360)\tloss 1.7236 (1.6631)\tgrad_norm 2.9636 (3.0476)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][160/625]\teta 0:00:16 lr 0.000477\t wd 0.0100\ttime 0.0353 (0.0360)\tloss 1.5420 (1.6644)\tgrad_norm 3.0285 (3.0489)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][170/625]\teta 0:00:16 lr 0.000482\t wd 0.0100\ttime 0.0363 (0.0359)\tloss 1.7002 (1.6640)\tgrad_norm 3.1128 (3.0343)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][180/625]\teta 0:00:16 lr 0.000486\t wd 0.0100\ttime 0.0370 (0.0360)\tloss 1.7803 (1.6649)\tgrad_norm 3.4537 (3.0351)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][190/625]\teta 0:00:15 lr 0.000491\t wd 0.0100\ttime 0.0330 (0.0361)\tloss 1.7734 (1.6619)\tgrad_norm 3.0007 (3.0261)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][200/625]\teta 0:00:15 lr 0.000496\t wd 0.0100\ttime 0.0328 (0.0360)\tloss 1.7627 (1.6582)\tgrad_norm 4.2304 (3.0385)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][210/625]\teta 0:00:14 lr 0.000501\t wd 0.0100\ttime 0.0358 (0.0360)\tloss 1.8438 (1.6609)\tgrad_norm 4.5245 (3.0653)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][220/625]\teta 0:00:14 lr 0.000506\t wd 0.0100\ttime 0.0358 (0.0360)\tloss 1.6426 (1.6594)\tgrad_norm 2.8057 (3.0619)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][230/625]\teta 0:00:14 lr 0.000510\t wd 0.0100\ttime 0.0328 (0.0360)\tloss 1.6084 (1.6562)\tgrad_norm 3.6804 (3.0534)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][240/625]\teta 0:00:13 lr 0.000515\t wd 0.0100\ttime 0.0353 (0.0359)\tloss 1.6406 (1.6555)\tgrad_norm 2.7906 (3.0437)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][250/625]\teta 0:00:13 lr 0.000520\t wd 0.0100\ttime 0.0329 (0.0359)\tloss 1.6709 (1.6560)\tgrad_norm 2.9362 (3.0281)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][260/625]\teta 0:00:13 lr 0.000525\t wd 0.0100\ttime 0.0328 (0.0358)\tloss 1.6514 (1.6558)\tgrad_norm 2.6941 (3.0106)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][270/625]\teta 0:00:12 lr 0.000530\t wd 0.0100\ttime 0.0330 (0.0358)\tloss 1.4854 (1.6555)\tgrad_norm 3.4530 (3.0170)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][280/625]\teta 0:00:12 lr 0.000534\t wd 0.0100\ttime 0.0357 (0.0358)\tloss 1.5977 (1.6513)\tgrad_norm 2.3382 (3.0016)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][290/625]\teta 0:00:11 lr 0.000539\t wd 0.0100\ttime 0.0361 (0.0358)\tloss 1.3652 (1.6487)\tgrad_norm 2.8997 (3.0012)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][300/625]\teta 0:00:11 lr 0.000544\t wd 0.0100\ttime 0.0354 (0.0358)\tloss 1.6963 (1.6488)\tgrad_norm 3.0641 (3.0037)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][310/625]\teta 0:00:11 lr 0.000549\t wd 0.0100\ttime 0.0365 (0.0357)\tloss 1.8369 (1.6487)\tgrad_norm 2.7536 (2.9988)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][320/625]\teta 0:00:10 lr 0.000554\t wd 0.0100\ttime 0.0325 (0.0357)\tloss 1.4365 (1.6474)\tgrad_norm 2.6070 (2.9969)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][330/625]\teta 0:00:10 lr 0.000558\t wd 0.0100\ttime 0.0328 (0.0357)\tloss 1.6318 (1.6472)\tgrad_norm 2.8746 (2.9903)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][340/625]\teta 0:00:10 lr 0.000563\t wd 0.0100\ttime 0.0370 (0.0358)\tloss 1.7236 (1.6480)\tgrad_norm 3.2355 (2.9872)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][350/625]\teta 0:00:09 lr 0.000568\t wd 0.0100\ttime 0.0363 (0.0358)\tloss 1.7559 (1.6469)\tgrad_norm 2.4346 (2.9815)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][360/625]\teta 0:00:09 lr 0.000573\t wd 0.0100\ttime 0.0332 (0.0358)\tloss 1.4072 (1.6462)\tgrad_norm 2.2109 (2.9785)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][370/625]\teta 0:00:09 lr 0.000578\t wd 0.0100\ttime 0.0329 (0.0358)\tloss 1.6807 (1.6444)\tgrad_norm 2.7872 (2.9746)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][380/625]\teta 0:00:08 lr 0.000582\t wd 0.0100\ttime 0.0373 (0.0358)\tloss 1.5811 (1.6428)\tgrad_norm 2.9042 (2.9714)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][390/625]\teta 0:00:08 lr 0.000587\t wd 0.0100\ttime 0.0331 (0.0358)\tloss 1.8057 (1.6420)\tgrad_norm 3.6903 (2.9713)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][400/625]\teta 0:00:08 lr 0.000592\t wd 0.0100\ttime 0.0388 (0.0358)\tloss 1.4883 (1.6397)\tgrad_norm 2.9260 (2.9739)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][410/625]\teta 0:00:07 lr 0.000597\t wd 0.0100\ttime 0.0336 (0.0358)\tloss 1.6562 (1.6380)\tgrad_norm 2.9068 (2.9721)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][420/625]\teta 0:00:07 lr 0.000602\t wd 0.0100\ttime 0.0359 (0.0358)\tloss 1.6191 (1.6383)\tgrad_norm 2.9455 (2.9723)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][430/625]\teta 0:00:06 lr 0.000606\t wd 0.0100\ttime 0.0335 (0.0358)\tloss 1.7119 (1.6361)\tgrad_norm 2.5881 (2.9625)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][440/625]\teta 0:00:06 lr 0.000611\t wd 0.0100\ttime 0.0362 (0.0359)\tloss 1.5488 (1.6358)\tgrad_norm 2.8405 (2.9714)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][450/625]\teta 0:00:06 lr 0.000616\t wd 0.0100\ttime 0.0335 (0.0359)\tloss 1.7129 (1.6363)\tgrad_norm 3.0004 (2.9699)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][460/625]\teta 0:00:05 lr 0.000621\t wd 0.0100\ttime 0.0329 (0.0359)\tloss 1.6846 (1.6362)\tgrad_norm 2.6354 (2.9641)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][470/625]\teta 0:00:05 lr 0.000626\t wd 0.0100\ttime 0.0364 (0.0359)\tloss 1.5723 (1.6358)\tgrad_norm 2.9095 (2.9570)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][480/625]\teta 0:00:05 lr 0.000630\t wd 0.0100\ttime 0.0329 (0.0359)\tloss 1.3535 (1.6341)\tgrad_norm 2.6745 (2.9514)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][490/625]\teta 0:00:04 lr 0.000635\t wd 0.0100\ttime 0.0334 (0.0358)\tloss 1.5908 (1.6320)\tgrad_norm 2.6764 (2.9401)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][500/625]\teta 0:00:04 lr 0.000640\t wd 0.0100\ttime 0.0327 (0.0358)\tloss 1.5957 (1.6312)\tgrad_norm 2.5977 (2.9393)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][510/625]\teta 0:00:04 lr 0.000645\t wd 0.0100\ttime 0.0329 (0.0358)\tloss 1.7021 (1.6306)\tgrad_norm 2.5445 (2.9382)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][520/625]\teta 0:00:03 lr 0.000650\t wd 0.0100\ttime 0.0329 (0.0358)\tloss 1.5615 (1.6293)\tgrad_norm 2.6103 (2.9328)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][530/625]\teta 0:00:03 lr 0.000654\t wd 0.0100\ttime 0.0368 (0.0358)\tloss 1.5439 (1.6289)\tgrad_norm 2.6149 (2.9278)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][540/625]\teta 0:00:03 lr 0.000659\t wd 0.0100\ttime 0.0362 (0.0358)\tloss 1.4443 (1.6279)\tgrad_norm 2.7531 (2.9248)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][550/625]\teta 0:00:02 lr 0.000664\t wd 0.0100\ttime 0.0334 (0.0358)\tloss 1.6230 (1.6272)\tgrad_norm 3.4411 (2.9258)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][560/625]\teta 0:00:02 lr 0.000669\t wd 0.0100\ttime 0.0354 (0.0358)\tloss 1.6963 (1.6274)\tgrad_norm 2.7471 (2.9240)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][570/625]\teta 0:00:01 lr 0.000674\t wd 0.0100\ttime 0.0400 (0.0358)\tloss 1.4473 (1.6256)\tgrad_norm 2.7452 (2.9227)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][580/625]\teta 0:00:01 lr 0.000678\t wd 0.0100\ttime 0.0329 (0.0358)\tloss 1.6650 (1.6263)\tgrad_norm 2.8185 (2.9251)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][590/625]\teta 0:00:01 lr 0.000683\t wd 0.0100\ttime 0.0378 (0.0358)\tloss 1.5557 (1.6255)\tgrad_norm 2.8682 (2.9258)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][600/625]\teta 0:00:00 lr 0.000688\t wd 0.0100\ttime 0.0394 (0.0358)\tloss 1.6641 (1.6250)\tgrad_norm 3.0092 (2.9234)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][610/625]\teta 0:00:00 lr 0.000693\t wd 0.0100\ttime 0.0356 (0.0358)\tloss 1.6123 (1.6238)\tgrad_norm 2.3649 (2.9173)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [1/100][620/625]\teta 0:00:00 lr 0.000698\t wd 0.0100\ttime 0.0328 (0.0358)\tloss 1.2979 (1.6226)\tgrad_norm 2.4292 (2.9110)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 1 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_1.pth saving......\n",
      "./model_save/ckpt_epoch_1.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 1.4990 (1.4990)\tAcc@1 43.750 (43.750)\tAcc@5 93.750 (93.750)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 1.5723 (1.5069)\tAcc@1 35.938 (44.886)\tAcc@5 89.062 (91.193)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 1.3525 (1.4794)\tAcc@1 45.312 (45.610)\tAcc@5 96.875 (92.708)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 1.5166 (1.4897)\tAcc@1 42.188 (45.565)\tAcc@5 93.750 (92.339)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 1.4268 (1.4894)\tAcc@1 53.125 (45.351)\tAcc@5 90.625 (91.845)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 1.6250 (1.4852)\tAcc@1 50.000 (45.527)\tAcc@5 85.938 (91.850)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 1.5615 (1.4855)\tAcc@1 43.750 (45.722)\tAcc@5 92.188 (91.803)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 1.6602 (1.4863)\tAcc@1 39.062 (45.335)\tAcc@5 87.500 (91.791)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 1.4531 (1.4934)\tAcc@1 50.000 (45.216)\tAcc@5 92.188 (91.667)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 1.5420 (1.4951)\tAcc@1 46.875 (45.141)\tAcc@5 89.062 (91.741)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 1.5273 (1.5033)\tAcc@1 42.188 (44.879)\tAcc@5 90.625 (91.491)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 1.5146 (1.5009)\tAcc@1 46.875 (45.045)\tAcc@5 95.312 (91.526)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 1.6240 (1.5026)\tAcc@1 43.750 (45.093)\tAcc@5 89.062 (91.439)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 1.4316 (1.4958)\tAcc@1 51.562 (45.324)\tAcc@5 92.188 (91.543)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 1.6855 (1.5004)\tAcc@1 39.062 (45.180)\tAcc@5 84.375 (91.412)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 1.5811 (1.5002)\tAcc@1 40.625 (45.209)\tAcc@5 84.375 (91.329)\tMem 455MB\n",
      " * Acc@1 45.130 Acc@5 91.380\n",
      "Accuracy of the network on the 10000 test images: 45.1%\n",
      "Max accuracy: 45.13%\n",
      "Train: [2/100][0/625]\teta 0:00:23 lr 0.000700\t wd 0.0100\ttime 0.0374 (0.0374)\tloss 1.6182 (1.6182)\tgrad_norm 3.5161 (3.5161)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][10/625]\teta 0:00:22 lr 0.000705\t wd 0.0100\ttime 0.0360 (0.0367)\tloss 1.5059 (1.5255)\tgrad_norm 2.5397 (2.8236)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][20/625]\teta 0:00:21 lr 0.000710\t wd 0.0100\ttime 0.0333 (0.0361)\tloss 1.4092 (1.5337)\tgrad_norm 2.9133 (2.8676)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][30/625]\teta 0:00:21 lr 0.000714\t wd 0.0100\ttime 0.0365 (0.0361)\tloss 1.6777 (1.5462)\tgrad_norm 3.2615 (2.7862)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][40/625]\teta 0:00:21 lr 0.000719\t wd 0.0100\ttime 0.0331 (0.0361)\tloss 1.6455 (1.5545)\tgrad_norm 2.8484 (2.7248)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][50/625]\teta 0:00:20 lr 0.000724\t wd 0.0100\ttime 0.0333 (0.0360)\tloss 1.4531 (1.5568)\tgrad_norm 1.9452 (2.7052)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][60/625]\teta 0:00:20 lr 0.000729\t wd 0.0100\ttime 0.0335 (0.0357)\tloss 1.6445 (1.5598)\tgrad_norm 2.8495 (2.6898)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][70/625]\teta 0:00:19 lr 0.000734\t wd 0.0100\ttime 0.0342 (0.0355)\tloss 1.5947 (1.5670)\tgrad_norm 2.6825 (2.7156)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][80/625]\teta 0:00:19 lr 0.000738\t wd 0.0100\ttime 0.0330 (0.0352)\tloss 1.4326 (1.5621)\tgrad_norm 2.0124 (2.7133)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][90/625]\teta 0:00:18 lr 0.000743\t wd 0.0100\ttime 0.0350 (0.0351)\tloss 1.5654 (1.5637)\tgrad_norm 3.5119 (2.7105)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][100/625]\teta 0:00:18 lr 0.000748\t wd 0.0100\ttime 0.0336 (0.0350)\tloss 1.4590 (1.5670)\tgrad_norm 2.0822 (2.7389)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][110/625]\teta 0:00:18 lr 0.000753\t wd 0.0100\ttime 0.0406 (0.0351)\tloss 1.5039 (1.5596)\tgrad_norm 2.6630 (2.7214)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][120/625]\teta 0:00:17 lr 0.000758\t wd 0.0100\ttime 0.0328 (0.0352)\tloss 1.5195 (1.5571)\tgrad_norm 2.5340 (2.7132)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][130/625]\teta 0:00:17 lr 0.000762\t wd 0.0100\ttime 0.0338 (0.0352)\tloss 1.4883 (1.5553)\tgrad_norm 2.1443 (2.7156)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][140/625]\teta 0:00:17 lr 0.000767\t wd 0.0100\ttime 0.0396 (0.0352)\tloss 1.6875 (1.5607)\tgrad_norm 2.9202 (2.7242)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][150/625]\teta 0:00:16 lr 0.000772\t wd 0.0100\ttime 0.0327 (0.0354)\tloss 1.4932 (1.5593)\tgrad_norm 2.8396 (2.7225)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][160/625]\teta 0:00:16 lr 0.000777\t wd 0.0100\ttime 0.0396 (0.0355)\tloss 1.4062 (1.5572)\tgrad_norm 2.4234 (2.7023)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][170/625]\teta 0:00:16 lr 0.000782\t wd 0.0100\ttime 0.0353 (0.0355)\tloss 1.5850 (1.5567)\tgrad_norm 2.9056 (2.7110)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][180/625]\teta 0:00:15 lr 0.000786\t wd 0.0100\ttime 0.0355 (0.0355)\tloss 1.6572 (1.5552)\tgrad_norm 2.2621 (2.6967)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][190/625]\teta 0:00:15 lr 0.000791\t wd 0.0100\ttime 0.0390 (0.0355)\tloss 1.5439 (1.5525)\tgrad_norm 2.4198 (2.6852)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][200/625]\teta 0:00:15 lr 0.000796\t wd 0.0100\ttime 0.0386 (0.0355)\tloss 1.6738 (1.5515)\tgrad_norm 3.0005 (2.6975)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][210/625]\teta 0:00:14 lr 0.000801\t wd 0.0100\ttime 0.0324 (0.0355)\tloss 1.5850 (1.5511)\tgrad_norm 4.5420 (2.7177)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][220/625]\teta 0:00:14 lr 0.000806\t wd 0.0100\ttime 0.0327 (0.0355)\tloss 1.3564 (1.5493)\tgrad_norm 2.4155 (2.7116)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][230/625]\teta 0:00:14 lr 0.000810\t wd 0.0100\ttime 0.0406 (0.0356)\tloss 1.5381 (1.5482)\tgrad_norm 3.4816 (2.7207)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][240/625]\teta 0:00:13 lr 0.000815\t wd 0.0100\ttime 0.0383 (0.0355)\tloss 1.3848 (1.5511)\tgrad_norm 2.6111 (2.7298)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][250/625]\teta 0:00:13 lr 0.000820\t wd 0.0100\ttime 0.0354 (0.0356)\tloss 1.4521 (1.5548)\tgrad_norm 3.0504 (2.7380)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][260/625]\teta 0:00:12 lr 0.000825\t wd 0.0100\ttime 0.0325 (0.0356)\tloss 1.3486 (1.5536)\tgrad_norm 2.3565 (2.7314)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][270/625]\teta 0:00:12 lr 0.000830\t wd 0.0100\ttime 0.0383 (0.0356)\tloss 1.8477 (1.5527)\tgrad_norm 2.5067 (2.7361)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][280/625]\teta 0:00:12 lr 0.000834\t wd 0.0100\ttime 0.0323 (0.0356)\tloss 1.5596 (1.5533)\tgrad_norm 1.8616 (2.7263)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][290/625]\teta 0:00:11 lr 0.000839\t wd 0.0100\ttime 0.0353 (0.0356)\tloss 1.4795 (1.5530)\tgrad_norm 2.3972 (2.7163)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][300/625]\teta 0:00:11 lr 0.000844\t wd 0.0100\ttime 0.0354 (0.0355)\tloss 1.5518 (1.5520)\tgrad_norm 2.4850 (2.7084)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][310/625]\teta 0:00:11 lr 0.000849\t wd 0.0100\ttime 0.0399 (0.0355)\tloss 1.5605 (1.5504)\tgrad_norm 2.7408 (2.7155)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][320/625]\teta 0:00:10 lr 0.000854\t wd 0.0100\ttime 0.0325 (0.0355)\tloss 1.6250 (1.5485)\tgrad_norm 3.1235 (2.7239)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][330/625]\teta 0:00:10 lr 0.000858\t wd 0.0100\ttime 0.0362 (0.0355)\tloss 1.4961 (1.5488)\tgrad_norm 2.4335 (2.7220)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][340/625]\teta 0:00:10 lr 0.000863\t wd 0.0100\ttime 0.0396 (0.0355)\tloss 1.5635 (1.5512)\tgrad_norm 2.6451 (2.7292)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][350/625]\teta 0:00:09 lr 0.000868\t wd 0.0100\ttime 0.0358 (0.0355)\tloss 1.5088 (1.5517)\tgrad_norm 2.4755 (2.7278)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][360/625]\teta 0:00:09 lr 0.000873\t wd 0.0100\ttime 0.0359 (0.0356)\tloss 1.4355 (1.5512)\tgrad_norm 2.2145 (2.7217)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][370/625]\teta 0:00:09 lr 0.000878\t wd 0.0100\ttime 0.0326 (0.0355)\tloss 1.4785 (1.5520)\tgrad_norm 2.1830 (2.7211)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][380/625]\teta 0:00:08 lr 0.000882\t wd 0.0100\ttime 0.0357 (0.0355)\tloss 1.4502 (1.5519)\tgrad_norm 3.2712 (2.7166)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][390/625]\teta 0:00:08 lr 0.000887\t wd 0.0100\ttime 0.0389 (0.0355)\tloss 1.4072 (1.5519)\tgrad_norm 3.0598 (2.7142)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][400/625]\teta 0:00:07 lr 0.000892\t wd 0.0100\ttime 0.0364 (0.0355)\tloss 1.4941 (1.5542)\tgrad_norm 2.4746 (2.7184)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][410/625]\teta 0:00:07 lr 0.000897\t wd 0.0100\ttime 0.0353 (0.0355)\tloss 1.6143 (1.5554)\tgrad_norm 2.2913 (2.7163)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][420/625]\teta 0:00:07 lr 0.000902\t wd 0.0100\ttime 0.0323 (0.0356)\tloss 1.3613 (1.5539)\tgrad_norm 2.0483 (2.7113)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][430/625]\teta 0:00:06 lr 0.000906\t wd 0.0100\ttime 0.0351 (0.0355)\tloss 1.5684 (1.5527)\tgrad_norm 2.6313 (2.7084)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][440/625]\teta 0:00:06 lr 0.000911\t wd 0.0100\ttime 0.0357 (0.0356)\tloss 1.5391 (1.5516)\tgrad_norm 2.5430 (2.7072)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][450/625]\teta 0:00:06 lr 0.000916\t wd 0.0100\ttime 0.0358 (0.0356)\tloss 1.4893 (1.5516)\tgrad_norm 2.4281 (2.7050)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][460/625]\teta 0:00:05 lr 0.000921\t wd 0.0100\ttime 0.0395 (0.0356)\tloss 1.5850 (1.5519)\tgrad_norm 3.4370 (2.7117)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][470/625]\teta 0:00:05 lr 0.000926\t wd 0.0100\ttime 0.0357 (0.0356)\tloss 1.4580 (1.5514)\tgrad_norm 2.5942 (2.7140)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][480/625]\teta 0:00:05 lr 0.000930\t wd 0.0100\ttime 0.0333 (0.0356)\tloss 1.4297 (1.5504)\tgrad_norm 2.5917 (2.7148)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][490/625]\teta 0:00:04 lr 0.000935\t wd 0.0100\ttime 0.0328 (0.0356)\tloss 1.7705 (1.5513)\tgrad_norm 3.2695 (2.7224)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][500/625]\teta 0:00:04 lr 0.000940\t wd 0.0100\ttime 0.0382 (0.0356)\tloss 1.6016 (1.5523)\tgrad_norm 2.8000 (2.7224)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][510/625]\teta 0:00:04 lr 0.000945\t wd 0.0100\ttime 0.0378 (0.0357)\tloss 1.5713 (1.5543)\tgrad_norm 3.5256 (2.7313)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][520/625]\teta 0:00:03 lr 0.000950\t wd 0.0100\ttime 0.0363 (0.0357)\tloss 1.3750 (1.5553)\tgrad_norm 2.5233 (2.7272)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][530/625]\teta 0:00:03 lr 0.000954\t wd 0.0100\ttime 0.0357 (0.0357)\tloss 1.6533 (1.5564)\tgrad_norm 3.0568 (2.7254)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][540/625]\teta 0:00:03 lr 0.000959\t wd 0.0100\ttime 0.0329 (0.0357)\tloss 1.6670 (1.5556)\tgrad_norm 2.5838 (2.7239)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][550/625]\teta 0:00:02 lr 0.000964\t wd 0.0100\ttime 0.0388 (0.0357)\tloss 1.5771 (1.5553)\tgrad_norm 3.0542 (2.7226)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][560/625]\teta 0:00:02 lr 0.000969\t wd 0.0100\ttime 0.0400 (0.0357)\tloss 1.3965 (1.5544)\tgrad_norm 2.0608 (2.7201)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][570/625]\teta 0:00:01 lr 0.000974\t wd 0.0100\ttime 0.0329 (0.0357)\tloss 1.5312 (1.5542)\tgrad_norm 2.1409 (2.7190)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][580/625]\teta 0:00:01 lr 0.000978\t wd 0.0100\ttime 0.0333 (0.0357)\tloss 1.5938 (1.5526)\tgrad_norm 2.2481 (2.7163)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][590/625]\teta 0:00:01 lr 0.000983\t wd 0.0100\ttime 0.0392 (0.0357)\tloss 1.6826 (1.5518)\tgrad_norm 2.7883 (2.7153)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][600/625]\teta 0:00:00 lr 0.000988\t wd 0.0100\ttime 0.0351 (0.0357)\tloss 1.7432 (1.5520)\tgrad_norm 3.4238 (2.7186)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][610/625]\teta 0:00:00 lr 0.000993\t wd 0.0100\ttime 0.0388 (0.0357)\tloss 1.6641 (1.5517)\tgrad_norm 3.4249 (2.7219)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [2/100][620/625]\teta 0:00:00 lr 0.000998\t wd 0.0100\ttime 0.0362 (0.0357)\tloss 1.7051 (1.5525)\tgrad_norm 2.2447 (2.7191)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 2 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_2.pth saving......\n",
      "./model_save/ckpt_epoch_2.pth saved !!!\n",
      "Test: [0/157]\tTime 0.019 (0.019)\tLoss 1.5088 (1.5088)\tAcc@1 48.438 (48.438)\tAcc@5 90.625 (90.625)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 1.5928 (1.5459)\tAcc@1 42.188 (43.324)\tAcc@5 95.312 (91.193)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 1.5166 (1.5334)\tAcc@1 43.750 (42.857)\tAcc@5 95.312 (91.592)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 1.4512 (1.5294)\tAcc@1 51.562 (43.397)\tAcc@5 95.312 (91.532)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 1.6934 (1.5381)\tAcc@1 42.188 (43.216)\tAcc@5 87.500 (91.616)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 1.6602 (1.5306)\tAcc@1 37.500 (43.444)\tAcc@5 85.938 (91.697)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 1.5088 (1.5285)\tAcc@1 43.750 (43.622)\tAcc@5 95.312 (91.931)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 1.4170 (1.5254)\tAcc@1 50.000 (43.662)\tAcc@5 95.312 (92.011)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.016 (0.015)\tLoss 1.4961 (1.5213)\tAcc@1 51.562 (44.097)\tAcc@5 92.188 (92.091)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.021 (0.015)\tLoss 1.4648 (1.5233)\tAcc@1 48.438 (44.042)\tAcc@5 93.750 (92.016)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.016 (0.015)\tLoss 1.6514 (1.5258)\tAcc@1 34.375 (43.750)\tAcc@5 92.188 (92.033)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 1.4453 (1.5233)\tAcc@1 45.312 (43.764)\tAcc@5 96.875 (92.019)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 1.5625 (1.5218)\tAcc@1 35.938 (44.008)\tAcc@5 92.188 (91.878)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 1.4912 (1.5250)\tAcc@1 39.062 (43.857)\tAcc@5 93.750 (91.901)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.016 (0.015)\tLoss 1.4580 (1.5322)\tAcc@1 50.000 (43.418)\tAcc@5 92.188 (91.800)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.016 (0.015)\tLoss 1.7334 (1.5331)\tAcc@1 32.812 (43.481)\tAcc@5 84.375 (91.722)\tMem 455MB\n",
      " * Acc@1 43.450 Acc@5 91.730\n",
      "Accuracy of the network on the 10000 test images: 43.5%\n",
      "Max accuracy: 45.13%\n",
      "Train: [3/100][0/625]\teta 0:00:23 lr 0.001000\t wd 0.0100\ttime 0.0380 (0.0380)\tloss 1.5684 (1.5684)\tgrad_norm 2.4002 (2.4002)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [3/100][10/625]\teta 0:00:21 lr 0.001000\t wd 0.0100\ttime 0.0359 (0.0356)\tloss 1.6562 (1.5685)\tgrad_norm 2.5118 (2.6693)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [3/100][20/625]\teta 0:00:21 lr 0.001000\t wd 0.0100\ttime 0.0398 (0.0358)\tloss 1.4004 (1.5336)\tgrad_norm 2.0658 (2.5731)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [3/100][30/625]\teta 0:00:21 lr 0.001000\t wd 0.0100\ttime 0.0393 (0.0365)\tloss 1.4941 (1.5523)\tgrad_norm 2.0207 (2.6178)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [3/100][40/625]\teta 0:00:21 lr 0.001000\t wd 0.0100\ttime 0.0395 (0.0368)\tloss 1.2803 (1.5366)\tgrad_norm 2.2394 (2.5904)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [3/100][50/625]\teta 0:00:21 lr 0.001000\t wd 0.0100\ttime 0.0365 (0.0366)\tloss 1.5039 (1.5383)\tgrad_norm 3.0932 (2.6206)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [3/100][60/625]\teta 0:00:20 lr 0.001000\t wd 0.0100\ttime 0.0325 (0.0362)\tloss 1.6660 (1.5475)\tgrad_norm 2.5444 (2.6497)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [3/100][70/625]\teta 0:00:20 lr 0.001000\t wd 0.0100\ttime 0.0398 (0.0363)\tloss 1.5879 (1.5479)\tgrad_norm 2.5398 (2.6709)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [3/100][80/625]\teta 0:00:19 lr 0.001000\t wd 0.0100\ttime 0.0328 (0.0361)\tloss 1.5547 (1.5483)\tgrad_norm 3.0905 (2.6865)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [3/100][90/625]\teta 0:00:19 lr 0.001000\t wd 0.0100\ttime 0.0333 (0.0360)\tloss 1.3965 (1.5456)\tgrad_norm 2.5912 (2.6906)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [3/100][100/625]\teta 0:00:18 lr 0.001000\t wd 0.0100\ttime 0.0363 (0.0361)\tloss 1.4727 (1.5396)\tgrad_norm 2.2115 (2.6692)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [3/100][110/625]\teta 0:00:18 lr 0.001000\t wd 0.0100\ttime 0.0392 (0.0361)\tloss 1.6357 (1.5332)\tgrad_norm 2.2219 (2.6627)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [3/100][120/625]\teta 0:00:18 lr 0.001000\t wd 0.0100\ttime 0.0335 (0.0361)\tloss 1.3408 (1.5269)\tgrad_norm 2.0112 (2.6727)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [3/100][130/625]\teta 0:00:17 lr 0.001000\t wd 0.0100\ttime 0.0327 (0.0359)\tloss 1.3887 (1.5267)\tgrad_norm 2.1344 (nan)\tloss_scale 32768.0000 (33018.1374)\tmem 455MB\n",
      "Train: [3/100][140/625]\teta 0:00:17 lr 0.001000\t wd 0.0100\ttime 0.0389 (0.0358)\tloss 1.5918 (1.5281)\tgrad_norm 2.9605 (nan)\tloss_scale 32768.0000 (33000.3972)\tmem 455MB\n",
      "Train: [3/100][150/625]\teta 0:00:17 lr 0.001000\t wd 0.0100\ttime 0.0325 (0.0359)\tloss 1.4854 (1.5273)\tgrad_norm 3.0049 (nan)\tloss_scale 32768.0000 (32985.0066)\tmem 455MB\n",
      "Train: [3/100][160/625]\teta 0:00:16 lr 0.001000\t wd 0.0100\ttime 0.0365 (0.0359)\tloss 1.7227 (1.5317)\tgrad_norm 2.5478 (nan)\tloss_scale 32768.0000 (32971.5280)\tmem 455MB\n",
      "Train: [3/100][170/625]\teta 0:00:16 lr 0.001000\t wd 0.0100\ttime 0.0330 (0.0359)\tloss 1.4707 (1.5319)\tgrad_norm 2.8550 (nan)\tloss_scale 32768.0000 (32959.6257)\tmem 455MB\n",
      "Train: [3/100][180/625]\teta 0:00:15 lr 0.001000\t wd 0.0100\ttime 0.0358 (0.0359)\tloss 1.6494 (1.5310)\tgrad_norm 2.5056 (nan)\tloss_scale 32768.0000 (32949.0387)\tmem 455MB\n",
      "Train: [3/100][190/625]\teta 0:00:15 lr 0.001000\t wd 0.0100\ttime 0.0332 (0.0359)\tloss 1.3398 (1.5320)\tgrad_norm 4.1066 (nan)\tloss_scale 32768.0000 (32939.5602)\tmem 455MB\n",
      "Train: [3/100][200/625]\teta 0:00:15 lr 0.001000\t wd 0.0100\ttime 0.0397 (0.0359)\tloss 1.4883 (1.5370)\tgrad_norm 2.1472 (nan)\tloss_scale 32768.0000 (32931.0249)\tmem 455MB\n",
      "Train: [3/100][210/625]\teta 0:00:14 lr 0.001000\t wd 0.0100\ttime 0.0401 (0.0359)\tloss 1.4922 (1.5394)\tgrad_norm 2.3269 (nan)\tloss_scale 32768.0000 (32923.2986)\tmem 455MB\n",
      "Train: [3/100][220/625]\teta 0:00:14 lr 0.001000\t wd 0.0100\ttime 0.0325 (0.0359)\tloss 1.3213 (1.5384)\tgrad_norm 2.2106 (nan)\tloss_scale 32768.0000 (32916.2715)\tmem 455MB\n",
      "Train: [3/100][230/625]\teta 0:00:14 lr 0.001000\t wd 0.0100\ttime 0.0333 (0.0358)\tloss 1.6523 (1.5411)\tgrad_norm 2.3473 (nan)\tloss_scale 32768.0000 (32909.8528)\tmem 455MB\n",
      "Train: [3/100][240/625]\teta 0:00:13 lr 0.001000\t wd 0.0100\ttime 0.0366 (0.0358)\tloss 1.4307 (1.5404)\tgrad_norm 2.3102 (nan)\tloss_scale 32768.0000 (32903.9668)\tmem 455MB\n",
      "Train: [3/100][250/625]\teta 0:00:13 lr 0.001000\t wd 0.0100\ttime 0.0361 (0.0358)\tloss 1.5098 (1.5373)\tgrad_norm 2.7756 (nan)\tloss_scale 32768.0000 (32898.5498)\tmem 455MB\n",
      "Train: [3/100][260/625]\teta 0:00:13 lr 0.001000\t wd 0.0100\ttime 0.0329 (0.0358)\tloss 1.4385 (1.5375)\tgrad_norm 2.5532 (nan)\tloss_scale 32768.0000 (32893.5479)\tmem 455MB\n",
      "Train: [3/100][270/625]\teta 0:00:12 lr 0.001000\t wd 0.0100\ttime 0.0358 (0.0358)\tloss 1.6934 (1.5376)\tgrad_norm 2.9508 (nan)\tloss_scale 32768.0000 (32888.9151)\tmem 455MB\n",
      "Train: [3/100][280/625]\teta 0:00:12 lr 0.001000\t wd 0.0100\ttime 0.0403 (0.0358)\tloss 1.5137 (1.5361)\tgrad_norm 2.3737 (nan)\tloss_scale 32768.0000 (32884.6121)\tmem 455MB\n",
      "Train: [3/100][290/625]\teta 0:00:11 lr 0.001000\t wd 0.0100\ttime 0.0358 (0.0358)\tloss 1.4824 (1.5363)\tgrad_norm 3.3160 (nan)\tloss_scale 32768.0000 (32880.6048)\tmem 455MB\n",
      "Train: [3/100][300/625]\teta 0:00:11 lr 0.001000\t wd 0.0100\ttime 0.0326 (0.0357)\tloss 1.5898 (1.5400)\tgrad_norm 2.1255 (nan)\tloss_scale 32768.0000 (32876.8638)\tmem 455MB\n",
      "Train: [3/100][310/625]\teta 0:00:11 lr 0.001000\t wd 0.0100\ttime 0.0328 (0.0357)\tloss 1.6494 (1.5372)\tgrad_norm 2.8241 (nan)\tloss_scale 32768.0000 (32873.3633)\tmem 455MB\n",
      "Train: [3/100][320/625]\teta 0:00:10 lr 0.001000\t wd 0.0100\ttime 0.0351 (0.0356)\tloss 1.4775 (1.5381)\tgrad_norm 2.5658 (nan)\tloss_scale 32768.0000 (32870.0810)\tmem 455MB\n",
      "Train: [3/100][330/625]\teta 0:00:10 lr 0.001000\t wd 0.0100\ttime 0.0325 (0.0356)\tloss 1.4795 (1.5373)\tgrad_norm 2.6983 (nan)\tloss_scale 32768.0000 (32866.9970)\tmem 455MB\n",
      "Train: [3/100][340/625]\teta 0:00:10 lr 0.001000\t wd 0.0100\ttime 0.0361 (0.0355)\tloss 1.4688 (1.5371)\tgrad_norm 2.3426 (nan)\tloss_scale 32768.0000 (32864.0938)\tmem 455MB\n",
      "Train: [3/100][350/625]\teta 0:00:09 lr 0.001000\t wd 0.0100\ttime 0.0324 (0.0354)\tloss 1.7051 (1.5374)\tgrad_norm 2.8413 (nan)\tloss_scale 32768.0000 (32861.3561)\tmem 455MB\n",
      "Train: [3/100][360/625]\teta 0:00:09 lr 0.001000\t wd 0.0100\ttime 0.0354 (0.0354)\tloss 1.6367 (1.5349)\tgrad_norm 2.1185 (nan)\tloss_scale 32768.0000 (32858.7701)\tmem 455MB\n",
      "Train: [3/100][370/625]\teta 0:00:09 lr 0.001000\t wd 0.0100\ttime 0.0378 (0.0354)\tloss 1.5303 (1.5366)\tgrad_norm 3.2441 (nan)\tloss_scale 32768.0000 (32856.3235)\tmem 455MB\n",
      "Train: [3/100][380/625]\teta 0:00:08 lr 0.001000\t wd 0.0100\ttime 0.0389 (0.0354)\tloss 1.3896 (1.5373)\tgrad_norm 2.9171 (nan)\tloss_scale 32768.0000 (32854.0052)\tmem 455MB\n",
      "Train: [3/100][390/625]\teta 0:00:08 lr 0.001000\t wd 0.0100\ttime 0.0388 (0.0354)\tloss 1.5713 (1.5365)\tgrad_norm 3.3209 (nan)\tloss_scale 32768.0000 (32851.8056)\tmem 455MB\n",
      "Train: [3/100][400/625]\teta 0:00:07 lr 0.001000\t wd 0.0100\ttime 0.0389 (0.0354)\tloss 1.6895 (1.5369)\tgrad_norm 3.0802 (nan)\tloss_scale 32768.0000 (32849.7157)\tmem 455MB\n",
      "Train: [3/100][410/625]\teta 0:00:07 lr 0.001000\t wd 0.0100\ttime 0.0325 (0.0354)\tloss 1.5605 (1.5363)\tgrad_norm 2.8652 (nan)\tloss_scale 32768.0000 (32847.7275)\tmem 455MB\n",
      "Train: [3/100][420/625]\teta 0:00:07 lr 0.001000\t wd 0.0100\ttime 0.0329 (0.0354)\tloss 1.3311 (1.5346)\tgrad_norm 2.6416 (nan)\tloss_scale 32768.0000 (32845.8337)\tmem 455MB\n",
      "Train: [3/100][430/625]\teta 0:00:06 lr 0.001000\t wd 0.0100\ttime 0.0329 (0.0354)\tloss 1.5957 (1.5342)\tgrad_norm 3.1577 (nan)\tloss_scale 32768.0000 (32844.0278)\tmem 455MB\n",
      "Train: [3/100][440/625]\teta 0:00:06 lr 0.001000\t wd 0.0100\ttime 0.0410 (0.0354)\tloss 1.4863 (1.5350)\tgrad_norm 3.6441 (nan)\tloss_scale 32768.0000 (32842.3039)\tmem 455MB\n",
      "Train: [3/100][450/625]\teta 0:00:06 lr 0.001000\t wd 0.0100\ttime 0.0324 (0.0354)\tloss 1.5674 (1.5356)\tgrad_norm 2.7524 (nan)\tloss_scale 32768.0000 (32840.6563)\tmem 455MB\n",
      "Train: [3/100][460/625]\teta 0:00:05 lr 0.001000\t wd 0.0100\ttime 0.0346 (0.0353)\tloss 1.8213 (1.5359)\tgrad_norm 3.3281 (nan)\tloss_scale 32768.0000 (32839.0803)\tmem 455MB\n",
      "Train: [3/100][470/625]\teta 0:00:05 lr 0.001000\t wd 0.0100\ttime 0.0335 (0.0353)\tloss 1.6299 (1.5367)\tgrad_norm 3.1266 (nan)\tloss_scale 32768.0000 (32837.5711)\tmem 455MB\n",
      "Train: [3/100][480/625]\teta 0:00:05 lr 0.001000\t wd 0.0100\ttime 0.0329 (0.0353)\tloss 1.3096 (1.5361)\tgrad_norm 2.2782 (nan)\tloss_scale 32768.0000 (32836.1247)\tmem 455MB\n",
      "Train: [3/100][490/625]\teta 0:00:04 lr 0.001000\t wd 0.0100\ttime 0.0325 (0.0353)\tloss 1.4785 (1.5343)\tgrad_norm 2.4024 (nan)\tloss_scale 32768.0000 (32834.7373)\tmem 455MB\n",
      "Train: [3/100][500/625]\teta 0:00:04 lr 0.001000\t wd 0.0100\ttime 0.0326 (0.0352)\tloss 1.5371 (1.5336)\tgrad_norm 2.4197 (nan)\tloss_scale 32768.0000 (32833.4052)\tmem 455MB\n",
      "Train: [3/100][510/625]\teta 0:00:04 lr 0.001000\t wd 0.0100\ttime 0.0372 (0.0352)\tloss 1.3008 (1.5344)\tgrad_norm 2.5260 (nan)\tloss_scale 32768.0000 (32832.1252)\tmem 455MB\n",
      "Train: [3/100][520/625]\teta 0:00:03 lr 0.001000\t wd 0.0100\ttime 0.0351 (0.0352)\tloss 1.7422 (1.5347)\tgrad_norm 3.3312 (nan)\tloss_scale 32768.0000 (32830.8944)\tmem 455MB\n",
      "Train: [3/100][530/625]\teta 0:00:03 lr 0.001000\t wd 0.0100\ttime 0.0333 (0.0352)\tloss 1.5664 (1.5348)\tgrad_norm 2.8134 (nan)\tloss_scale 32768.0000 (32829.7100)\tmem 455MB\n",
      "Train: [3/100][540/625]\teta 0:00:02 lr 0.001000\t wd 0.0100\ttime 0.0389 (0.0352)\tloss 1.3848 (1.5331)\tgrad_norm 1.8793 (nan)\tloss_scale 32768.0000 (32828.5693)\tmem 455MB\n",
      "Train: [3/100][550/625]\teta 0:00:02 lr 0.001000\t wd 0.0100\ttime 0.0359 (0.0353)\tloss 1.2793 (1.5311)\tgrad_norm 2.0790 (nan)\tloss_scale 32768.0000 (32827.4701)\tmem 455MB\n",
      "Train: [3/100][560/625]\teta 0:00:02 lr 0.001000\t wd 0.0100\ttime 0.0396 (0.0353)\tloss 1.4688 (1.5298)\tgrad_norm 2.7187 (nan)\tloss_scale 32768.0000 (32826.4100)\tmem 455MB\n",
      "Train: [3/100][570/625]\teta 0:00:01 lr 0.001000\t wd 0.0100\ttime 0.0325 (0.0353)\tloss 1.3535 (1.5292)\tgrad_norm 3.1972 (nan)\tloss_scale 32768.0000 (32825.3870)\tmem 455MB\n",
      "Train: [3/100][580/625]\teta 0:00:01 lr 0.001000\t wd 0.0100\ttime 0.0372 (0.0353)\tloss 1.5889 (1.5275)\tgrad_norm 2.8670 (nan)\tloss_scale 32768.0000 (32824.3993)\tmem 455MB\n",
      "Train: [3/100][590/625]\teta 0:00:01 lr 0.001000\t wd 0.0100\ttime 0.0326 (0.0352)\tloss 1.5605 (1.5265)\tgrad_norm 2.3021 (nan)\tloss_scale 32768.0000 (32823.4450)\tmem 455MB\n",
      "Train: [3/100][600/625]\teta 0:00:00 lr 0.001000\t wd 0.0100\ttime 0.0324 (0.0352)\tloss 1.5713 (1.5264)\tgrad_norm 2.8366 (nan)\tloss_scale 32768.0000 (32822.5225)\tmem 455MB\n",
      "Train: [3/100][610/625]\teta 0:00:00 lr 0.001000\t wd 0.0100\ttime 0.0333 (0.0352)\tloss 1.4941 (1.5265)\tgrad_norm 2.7530 (nan)\tloss_scale 32768.0000 (32821.6301)\tmem 455MB\n",
      "Train: [3/100][620/625]\teta 0:00:00 lr 0.001000\t wd 0.0100\ttime 0.0326 (0.0352)\tloss 1.4688 (1.5267)\tgrad_norm 2.4908 (nan)\tloss_scale 32768.0000 (32820.7665)\tmem 455MB\n",
      "EPOCH 3 training takes 0:00:21\n",
      "./model_save/ckpt_epoch_3.pth saving......\n",
      "./model_save/ckpt_epoch_3.pth saved !!!\n",
      "Test: [0/157]\tTime 0.018 (0.018)\tLoss 1.4775 (1.4775)\tAcc@1 46.875 (46.875)\tAcc@5 90.625 (90.625)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 1.3398 (1.4729)\tAcc@1 50.000 (45.028)\tAcc@5 92.188 (91.193)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 1.4678 (1.4602)\tAcc@1 46.875 (45.238)\tAcc@5 93.750 (92.262)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 1.4658 (1.4615)\tAcc@1 45.312 (45.716)\tAcc@5 89.062 (91.885)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 1.3252 (1.4601)\tAcc@1 46.875 (45.579)\tAcc@5 92.188 (91.921)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 1.4111 (1.4582)\tAcc@1 40.625 (45.343)\tAcc@5 95.312 (92.157)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 1.4111 (1.4533)\tAcc@1 48.438 (45.850)\tAcc@5 92.188 (92.213)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 1.4062 (1.4533)\tAcc@1 43.750 (46.325)\tAcc@5 92.188 (91.945)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 1.6943 (1.4547)\tAcc@1 31.250 (46.026)\tAcc@5 89.062 (91.975)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 1.5732 (1.4568)\tAcc@1 40.625 (45.776)\tAcc@5 93.750 (92.050)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 1.3457 (1.4535)\tAcc@1 46.875 (46.071)\tAcc@5 96.875 (92.033)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 1.7295 (1.4575)\tAcc@1 34.375 (45.876)\tAcc@5 85.938 (91.948)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 1.2910 (1.4559)\tAcc@1 56.250 (45.842)\tAcc@5 95.312 (92.071)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 1.5400 (1.4597)\tAcc@1 40.625 (45.682)\tAcc@5 89.062 (91.985)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 1.6416 (1.4620)\tAcc@1 40.625 (45.734)\tAcc@5 85.938 (91.877)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 1.6602 (1.4672)\tAcc@1 35.938 (45.488)\tAcc@5 89.062 (91.856)\tMem 455MB\n",
      " * Acc@1 45.550 Acc@5 91.920\n",
      "Accuracy of the network on the 10000 test images: 45.5%\n",
      "Max accuracy: 45.55%\n",
      "Train: [4/100][0/625]\teta 0:00:21 lr 0.001000\t wd 0.0100\ttime 0.0343 (0.0343)\tloss 1.5498 (1.5498)\tgrad_norm 2.4560 (2.4560)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][10/625]\teta 0:00:20 lr 0.001000\t wd 0.0100\ttime 0.0328 (0.0332)\tloss 1.5469 (1.5467)\tgrad_norm 3.7618 (2.6885)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][20/625]\teta 0:00:20 lr 0.001000\t wd 0.0100\ttime 0.0329 (0.0335)\tloss 1.2969 (1.5010)\tgrad_norm 2.3700 (2.7359)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][30/625]\teta 0:00:20 lr 0.001000\t wd 0.0100\ttime 0.0369 (0.0338)\tloss 1.5771 (1.5385)\tgrad_norm 2.3408 (2.6905)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][40/625]\teta 0:00:19 lr 0.001000\t wd 0.0100\ttime 0.0328 (0.0338)\tloss 1.3828 (1.5241)\tgrad_norm 2.2610 (2.6763)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][50/625]\teta 0:00:19 lr 0.001000\t wd 0.0100\ttime 0.0368 (0.0340)\tloss 1.4922 (1.5141)\tgrad_norm 2.8573 (2.6655)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][60/625]\teta 0:00:19 lr 0.001000\t wd 0.0100\ttime 0.0326 (0.0343)\tloss 1.1562 (1.4893)\tgrad_norm 1.8078 (2.6171)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][70/625]\teta 0:00:19 lr 0.001000\t wd 0.0100\ttime 0.0342 (0.0346)\tloss 1.4639 (1.4905)\tgrad_norm 2.3486 (2.6160)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][80/625]\teta 0:00:18 lr 0.001000\t wd 0.0100\ttime 0.0360 (0.0347)\tloss 1.3193 (1.4863)\tgrad_norm 1.9574 (2.5792)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][90/625]\teta 0:00:18 lr 0.001000\t wd 0.0100\ttime 0.0361 (0.0348)\tloss 1.4570 (1.4848)\tgrad_norm 2.4935 (2.5565)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][100/625]\teta 0:00:18 lr 0.001000\t wd 0.0100\ttime 0.0397 (0.0348)\tloss 1.5693 (1.4754)\tgrad_norm 2.9502 (2.5453)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][110/625]\teta 0:00:18 lr 0.001000\t wd 0.0100\ttime 0.0394 (0.0350)\tloss 1.3330 (1.4696)\tgrad_norm 2.4909 (2.5447)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][120/625]\teta 0:00:17 lr 0.001000\t wd 0.0100\ttime 0.0328 (0.0350)\tloss 1.7559 (1.4763)\tgrad_norm 3.0874 (2.5897)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][130/625]\teta 0:00:17 lr 0.001000\t wd 0.0100\ttime 0.0342 (0.0350)\tloss 1.5508 (1.4743)\tgrad_norm 3.5578 (2.5969)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][140/625]\teta 0:00:16 lr 0.001000\t wd 0.0100\ttime 0.0364 (0.0350)\tloss 1.3799 (1.4708)\tgrad_norm 2.5894 (2.6007)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][150/625]\teta 0:00:16 lr 0.001000\t wd 0.0100\ttime 0.0367 (0.0350)\tloss 1.3164 (1.4674)\tgrad_norm 2.1537 (2.5966)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][160/625]\teta 0:00:16 lr 0.001000\t wd 0.0100\ttime 0.0329 (0.0350)\tloss 1.3955 (1.4639)\tgrad_norm 2.5792 (2.6055)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][170/625]\teta 0:00:15 lr 0.001000\t wd 0.0100\ttime 0.0352 (0.0350)\tloss 1.3740 (1.4647)\tgrad_norm 2.9619 (2.6192)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][180/625]\teta 0:00:15 lr 0.001000\t wd 0.0100\ttime 0.0329 (0.0350)\tloss 1.6465 (1.4665)\tgrad_norm 2.1825 (2.6305)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][190/625]\teta 0:00:15 lr 0.001000\t wd 0.0100\ttime 0.0411 (0.0351)\tloss 1.3555 (1.4677)\tgrad_norm 3.2276 (2.6861)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][200/625]\teta 0:00:14 lr 0.001000\t wd 0.0100\ttime 0.0359 (0.0352)\tloss 1.4619 (1.4683)\tgrad_norm 2.9121 (2.6925)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][210/625]\teta 0:00:14 lr 0.001000\t wd 0.0100\ttime 0.0368 (0.0352)\tloss 1.4570 (1.4702)\tgrad_norm 2.1828 (2.6958)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][220/625]\teta 0:00:14 lr 0.001000\t wd 0.0100\ttime 0.0358 (0.0353)\tloss 1.3164 (1.4691)\tgrad_norm 2.0448 (2.6852)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][230/625]\teta 0:00:13 lr 0.001000\t wd 0.0100\ttime 0.0330 (0.0352)\tloss 1.3359 (1.4689)\tgrad_norm 2.3916 (2.6777)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][240/625]\teta 0:00:13 lr 0.001000\t wd 0.0100\ttime 0.0348 (0.0352)\tloss 1.5430 (1.4713)\tgrad_norm 3.0510 (2.6691)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][250/625]\teta 0:00:13 lr 0.000999\t wd 0.0100\ttime 0.0349 (0.0352)\tloss 1.4189 (1.4711)\tgrad_norm 2.8409 (2.6692)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][260/625]\teta 0:00:12 lr 0.000999\t wd 0.0100\ttime 0.0328 (0.0352)\tloss 1.5518 (1.4736)\tgrad_norm 3.0179 (2.6562)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][270/625]\teta 0:00:12 lr 0.000999\t wd 0.0100\ttime 0.0328 (0.0352)\tloss 1.4209 (1.4726)\tgrad_norm 3.3438 (2.6554)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][280/625]\teta 0:00:12 lr 0.000999\t wd 0.0100\ttime 0.0363 (0.0352)\tloss 1.3203 (1.4724)\tgrad_norm 2.0306 (2.6613)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][290/625]\teta 0:00:11 lr 0.000999\t wd 0.0100\ttime 0.0355 (0.0352)\tloss 1.5264 (1.4712)\tgrad_norm 2.4243 (2.6652)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][300/625]\teta 0:00:11 lr 0.000999\t wd 0.0100\ttime 0.0325 (0.0351)\tloss 1.4443 (1.4688)\tgrad_norm 3.1494 (2.6614)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][310/625]\teta 0:00:11 lr 0.000999\t wd 0.0100\ttime 0.0349 (0.0352)\tloss 1.6299 (1.4665)\tgrad_norm 4.2614 (2.6804)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][320/625]\teta 0:00:10 lr 0.000999\t wd 0.0100\ttime 0.0325 (0.0352)\tloss 1.5000 (1.4687)\tgrad_norm 3.1031 (2.6931)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][330/625]\teta 0:00:10 lr 0.000999\t wd 0.0100\ttime 0.0332 (0.0352)\tloss 1.5410 (1.4710)\tgrad_norm 2.2458 (2.7058)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][340/625]\teta 0:00:10 lr 0.000999\t wd 0.0100\ttime 0.0324 (0.0352)\tloss 1.4365 (1.4704)\tgrad_norm 2.6790 (2.6990)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][350/625]\teta 0:00:09 lr 0.000999\t wd 0.0100\ttime 0.0387 (0.0352)\tloss 1.4268 (1.4711)\tgrad_norm 2.2812 (2.6980)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][360/625]\teta 0:00:09 lr 0.000999\t wd 0.0100\ttime 0.0332 (0.0352)\tloss 1.7637 (1.4717)\tgrad_norm 3.3513 (2.6925)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][370/625]\teta 0:00:08 lr 0.000999\t wd 0.0100\ttime 0.0326 (0.0353)\tloss 1.6445 (1.4704)\tgrad_norm 2.4424 (2.6850)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][380/625]\teta 0:00:08 lr 0.000999\t wd 0.0100\ttime 0.0360 (0.0353)\tloss 1.3340 (1.4691)\tgrad_norm 1.9977 (2.6859)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][390/625]\teta 0:00:08 lr 0.000999\t wd 0.0100\ttime 0.0363 (0.0353)\tloss 1.3506 (1.4715)\tgrad_norm 2.4063 (2.6853)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][400/625]\teta 0:00:07 lr 0.000999\t wd 0.0100\ttime 0.0397 (0.0354)\tloss 1.6250 (1.4705)\tgrad_norm 2.8411 (2.6860)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][410/625]\teta 0:00:07 lr 0.000999\t wd 0.0100\ttime 0.0400 (0.0354)\tloss 1.6787 (1.4730)\tgrad_norm 2.4594 (2.6870)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][420/625]\teta 0:00:07 lr 0.000999\t wd 0.0100\ttime 0.0369 (0.0355)\tloss 1.5342 (1.4734)\tgrad_norm 2.4041 (2.6850)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][430/625]\teta 0:00:06 lr 0.000999\t wd 0.0100\ttime 0.0356 (0.0355)\tloss 1.4258 (1.4737)\tgrad_norm 2.6803 (2.6876)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][440/625]\teta 0:00:06 lr 0.000999\t wd 0.0100\ttime 0.0398 (0.0355)\tloss 1.4844 (1.4717)\tgrad_norm 2.7575 (2.6915)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][450/625]\teta 0:00:06 lr 0.000999\t wd 0.0100\ttime 0.0361 (0.0355)\tloss 1.7969 (1.4737)\tgrad_norm 4.3067 (2.7033)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][460/625]\teta 0:00:05 lr 0.000999\t wd 0.0100\ttime 0.0331 (0.0355)\tloss 1.5918 (1.4740)\tgrad_norm 3.3894 (2.7058)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][470/625]\teta 0:00:05 lr 0.000999\t wd 0.0100\ttime 0.0336 (0.0355)\tloss 1.3506 (1.4745)\tgrad_norm 2.1257 (2.7033)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][480/625]\teta 0:00:05 lr 0.000999\t wd 0.0100\ttime 0.0325 (0.0355)\tloss 1.5293 (1.4760)\tgrad_norm 2.7294 (2.7194)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][490/625]\teta 0:00:04 lr 0.000999\t wd 0.0100\ttime 0.0335 (0.0355)\tloss 1.7246 (1.4760)\tgrad_norm 2.9155 (2.7149)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][500/625]\teta 0:00:04 lr 0.000999\t wd 0.0100\ttime 0.0325 (0.0355)\tloss 1.2480 (1.4748)\tgrad_norm 2.5110 (2.7122)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][510/625]\teta 0:00:04 lr 0.000999\t wd 0.0100\ttime 0.0334 (0.0355)\tloss 1.2988 (1.4751)\tgrad_norm 2.6214 (2.7139)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][520/625]\teta 0:00:03 lr 0.000999\t wd 0.0100\ttime 0.0326 (0.0355)\tloss 1.3799 (1.4744)\tgrad_norm 2.5214 (2.7176)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][530/625]\teta 0:00:03 lr 0.000999\t wd 0.0100\ttime 0.0365 (0.0355)\tloss 1.4775 (1.4754)\tgrad_norm 2.8146 (2.7191)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][540/625]\teta 0:00:03 lr 0.000999\t wd 0.0100\ttime 0.0356 (0.0356)\tloss 1.6582 (1.4756)\tgrad_norm 2.6856 (2.7160)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][550/625]\teta 0:00:02 lr 0.000999\t wd 0.0100\ttime 0.0326 (0.0355)\tloss 1.4668 (1.4741)\tgrad_norm 3.1791 (2.7135)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][560/625]\teta 0:00:02 lr 0.000999\t wd 0.0100\ttime 0.0370 (0.0355)\tloss 1.3496 (1.4741)\tgrad_norm 2.9390 (2.7150)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][570/625]\teta 0:00:01 lr 0.000999\t wd 0.0100\ttime 0.0363 (0.0356)\tloss 1.3408 (1.4728)\tgrad_norm 2.7982 (2.7238)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][580/625]\teta 0:00:01 lr 0.000999\t wd 0.0100\ttime 0.0328 (0.0355)\tloss 1.7275 (1.4744)\tgrad_norm 3.6501 (2.7314)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][590/625]\teta 0:00:01 lr 0.000999\t wd 0.0100\ttime 0.0326 (0.0355)\tloss 1.3330 (1.4726)\tgrad_norm 3.2521 (2.7348)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][600/625]\teta 0:00:00 lr 0.000999\t wd 0.0100\ttime 0.0329 (0.0355)\tloss 1.5713 (1.4717)\tgrad_norm 6.5590 (2.7471)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][610/625]\teta 0:00:00 lr 0.000999\t wd 0.0100\ttime 0.0327 (0.0355)\tloss 1.4570 (1.4706)\tgrad_norm 2.3130 (2.7508)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [4/100][620/625]\teta 0:00:00 lr 0.000999\t wd 0.0100\ttime 0.0362 (0.0355)\tloss 1.3506 (1.4713)\tgrad_norm 2.7390 (2.7569)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 4 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_4.pth saving......\n",
      "./model_save/ckpt_epoch_4.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 1.3887 (1.3887)\tAcc@1 40.625 (40.625)\tAcc@5 93.750 (93.750)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 1.7090 (1.5168)\tAcc@1 39.062 (44.602)\tAcc@5 90.625 (90.341)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 1.5039 (1.4883)\tAcc@1 46.875 (46.280)\tAcc@5 92.188 (90.997)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 1.4111 (1.4870)\tAcc@1 64.062 (45.968)\tAcc@5 89.062 (91.280)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.016 (0.015)\tLoss 1.5381 (1.4988)\tAcc@1 40.625 (45.579)\tAcc@5 92.188 (91.120)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.016 (0.015)\tLoss 1.4004 (1.4982)\tAcc@1 40.625 (45.588)\tAcc@5 92.188 (91.330)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.016 (0.015)\tLoss 1.4346 (1.5047)\tAcc@1 54.688 (45.415)\tAcc@5 89.062 (91.240)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 1.2949 (1.4993)\tAcc@1 53.125 (45.312)\tAcc@5 93.750 (91.351)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 1.3867 (1.4977)\tAcc@1 43.750 (45.274)\tAcc@5 93.750 (91.416)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 1.6436 (1.5049)\tAcc@1 43.750 (45.089)\tAcc@5 89.062 (91.277)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 1.4785 (1.5110)\tAcc@1 43.750 (44.817)\tAcc@5 95.312 (91.182)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 1.6689 (1.5079)\tAcc@1 39.062 (44.961)\tAcc@5 87.500 (91.343)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 1.4443 (1.5140)\tAcc@1 43.750 (44.770)\tAcc@5 90.625 (91.322)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 1.6309 (1.5143)\tAcc@1 40.625 (44.931)\tAcc@5 89.062 (91.245)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 1.5273 (1.5172)\tAcc@1 37.500 (44.504)\tAcc@5 89.062 (91.257)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 1.4854 (1.5142)\tAcc@1 43.750 (44.661)\tAcc@5 90.625 (91.298)\tMem 455MB\n",
      " * Acc@1 44.620 Acc@5 91.310\n",
      "Accuracy of the network on the 10000 test images: 44.6%\n",
      "Max accuracy: 45.55%\n",
      "Train: [5/100][0/625]\teta 0:00:21 lr 0.000999\t wd 0.0100\ttime 0.0349 (0.0349)\tloss 1.5664 (1.5664)\tgrad_norm 3.1337 (3.1337)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][10/625]\teta 0:00:20 lr 0.000999\t wd 0.0100\ttime 0.0330 (0.0337)\tloss 1.5762 (1.5469)\tgrad_norm 3.1379 (2.9594)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][20/625]\teta 0:00:20 lr 0.000999\t wd 0.0100\ttime 0.0328 (0.0334)\tloss 1.7158 (1.5317)\tgrad_norm 3.0183 (2.9969)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][30/625]\teta 0:00:19 lr 0.000999\t wd 0.0100\ttime 0.0329 (0.0333)\tloss 1.5703 (1.5295)\tgrad_norm 2.4863 (3.0244)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][40/625]\teta 0:00:19 lr 0.000999\t wd 0.0100\ttime 0.0331 (0.0333)\tloss 1.4219 (1.5305)\tgrad_norm 4.3384 (3.1253)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][50/625]\teta 0:00:19 lr 0.000999\t wd 0.0100\ttime 0.0333 (0.0333)\tloss 1.4756 (1.5309)\tgrad_norm 2.8223 (3.1311)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][60/625]\teta 0:00:18 lr 0.000999\t wd 0.0100\ttime 0.0327 (0.0333)\tloss 1.4814 (1.5125)\tgrad_norm 2.2919 (3.1219)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][70/625]\teta 0:00:18 lr 0.000999\t wd 0.0100\ttime 0.0332 (0.0332)\tloss 1.7236 (1.5020)\tgrad_norm 4.3177 (3.1736)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][80/625]\teta 0:00:18 lr 0.000999\t wd 0.0100\ttime 0.0355 (0.0334)\tloss 1.5693 (1.4934)\tgrad_norm 2.8777 (3.1477)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][90/625]\teta 0:00:18 lr 0.000999\t wd 0.0100\ttime 0.0386 (0.0337)\tloss 1.6211 (1.4960)\tgrad_norm 2.7944 (3.1331)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][100/625]\teta 0:00:17 lr 0.000999\t wd 0.0100\ttime 0.0330 (0.0341)\tloss 1.5723 (1.4969)\tgrad_norm 3.0614 (3.1139)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][110/625]\teta 0:00:17 lr 0.000999\t wd 0.0100\ttime 0.0355 (0.0342)\tloss 1.3447 (1.4951)\tgrad_norm 3.1315 (3.1297)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][120/625]\teta 0:00:17 lr 0.000999\t wd 0.0100\ttime 0.0334 (0.0343)\tloss 1.4268 (1.4964)\tgrad_norm 3.1625 (3.1091)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][130/625]\teta 0:00:17 lr 0.000999\t wd 0.0100\ttime 0.0328 (0.0344)\tloss 1.5381 (1.4971)\tgrad_norm 3.1886 (3.1108)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][140/625]\teta 0:00:16 lr 0.000999\t wd 0.0100\ttime 0.0370 (0.0344)\tloss 1.5166 (1.4995)\tgrad_norm 3.0416 (3.0841)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][150/625]\teta 0:00:16 lr 0.000999\t wd 0.0100\ttime 0.0324 (0.0344)\tloss 1.5547 (1.4951)\tgrad_norm 3.0763 (3.0657)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][160/625]\teta 0:00:15 lr 0.000999\t wd 0.0100\ttime 0.0327 (0.0344)\tloss 1.6787 (1.4934)\tgrad_norm 3.6692 (3.0735)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][170/625]\teta 0:00:15 lr 0.000999\t wd 0.0100\ttime 0.0337 (0.0344)\tloss 1.5430 (1.4917)\tgrad_norm 3.1678 (3.0829)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][180/625]\teta 0:00:15 lr 0.000999\t wd 0.0100\ttime 0.0329 (0.0343)\tloss 1.3828 (1.4922)\tgrad_norm 3.9737 (3.0811)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][190/625]\teta 0:00:14 lr 0.000999\t wd 0.0100\ttime 0.0376 (0.0344)\tloss 1.4756 (1.4934)\tgrad_norm 4.7431 (3.0765)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][200/625]\teta 0:00:14 lr 0.000999\t wd 0.0100\ttime 0.0383 (0.0345)\tloss 1.4365 (1.4923)\tgrad_norm 2.9104 (3.0866)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][210/625]\teta 0:00:14 lr 0.000999\t wd 0.0100\ttime 0.0353 (0.0346)\tloss 1.7070 (1.4963)\tgrad_norm 3.6343 (3.1123)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][220/625]\teta 0:00:14 lr 0.000999\t wd 0.0100\ttime 0.0355 (0.0346)\tloss 1.2900 (1.4982)\tgrad_norm 5.8674 (3.1250)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][230/625]\teta 0:00:13 lr 0.000999\t wd 0.0100\ttime 0.0324 (0.0347)\tloss 1.4307 (1.4967)\tgrad_norm 2.2051 (3.1013)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][240/625]\teta 0:00:13 lr 0.000999\t wd 0.0100\ttime 0.0333 (0.0347)\tloss 1.3984 (1.4950)\tgrad_norm 2.3779 (3.0810)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][250/625]\teta 0:00:13 lr 0.000999\t wd 0.0100\ttime 0.0326 (0.0347)\tloss 1.2402 (1.4939)\tgrad_norm 3.2829 (3.0901)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][260/625]\teta 0:00:12 lr 0.000998\t wd 0.0100\ttime 0.0328 (0.0347)\tloss 1.6230 (1.4937)\tgrad_norm 3.0461 (3.0982)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][270/625]\teta 0:00:12 lr 0.000998\t wd 0.0100\ttime 0.0324 (0.0347)\tloss 1.5869 (1.4913)\tgrad_norm 3.1751 (3.0821)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][280/625]\teta 0:00:11 lr 0.000998\t wd 0.0100\ttime 0.0346 (0.0347)\tloss 1.5527 (1.4960)\tgrad_norm 3.9154 (3.1007)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][290/625]\teta 0:00:11 lr 0.000998\t wd 0.0100\ttime 0.0361 (0.0347)\tloss 1.4941 (1.4933)\tgrad_norm 2.5166 (3.0963)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][300/625]\teta 0:00:11 lr 0.000998\t wd 0.0100\ttime 0.0354 (0.0347)\tloss 1.4951 (1.4908)\tgrad_norm 2.7656 (3.0824)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][310/625]\teta 0:00:10 lr 0.000998\t wd 0.0100\ttime 0.0334 (0.0347)\tloss 1.5938 (1.4915)\tgrad_norm 2.0983 (3.0685)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][320/625]\teta 0:00:10 lr 0.000998\t wd 0.0100\ttime 0.0357 (0.0348)\tloss 1.3408 (1.4913)\tgrad_norm 2.7479 (3.0628)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][330/625]\teta 0:00:10 lr 0.000998\t wd 0.0100\ttime 0.0367 (0.0349)\tloss 1.4707 (1.4895)\tgrad_norm 2.1382 (3.0407)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][340/625]\teta 0:00:09 lr 0.000998\t wd 0.0100\ttime 0.0330 (0.0349)\tloss 1.5020 (1.4889)\tgrad_norm 2.3002 (3.0312)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][350/625]\teta 0:00:09 lr 0.000998\t wd 0.0100\ttime 0.0365 (0.0349)\tloss 1.4160 (1.4890)\tgrad_norm 2.7438 (3.0198)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][360/625]\teta 0:00:09 lr 0.000998\t wd 0.0100\ttime 0.0392 (0.0349)\tloss 1.4316 (1.4870)\tgrad_norm 2.4006 (3.0039)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][370/625]\teta 0:00:08 lr 0.000998\t wd 0.0100\ttime 0.0392 (0.0349)\tloss 1.2354 (1.4846)\tgrad_norm 3.0768 (2.9913)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][380/625]\teta 0:00:08 lr 0.000998\t wd 0.0100\ttime 0.0328 (0.0349)\tloss 1.1924 (1.4837)\tgrad_norm 2.2525 (2.9833)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][390/625]\teta 0:00:08 lr 0.000998\t wd 0.0100\ttime 0.0400 (0.0350)\tloss 1.5420 (1.4822)\tgrad_norm 2.5398 (2.9714)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][400/625]\teta 0:00:07 lr 0.000998\t wd 0.0100\ttime 0.0355 (0.0350)\tloss 1.5176 (1.4810)\tgrad_norm 3.8301 (2.9704)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][410/625]\teta 0:00:07 lr 0.000998\t wd 0.0100\ttime 0.0402 (0.0350)\tloss 1.3770 (1.4804)\tgrad_norm 2.3524 (2.9655)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][420/625]\teta 0:00:07 lr 0.000998\t wd 0.0100\ttime 0.0406 (0.0350)\tloss 1.4004 (1.4793)\tgrad_norm 2.4993 (2.9554)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][430/625]\teta 0:00:06 lr 0.000998\t wd 0.0100\ttime 0.0326 (0.0351)\tloss 1.4590 (1.4776)\tgrad_norm 2.2232 (2.9505)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][440/625]\teta 0:00:06 lr 0.000998\t wd 0.0100\ttime 0.0350 (0.0351)\tloss 1.4033 (1.4748)\tgrad_norm 3.0867 (2.9463)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][450/625]\teta 0:00:06 lr 0.000998\t wd 0.0100\ttime 0.0330 (0.0351)\tloss 1.3301 (1.4746)\tgrad_norm 2.7979 (2.9454)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][460/625]\teta 0:00:05 lr 0.000998\t wd 0.0100\ttime 0.0394 (0.0351)\tloss 1.2734 (1.4728)\tgrad_norm 2.0193 (2.9403)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][470/625]\teta 0:00:05 lr 0.000998\t wd 0.0100\ttime 0.0357 (0.0351)\tloss 1.3555 (1.4725)\tgrad_norm 2.5805 (2.9339)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][480/625]\teta 0:00:05 lr 0.000998\t wd 0.0100\ttime 0.0328 (0.0351)\tloss 1.4492 (1.4714)\tgrad_norm 2.4679 (2.9246)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][490/625]\teta 0:00:04 lr 0.000998\t wd 0.0100\ttime 0.0392 (0.0351)\tloss 1.4502 (1.4704)\tgrad_norm 2.5958 (2.9149)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][500/625]\teta 0:00:04 lr 0.000998\t wd 0.0100\ttime 0.0364 (0.0351)\tloss 1.6221 (1.4699)\tgrad_norm 2.6239 (2.9054)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][510/625]\teta 0:00:04 lr 0.000998\t wd 0.0100\ttime 0.0327 (0.0351)\tloss 1.3438 (1.4689)\tgrad_norm 1.8381 (2.8975)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][520/625]\teta 0:00:03 lr 0.000998\t wd 0.0100\ttime 0.0357 (0.0351)\tloss 1.3623 (1.4692)\tgrad_norm 2.9273 (2.9078)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][530/625]\teta 0:00:03 lr 0.000998\t wd 0.0100\ttime 0.0327 (0.0351)\tloss 1.4492 (1.4684)\tgrad_norm 3.7362 (2.9017)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][540/625]\teta 0:00:02 lr 0.000998\t wd 0.0100\ttime 0.0330 (0.0351)\tloss 1.5547 (1.4682)\tgrad_norm 3.0267 (2.9099)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][550/625]\teta 0:00:02 lr 0.000998\t wd 0.0100\ttime 0.0365 (0.0351)\tloss 1.3418 (1.4673)\tgrad_norm 2.0930 (2.9073)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][560/625]\teta 0:00:02 lr 0.000998\t wd 0.0100\ttime 0.0324 (0.0350)\tloss 1.2051 (1.4655)\tgrad_norm 2.5258 (2.9016)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][570/625]\teta 0:00:01 lr 0.000998\t wd 0.0100\ttime 0.0328 (0.0350)\tloss 1.4717 (1.4639)\tgrad_norm 2.6702 (2.8996)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][580/625]\teta 0:00:01 lr 0.000998\t wd 0.0100\ttime 0.0365 (0.0350)\tloss 1.4336 (1.4631)\tgrad_norm 3.0104 (2.8929)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][590/625]\teta 0:00:01 lr 0.000998\t wd 0.0100\ttime 0.0326 (0.0350)\tloss 1.3477 (1.4620)\tgrad_norm 2.6529 (2.8907)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][600/625]\teta 0:00:00 lr 0.000998\t wd 0.0100\ttime 0.0327 (0.0349)\tloss 1.5811 (1.4621)\tgrad_norm 2.3815 (2.8885)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][610/625]\teta 0:00:00 lr 0.000998\t wd 0.0100\ttime 0.0322 (0.0349)\tloss 1.5410 (1.4616)\tgrad_norm 2.2435 (2.8816)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [5/100][620/625]\teta 0:00:00 lr 0.000998\t wd 0.0100\ttime 0.0326 (0.0349)\tloss 1.4922 (1.4585)\tgrad_norm 2.3239 (2.8824)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 5 training takes 0:00:21\n",
      "./model_save/ckpt_epoch_5.pth saving......\n",
      "./model_save/ckpt_epoch_5.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 1.4834 (1.4834)\tAcc@1 45.312 (45.312)\tAcc@5 95.312 (95.312)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 1.6055 (1.3968)\tAcc@1 35.938 (49.716)\tAcc@5 87.500 (91.761)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 1.1104 (1.4140)\tAcc@1 53.125 (47.619)\tAcc@5 98.438 (93.006)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 1.3750 (1.4193)\tAcc@1 45.312 (47.883)\tAcc@5 95.312 (92.792)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 1.3682 (1.4147)\tAcc@1 51.562 (47.942)\tAcc@5 93.750 (92.835)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 1.1875 (1.3924)\tAcc@1 53.125 (48.468)\tAcc@5 96.875 (93.290)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 1.3330 (1.3900)\tAcc@1 56.250 (48.617)\tAcc@5 93.750 (93.315)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 1.3711 (1.3941)\tAcc@1 50.000 (48.482)\tAcc@5 92.188 (92.980)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 1.2520 (1.3899)\tAcc@1 56.250 (48.264)\tAcc@5 96.875 (92.921)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 1.5615 (1.3907)\tAcc@1 48.438 (48.506)\tAcc@5 90.625 (92.874)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 1.3164 (1.3871)\tAcc@1 50.000 (48.515)\tAcc@5 90.625 (92.992)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 1.4922 (1.3849)\tAcc@1 43.750 (48.564)\tAcc@5 92.188 (93.046)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 1.2217 (1.3908)\tAcc@1 53.125 (48.360)\tAcc@5 96.875 (92.924)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 1.6035 (1.3911)\tAcc@1 43.750 (48.402)\tAcc@5 89.062 (92.975)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 1.2607 (1.3899)\tAcc@1 56.250 (48.426)\tAcc@5 93.750 (93.030)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 1.6152 (1.3898)\tAcc@1 45.312 (48.551)\tAcc@5 87.500 (93.046)\tMem 455MB\n",
      " * Acc@1 48.640 Acc@5 93.030\n",
      "Accuracy of the network on the 10000 test images: 48.6%\n",
      "Max accuracy: 48.64%\n",
      "Train: [6/100][0/625]\teta 0:00:21 lr 0.000998\t wd 0.0100\ttime 0.0337 (0.0337)\tloss 1.3066 (1.3066)\tgrad_norm 3.0172 (3.0172)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [6/100][10/625]\teta 0:00:20 lr 0.000998\t wd 0.0100\ttime 0.0331 (0.0335)\tloss 1.3535 (1.3901)\tgrad_norm 2.5367 (2.8778)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [6/100][20/625]\teta 0:00:20 lr 0.000998\t wd 0.0100\ttime 0.0324 (0.0337)\tloss 1.2959 (1.3946)\tgrad_norm 2.3137 (2.7778)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [6/100][30/625]\teta 0:00:20 lr 0.000998\t wd 0.0100\ttime 0.0327 (0.0337)\tloss 1.4043 (1.3931)\tgrad_norm 1.9589 (2.7463)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [6/100][40/625]\teta 0:00:19 lr 0.000998\t wd 0.0100\ttime 0.0360 (0.0339)\tloss 1.2793 (1.3868)\tgrad_norm 2.7481 (2.7141)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [6/100][50/625]\teta 0:00:19 lr 0.000998\t wd 0.0100\ttime 0.0327 (0.0337)\tloss 1.3838 (1.4019)\tgrad_norm 2.8723 (2.7763)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [6/100][60/625]\teta 0:00:18 lr 0.000998\t wd 0.0100\ttime 0.0329 (0.0336)\tloss 1.4443 (1.4089)\tgrad_norm 2.3717 (2.8276)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [6/100][70/625]\teta 0:00:18 lr 0.000997\t wd 0.0100\ttime 0.0328 (0.0337)\tloss 1.2109 (1.4046)\tgrad_norm 2.2108 (2.8426)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [6/100][80/625]\teta 0:00:18 lr 0.000997\t wd 0.0100\ttime 0.0356 (0.0338)\tloss 1.4209 (1.4130)\tgrad_norm 2.7417 (2.8783)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [6/100][90/625]\teta 0:00:18 lr 0.000997\t wd 0.0100\ttime 0.0360 (0.0339)\tloss 1.5576 (1.4193)\tgrad_norm 3.1209 (2.8686)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [6/100][100/625]\teta 0:00:17 lr 0.000997\t wd 0.0100\ttime 0.0384 (0.0340)\tloss 1.5117 (1.4268)\tgrad_norm 3.8682 (2.8792)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [6/100][110/625]\teta 0:00:17 lr 0.000997\t wd 0.0100\ttime 0.0328 (0.0341)\tloss 1.3340 (1.4301)\tgrad_norm 2.6028 (2.9211)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [6/100][120/625]\teta 0:00:17 lr 0.000997\t wd 0.0100\ttime 0.0350 (0.0343)\tloss 1.3486 (1.4279)\tgrad_norm 2.3934 (2.8793)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [6/100][130/625]\teta 0:00:16 lr 0.000997\t wd 0.0100\ttime 0.0331 (0.0343)\tloss 1.3916 (1.4275)\tgrad_norm 2.3012 (2.8866)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [6/100][140/625]\teta 0:00:16 lr 0.000997\t wd 0.0100\ttime 0.0324 (0.0343)\tloss 1.5303 (1.4252)\tgrad_norm 2.4937 (2.8807)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [6/100][150/625]\teta 0:00:16 lr 0.000997\t wd 0.0100\ttime 0.0326 (0.0343)\tloss 1.4355 (1.4230)\tgrad_norm 2.9402 (2.9004)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [6/100][160/625]\teta 0:00:15 lr 0.000997\t wd 0.0100\ttime 0.0364 (0.0343)\tloss 1.4043 (1.4203)\tgrad_norm 2.8824 (2.9152)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [6/100][170/625]\teta 0:00:15 lr 0.000997\t wd 0.0100\ttime 0.0354 (0.0343)\tloss 1.3857 (1.4210)\tgrad_norm 3.5542 (2.9140)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [6/100][180/625]\teta 0:00:15 lr 0.000997\t wd 0.0100\ttime 0.0361 (0.0344)\tloss 1.3398 (1.4250)\tgrad_norm 2.9793 (2.9184)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [6/100][190/625]\teta 0:00:14 lr 0.000997\t wd 0.0100\ttime 0.0330 (0.0345)\tloss 1.5947 (1.4255)\tgrad_norm 4.9531 (2.9510)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [6/100][200/625]\teta 0:00:14 lr 0.000997\t wd 0.0100\ttime 0.0325 (0.0345)\tloss 1.4297 (1.4275)\tgrad_norm 2.9642 (2.9827)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [6/100][210/625]\teta 0:00:14 lr 0.000997\t wd 0.0100\ttime 0.0366 (0.0345)\tloss 1.4141 (1.4273)\tgrad_norm 2.7240 (2.9743)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [6/100][220/625]\teta 0:00:13 lr 0.000997\t wd 0.0100\ttime 0.0329 (0.0346)\tloss 1.5273 (1.4308)\tgrad_norm 3.2681 (2.9890)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [6/100][230/625]\teta 0:00:13 lr 0.000997\t wd 0.0100\ttime 0.0355 (0.0346)\tloss 1.4365 (1.4318)\tgrad_norm 2.6624 (2.9759)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [6/100][240/625]\teta 0:00:13 lr 0.000997\t wd 0.0100\ttime 0.0324 (0.0346)\tloss 1.4453 (1.4333)\tgrad_norm 3.4769 (2.9600)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [6/100][250/625]\teta 0:00:12 lr 0.000997\t wd 0.0100\ttime 0.0325 (0.0345)\tloss 1.3994 (1.4312)\tgrad_norm 2.2907 (2.9447)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [6/100][260/625]\teta 0:00:12 lr 0.000997\t wd 0.0100\ttime 0.0332 (0.0345)\tloss 1.4844 (1.4341)\tgrad_norm 2.4790 (nan)\tloss_scale 32768.0000 (32893.5479)\tmem 455MB\n",
      "Train: [6/100][270/625]\teta 0:00:12 lr 0.000997\t wd 0.0100\ttime 0.0354 (0.0345)\tloss 1.5859 (1.4332)\tgrad_norm 2.8874 (nan)\tloss_scale 32768.0000 (32888.9151)\tmem 455MB\n",
      "Train: [6/100][280/625]\teta 0:00:11 lr 0.000997\t wd 0.0100\ttime 0.0352 (0.0344)\tloss 1.1885 (1.4318)\tgrad_norm 2.7581 (nan)\tloss_scale 32768.0000 (32884.6121)\tmem 455MB\n",
      "Train: [6/100][290/625]\teta 0:00:11 lr 0.000997\t wd 0.0100\ttime 0.0324 (0.0345)\tloss 1.5059 (1.4313)\tgrad_norm 2.4307 (nan)\tloss_scale 32768.0000 (32880.6048)\tmem 455MB\n",
      "Train: [6/100][300/625]\teta 0:00:11 lr 0.000997\t wd 0.0100\ttime 0.0350 (0.0345)\tloss 1.3457 (1.4295)\tgrad_norm 2.3499 (nan)\tloss_scale 32768.0000 (32876.8638)\tmem 455MB\n",
      "Train: [6/100][310/625]\teta 0:00:10 lr 0.000997\t wd 0.0100\ttime 0.0326 (0.0345)\tloss 1.4873 (1.4279)\tgrad_norm 3.4147 (nan)\tloss_scale 32768.0000 (32873.3633)\tmem 455MB\n",
      "Train: [6/100][320/625]\teta 0:00:10 lr 0.000997\t wd 0.0100\ttime 0.0393 (0.0346)\tloss 1.2402 (1.4255)\tgrad_norm 2.2261 (nan)\tloss_scale 32768.0000 (32870.0810)\tmem 455MB\n",
      "Train: [6/100][330/625]\teta 0:00:10 lr 0.000997\t wd 0.0100\ttime 0.0324 (0.0346)\tloss 1.2227 (1.4262)\tgrad_norm 2.0041 (nan)\tloss_scale 32768.0000 (32866.9970)\tmem 455MB\n",
      "Train: [6/100][340/625]\teta 0:00:09 lr 0.000997\t wd 0.0100\ttime 0.0324 (0.0347)\tloss 1.2910 (1.4263)\tgrad_norm 2.8574 (nan)\tloss_scale 32768.0000 (32864.0938)\tmem 455MB\n",
      "Train: [6/100][350/625]\teta 0:00:09 lr 0.000997\t wd 0.0100\ttime 0.0328 (0.0346)\tloss 1.5186 (1.4257)\tgrad_norm 2.5944 (nan)\tloss_scale 32768.0000 (32861.3561)\tmem 455MB\n",
      "Train: [6/100][360/625]\teta 0:00:09 lr 0.000997\t wd 0.0100\ttime 0.0401 (0.0347)\tloss 1.3037 (1.4227)\tgrad_norm 2.2227 (nan)\tloss_scale 32768.0000 (32858.7701)\tmem 455MB\n",
      "Train: [6/100][370/625]\teta 0:00:08 lr 0.000997\t wd 0.0100\ttime 0.0379 (0.0348)\tloss 1.3594 (1.4214)\tgrad_norm 2.0667 (nan)\tloss_scale 32768.0000 (32856.3235)\tmem 455MB\n",
      "Train: [6/100][380/625]\teta 0:00:08 lr 0.000997\t wd 0.0100\ttime 0.0391 (0.0349)\tloss 1.4170 (1.4198)\tgrad_norm 2.3655 (nan)\tloss_scale 32768.0000 (32854.0052)\tmem 455MB\n",
      "Train: [6/100][390/625]\teta 0:00:08 lr 0.000997\t wd 0.0100\ttime 0.0360 (0.0349)\tloss 1.2773 (1.4186)\tgrad_norm 2.9006 (nan)\tloss_scale 32768.0000 (32851.8056)\tmem 455MB\n",
      "Train: [6/100][400/625]\teta 0:00:07 lr 0.000997\t wd 0.0100\ttime 0.0364 (0.0349)\tloss 1.3965 (1.4193)\tgrad_norm 2.6391 (nan)\tloss_scale 32768.0000 (32849.7157)\tmem 455MB\n",
      "Train: [6/100][410/625]\teta 0:00:07 lr 0.000997\t wd 0.0100\ttime 0.0388 (0.0350)\tloss 1.4580 (1.4183)\tgrad_norm 2.2247 (nan)\tloss_scale 32768.0000 (32847.7275)\tmem 455MB\n",
      "Train: [6/100][420/625]\teta 0:00:07 lr 0.000997\t wd 0.0100\ttime 0.0329 (0.0350)\tloss 1.4648 (1.4166)\tgrad_norm 3.4829 (nan)\tloss_scale 32768.0000 (32845.8337)\tmem 455MB\n",
      "Train: [6/100][430/625]\teta 0:00:06 lr 0.000996\t wd 0.0100\ttime 0.0367 (0.0351)\tloss 1.2715 (1.4159)\tgrad_norm 3.1968 (nan)\tloss_scale 32768.0000 (32844.0278)\tmem 455MB\n",
      "Train: [6/100][440/625]\teta 0:00:06 lr 0.000996\t wd 0.0100\ttime 0.0365 (0.0351)\tloss 1.3057 (1.4138)\tgrad_norm 4.3792 (nan)\tloss_scale 32768.0000 (32842.3039)\tmem 455MB\n",
      "Train: [6/100][450/625]\teta 0:00:06 lr 0.000996\t wd 0.0100\ttime 0.0345 (0.0351)\tloss 1.5146 (1.4128)\tgrad_norm 3.3999 (nan)\tloss_scale 32768.0000 (32840.6563)\tmem 455MB\n",
      "Train: [6/100][460/625]\teta 0:00:05 lr 0.000996\t wd 0.0100\ttime 0.0330 (0.0352)\tloss 1.2832 (1.4119)\tgrad_norm 2.1853 (nan)\tloss_scale 32768.0000 (32839.0803)\tmem 455MB\n",
      "Train: [6/100][470/625]\teta 0:00:05 lr 0.000996\t wd 0.0100\ttime 0.0333 (0.0352)\tloss 1.2949 (1.4101)\tgrad_norm 2.1259 (nan)\tloss_scale 32768.0000 (32837.5711)\tmem 455MB\n",
      "Train: [6/100][480/625]\teta 0:00:05 lr 0.000996\t wd 0.0100\ttime 0.0381 (0.0352)\tloss 1.3975 (1.4091)\tgrad_norm 2.6407 (nan)\tloss_scale 32768.0000 (32836.1247)\tmem 455MB\n",
      "Train: [6/100][490/625]\teta 0:00:04 lr 0.000996\t wd 0.0100\ttime 0.0381 (0.0352)\tloss 1.4150 (1.4080)\tgrad_norm 2.5873 (nan)\tloss_scale 32768.0000 (32834.7373)\tmem 455MB\n",
      "Train: [6/100][500/625]\teta 0:00:04 lr 0.000996\t wd 0.0100\ttime 0.0360 (0.0352)\tloss 1.3652 (1.4089)\tgrad_norm 2.0208 (nan)\tloss_scale 32768.0000 (32833.4052)\tmem 455MB\n",
      "Train: [6/100][510/625]\teta 0:00:04 lr 0.000996\t wd 0.0100\ttime 0.0400 (0.0353)\tloss 1.1396 (1.4078)\tgrad_norm 2.3152 (nan)\tloss_scale 32768.0000 (32832.1252)\tmem 455MB\n",
      "Train: [6/100][520/625]\teta 0:00:03 lr 0.000996\t wd 0.0100\ttime 0.0354 (0.0353)\tloss 1.3965 (1.4078)\tgrad_norm 2.5689 (nan)\tloss_scale 32768.0000 (32830.8944)\tmem 455MB\n",
      "Train: [6/100][530/625]\teta 0:00:03 lr 0.000996\t wd 0.0100\ttime 0.0329 (0.0352)\tloss 1.3301 (1.4070)\tgrad_norm 2.5238 (nan)\tloss_scale 32768.0000 (32829.7100)\tmem 455MB\n",
      "Train: [6/100][540/625]\teta 0:00:02 lr 0.000996\t wd 0.0100\ttime 0.0330 (0.0352)\tloss 1.4619 (1.4068)\tgrad_norm 1.9897 (nan)\tloss_scale 32768.0000 (32828.5693)\tmem 455MB\n",
      "Train: [6/100][550/625]\teta 0:00:02 lr 0.000996\t wd 0.0100\ttime 0.0394 (0.0353)\tloss 1.3438 (1.4061)\tgrad_norm 2.5431 (nan)\tloss_scale 32768.0000 (32827.4701)\tmem 455MB\n",
      "Train: [6/100][560/625]\teta 0:00:02 lr 0.000996\t wd 0.0100\ttime 0.0366 (0.0353)\tloss 1.4307 (1.4055)\tgrad_norm 3.2827 (nan)\tloss_scale 32768.0000 (32826.4100)\tmem 455MB\n",
      "Train: [6/100][570/625]\teta 0:00:01 lr 0.000996\t wd 0.0100\ttime 0.0386 (0.0353)\tloss 1.3369 (1.4055)\tgrad_norm 2.2688 (nan)\tloss_scale 32768.0000 (32825.3870)\tmem 455MB\n",
      "Train: [6/100][580/625]\teta 0:00:01 lr 0.000996\t wd 0.0100\ttime 0.0334 (0.0353)\tloss 1.4473 (1.4050)\tgrad_norm 2.9338 (nan)\tloss_scale 32768.0000 (32824.3993)\tmem 455MB\n",
      "Train: [6/100][590/625]\teta 0:00:01 lr 0.000996\t wd 0.0100\ttime 0.0357 (0.0354)\tloss 1.3652 (1.4046)\tgrad_norm 2.3730 (nan)\tloss_scale 32768.0000 (32823.4450)\tmem 455MB\n",
      "Train: [6/100][600/625]\teta 0:00:00 lr 0.000996\t wd 0.0100\ttime 0.0396 (0.0354)\tloss 1.4287 (1.4038)\tgrad_norm 2.4678 (nan)\tloss_scale 32768.0000 (32822.5225)\tmem 455MB\n",
      "Train: [6/100][610/625]\teta 0:00:00 lr 0.000996\t wd 0.0100\ttime 0.0379 (0.0354)\tloss 1.3643 (1.4020)\tgrad_norm 2.5299 (nan)\tloss_scale 32768.0000 (32821.6301)\tmem 455MB\n",
      "Train: [6/100][620/625]\teta 0:00:00 lr 0.000996\t wd 0.0100\ttime 0.0327 (0.0354)\tloss 1.3389 (1.4011)\tgrad_norm 2.7335 (nan)\tloss_scale 32768.0000 (32820.7665)\tmem 455MB\n",
      "EPOCH 6 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_6.pth saving......\n",
      "./model_save/ckpt_epoch_6.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 1.1289 (1.1289)\tAcc@1 65.625 (65.625)\tAcc@5 93.750 (93.750)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 1.2432 (1.3336)\tAcc@1 50.000 (51.847)\tAcc@5 96.875 (93.324)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 1.1709 (1.3123)\tAcc@1 64.062 (53.199)\tAcc@5 95.312 (93.676)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 1.3506 (1.3386)\tAcc@1 46.875 (51.310)\tAcc@5 96.875 (93.901)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 1.4111 (1.3432)\tAcc@1 53.125 (50.686)\tAcc@5 93.750 (94.017)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 1.3662 (1.3441)\tAcc@1 54.688 (50.551)\tAcc@5 90.625 (94.056)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.020 (0.015)\tLoss 1.1904 (1.3309)\tAcc@1 56.250 (51.306)\tAcc@5 98.438 (94.160)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 1.5381 (1.3358)\tAcc@1 39.062 (50.990)\tAcc@5 87.500 (94.036)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 1.1699 (1.3366)\tAcc@1 56.250 (50.772)\tAcc@5 95.312 (93.981)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 1.4121 (1.3335)\tAcc@1 50.000 (50.721)\tAcc@5 95.312 (94.128)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.016 (0.015)\tLoss 1.1982 (1.3373)\tAcc@1 60.938 (50.634)\tAcc@5 93.750 (94.106)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.016 (0.015)\tLoss 1.3496 (1.3378)\tAcc@1 51.562 (50.929)\tAcc@5 98.438 (94.243)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.016 (0.015)\tLoss 1.1016 (1.3318)\tAcc@1 57.812 (51.046)\tAcc@5 95.312 (94.228)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 1.0947 (1.3281)\tAcc@1 62.500 (51.097)\tAcc@5 98.438 (94.323)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.016 (0.015)\tLoss 1.3799 (1.3260)\tAcc@1 51.562 (51.197)\tAcc@5 93.750 (94.359)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.016 (0.015)\tLoss 1.3320 (1.3278)\tAcc@1 54.688 (51.180)\tAcc@5 92.188 (94.319)\tMem 455MB\n",
      " * Acc@1 51.100 Acc@5 94.350\n",
      "Accuracy of the network on the 10000 test images: 51.1%\n",
      "Max accuracy: 51.10%\n",
      "Train: [7/100][0/625]\teta 0:00:24 lr 0.000996\t wd 0.0100\ttime 0.0393 (0.0393)\tloss 1.2109 (1.2109)\tgrad_norm 2.1683 (2.1683)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][10/625]\teta 0:00:22 lr 0.000996\t wd 0.0100\ttime 0.0361 (0.0369)\tloss 1.5791 (1.3590)\tgrad_norm 2.5447 (2.2573)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][20/625]\teta 0:00:22 lr 0.000996\t wd 0.0100\ttime 0.0360 (0.0365)\tloss 1.3203 (1.3185)\tgrad_norm 2.6348 (2.2157)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][30/625]\teta 0:00:22 lr 0.000996\t wd 0.0100\ttime 0.0361 (0.0370)\tloss 1.0020 (1.3054)\tgrad_norm 1.9213 (2.3102)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][40/625]\teta 0:00:21 lr 0.000996\t wd 0.0100\ttime 0.0375 (0.0368)\tloss 1.4463 (1.3084)\tgrad_norm 2.9914 (2.3605)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][50/625]\teta 0:00:21 lr 0.000996\t wd 0.0100\ttime 0.0378 (0.0366)\tloss 1.3008 (1.3169)\tgrad_norm 3.2223 (2.4070)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][60/625]\teta 0:00:20 lr 0.000996\t wd 0.0100\ttime 0.0397 (0.0366)\tloss 1.1904 (1.3124)\tgrad_norm 3.0603 (2.4337)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][70/625]\teta 0:00:20 lr 0.000996\t wd 0.0100\ttime 0.0323 (0.0365)\tloss 1.2920 (1.3133)\tgrad_norm 2.5884 (2.4216)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][80/625]\teta 0:00:19 lr 0.000996\t wd 0.0100\ttime 0.0327 (0.0364)\tloss 1.1885 (1.3216)\tgrad_norm 2.5539 (2.4300)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][90/625]\teta 0:00:19 lr 0.000996\t wd 0.0100\ttime 0.0356 (0.0363)\tloss 1.4219 (1.3277)\tgrad_norm 2.8403 (2.4659)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][100/625]\teta 0:00:19 lr 0.000996\t wd 0.0100\ttime 0.0360 (0.0362)\tloss 1.2949 (1.3327)\tgrad_norm 3.0662 (2.4736)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][110/625]\teta 0:00:18 lr 0.000995\t wd 0.0100\ttime 0.0334 (0.0361)\tloss 1.4941 (1.3373)\tgrad_norm 2.6619 (2.4965)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][120/625]\teta 0:00:18 lr 0.000995\t wd 0.0100\ttime 0.0388 (0.0362)\tloss 1.2578 (1.3394)\tgrad_norm 2.1034 (2.5285)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][130/625]\teta 0:00:17 lr 0.000995\t wd 0.0100\ttime 0.0331 (0.0361)\tloss 1.4609 (1.3444)\tgrad_norm 2.0933 (2.5410)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][140/625]\teta 0:00:17 lr 0.000995\t wd 0.0100\ttime 0.0356 (0.0361)\tloss 1.3428 (1.3428)\tgrad_norm 2.3484 (2.5403)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][150/625]\teta 0:00:17 lr 0.000995\t wd 0.0100\ttime 0.0346 (0.0361)\tloss 1.6025 (1.3493)\tgrad_norm 3.8876 (2.5524)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][160/625]\teta 0:00:16 lr 0.000995\t wd 0.0100\ttime 0.0362 (0.0361)\tloss 1.3311 (1.3517)\tgrad_norm 3.6859 (2.5596)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][170/625]\teta 0:00:16 lr 0.000995\t wd 0.0100\ttime 0.0388 (0.0362)\tloss 1.3633 (1.3514)\tgrad_norm 7.6344 (2.5853)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][180/625]\teta 0:00:16 lr 0.000995\t wd 0.0100\ttime 0.0364 (0.0362)\tloss 1.1758 (1.3483)\tgrad_norm 2.2550 (2.5866)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][190/625]\teta 0:00:15 lr 0.000995\t wd 0.0100\ttime 0.0327 (0.0362)\tloss 1.3643 (1.3502)\tgrad_norm 2.3269 (2.5975)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][200/625]\teta 0:00:15 lr 0.000995\t wd 0.0100\ttime 0.0347 (0.0362)\tloss 1.3164 (1.3477)\tgrad_norm 3.3904 (2.6383)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][210/625]\teta 0:00:15 lr 0.000995\t wd 0.0100\ttime 0.0337 (0.0363)\tloss 1.3926 (1.3507)\tgrad_norm 4.0638 (2.6714)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][220/625]\teta 0:00:14 lr 0.000995\t wd 0.0100\ttime 0.0329 (0.0361)\tloss 1.5400 (1.3548)\tgrad_norm 5.8846 (2.7059)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][230/625]\teta 0:00:14 lr 0.000995\t wd 0.0100\ttime 0.0362 (0.0361)\tloss 1.3457 (1.3548)\tgrad_norm 2.2907 (2.7103)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][240/625]\teta 0:00:13 lr 0.000995\t wd 0.0100\ttime 0.0366 (0.0361)\tloss 1.3516 (1.3561)\tgrad_norm 2.6262 (2.7234)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][250/625]\teta 0:00:13 lr 0.000995\t wd 0.0100\ttime 0.0361 (0.0361)\tloss 1.6113 (1.3605)\tgrad_norm 5.3159 (2.7537)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][260/625]\teta 0:00:13 lr 0.000995\t wd 0.0100\ttime 0.0362 (0.0361)\tloss 1.4287 (1.3612)\tgrad_norm 3.3018 (2.7512)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][270/625]\teta 0:00:12 lr 0.000995\t wd 0.0100\ttime 0.0393 (0.0361)\tloss 1.4268 (1.3617)\tgrad_norm 3.1656 (2.7528)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][280/625]\teta 0:00:12 lr 0.000995\t wd 0.0100\ttime 0.0426 (0.0362)\tloss 1.2480 (1.3627)\tgrad_norm 2.7811 (2.7413)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][290/625]\teta 0:00:12 lr 0.000995\t wd 0.0100\ttime 0.0394 (0.0362)\tloss 1.2822 (1.3636)\tgrad_norm 2.5421 (2.7268)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][300/625]\teta 0:00:11 lr 0.000995\t wd 0.0100\ttime 0.0355 (0.0361)\tloss 1.7041 (1.3663)\tgrad_norm 3.6671 (2.7283)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][310/625]\teta 0:00:11 lr 0.000995\t wd 0.0100\ttime 0.0370 (0.0361)\tloss 1.6045 (1.3672)\tgrad_norm 2.9253 (2.7254)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][320/625]\teta 0:00:11 lr 0.000995\t wd 0.0100\ttime 0.0356 (0.0361)\tloss 1.3486 (1.3690)\tgrad_norm 2.4253 (2.7167)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][330/625]\teta 0:00:10 lr 0.000995\t wd 0.0100\ttime 0.0393 (0.0361)\tloss 1.3408 (1.3701)\tgrad_norm 2.9032 (2.7090)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][340/625]\teta 0:00:10 lr 0.000995\t wd 0.0100\ttime 0.0357 (0.0361)\tloss 1.2549 (1.3687)\tgrad_norm 2.9027 (2.7052)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][350/625]\teta 0:00:09 lr 0.000995\t wd 0.0100\ttime 0.0328 (0.0360)\tloss 1.3320 (1.3679)\tgrad_norm 3.2300 (2.6999)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][360/625]\teta 0:00:09 lr 0.000995\t wd 0.0100\ttime 0.0328 (0.0360)\tloss 1.3096 (1.3676)\tgrad_norm 3.1805 (2.7126)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][370/625]\teta 0:00:09 lr 0.000995\t wd 0.0100\ttime 0.0394 (0.0360)\tloss 1.3467 (1.3682)\tgrad_norm 2.1921 (2.7106)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][380/625]\teta 0:00:08 lr 0.000994\t wd 0.0100\ttime 0.0326 (0.0360)\tloss 1.2500 (1.3686)\tgrad_norm 2.2921 (2.7080)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][390/625]\teta 0:00:08 lr 0.000994\t wd 0.0100\ttime 0.0328 (0.0359)\tloss 1.3408 (1.3689)\tgrad_norm 2.3383 (2.7001)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][400/625]\teta 0:00:08 lr 0.000994\t wd 0.0100\ttime 0.0326 (0.0359)\tloss 1.5850 (1.3698)\tgrad_norm 2.7914 (2.7096)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][410/625]\teta 0:00:07 lr 0.000994\t wd 0.0100\ttime 0.0323 (0.0358)\tloss 1.1025 (1.3688)\tgrad_norm 1.9786 (2.7174)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][420/625]\teta 0:00:07 lr 0.000994\t wd 0.0100\ttime 0.0361 (0.0358)\tloss 1.2393 (1.3693)\tgrad_norm 2.3155 (2.7262)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][430/625]\teta 0:00:06 lr 0.000994\t wd 0.0100\ttime 0.0324 (0.0357)\tloss 1.5986 (1.3691)\tgrad_norm 3.1934 (2.7306)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][440/625]\teta 0:00:06 lr 0.000994\t wd 0.0100\ttime 0.0325 (0.0357)\tloss 1.2354 (1.3689)\tgrad_norm 2.6436 (2.7438)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][450/625]\teta 0:00:06 lr 0.000994\t wd 0.0100\ttime 0.0371 (0.0356)\tloss 1.4688 (1.3691)\tgrad_norm 3.5685 (2.7587)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][460/625]\teta 0:00:05 lr 0.000994\t wd 0.0100\ttime 0.0325 (0.0356)\tloss 1.4600 (1.3701)\tgrad_norm 2.7375 (2.7655)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][470/625]\teta 0:00:05 lr 0.000994\t wd 0.0100\ttime 0.0357 (0.0356)\tloss 1.3311 (1.3709)\tgrad_norm 2.4136 (2.7748)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][480/625]\teta 0:00:05 lr 0.000994\t wd 0.0100\ttime 0.0361 (0.0355)\tloss 1.4268 (1.3715)\tgrad_norm 2.6652 (2.7729)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][490/625]\teta 0:00:04 lr 0.000994\t wd 0.0100\ttime 0.0332 (0.0355)\tloss 1.1895 (1.3712)\tgrad_norm 2.9291 (2.7698)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][500/625]\teta 0:00:04 lr 0.000994\t wd 0.0100\ttime 0.0328 (0.0355)\tloss 1.5293 (1.3705)\tgrad_norm 2.5625 (2.7674)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][510/625]\teta 0:00:04 lr 0.000994\t wd 0.0100\ttime 0.0359 (0.0355)\tloss 1.2656 (1.3713)\tgrad_norm 3.0723 (2.7656)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][520/625]\teta 0:00:03 lr 0.000994\t wd 0.0100\ttime 0.0391 (0.0355)\tloss 1.3828 (1.3701)\tgrad_norm 5.3981 (2.7611)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][530/625]\teta 0:00:03 lr 0.000994\t wd 0.0100\ttime 0.0329 (0.0355)\tloss 1.3262 (1.3681)\tgrad_norm 2.7661 (2.7859)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][540/625]\teta 0:00:03 lr 0.000994\t wd 0.0100\ttime 0.0362 (0.0355)\tloss 1.3789 (1.3703)\tgrad_norm 3.4422 (2.7851)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][550/625]\teta 0:00:02 lr 0.000994\t wd 0.0100\ttime 0.0355 (0.0355)\tloss 1.3271 (1.3697)\tgrad_norm 2.8872 (2.7890)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][560/625]\teta 0:00:02 lr 0.000994\t wd 0.0100\ttime 0.0326 (0.0355)\tloss 1.3359 (1.3693)\tgrad_norm 2.6354 (2.7854)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][570/625]\teta 0:00:01 lr 0.000994\t wd 0.0100\ttime 0.0325 (0.0355)\tloss 1.2656 (1.3687)\tgrad_norm 2.1859 (2.7800)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][580/625]\teta 0:00:01 lr 0.000994\t wd 0.0100\ttime 0.0332 (0.0355)\tloss 1.3750 (1.3693)\tgrad_norm 2.4932 (2.7744)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][590/625]\teta 0:00:01 lr 0.000994\t wd 0.0100\ttime 0.0382 (0.0355)\tloss 1.4775 (1.3699)\tgrad_norm 4.6583 (2.7705)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][600/625]\teta 0:00:00 lr 0.000994\t wd 0.0100\ttime 0.0330 (0.0356)\tloss 1.0654 (1.3684)\tgrad_norm 1.5814 (2.7614)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][610/625]\teta 0:00:00 lr 0.000994\t wd 0.0100\ttime 0.0328 (0.0356)\tloss 1.4053 (1.3662)\tgrad_norm 2.0786 (2.7498)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [7/100][620/625]\teta 0:00:00 lr 0.000994\t wd 0.0100\ttime 0.0332 (0.0355)\tloss 1.4932 (1.3656)\tgrad_norm 2.2202 (2.7487)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 7 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_7.pth saving......\n",
      "./model_save/ckpt_epoch_7.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 1.3369 (1.3369)\tAcc@1 53.125 (53.125)\tAcc@5 89.062 (89.062)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.016 (0.016)\tLoss 1.5537 (1.3093)\tAcc@1 42.188 (52.841)\tAcc@5 89.062 (93.040)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 1.3213 (1.3238)\tAcc@1 45.312 (51.860)\tAcc@5 95.312 (93.155)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 1.5146 (1.3373)\tAcc@1 48.438 (52.117)\tAcc@5 90.625 (93.296)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.016 (0.015)\tLoss 1.4189 (1.3428)\tAcc@1 46.875 (51.715)\tAcc@5 95.312 (93.369)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.016 (0.015)\tLoss 1.2871 (1.3254)\tAcc@1 53.125 (51.869)\tAcc@5 93.750 (93.689)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 1.3896 (1.3312)\tAcc@1 45.312 (51.460)\tAcc@5 93.750 (93.494)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 1.3184 (1.3303)\tAcc@1 45.312 (51.232)\tAcc@5 96.875 (93.530)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.016 (0.015)\tLoss 1.3174 (1.3285)\tAcc@1 48.438 (51.524)\tAcc@5 96.875 (93.576)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.016 (0.015)\tLoss 1.3848 (1.3163)\tAcc@1 48.438 (51.820)\tAcc@5 90.625 (93.733)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 1.5078 (1.3210)\tAcc@1 46.875 (51.671)\tAcc@5 90.625 (93.765)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 1.2695 (1.3213)\tAcc@1 51.562 (51.633)\tAcc@5 95.312 (93.722)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.016 (0.015)\tLoss 1.4609 (1.3212)\tAcc@1 42.188 (51.524)\tAcc@5 93.750 (93.802)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 1.4121 (1.3199)\tAcc@1 48.438 (51.503)\tAcc@5 92.188 (93.762)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 1.3076 (1.3179)\tAcc@1 50.000 (51.496)\tAcc@5 95.312 (93.794)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 1.3184 (1.3174)\tAcc@1 53.125 (51.459)\tAcc@5 93.750 (93.833)\tMem 455MB\n",
      " * Acc@1 51.420 Acc@5 93.870\n",
      "Accuracy of the network on the 10000 test images: 51.4%\n",
      "Max accuracy: 51.42%\n",
      "Train: [8/100][0/625]\teta 0:00:25 lr 0.000994\t wd 0.0100\ttime 0.0415 (0.0415)\tloss 1.6045 (1.6045)\tgrad_norm 2.8069 (2.8069)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][10/625]\teta 0:00:22 lr 0.000993\t wd 0.0100\ttime 0.0329 (0.0359)\tloss 1.3779 (1.3457)\tgrad_norm 3.2464 (2.6770)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][20/625]\teta 0:00:22 lr 0.000993\t wd 0.0100\ttime 0.0360 (0.0366)\tloss 1.2109 (1.3388)\tgrad_norm 2.8362 (2.6242)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][30/625]\teta 0:00:21 lr 0.000993\t wd 0.0100\ttime 0.0328 (0.0368)\tloss 1.1074 (1.3122)\tgrad_norm 2.5049 (2.6419)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][40/625]\teta 0:00:21 lr 0.000993\t wd 0.0100\ttime 0.0331 (0.0364)\tloss 1.4512 (1.3127)\tgrad_norm 3.4994 (2.6531)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][50/625]\teta 0:00:20 lr 0.000993\t wd 0.0100\ttime 0.0360 (0.0365)\tloss 1.2695 (1.3025)\tgrad_norm 3.1021 (2.6398)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][60/625]\teta 0:00:20 lr 0.000993\t wd 0.0100\ttime 0.0398 (0.0364)\tloss 1.3047 (1.3086)\tgrad_norm 3.1095 (2.6672)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][70/625]\teta 0:00:20 lr 0.000993\t wd 0.0100\ttime 0.0369 (0.0363)\tloss 1.3037 (1.3096)\tgrad_norm 4.2680 (2.6785)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][80/625]\teta 0:00:19 lr 0.000993\t wd 0.0100\ttime 0.0326 (0.0362)\tloss 1.1582 (1.3158)\tgrad_norm 3.0372 (2.7175)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][90/625]\teta 0:00:19 lr 0.000993\t wd 0.0100\ttime 0.0328 (0.0359)\tloss 1.4492 (1.3223)\tgrad_norm 3.1079 (2.7116)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][100/625]\teta 0:00:18 lr 0.000993\t wd 0.0100\ttime 0.0327 (0.0359)\tloss 1.2480 (1.3194)\tgrad_norm 2.3775 (2.6832)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][110/625]\teta 0:00:18 lr 0.000993\t wd 0.0100\ttime 0.0360 (0.0359)\tloss 1.4082 (1.3195)\tgrad_norm 2.8968 (2.6678)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][120/625]\teta 0:00:18 lr 0.000993\t wd 0.0100\ttime 0.0328 (0.0358)\tloss 1.5283 (1.3289)\tgrad_norm 2.3966 (2.6639)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][130/625]\teta 0:00:17 lr 0.000993\t wd 0.0100\ttime 0.0333 (0.0358)\tloss 1.2910 (1.3299)\tgrad_norm 2.1920 (2.6554)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][140/625]\teta 0:00:17 lr 0.000993\t wd 0.0100\ttime 0.0330 (0.0357)\tloss 1.2744 (1.3300)\tgrad_norm 1.9172 (2.6361)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][150/625]\teta 0:00:16 lr 0.000993\t wd 0.0100\ttime 0.0395 (0.0357)\tloss 1.1455 (1.3286)\tgrad_norm 2.1098 (2.6310)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][160/625]\teta 0:00:16 lr 0.000993\t wd 0.0100\ttime 0.0329 (0.0357)\tloss 1.2734 (1.3286)\tgrad_norm 2.5099 (2.6114)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][170/625]\teta 0:00:16 lr 0.000993\t wd 0.0100\ttime 0.0390 (0.0357)\tloss 1.2646 (1.3289)\tgrad_norm 2.6114 (2.5918)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][180/625]\teta 0:00:15 lr 0.000993\t wd 0.0100\ttime 0.0327 (0.0357)\tloss 1.1729 (1.3299)\tgrad_norm 2.0484 (2.5825)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][190/625]\teta 0:00:15 lr 0.000993\t wd 0.0100\ttime 0.0358 (0.0356)\tloss 1.3066 (1.3281)\tgrad_norm 2.3860 (2.5742)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][200/625]\teta 0:00:15 lr 0.000993\t wd 0.0100\ttime 0.0349 (0.0355)\tloss 1.7285 (1.3279)\tgrad_norm 4.0983 (2.5961)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][210/625]\teta 0:00:14 lr 0.000993\t wd 0.0100\ttime 0.0330 (0.0355)\tloss 1.4180 (1.3262)\tgrad_norm 5.6624 (2.6123)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][220/625]\teta 0:00:14 lr 0.000993\t wd 0.0100\ttime 0.0325 (0.0355)\tloss 1.3691 (1.3310)\tgrad_norm 2.3351 (2.6158)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][230/625]\teta 0:00:13 lr 0.000993\t wd 0.0100\ttime 0.0360 (0.0354)\tloss 1.2871 (1.3296)\tgrad_norm 4.6003 (2.6374)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][240/625]\teta 0:00:13 lr 0.000992\t wd 0.0100\ttime 0.0358 (0.0354)\tloss 1.5332 (1.3305)\tgrad_norm 4.7692 (2.6449)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][250/625]\teta 0:00:13 lr 0.000992\t wd 0.0100\ttime 0.0360 (0.0354)\tloss 1.3652 (1.3320)\tgrad_norm 2.1469 (2.6446)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][260/625]\teta 0:00:12 lr 0.000992\t wd 0.0100\ttime 0.0326 (0.0354)\tloss 1.4932 (1.3322)\tgrad_norm 3.1069 (2.6400)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][270/625]\teta 0:00:12 lr 0.000992\t wd 0.0100\ttime 0.0365 (0.0354)\tloss 1.4697 (1.3319)\tgrad_norm 3.1734 (2.6462)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][280/625]\teta 0:00:12 lr 0.000992\t wd 0.0100\ttime 0.0329 (0.0353)\tloss 1.3164 (1.3320)\tgrad_norm 2.4803 (2.6471)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][290/625]\teta 0:00:11 lr 0.000992\t wd 0.0100\ttime 0.0328 (0.0353)\tloss 1.1768 (1.3308)\tgrad_norm 3.2410 (2.6402)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][300/625]\teta 0:00:11 lr 0.000992\t wd 0.0100\ttime 0.0401 (0.0353)\tloss 1.2031 (1.3303)\tgrad_norm 3.8431 (2.6458)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][310/625]\teta 0:00:11 lr 0.000992\t wd 0.0100\ttime 0.0359 (0.0353)\tloss 1.2695 (1.3304)\tgrad_norm 4.8251 (2.6615)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][320/625]\teta 0:00:10 lr 0.000992\t wd 0.0100\ttime 0.0356 (0.0354)\tloss 1.5264 (1.3330)\tgrad_norm 3.2512 (2.6802)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][330/625]\teta 0:00:10 lr 0.000992\t wd 0.0100\ttime 0.0368 (0.0354)\tloss 1.3848 (1.3364)\tgrad_norm 2.3007 (2.6814)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][340/625]\teta 0:00:10 lr 0.000992\t wd 0.0100\ttime 0.0329 (0.0354)\tloss 1.4404 (1.3365)\tgrad_norm 2.7901 (2.6807)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][350/625]\teta 0:00:09 lr 0.000992\t wd 0.0100\ttime 0.0396 (0.0355)\tloss 1.7070 (1.3360)\tgrad_norm 2.7550 (2.6699)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][360/625]\teta 0:00:09 lr 0.000992\t wd 0.0100\ttime 0.0363 (0.0355)\tloss 1.3809 (1.3365)\tgrad_norm 2.0026 (2.6579)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][370/625]\teta 0:00:09 lr 0.000992\t wd 0.0100\ttime 0.0334 (0.0355)\tloss 1.4727 (1.3346)\tgrad_norm 3.6093 (2.6520)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][380/625]\teta 0:00:08 lr 0.000992\t wd 0.0100\ttime 0.0407 (0.0356)\tloss 1.5615 (1.3353)\tgrad_norm 4.5505 (2.6799)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][390/625]\teta 0:00:08 lr 0.000992\t wd 0.0100\ttime 0.0342 (0.0356)\tloss 1.6133 (1.3355)\tgrad_norm 3.1066 (2.6884)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][400/625]\teta 0:00:07 lr 0.000992\t wd 0.0100\ttime 0.0327 (0.0355)\tloss 1.2598 (1.3344)\tgrad_norm 2.9053 (2.6982)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][410/625]\teta 0:00:07 lr 0.000992\t wd 0.0100\ttime 0.0401 (0.0355)\tloss 1.4355 (1.3343)\tgrad_norm 3.2212 (2.7107)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][420/625]\teta 0:00:07 lr 0.000992\t wd 0.0100\ttime 0.0361 (0.0355)\tloss 1.4111 (1.3355)\tgrad_norm 2.5786 (2.7151)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][430/625]\teta 0:00:06 lr 0.000992\t wd 0.0100\ttime 0.0329 (0.0356)\tloss 1.3955 (1.3376)\tgrad_norm 2.5410 (2.7110)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][440/625]\teta 0:00:06 lr 0.000992\t wd 0.0100\ttime 0.0329 (0.0356)\tloss 1.2881 (1.3388)\tgrad_norm 2.6046 (2.7092)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][450/625]\teta 0:00:06 lr 0.000992\t wd 0.0100\ttime 0.0326 (0.0355)\tloss 1.4150 (1.3383)\tgrad_norm 2.1674 (2.7035)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][460/625]\teta 0:00:05 lr 0.000991\t wd 0.0100\ttime 0.0357 (0.0355)\tloss 1.3496 (1.3367)\tgrad_norm 2.7659 (2.7038)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][470/625]\teta 0:00:05 lr 0.000991\t wd 0.0100\ttime 0.0362 (0.0355)\tloss 1.2783 (1.3364)\tgrad_norm 2.3876 (2.7023)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][480/625]\teta 0:00:05 lr 0.000991\t wd 0.0100\ttime 0.0326 (0.0354)\tloss 1.1504 (1.3353)\tgrad_norm 2.7092 (2.7019)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][490/625]\teta 0:00:04 lr 0.000991\t wd 0.0100\ttime 0.0327 (0.0354)\tloss 1.3750 (1.3357)\tgrad_norm 2.0628 (2.7036)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][500/625]\teta 0:00:04 lr 0.000991\t wd 0.0100\ttime 0.0366 (0.0353)\tloss 1.3203 (1.3353)\tgrad_norm 1.9363 (2.7070)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][510/625]\teta 0:00:04 lr 0.000991\t wd 0.0100\ttime 0.0331 (0.0353)\tloss 1.3262 (1.3357)\tgrad_norm 2.3088 (2.7147)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][520/625]\teta 0:00:03 lr 0.000991\t wd 0.0100\ttime 0.0395 (0.0354)\tloss 1.2539 (1.3360)\tgrad_norm 2.8976 (2.7090)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][530/625]\teta 0:00:03 lr 0.000991\t wd 0.0100\ttime 0.0370 (0.0354)\tloss 1.4570 (1.3358)\tgrad_norm 2.4193 (2.7020)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][540/625]\teta 0:00:03 lr 0.000991\t wd 0.0100\ttime 0.0325 (0.0354)\tloss 1.2979 (1.3352)\tgrad_norm 2.2033 (2.6958)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][550/625]\teta 0:00:02 lr 0.000991\t wd 0.0100\ttime 0.0329 (0.0354)\tloss 1.1377 (1.3349)\tgrad_norm 2.5228 (2.6918)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][560/625]\teta 0:00:02 lr 0.000991\t wd 0.0100\ttime 0.0323 (0.0354)\tloss 1.2617 (1.3346)\tgrad_norm 1.9554 (2.6842)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][570/625]\teta 0:00:01 lr 0.000991\t wd 0.0100\ttime 0.0328 (0.0354)\tloss 1.1689 (1.3334)\tgrad_norm 1.4519 (2.6721)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][580/625]\teta 0:00:01 lr 0.000991\t wd 0.0100\ttime 0.0326 (0.0354)\tloss 1.1963 (1.3324)\tgrad_norm 2.2783 (2.6640)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][590/625]\teta 0:00:01 lr 0.000991\t wd 0.0100\ttime 0.0359 (0.0354)\tloss 1.4385 (1.3320)\tgrad_norm 3.0692 (2.6597)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][600/625]\teta 0:00:00 lr 0.000991\t wd 0.0100\ttime 0.0329 (0.0354)\tloss 1.3447 (1.3331)\tgrad_norm 2.1271 (2.6615)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][610/625]\teta 0:00:00 lr 0.000991\t wd 0.0100\ttime 0.0356 (0.0354)\tloss 1.4346 (1.3324)\tgrad_norm 2.1170 (2.6541)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [8/100][620/625]\teta 0:00:00 lr 0.000991\t wd 0.0100\ttime 0.0350 (0.0354)\tloss 1.4092 (1.3325)\tgrad_norm 2.4482 (2.6515)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 8 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_8.pth saving......\n",
      "./model_save/ckpt_epoch_8.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 1.1104 (1.1104)\tAcc@1 59.375 (59.375)\tAcc@5 95.312 (95.312)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 1.4736 (1.2939)\tAcc@1 43.750 (52.841)\tAcc@5 90.625 (94.176)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 1.2510 (1.2572)\tAcc@1 48.438 (53.795)\tAcc@5 96.875 (95.164)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.016 (0.015)\tLoss 1.1270 (1.2501)\tAcc@1 57.812 (54.234)\tAcc@5 96.875 (95.111)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.016 (0.015)\tLoss 1.1318 (1.2268)\tAcc@1 60.938 (55.335)\tAcc@5 96.875 (95.427)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.016 (0.015)\tLoss 1.2578 (1.2181)\tAcc@1 53.125 (55.515)\tAcc@5 96.875 (95.374)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.016 (0.016)\tLoss 1.2539 (1.2209)\tAcc@1 57.812 (55.558)\tAcc@5 92.188 (95.031)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.016 (0.016)\tLoss 1.2305 (1.2211)\tAcc@1 57.812 (55.326)\tAcc@5 92.188 (95.136)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.016 (0.016)\tLoss 1.2510 (1.2241)\tAcc@1 53.125 (55.035)\tAcc@5 96.875 (95.235)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.016)\tLoss 1.3213 (1.2251)\tAcc@1 53.125 (54.842)\tAcc@5 95.312 (95.141)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.016 (0.016)\tLoss 1.0166 (1.2274)\tAcc@1 57.812 (54.749)\tAcc@5 100.000 (95.096)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.016)\tLoss 1.1240 (1.2365)\tAcc@1 65.625 (54.786)\tAcc@5 98.438 (94.890)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.016 (0.016)\tLoss 1.2578 (1.2342)\tAcc@1 56.250 (54.997)\tAcc@5 95.312 (94.873)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.016 (0.016)\tLoss 1.1416 (1.2359)\tAcc@1 54.688 (54.902)\tAcc@5 96.875 (94.895)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.016 (0.016)\tLoss 0.9429 (1.2378)\tAcc@1 67.188 (54.887)\tAcc@5 100.000 (94.891)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.016 (0.016)\tLoss 1.3555 (1.2370)\tAcc@1 51.562 (54.801)\tAcc@5 93.750 (94.909)\tMem 455MB\n",
      " * Acc@1 54.780 Acc@5 94.890\n",
      "Accuracy of the network on the 10000 test images: 54.8%\n",
      "Max accuracy: 54.78%\n",
      "Train: [9/100][0/625]\teta 0:00:25 lr 0.000991\t wd 0.0100\ttime 0.0408 (0.0408)\tloss 1.2656 (1.2656)\tgrad_norm 2.7608 (2.7608)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [9/100][10/625]\teta 0:00:22 lr 0.000991\t wd 0.0100\ttime 0.0328 (0.0366)\tloss 1.3057 (1.2832)\tgrad_norm 2.5001 (2.3776)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [9/100][20/625]\teta 0:00:21 lr 0.000991\t wd 0.0100\ttime 0.0362 (0.0363)\tloss 1.4082 (1.2673)\tgrad_norm 2.8526 (2.4411)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [9/100][30/625]\teta 0:00:21 lr 0.000991\t wd 0.0100\ttime 0.0363 (0.0364)\tloss 1.3809 (1.2918)\tgrad_norm 2.1879 (2.4071)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [9/100][40/625]\teta 0:00:21 lr 0.000990\t wd 0.0100\ttime 0.0381 (0.0365)\tloss 1.4756 (1.3083)\tgrad_norm 1.8686 (2.4005)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [9/100][50/625]\teta 0:00:20 lr 0.000990\t wd 0.0100\ttime 0.0326 (0.0361)\tloss 1.3936 (1.3100)\tgrad_norm 2.9599 (2.4109)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [9/100][60/625]\teta 0:00:20 lr 0.000990\t wd 0.0100\ttime 0.0359 (0.0360)\tloss 1.1406 (1.3163)\tgrad_norm 2.3091 (2.4203)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [9/100][70/625]\teta 0:00:19 lr 0.000990\t wd 0.0100\ttime 0.0354 (0.0360)\tloss 1.3477 (1.3067)\tgrad_norm 2.3386 (2.3948)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [9/100][80/625]\teta 0:00:19 lr 0.000990\t wd 0.0100\ttime 0.0391 (0.0361)\tloss 1.4902 (1.3047)\tgrad_norm 2.3577 (2.4107)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [9/100][90/625]\teta 0:00:19 lr 0.000990\t wd 0.0100\ttime 0.0347 (0.0361)\tloss 1.5723 (1.3090)\tgrad_norm 3.7401 (2.4713)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [9/100][100/625]\teta 0:00:18 lr 0.000990\t wd 0.0100\ttime 0.0355 (0.0361)\tloss 1.3486 (1.3065)\tgrad_norm 1.9733 (2.4760)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [9/100][110/625]\teta 0:00:18 lr 0.000990\t wd 0.0100\ttime 0.0392 (0.0362)\tloss 1.1465 (1.3003)\tgrad_norm 2.2790 (2.4820)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [9/100][120/625]\teta 0:00:18 lr 0.000990\t wd 0.0100\ttime 0.0363 (0.0362)\tloss 1.4150 (1.2996)\tgrad_norm 3.2034 (2.4904)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [9/100][130/625]\teta 0:00:17 lr 0.000990\t wd 0.0100\ttime 0.0396 (0.0362)\tloss 1.2832 (1.2993)\tgrad_norm 2.7902 (2.4722)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [9/100][140/625]\teta 0:00:17 lr 0.000990\t wd 0.0100\ttime 0.0331 (0.0362)\tloss 1.1709 (1.2965)\tgrad_norm 1.9462 (2.4894)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [9/100][150/625]\teta 0:00:17 lr 0.000990\t wd 0.0100\ttime 0.0357 (0.0362)\tloss 1.3281 (1.2914)\tgrad_norm 2.6428 (2.4782)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [9/100][160/625]\teta 0:00:16 lr 0.000990\t wd 0.0100\ttime 0.0327 (0.0362)\tloss 1.2324 (1.2930)\tgrad_norm 2.9029 (2.4814)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [9/100][170/625]\teta 0:00:16 lr 0.000990\t wd 0.0100\ttime 0.0334 (0.0361)\tloss 1.3711 (1.2944)\tgrad_norm 2.8940 (2.4846)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [9/100][180/625]\teta 0:00:16 lr 0.000990\t wd 0.0100\ttime 0.0362 (0.0360)\tloss 1.3809 (1.2928)\tgrad_norm 2.6162 (2.5146)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [9/100][190/625]\teta 0:00:15 lr 0.000990\t wd 0.0100\ttime 0.0361 (0.0360)\tloss 1.0215 (1.2964)\tgrad_norm 2.0659 (2.5266)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [9/100][200/625]\teta 0:00:15 lr 0.000990\t wd 0.0100\ttime 0.0355 (0.0360)\tloss 1.2393 (1.2940)\tgrad_norm 2.6733 (2.5322)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [9/100][210/625]\teta 0:00:14 lr 0.000990\t wd 0.0100\ttime 0.0357 (0.0360)\tloss 1.4727 (1.2958)\tgrad_norm 2.1464 (2.5241)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [9/100][220/625]\teta 0:00:14 lr 0.000990\t wd 0.0100\ttime 0.0397 (0.0361)\tloss 1.2490 (1.2947)\tgrad_norm 1.8768 (2.5125)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [9/100][230/625]\teta 0:00:14 lr 0.000990\t wd 0.0100\ttime 0.0395 (0.0361)\tloss 1.2803 (1.2950)\tgrad_norm 1.8233 (2.4967)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [9/100][240/625]\teta 0:00:13 lr 0.000989\t wd 0.0100\ttime 0.0333 (0.0360)\tloss 1.3691 (1.2908)\tgrad_norm 1.9958 (2.4823)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [9/100][250/625]\teta 0:00:13 lr 0.000989\t wd 0.0100\ttime 0.0353 (0.0360)\tloss 1.4531 (1.2903)\tgrad_norm 2.4747 (2.4779)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [9/100][260/625]\teta 0:00:13 lr 0.000989\t wd 0.0100\ttime 0.0389 (0.0360)\tloss 1.2236 (1.2879)\tgrad_norm 1.9553 (2.4817)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [9/100][270/625]\teta 0:00:12 lr 0.000989\t wd 0.0100\ttime 0.0331 (0.0360)\tloss 1.2070 (1.2893)\tgrad_norm 2.4186 (2.4887)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [9/100][280/625]\teta 0:00:12 lr 0.000989\t wd 0.0100\ttime 0.0359 (0.0360)\tloss 1.2920 (1.2889)\tgrad_norm 2.8090 (2.4805)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [9/100][290/625]\teta 0:00:12 lr 0.000989\t wd 0.0100\ttime 0.0369 (0.0359)\tloss 0.9937 (1.2874)\tgrad_norm 1.7261 (2.4740)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [9/100][300/625]\teta 0:00:11 lr 0.000989\t wd 0.0100\ttime 0.0328 (0.0359)\tloss 1.3564 (1.2853)\tgrad_norm 2.5523 (2.4749)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [9/100][310/625]\teta 0:00:11 lr 0.000989\t wd 0.0100\ttime 0.0327 (0.0359)\tloss 1.3438 (1.2854)\tgrad_norm 2.2883 (2.4766)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [9/100][320/625]\teta 0:00:10 lr 0.000989\t wd 0.0100\ttime 0.0361 (0.0358)\tloss 1.3564 (1.2828)\tgrad_norm 1.9789 (2.4836)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [9/100][330/625]\teta 0:00:10 lr 0.000989\t wd 0.0100\ttime 0.0352 (0.0358)\tloss 1.1094 (1.2821)\tgrad_norm 2.2144 (2.4839)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [9/100][340/625]\teta 0:00:10 lr 0.000989\t wd 0.0100\ttime 0.0364 (0.0358)\tloss 1.4268 (1.2817)\tgrad_norm 2.5996 (2.4809)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [9/100][350/625]\teta 0:00:09 lr 0.000989\t wd 0.0100\ttime 0.0362 (0.0358)\tloss 1.1592 (1.2836)\tgrad_norm 2.1921 (2.4853)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [9/100][360/625]\teta 0:00:09 lr 0.000989\t wd 0.0100\ttime 0.0328 (0.0357)\tloss 1.3457 (1.2847)\tgrad_norm 2.0737 (2.4823)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [9/100][370/625]\teta 0:00:09 lr 0.000989\t wd 0.0100\ttime 0.0327 (0.0357)\tloss 1.3311 (1.2834)\tgrad_norm 3.1052 (2.4775)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [9/100][380/625]\teta 0:00:08 lr 0.000989\t wd 0.0100\ttime 0.0333 (0.0357)\tloss 1.1738 (1.2814)\tgrad_norm 2.0740 (nan)\tloss_scale 32768.0000 (32854.0052)\tmem 455MB\n",
      "Train: [9/100][390/625]\teta 0:00:08 lr 0.000989\t wd 0.0100\ttime 0.0325 (0.0357)\tloss 1.1250 (1.2793)\tgrad_norm 2.1551 (nan)\tloss_scale 32768.0000 (32851.8056)\tmem 455MB\n",
      "Train: [9/100][400/625]\teta 0:00:08 lr 0.000989\t wd 0.0100\ttime 0.0355 (0.0357)\tloss 1.1904 (1.2796)\tgrad_norm 2.0097 (nan)\tloss_scale 32768.0000 (32849.7157)\tmem 455MB\n",
      "Train: [9/100][410/625]\teta 0:00:07 lr 0.000989\t wd 0.0100\ttime 0.0327 (0.0356)\tloss 1.2275 (1.2791)\tgrad_norm 3.1021 (nan)\tloss_scale 32768.0000 (32847.7275)\tmem 455MB\n",
      "Train: [9/100][420/625]\teta 0:00:07 lr 0.000988\t wd 0.0100\ttime 0.0330 (0.0356)\tloss 1.5732 (1.2795)\tgrad_norm 2.4470 (nan)\tloss_scale 32768.0000 (32845.8337)\tmem 455MB\n",
      "Train: [9/100][430/625]\teta 0:00:06 lr 0.000988\t wd 0.0100\ttime 0.0383 (0.0356)\tloss 1.1924 (1.2788)\tgrad_norm 1.5974 (nan)\tloss_scale 32768.0000 (32844.0278)\tmem 455MB\n",
      "Train: [9/100][440/625]\teta 0:00:06 lr 0.000988\t wd 0.0100\ttime 0.0326 (0.0357)\tloss 1.0088 (1.2782)\tgrad_norm 2.1656 (nan)\tloss_scale 32768.0000 (32842.3039)\tmem 455MB\n",
      "Train: [9/100][450/625]\teta 0:00:06 lr 0.000988\t wd 0.0100\ttime 0.0365 (0.0357)\tloss 1.4697 (1.2784)\tgrad_norm 2.2082 (nan)\tloss_scale 32768.0000 (32840.6563)\tmem 455MB\n",
      "Train: [9/100][460/625]\teta 0:00:05 lr 0.000988\t wd 0.0100\ttime 0.0325 (0.0357)\tloss 1.4033 (1.2808)\tgrad_norm 2.6996 (nan)\tloss_scale 32768.0000 (32839.0803)\tmem 455MB\n",
      "Train: [9/100][470/625]\teta 0:00:05 lr 0.000988\t wd 0.0100\ttime 0.0333 (0.0357)\tloss 1.2002 (1.2806)\tgrad_norm 3.4872 (nan)\tloss_scale 32768.0000 (32837.5711)\tmem 455MB\n",
      "Train: [9/100][480/625]\teta 0:00:05 lr 0.000988\t wd 0.0100\ttime 0.0355 (0.0356)\tloss 1.3271 (1.2815)\tgrad_norm 6.0691 (nan)\tloss_scale 32768.0000 (32836.1247)\tmem 455MB\n",
      "Train: [9/100][490/625]\teta 0:00:04 lr 0.000988\t wd 0.0100\ttime 0.0329 (0.0356)\tloss 1.0479 (1.2801)\tgrad_norm 2.9753 (nan)\tloss_scale 32768.0000 (32834.7373)\tmem 455MB\n",
      "Train: [9/100][500/625]\teta 0:00:04 lr 0.000988\t wd 0.0100\ttime 0.0325 (0.0356)\tloss 1.4941 (1.2809)\tgrad_norm 3.7240 (nan)\tloss_scale 32768.0000 (32833.4052)\tmem 455MB\n",
      "Train: [9/100][510/625]\teta 0:00:04 lr 0.000988\t wd 0.0100\ttime 0.0356 (0.0356)\tloss 1.1367 (1.2808)\tgrad_norm 2.3755 (nan)\tloss_scale 32768.0000 (32832.1252)\tmem 455MB\n",
      "Train: [9/100][520/625]\teta 0:00:03 lr 0.000988\t wd 0.0100\ttime 0.0326 (0.0356)\tloss 1.2061 (1.2827)\tgrad_norm 2.1019 (nan)\tloss_scale 32768.0000 (32830.8944)\tmem 455MB\n",
      "Train: [9/100][530/625]\teta 0:00:03 lr 0.000988\t wd 0.0100\ttime 0.0356 (0.0356)\tloss 1.1934 (1.2827)\tgrad_norm 1.8324 (nan)\tloss_scale 32768.0000 (32829.7100)\tmem 455MB\n",
      "Train: [9/100][540/625]\teta 0:00:03 lr 0.000988\t wd 0.0100\ttime 0.0391 (0.0355)\tloss 1.4766 (1.2815)\tgrad_norm 2.4800 (nan)\tloss_scale 32768.0000 (32828.5693)\tmem 455MB\n",
      "Train: [9/100][550/625]\teta 0:00:02 lr 0.000988\t wd 0.0100\ttime 0.0362 (0.0355)\tloss 1.1660 (1.2808)\tgrad_norm 3.3960 (nan)\tloss_scale 32768.0000 (32827.4701)\tmem 455MB\n",
      "Train: [9/100][560/625]\teta 0:00:02 lr 0.000988\t wd 0.0100\ttime 0.0330 (0.0355)\tloss 1.1885 (1.2799)\tgrad_norm 2.2817 (nan)\tloss_scale 32768.0000 (32826.4100)\tmem 455MB\n",
      "Train: [9/100][570/625]\teta 0:00:01 lr 0.000988\t wd 0.0100\ttime 0.0329 (0.0355)\tloss 1.1016 (1.2800)\tgrad_norm 1.9061 (nan)\tloss_scale 32768.0000 (32825.3870)\tmem 455MB\n",
      "Train: [9/100][580/625]\teta 0:00:01 lr 0.000988\t wd 0.0100\ttime 0.0328 (0.0355)\tloss 1.3135 (1.2799)\tgrad_norm 2.4191 (nan)\tloss_scale 32768.0000 (32824.3993)\tmem 455MB\n",
      "Train: [9/100][590/625]\teta 0:00:01 lr 0.000988\t wd 0.0100\ttime 0.0400 (0.0356)\tloss 1.3340 (1.2804)\tgrad_norm 2.2553 (nan)\tloss_scale 32768.0000 (32823.4450)\tmem 455MB\n",
      "Train: [9/100][600/625]\teta 0:00:00 lr 0.000987\t wd 0.0100\ttime 0.0347 (0.0356)\tloss 1.4229 (1.2805)\tgrad_norm 2.2421 (nan)\tloss_scale 32768.0000 (32822.5225)\tmem 455MB\n",
      "Train: [9/100][610/625]\teta 0:00:00 lr 0.000987\t wd 0.0100\ttime 0.0332 (0.0356)\tloss 1.3232 (1.2804)\tgrad_norm 2.4896 (nan)\tloss_scale 32768.0000 (32821.6301)\tmem 455MB\n",
      "Train: [9/100][620/625]\teta 0:00:00 lr 0.000987\t wd 0.0100\ttime 0.0357 (0.0356)\tloss 1.1631 (1.2795)\tgrad_norm 2.9506 (nan)\tloss_scale 32768.0000 (32820.7665)\tmem 455MB\n",
      "EPOCH 9 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_9.pth saving......\n",
      "./model_save/ckpt_epoch_9.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 1.4229 (1.4229)\tAcc@1 50.000 (50.000)\tAcc@5 92.188 (92.188)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 1.2676 (1.1851)\tAcc@1 51.562 (57.670)\tAcc@5 96.875 (95.170)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 1.2979 (1.2023)\tAcc@1 53.125 (56.399)\tAcc@5 90.625 (95.089)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 1.2793 (1.2391)\tAcc@1 46.875 (54.688)\tAcc@5 95.312 (95.161)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 1.1680 (1.2456)\tAcc@1 53.125 (54.688)\tAcc@5 98.438 (94.970)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 1.1719 (1.2384)\tAcc@1 53.125 (54.688)\tAcc@5 95.312 (95.006)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 1.1748 (1.2359)\tAcc@1 57.812 (55.302)\tAcc@5 95.312 (94.800)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 1.4482 (1.2301)\tAcc@1 56.250 (55.810)\tAcc@5 92.188 (94.850)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 1.1963 (1.2311)\tAcc@1 54.688 (55.883)\tAcc@5 93.750 (94.792)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 1.0596 (1.2339)\tAcc@1 62.500 (55.512)\tAcc@5 93.750 (94.712)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 1.1826 (1.2312)\tAcc@1 50.000 (55.538)\tAcc@5 98.438 (94.771)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 1.3574 (1.2328)\tAcc@1 53.125 (55.293)\tAcc@5 90.625 (94.721)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 1.0215 (1.2345)\tAcc@1 64.062 (55.191)\tAcc@5 96.875 (94.718)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 1.4424 (1.2356)\tAcc@1 51.562 (55.010)\tAcc@5 96.875 (94.680)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 1.1260 (1.2324)\tAcc@1 64.062 (55.164)\tAcc@5 95.312 (94.692)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 1.0137 (1.2278)\tAcc@1 62.500 (55.360)\tAcc@5 95.312 (94.723)\tMem 455MB\n",
      " * Acc@1 55.390 Acc@5 94.780\n",
      "Accuracy of the network on the 10000 test images: 55.4%\n",
      "Max accuracy: 55.39%\n",
      "Train: [10/100][0/625]\teta 0:00:25 lr 0.000987\t wd 0.0100\ttime 0.0405 (0.0405)\tloss 1.3301 (1.3301)\tgrad_norm 3.3103 (3.3103)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][10/625]\teta 0:00:21 lr 0.000987\t wd 0.0100\ttime 0.0328 (0.0354)\tloss 0.9302 (1.2722)\tgrad_norm 2.7478 (2.9637)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][20/625]\teta 0:00:21 lr 0.000987\t wd 0.0100\ttime 0.0365 (0.0354)\tloss 1.4766 (1.2956)\tgrad_norm 3.5777 (2.8206)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][30/625]\teta 0:00:20 lr 0.000987\t wd 0.0100\ttime 0.0353 (0.0353)\tloss 1.4092 (1.2945)\tgrad_norm 2.6011 (2.7345)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][40/625]\teta 0:00:20 lr 0.000987\t wd 0.0100\ttime 0.0354 (0.0352)\tloss 1.1230 (1.2920)\tgrad_norm 2.0822 (2.6647)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][50/625]\teta 0:00:20 lr 0.000987\t wd 0.0100\ttime 0.0391 (0.0355)\tloss 1.2109 (1.2846)\tgrad_norm 2.8999 (2.6378)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][60/625]\teta 0:00:20 lr 0.000987\t wd 0.0100\ttime 0.0346 (0.0355)\tloss 1.2979 (1.2808)\tgrad_norm 2.6678 (2.7192)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][70/625]\teta 0:00:19 lr 0.000987\t wd 0.0100\ttime 0.0328 (0.0352)\tloss 1.3398 (1.2850)\tgrad_norm 2.1124 (2.6742)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][80/625]\teta 0:00:19 lr 0.000987\t wd 0.0100\ttime 0.0329 (0.0351)\tloss 1.1924 (1.2852)\tgrad_norm 16.9081 (2.7979)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][90/625]\teta 0:00:18 lr 0.000987\t wd 0.0100\ttime 0.0349 (0.0351)\tloss 1.1826 (1.2818)\tgrad_norm 2.6863 (2.7467)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][100/625]\teta 0:00:18 lr 0.000987\t wd 0.0100\ttime 0.0364 (0.0352)\tloss 1.2764 (1.2780)\tgrad_norm 2.5139 (2.7201)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][110/625]\teta 0:00:18 lr 0.000987\t wd 0.0100\ttime 0.0358 (0.0354)\tloss 1.1758 (1.2762)\tgrad_norm 2.1881 (2.7276)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][120/625]\teta 0:00:17 lr 0.000987\t wd 0.0100\ttime 0.0374 (0.0355)\tloss 1.3438 (1.2761)\tgrad_norm 3.4823 (2.7633)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][130/625]\teta 0:00:17 lr 0.000987\t wd 0.0100\ttime 0.0331 (0.0356)\tloss 1.1738 (1.2784)\tgrad_norm 2.0447 (2.7610)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][140/625]\teta 0:00:17 lr 0.000987\t wd 0.0100\ttime 0.0363 (0.0357)\tloss 1.3105 (1.2845)\tgrad_norm 2.1998 (2.7667)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][150/625]\teta 0:00:16 lr 0.000986\t wd 0.0100\ttime 0.0397 (0.0358)\tloss 1.2412 (1.2840)\tgrad_norm 2.2961 (2.7456)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][160/625]\teta 0:00:16 lr 0.000986\t wd 0.0100\ttime 0.0393 (0.0359)\tloss 1.3066 (1.2840)\tgrad_norm 2.4460 (2.7309)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][170/625]\teta 0:00:16 lr 0.000986\t wd 0.0100\ttime 0.0330 (0.0358)\tloss 1.1846 (1.2853)\tgrad_norm 1.9915 (2.7180)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][180/625]\teta 0:00:16 lr 0.000986\t wd 0.0100\ttime 0.0398 (0.0360)\tloss 1.2764 (1.2870)\tgrad_norm 2.2694 (2.7186)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][190/625]\teta 0:00:15 lr 0.000986\t wd 0.0100\ttime 0.0331 (0.0361)\tloss 1.3301 (1.2859)\tgrad_norm 2.3642 (2.6922)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][200/625]\teta 0:00:15 lr 0.000986\t wd 0.0100\ttime 0.0365 (0.0361)\tloss 1.2500 (1.2830)\tgrad_norm 2.1472 (2.7006)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][210/625]\teta 0:00:14 lr 0.000986\t wd 0.0100\ttime 0.0333 (0.0360)\tloss 1.2451 (1.2822)\tgrad_norm 2.4132 (2.6954)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][220/625]\teta 0:00:14 lr 0.000986\t wd 0.0100\ttime 0.0373 (0.0360)\tloss 1.1816 (1.2814)\tgrad_norm 2.1876 (2.6892)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][230/625]\teta 0:00:14 lr 0.000986\t wd 0.0100\ttime 0.0358 (0.0360)\tloss 1.3086 (1.2796)\tgrad_norm 3.2705 (2.6860)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][240/625]\teta 0:00:13 lr 0.000986\t wd 0.0100\ttime 0.0407 (0.0361)\tloss 1.4238 (1.2803)\tgrad_norm 2.7728 (2.6869)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][250/625]\teta 0:00:13 lr 0.000986\t wd 0.0100\ttime 0.0329 (0.0361)\tloss 1.1201 (1.2828)\tgrad_norm 2.6756 (2.6869)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][260/625]\teta 0:00:13 lr 0.000986\t wd 0.0100\ttime 0.0385 (0.0361)\tloss 1.1914 (1.2820)\tgrad_norm 2.5344 (2.6917)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][270/625]\teta 0:00:12 lr 0.000986\t wd 0.0100\ttime 0.0346 (0.0360)\tloss 1.4521 (1.2822)\tgrad_norm 3.0746 (2.6920)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][280/625]\teta 0:00:12 lr 0.000986\t wd 0.0100\ttime 0.0372 (0.0361)\tloss 1.4297 (1.2809)\tgrad_norm 3.0122 (2.6918)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][290/625]\teta 0:00:12 lr 0.000986\t wd 0.0100\ttime 0.0405 (0.0361)\tloss 1.2334 (1.2799)\tgrad_norm 2.2378 (2.6838)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][300/625]\teta 0:00:11 lr 0.000986\t wd 0.0100\ttime 0.0421 (0.0361)\tloss 1.3252 (1.2793)\tgrad_norm 3.0656 (2.6786)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][310/625]\teta 0:00:11 lr 0.000985\t wd 0.0100\ttime 0.0334 (0.0361)\tloss 1.1758 (1.2761)\tgrad_norm 2.1148 (2.6687)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][320/625]\teta 0:00:11 lr 0.000985\t wd 0.0100\ttime 0.0391 (0.0362)\tloss 1.1738 (1.2767)\tgrad_norm 2.2479 (2.6594)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][330/625]\teta 0:00:10 lr 0.000985\t wd 0.0100\ttime 0.0365 (0.0362)\tloss 1.2061 (1.2747)\tgrad_norm 2.0979 (2.6464)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][340/625]\teta 0:00:10 lr 0.000985\t wd 0.0100\ttime 0.0336 (0.0362)\tloss 1.1924 (1.2745)\tgrad_norm 1.9237 (2.6321)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][350/625]\teta 0:00:09 lr 0.000985\t wd 0.0100\ttime 0.0383 (0.0363)\tloss 1.3301 (1.2729)\tgrad_norm 2.6747 (2.6246)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][360/625]\teta 0:00:09 lr 0.000985\t wd 0.0100\ttime 0.0358 (0.0363)\tloss 1.4248 (1.2735)\tgrad_norm 2.7779 (2.6179)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][370/625]\teta 0:00:09 lr 0.000985\t wd 0.0100\ttime 0.0336 (0.0363)\tloss 1.1006 (1.2742)\tgrad_norm 2.5820 (2.6198)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][380/625]\teta 0:00:08 lr 0.000985\t wd 0.0100\ttime 0.0400 (0.0363)\tloss 1.4131 (1.2753)\tgrad_norm 2.3073 (2.6240)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][390/625]\teta 0:00:08 lr 0.000985\t wd 0.0100\ttime 0.0368 (0.0363)\tloss 1.2803 (1.2740)\tgrad_norm 2.5566 (2.6151)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][400/625]\teta 0:00:08 lr 0.000985\t wd 0.0100\ttime 0.0364 (0.0363)\tloss 1.3320 (1.2721)\tgrad_norm 2.8596 (2.6327)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][410/625]\teta 0:00:07 lr 0.000985\t wd 0.0100\ttime 0.0358 (0.0363)\tloss 1.3115 (1.2726)\tgrad_norm 2.6919 (2.6439)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][420/625]\teta 0:00:07 lr 0.000985\t wd 0.0100\ttime 0.0404 (0.0363)\tloss 1.1992 (1.2734)\tgrad_norm 2.6681 (2.6474)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][430/625]\teta 0:00:07 lr 0.000985\t wd 0.0100\ttime 0.0363 (0.0363)\tloss 1.2119 (1.2736)\tgrad_norm 1.7904 (2.6446)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][440/625]\teta 0:00:06 lr 0.000985\t wd 0.0100\ttime 0.0358 (0.0363)\tloss 1.0791 (1.2723)\tgrad_norm 2.0831 (2.6340)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][450/625]\teta 0:00:06 lr 0.000985\t wd 0.0100\ttime 0.0389 (0.0363)\tloss 1.3613 (1.2725)\tgrad_norm 3.0833 (2.6331)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][460/625]\teta 0:00:05 lr 0.000985\t wd 0.0100\ttime 0.0326 (0.0363)\tloss 1.4170 (1.2716)\tgrad_norm 2.5065 (2.6293)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][470/625]\teta 0:00:05 lr 0.000984\t wd 0.0100\ttime 0.0334 (0.0363)\tloss 1.2949 (1.2714)\tgrad_norm 2.6626 (2.6259)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][480/625]\teta 0:00:05 lr 0.000984\t wd 0.0100\ttime 0.0325 (0.0362)\tloss 1.4092 (1.2714)\tgrad_norm 2.7491 (2.6268)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][490/625]\teta 0:00:04 lr 0.000984\t wd 0.0100\ttime 0.0334 (0.0362)\tloss 1.0596 (1.2707)\tgrad_norm 2.4760 (2.6229)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][500/625]\teta 0:00:04 lr 0.000984\t wd 0.0100\ttime 0.0325 (0.0361)\tloss 1.1484 (1.2706)\tgrad_norm 2.8414 (2.6231)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][510/625]\teta 0:00:04 lr 0.000984\t wd 0.0100\ttime 0.0329 (0.0361)\tloss 1.3516 (1.2712)\tgrad_norm 2.7181 (2.6163)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][520/625]\teta 0:00:03 lr 0.000984\t wd 0.0100\ttime 0.0394 (0.0361)\tloss 1.2324 (1.2710)\tgrad_norm 2.4801 (2.6226)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][530/625]\teta 0:00:03 lr 0.000984\t wd 0.0100\ttime 0.0326 (0.0361)\tloss 1.3252 (1.2720)\tgrad_norm 2.3286 (2.6210)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][540/625]\teta 0:00:03 lr 0.000984\t wd 0.0100\ttime 0.0341 (0.0360)\tloss 1.3701 (1.2738)\tgrad_norm 2.8727 (2.6215)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][550/625]\teta 0:00:02 lr 0.000984\t wd 0.0100\ttime 0.0356 (0.0360)\tloss 1.1680 (1.2736)\tgrad_norm 2.6509 (2.6192)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][560/625]\teta 0:00:02 lr 0.000984\t wd 0.0100\ttime 0.0362 (0.0360)\tloss 1.1172 (1.2729)\tgrad_norm 2.0452 (2.6166)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][570/625]\teta 0:00:01 lr 0.000984\t wd 0.0100\ttime 0.0332 (0.0360)\tloss 1.3047 (1.2718)\tgrad_norm 2.8626 (2.6130)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][580/625]\teta 0:00:01 lr 0.000984\t wd 0.0100\ttime 0.0364 (0.0360)\tloss 1.2314 (1.2714)\tgrad_norm 2.8064 (2.6142)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][590/625]\teta 0:00:01 lr 0.000984\t wd 0.0100\ttime 0.0385 (0.0360)\tloss 1.4160 (1.2717)\tgrad_norm 3.1233 (2.6143)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][600/625]\teta 0:00:00 lr 0.000984\t wd 0.0100\ttime 0.0343 (0.0360)\tloss 1.2158 (1.2711)\tgrad_norm 2.1806 (2.6098)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][610/625]\teta 0:00:00 lr 0.000984\t wd 0.0100\ttime 0.0390 (0.0360)\tloss 1.3262 (1.2703)\tgrad_norm 2.5586 (2.6044)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [10/100][620/625]\teta 0:00:00 lr 0.000984\t wd 0.0100\ttime 0.0363 (0.0360)\tloss 1.5361 (1.2701)\tgrad_norm 2.8288 (2.5998)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 10 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_10.pth saving......\n",
      "./model_save/ckpt_epoch_10.pth saved !!!\n",
      "Test: [0/157]\tTime 0.017 (0.017)\tLoss 1.0195 (1.0195)\tAcc@1 60.938 (60.938)\tAcc@5 98.438 (98.438)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 1.3467 (1.1947)\tAcc@1 53.125 (56.108)\tAcc@5 93.750 (95.881)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.016 (0.016)\tLoss 1.2207 (1.1881)\tAcc@1 48.438 (56.696)\tAcc@5 100.000 (96.057)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.016 (0.016)\tLoss 1.1562 (1.1891)\tAcc@1 56.250 (57.056)\tAcc@5 98.438 (96.169)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.016)\tLoss 1.2070 (1.2006)\tAcc@1 57.812 (56.555)\tAcc@5 96.875 (96.075)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 1.1201 (1.2159)\tAcc@1 56.250 (56.127)\tAcc@5 95.312 (95.711)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.016 (0.015)\tLoss 1.3262 (1.2112)\tAcc@1 53.125 (56.327)\tAcc@5 89.062 (95.517)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 1.0557 (1.2115)\tAcc@1 62.500 (56.470)\tAcc@5 95.312 (95.290)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 1.2051 (1.2144)\tAcc@1 48.438 (55.980)\tAcc@5 96.875 (95.409)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 1.2803 (1.2162)\tAcc@1 56.250 (55.872)\tAcc@5 98.438 (95.416)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 1.1484 (1.2177)\tAcc@1 54.688 (55.848)\tAcc@5 96.875 (95.282)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 1.3350 (1.2167)\tAcc@1 53.125 (55.828)\tAcc@5 92.188 (95.298)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.016 (0.015)\tLoss 1.3447 (1.2205)\tAcc@1 50.000 (55.798)\tAcc@5 93.750 (95.274)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.016 (0.015)\tLoss 1.2461 (1.2183)\tAcc@1 51.562 (55.880)\tAcc@5 93.750 (95.265)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 1.1230 (1.2195)\tAcc@1 56.250 (55.818)\tAcc@5 98.438 (95.279)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 1.0537 (1.2143)\tAcc@1 54.688 (56.012)\tAcc@5 96.875 (95.385)\tMem 455MB\n",
      " * Acc@1 56.060 Acc@5 95.400\n",
      "Accuracy of the network on the 10000 test images: 56.1%\n",
      "Max accuracy: 56.06%\n",
      "Train: [11/100][0/625]\teta 0:00:25 lr 0.000983\t wd 0.0100\ttime 0.0401 (0.0401)\tloss 1.1338 (1.1338)\tgrad_norm 2.3110 (2.3110)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][10/625]\teta 0:00:22 lr 0.000983\t wd 0.0100\ttime 0.0356 (0.0371)\tloss 1.2422 (1.1996)\tgrad_norm 2.9016 (2.6965)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][20/625]\teta 0:00:22 lr 0.000983\t wd 0.0100\ttime 0.0331 (0.0371)\tloss 1.1240 (1.2475)\tgrad_norm 2.6842 (2.7038)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][30/625]\teta 0:00:21 lr 0.000983\t wd 0.0100\ttime 0.0348 (0.0368)\tloss 1.1152 (1.2381)\tgrad_norm 3.8218 (2.6976)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][40/625]\teta 0:00:21 lr 0.000983\t wd 0.0100\ttime 0.0359 (0.0366)\tloss 1.2197 (1.2508)\tgrad_norm 2.5818 (2.7031)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][50/625]\teta 0:00:20 lr 0.000983\t wd 0.0100\ttime 0.0325 (0.0364)\tloss 1.4160 (1.2479)\tgrad_norm 2.9845 (2.9014)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][60/625]\teta 0:00:20 lr 0.000983\t wd 0.0100\ttime 0.0393 (0.0363)\tloss 1.4980 (1.2646)\tgrad_norm 2.6997 (2.8645)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][70/625]\teta 0:00:20 lr 0.000983\t wd 0.0100\ttime 0.0325 (0.0363)\tloss 1.3691 (1.2707)\tgrad_norm 3.0395 (2.8512)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][80/625]\teta 0:00:19 lr 0.000983\t wd 0.0100\ttime 0.0360 (0.0364)\tloss 1.4941 (1.2701)\tgrad_norm 3.5018 (2.8243)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][90/625]\teta 0:00:19 lr 0.000983\t wd 0.0100\ttime 0.0408 (0.0364)\tloss 1.0791 (1.2678)\tgrad_norm 3.0941 (2.8179)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][100/625]\teta 0:00:19 lr 0.000983\t wd 0.0100\ttime 0.0351 (0.0364)\tloss 1.3594 (1.2639)\tgrad_norm 2.0990 (2.8000)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][110/625]\teta 0:00:18 lr 0.000983\t wd 0.0100\ttime 0.0321 (0.0361)\tloss 1.0479 (1.2611)\tgrad_norm 2.4472 (2.7860)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][120/625]\teta 0:00:18 lr 0.000983\t wd 0.0100\ttime 0.0348 (0.0359)\tloss 1.2412 (1.2608)\tgrad_norm 2.8771 (2.7887)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][130/625]\teta 0:00:17 lr 0.000983\t wd 0.0100\ttime 0.0357 (0.0357)\tloss 1.0869 (1.2578)\tgrad_norm 1.8805 (2.7607)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][140/625]\teta 0:00:17 lr 0.000983\t wd 0.0100\ttime 0.0326 (0.0356)\tloss 1.2090 (1.2542)\tgrad_norm 1.8958 (2.7526)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][150/625]\teta 0:00:16 lr 0.000982\t wd 0.0100\ttime 0.0329 (0.0355)\tloss 1.3525 (1.2525)\tgrad_norm 1.9091 (2.7222)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][160/625]\teta 0:00:16 lr 0.000982\t wd 0.0100\ttime 0.0398 (0.0355)\tloss 1.1611 (1.2490)\tgrad_norm 2.2189 (2.7008)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][170/625]\teta 0:00:16 lr 0.000982\t wd 0.0100\ttime 0.0336 (0.0356)\tloss 1.1787 (1.2522)\tgrad_norm 2.8321 (2.7085)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][180/625]\teta 0:00:15 lr 0.000982\t wd 0.0100\ttime 0.0359 (0.0356)\tloss 1.1758 (1.2510)\tgrad_norm 2.1848 (2.6922)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][190/625]\teta 0:00:15 lr 0.000982\t wd 0.0100\ttime 0.0359 (0.0357)\tloss 1.3242 (1.2554)\tgrad_norm 2.8009 (2.6811)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][200/625]\teta 0:00:15 lr 0.000982\t wd 0.0100\ttime 0.0453 (0.0358)\tloss 1.2881 (1.2542)\tgrad_norm 3.0555 (2.6686)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][210/625]\teta 0:00:14 lr 0.000982\t wd 0.0100\ttime 0.0371 (0.0358)\tloss 1.3086 (1.2514)\tgrad_norm 2.2086 (2.6559)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][220/625]\teta 0:00:14 lr 0.000982\t wd 0.0100\ttime 0.0338 (0.0359)\tloss 1.3506 (1.2531)\tgrad_norm 4.1945 (2.6646)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][230/625]\teta 0:00:14 lr 0.000982\t wd 0.0100\ttime 0.0383 (0.0359)\tloss 1.2549 (1.2509)\tgrad_norm 3.7141 (2.6583)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][240/625]\teta 0:00:13 lr 0.000982\t wd 0.0100\ttime 0.0388 (0.0359)\tloss 1.1123 (1.2495)\tgrad_norm 3.1114 (2.6536)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][250/625]\teta 0:00:13 lr 0.000982\t wd 0.0100\ttime 0.0391 (0.0360)\tloss 1.3721 (1.2478)\tgrad_norm 1.7715 (2.6369)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][260/625]\teta 0:00:13 lr 0.000982\t wd 0.0100\ttime 0.0374 (0.0360)\tloss 1.4473 (1.2449)\tgrad_norm 2.7675 (2.6350)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][270/625]\teta 0:00:12 lr 0.000982\t wd 0.0100\ttime 0.0323 (0.0360)\tloss 1.0801 (1.2424)\tgrad_norm 2.9361 (2.6426)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][280/625]\teta 0:00:12 lr 0.000982\t wd 0.0100\ttime 0.0324 (0.0359)\tloss 1.2686 (1.2401)\tgrad_norm 2.3591 (2.6410)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][290/625]\teta 0:00:11 lr 0.000982\t wd 0.0100\ttime 0.0325 (0.0358)\tloss 1.3027 (1.2377)\tgrad_norm 2.8585 (2.6395)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][300/625]\teta 0:00:11 lr 0.000981\t wd 0.0100\ttime 0.0325 (0.0357)\tloss 1.3076 (1.2368)\tgrad_norm 4.8170 (2.6556)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][310/625]\teta 0:00:11 lr 0.000981\t wd 0.0100\ttime 0.0325 (0.0356)\tloss 1.3164 (1.2388)\tgrad_norm 3.0141 (2.6625)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][320/625]\teta 0:00:10 lr 0.000981\t wd 0.0100\ttime 0.0326 (0.0356)\tloss 1.5947 (1.2391)\tgrad_norm 3.1280 (2.6614)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][330/625]\teta 0:00:10 lr 0.000981\t wd 0.0100\ttime 0.0326 (0.0355)\tloss 1.1621 (1.2385)\tgrad_norm 2.8201 (2.6500)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][340/625]\teta 0:00:10 lr 0.000981\t wd 0.0100\ttime 0.0328 (0.0354)\tloss 0.9028 (1.2372)\tgrad_norm 1.6983 (2.6357)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][350/625]\teta 0:00:09 lr 0.000981\t wd 0.0100\ttime 0.0379 (0.0355)\tloss 1.2520 (1.2374)\tgrad_norm 1.7450 (2.6249)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][360/625]\teta 0:00:09 lr 0.000981\t wd 0.0100\ttime 0.0378 (0.0355)\tloss 1.1494 (1.2379)\tgrad_norm 2.2028 (2.6167)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][370/625]\teta 0:00:09 lr 0.000981\t wd 0.0100\ttime 0.0378 (0.0356)\tloss 1.4189 (1.2387)\tgrad_norm 2.8452 (2.6066)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][380/625]\teta 0:00:08 lr 0.000981\t wd 0.0100\ttime 0.0362 (0.0357)\tloss 1.1709 (1.2399)\tgrad_norm 2.6069 (2.6060)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][390/625]\teta 0:00:08 lr 0.000981\t wd 0.0100\ttime 0.0423 (0.0357)\tloss 0.9609 (1.2414)\tgrad_norm 1.8660 (2.5996)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][400/625]\teta 0:00:08 lr 0.000981\t wd 0.0100\ttime 0.0399 (0.0357)\tloss 1.2344 (1.2399)\tgrad_norm 2.1224 (2.5893)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][410/625]\teta 0:00:07 lr 0.000981\t wd 0.0100\ttime 0.0399 (0.0357)\tloss 1.1133 (1.2380)\tgrad_norm 2.6623 (2.5861)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][420/625]\teta 0:00:07 lr 0.000981\t wd 0.0100\ttime 0.0359 (0.0357)\tloss 1.2920 (1.2376)\tgrad_norm 2.0856 (2.5824)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][430/625]\teta 0:00:06 lr 0.000981\t wd 0.0100\ttime 0.0398 (0.0357)\tloss 1.3008 (1.2379)\tgrad_norm 3.3036 (2.5860)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][440/625]\teta 0:00:06 lr 0.000980\t wd 0.0100\ttime 0.0364 (0.0357)\tloss 1.2734 (1.2384)\tgrad_norm 2.2665 (2.5817)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][450/625]\teta 0:00:06 lr 0.000980\t wd 0.0100\ttime 0.0374 (0.0357)\tloss 1.3467 (1.2384)\tgrad_norm 5.1050 (2.5824)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][460/625]\teta 0:00:05 lr 0.000980\t wd 0.0100\ttime 0.0355 (0.0357)\tloss 1.3809 (1.2388)\tgrad_norm 2.5188 (2.5793)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][470/625]\teta 0:00:05 lr 0.000980\t wd 0.0100\ttime 0.0346 (0.0357)\tloss 1.2842 (1.2390)\tgrad_norm 2.7376 (2.5773)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][480/625]\teta 0:00:05 lr 0.000980\t wd 0.0100\ttime 0.0328 (0.0358)\tloss 1.2803 (1.2389)\tgrad_norm 2.5572 (2.5714)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][490/625]\teta 0:00:04 lr 0.000980\t wd 0.0100\ttime 0.0405 (0.0358)\tloss 1.1201 (1.2393)\tgrad_norm 1.9868 (2.5756)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][500/625]\teta 0:00:04 lr 0.000980\t wd 0.0100\ttime 0.0325 (0.0357)\tloss 1.2646 (1.2386)\tgrad_norm 3.9454 (2.5791)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][510/625]\teta 0:00:04 lr 0.000980\t wd 0.0100\ttime 0.0329 (0.0357)\tloss 1.4443 (1.2396)\tgrad_norm 1.6509 (2.5757)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][520/625]\teta 0:00:03 lr 0.000980\t wd 0.0100\ttime 0.0389 (0.0357)\tloss 1.1592 (1.2400)\tgrad_norm 1.9300 (2.5682)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][530/625]\teta 0:00:03 lr 0.000980\t wd 0.0100\ttime 0.0353 (0.0357)\tloss 1.1699 (1.2389)\tgrad_norm 2.4634 (2.5647)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][540/625]\teta 0:00:03 lr 0.000980\t wd 0.0100\ttime 0.0360 (0.0357)\tloss 1.3164 (1.2386)\tgrad_norm 3.0396 (2.5666)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][550/625]\teta 0:00:02 lr 0.000980\t wd 0.0100\ttime 0.0363 (0.0357)\tloss 1.3623 (1.2403)\tgrad_norm 1.9817 (2.5646)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][560/625]\teta 0:00:02 lr 0.000980\t wd 0.0100\ttime 0.0327 (0.0357)\tloss 1.2539 (1.2404)\tgrad_norm 2.1624 (2.5596)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][570/625]\teta 0:00:01 lr 0.000980\t wd 0.0100\ttime 0.0331 (0.0357)\tloss 1.2959 (1.2392)\tgrad_norm 3.3827 (2.5568)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][580/625]\teta 0:00:01 lr 0.000979\t wd 0.0100\ttime 0.0325 (0.0356)\tloss 1.3369 (1.2380)\tgrad_norm 2.8102 (2.5546)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][590/625]\teta 0:00:01 lr 0.000979\t wd 0.0100\ttime 0.0334 (0.0356)\tloss 1.3672 (1.2388)\tgrad_norm 2.2278 (2.5646)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][600/625]\teta 0:00:00 lr 0.000979\t wd 0.0100\ttime 0.0365 (0.0356)\tloss 1.5625 (1.2406)\tgrad_norm 2.9293 (2.5686)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][610/625]\teta 0:00:00 lr 0.000979\t wd 0.0100\ttime 0.0369 (0.0356)\tloss 1.1758 (1.2406)\tgrad_norm 2.4007 (2.5687)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [11/100][620/625]\teta 0:00:00 lr 0.000979\t wd 0.0100\ttime 0.0353 (0.0356)\tloss 1.1973 (1.2399)\tgrad_norm 3.7011 (2.5716)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 11 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_11.pth saving......\n",
      "./model_save/ckpt_epoch_11.pth saved !!!\n",
      "Test: [0/157]\tTime 0.017 (0.017)\tLoss 1.2480 (1.2480)\tAcc@1 54.688 (54.688)\tAcc@5 95.312 (95.312)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 1.1846 (1.1632)\tAcc@1 59.375 (61.080)\tAcc@5 95.312 (95.028)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 1.2607 (1.2037)\tAcc@1 54.688 (58.259)\tAcc@5 93.750 (95.238)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 1.1650 (1.2024)\tAcc@1 50.000 (57.913)\tAcc@5 93.750 (95.262)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 1.3867 (1.1968)\tAcc@1 46.875 (57.355)\tAcc@5 95.312 (95.427)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 1.0938 (1.1902)\tAcc@1 59.375 (57.414)\tAcc@5 89.062 (95.527)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 1.1797 (1.1992)\tAcc@1 57.812 (57.198)\tAcc@5 96.875 (95.389)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 1.3750 (1.1950)\tAcc@1 48.438 (57.020)\tAcc@5 93.750 (95.533)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 1.0010 (1.1936)\tAcc@1 57.812 (56.790)\tAcc@5 98.438 (95.505)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 1.2100 (1.1937)\tAcc@1 62.500 (56.885)\tAcc@5 93.750 (95.381)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 1.0635 (1.1935)\tAcc@1 59.375 (56.946)\tAcc@5 96.875 (95.343)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 1.1807 (1.1920)\tAcc@1 62.500 (57.081)\tAcc@5 95.312 (95.270)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 1.0967 (1.1926)\tAcc@1 57.812 (56.857)\tAcc@5 96.875 (95.429)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 1.1836 (1.1886)\tAcc@1 56.250 (57.049)\tAcc@5 98.438 (95.468)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 1.2344 (1.1919)\tAcc@1 53.125 (56.893)\tAcc@5 89.062 (95.357)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.016 (0.015)\tLoss 1.1680 (1.1933)\tAcc@1 62.500 (56.861)\tAcc@5 93.750 (95.375)\tMem 455MB\n",
      " * Acc@1 56.840 Acc@5 95.390\n",
      "Accuracy of the network on the 10000 test images: 56.8%\n",
      "Max accuracy: 56.84%\n",
      "Train: [12/100][0/625]\teta 0:00:23 lr 0.000979\t wd 0.0100\ttime 0.0369 (0.0369)\tloss 1.1738 (1.1738)\tgrad_norm 2.3554 (2.3554)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][10/625]\teta 0:00:21 lr 0.000979\t wd 0.0100\ttime 0.0354 (0.0353)\tloss 1.3740 (1.2480)\tgrad_norm 2.2481 (2.7909)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][20/625]\teta 0:00:21 lr 0.000979\t wd 0.0100\ttime 0.0324 (0.0351)\tloss 1.1475 (1.2186)\tgrad_norm 2.2670 (2.8635)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][30/625]\teta 0:00:21 lr 0.000979\t wd 0.0100\ttime 0.0354 (0.0355)\tloss 1.3838 (1.1898)\tgrad_norm 2.6855 (2.8110)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][40/625]\teta 0:00:20 lr 0.000979\t wd 0.0100\ttime 0.0326 (0.0355)\tloss 1.2197 (1.2144)\tgrad_norm 2.0956 (2.7493)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][50/625]\teta 0:00:20 lr 0.000979\t wd 0.0100\ttime 0.0328 (0.0357)\tloss 1.0762 (1.2171)\tgrad_norm 1.8976 (2.8133)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][60/625]\teta 0:00:20 lr 0.000979\t wd 0.0100\ttime 0.0355 (0.0358)\tloss 1.1309 (1.2141)\tgrad_norm 1.7581 (2.8223)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][70/625]\teta 0:00:19 lr 0.000979\t wd 0.0100\ttime 0.0327 (0.0359)\tloss 1.1592 (1.2124)\tgrad_norm 1.9121 (2.7825)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][80/625]\teta 0:00:19 lr 0.000979\t wd 0.0100\ttime 0.0328 (0.0358)\tloss 1.1719 (1.2147)\tgrad_norm 2.3216 (2.7748)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][90/625]\teta 0:00:19 lr 0.000978\t wd 0.0100\ttime 0.0328 (0.0357)\tloss 1.1934 (1.2088)\tgrad_norm 2.7391 (2.7352)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][100/625]\teta 0:00:18 lr 0.000978\t wd 0.0100\ttime 0.0354 (0.0358)\tloss 1.1035 (1.2149)\tgrad_norm 2.3997 (2.7260)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][110/625]\teta 0:00:18 lr 0.000978\t wd 0.0100\ttime 0.0357 (0.0357)\tloss 1.2344 (1.2219)\tgrad_norm 2.3950 (2.7214)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][120/625]\teta 0:00:17 lr 0.000978\t wd 0.0100\ttime 0.0357 (0.0355)\tloss 1.1084 (1.2193)\tgrad_norm 2.4938 (2.7046)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][130/625]\teta 0:00:17 lr 0.000978\t wd 0.0100\ttime 0.0329 (0.0355)\tloss 1.2021 (1.2228)\tgrad_norm 2.3457 (2.7054)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][140/625]\teta 0:00:17 lr 0.000978\t wd 0.0100\ttime 0.0329 (0.0355)\tloss 1.2910 (1.2239)\tgrad_norm 2.4383 (2.6980)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][150/625]\teta 0:00:16 lr 0.000978\t wd 0.0100\ttime 0.0388 (0.0356)\tloss 1.2256 (1.2226)\tgrad_norm 2.4832 (2.6958)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][160/625]\teta 0:00:16 lr 0.000978\t wd 0.0100\ttime 0.0358 (0.0356)\tloss 1.2061 (1.2230)\tgrad_norm 2.1987 (2.6832)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][170/625]\teta 0:00:16 lr 0.000978\t wd 0.0100\ttime 0.0392 (0.0357)\tloss 1.3223 (1.2234)\tgrad_norm 2.8042 (2.6969)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][180/625]\teta 0:00:15 lr 0.000978\t wd 0.0100\ttime 0.0357 (0.0357)\tloss 1.3125 (1.2239)\tgrad_norm 2.6274 (2.6893)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][190/625]\teta 0:00:15 lr 0.000978\t wd 0.0100\ttime 0.0394 (0.0357)\tloss 1.1484 (1.2279)\tgrad_norm 3.2508 (2.7079)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][200/625]\teta 0:00:15 lr 0.000978\t wd 0.0100\ttime 0.0361 (0.0357)\tloss 1.1973 (1.2276)\tgrad_norm 2.1823 (2.7203)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][210/625]\teta 0:00:14 lr 0.000978\t wd 0.0100\ttime 0.0392 (0.0357)\tloss 1.1162 (1.2272)\tgrad_norm 2.7641 (2.6943)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][220/625]\teta 0:00:14 lr 0.000977\t wd 0.0100\ttime 0.0351 (0.0357)\tloss 1.2715 (1.2286)\tgrad_norm 2.1607 (2.6833)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][230/625]\teta 0:00:14 lr 0.000977\t wd 0.0100\ttime 0.0389 (0.0357)\tloss 1.2998 (1.2285)\tgrad_norm 2.1816 (2.6598)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][240/625]\teta 0:00:13 lr 0.000977\t wd 0.0100\ttime 0.0324 (0.0356)\tloss 1.1025 (1.2265)\tgrad_norm 2.5548 (2.6425)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][250/625]\teta 0:00:13 lr 0.000977\t wd 0.0100\ttime 0.0353 (0.0356)\tloss 1.2969 (1.2269)\tgrad_norm 4.0068 (2.6403)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][260/625]\teta 0:00:12 lr 0.000977\t wd 0.0100\ttime 0.0360 (0.0355)\tloss 1.1582 (1.2248)\tgrad_norm 2.3383 (2.6302)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][270/625]\teta 0:00:12 lr 0.000977\t wd 0.0100\ttime 0.0357 (0.0355)\tloss 1.2363 (1.2255)\tgrad_norm 2.0417 (2.6224)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][280/625]\teta 0:00:12 lr 0.000977\t wd 0.0100\ttime 0.0388 (0.0355)\tloss 1.0918 (1.2262)\tgrad_norm 2.1131 (2.6142)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][290/625]\teta 0:00:11 lr 0.000977\t wd 0.0100\ttime 0.0345 (0.0356)\tloss 1.2451 (1.2246)\tgrad_norm 3.1023 (2.6081)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][300/625]\teta 0:00:11 lr 0.000977\t wd 0.0100\ttime 0.0364 (0.0355)\tloss 1.4326 (1.2241)\tgrad_norm 2.3924 (2.6037)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][310/625]\teta 0:00:11 lr 0.000977\t wd 0.0100\ttime 0.0395 (0.0356)\tloss 1.2129 (1.2235)\tgrad_norm 5.5178 (2.6138)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][320/625]\teta 0:00:10 lr 0.000977\t wd 0.0100\ttime 0.0360 (0.0355)\tloss 1.1807 (1.2245)\tgrad_norm 1.9766 (2.6226)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][330/625]\teta 0:00:10 lr 0.000977\t wd 0.0100\ttime 0.0329 (0.0355)\tloss 1.2471 (1.2243)\tgrad_norm 2.2981 (2.6193)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][340/625]\teta 0:00:10 lr 0.000977\t wd 0.0100\ttime 0.0330 (0.0355)\tloss 1.4189 (1.2256)\tgrad_norm 3.1078 (2.6157)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][350/625]\teta 0:00:09 lr 0.000976\t wd 0.0100\ttime 0.0370 (0.0355)\tloss 1.1777 (1.2246)\tgrad_norm 3.2111 (2.6257)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][360/625]\teta 0:00:09 lr 0.000976\t wd 0.0100\ttime 0.0347 (0.0355)\tloss 1.2012 (1.2225)\tgrad_norm 2.6991 (2.6204)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][370/625]\teta 0:00:09 lr 0.000976\t wd 0.0100\ttime 0.0357 (0.0355)\tloss 1.0801 (1.2211)\tgrad_norm 2.2663 (2.6236)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][380/625]\teta 0:00:08 lr 0.000976\t wd 0.0100\ttime 0.0333 (0.0355)\tloss 1.2334 (1.2191)\tgrad_norm 1.8343 (2.6237)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][390/625]\teta 0:00:08 lr 0.000976\t wd 0.0100\ttime 0.0399 (0.0355)\tloss 1.1064 (1.2186)\tgrad_norm 2.3629 (2.6238)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][400/625]\teta 0:00:08 lr 0.000976\t wd 0.0100\ttime 0.0406 (0.0356)\tloss 1.6436 (1.2200)\tgrad_norm 4.0793 (2.6280)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][410/625]\teta 0:00:07 lr 0.000976\t wd 0.0100\ttime 0.0366 (0.0356)\tloss 1.0498 (1.2212)\tgrad_norm 2.3635 (2.6273)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][420/625]\teta 0:00:07 lr 0.000976\t wd 0.0100\ttime 0.0363 (0.0356)\tloss 0.9639 (1.2194)\tgrad_norm 2.4657 (2.6267)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][430/625]\teta 0:00:06 lr 0.000976\t wd 0.0100\ttime 0.0337 (0.0356)\tloss 1.3262 (1.2204)\tgrad_norm 2.8854 (2.6235)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][440/625]\teta 0:00:06 lr 0.000976\t wd 0.0100\ttime 0.0332 (0.0356)\tloss 1.2236 (1.2201)\tgrad_norm 2.6094 (2.6163)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][450/625]\teta 0:00:06 lr 0.000976\t wd 0.0100\ttime 0.0331 (0.0356)\tloss 1.3623 (1.2200)\tgrad_norm 2.0116 (2.6089)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][460/625]\teta 0:00:05 lr 0.000976\t wd 0.0100\ttime 0.0331 (0.0356)\tloss 1.2666 (1.2201)\tgrad_norm 3.4440 (2.6062)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][470/625]\teta 0:00:05 lr 0.000976\t wd 0.0100\ttime 0.0329 (0.0356)\tloss 1.4209 (1.2194)\tgrad_norm 3.8527 (2.6115)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][480/625]\teta 0:00:05 lr 0.000975\t wd 0.0100\ttime 0.0327 (0.0357)\tloss 1.0029 (1.2192)\tgrad_norm 2.0918 (2.6117)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][490/625]\teta 0:00:04 lr 0.000975\t wd 0.0100\ttime 0.0332 (0.0356)\tloss 1.1611 (1.2187)\tgrad_norm 2.7419 (2.6114)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][500/625]\teta 0:00:04 lr 0.000975\t wd 0.0100\ttime 0.0354 (0.0357)\tloss 1.3398 (1.2197)\tgrad_norm 2.1708 (2.6102)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [12/100][510/625]\teta 0:00:04 lr 0.000975\t wd 0.0100\ttime 0.0329 (0.0357)\tloss 1.2129 (1.2193)\tgrad_norm 2.7625 (nan)\tloss_scale 32768.0000 (32832.1252)\tmem 455MB\n",
      "Train: [12/100][520/625]\teta 0:00:03 lr 0.000975\t wd 0.0100\ttime 0.0398 (0.0357)\tloss 1.2627 (1.2201)\tgrad_norm 2.9160 (nan)\tloss_scale 32768.0000 (32830.8944)\tmem 455MB\n",
      "Train: [12/100][530/625]\teta 0:00:03 lr 0.000975\t wd 0.0100\ttime 0.0365 (0.0357)\tloss 1.2852 (1.2207)\tgrad_norm 2.0317 (nan)\tloss_scale 32768.0000 (32829.7100)\tmem 455MB\n",
      "Train: [12/100][540/625]\teta 0:00:03 lr 0.000975\t wd 0.0100\ttime 0.0348 (0.0357)\tloss 1.3135 (1.2210)\tgrad_norm 2.9032 (nan)\tloss_scale 32768.0000 (32828.5693)\tmem 455MB\n",
      "Train: [12/100][550/625]\teta 0:00:02 lr 0.000975\t wd 0.0100\ttime 0.0393 (0.0358)\tloss 1.1221 (1.2197)\tgrad_norm 2.6787 (nan)\tloss_scale 32768.0000 (32827.4701)\tmem 455MB\n",
      "Train: [12/100][560/625]\teta 0:00:02 lr 0.000975\t wd 0.0100\ttime 0.0346 (0.0357)\tloss 1.1924 (1.2192)\tgrad_norm 2.0706 (nan)\tloss_scale 32768.0000 (32826.4100)\tmem 455MB\n",
      "Train: [12/100][570/625]\teta 0:00:01 lr 0.000975\t wd 0.0100\ttime 0.0369 (0.0357)\tloss 1.2529 (1.2180)\tgrad_norm 2.2319 (nan)\tloss_scale 32768.0000 (32825.3870)\tmem 455MB\n",
      "Train: [12/100][580/625]\teta 0:00:01 lr 0.000975\t wd 0.0100\ttime 0.0333 (0.0357)\tloss 1.1445 (1.2170)\tgrad_norm 2.2622 (nan)\tloss_scale 32768.0000 (32824.3993)\tmem 455MB\n",
      "Train: [12/100][590/625]\teta 0:00:01 lr 0.000975\t wd 0.0100\ttime 0.0327 (0.0357)\tloss 1.2441 (1.2166)\tgrad_norm 2.8974 (nan)\tloss_scale 32768.0000 (32823.4450)\tmem 455MB\n",
      "Train: [12/100][600/625]\teta 0:00:00 lr 0.000974\t wd 0.0100\ttime 0.0380 (0.0356)\tloss 1.1406 (1.2152)\tgrad_norm 2.2765 (nan)\tloss_scale 32768.0000 (32822.5225)\tmem 455MB\n",
      "Train: [12/100][610/625]\teta 0:00:00 lr 0.000974\t wd 0.0100\ttime 0.0335 (0.0356)\tloss 1.5303 (1.2158)\tgrad_norm 3.6040 (nan)\tloss_scale 32768.0000 (32821.6301)\tmem 455MB\n",
      "Train: [12/100][620/625]\teta 0:00:00 lr 0.000974\t wd 0.0100\ttime 0.0389 (0.0357)\tloss 1.1670 (1.2153)\tgrad_norm 2.1423 (nan)\tloss_scale 32768.0000 (32820.7665)\tmem 455MB\n",
      "EPOCH 12 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_12.pth saving......\n",
      "./model_save/ckpt_epoch_12.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 1.1836 (1.1836)\tAcc@1 56.250 (56.250)\tAcc@5 95.312 (95.312)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.016 (0.016)\tLoss 1.1016 (1.1936)\tAcc@1 57.812 (56.676)\tAcc@5 98.438 (96.023)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.016 (0.016)\tLoss 1.0938 (1.1502)\tAcc@1 59.375 (57.515)\tAcc@5 98.438 (96.354)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.016)\tLoss 1.1426 (1.1433)\tAcc@1 59.375 (57.308)\tAcc@5 100.000 (96.220)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.016)\tLoss 1.0469 (1.1346)\tAcc@1 56.250 (57.851)\tAcc@5 100.000 (96.494)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 1.2334 (1.1436)\tAcc@1 50.000 (57.292)\tAcc@5 96.875 (96.507)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 1.0312 (1.1363)\tAcc@1 62.500 (57.710)\tAcc@5 93.750 (96.465)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 1.1895 (1.1315)\tAcc@1 60.938 (57.945)\tAcc@5 93.750 (96.479)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.016 (0.015)\tLoss 1.2529 (1.1333)\tAcc@1 54.688 (57.793)\tAcc@5 98.438 (96.354)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.016 (0.015)\tLoss 1.0742 (1.1338)\tAcc@1 59.375 (57.812)\tAcc@5 95.312 (96.291)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 1.1846 (1.1377)\tAcc@1 57.812 (57.534)\tAcc@5 98.438 (96.272)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 1.2568 (1.1356)\tAcc@1 56.250 (57.728)\tAcc@5 90.625 (96.270)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 1.0908 (1.1386)\tAcc@1 64.062 (57.761)\tAcc@5 96.875 (96.178)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 1.1035 (1.1335)\tAcc@1 60.938 (57.860)\tAcc@5 98.438 (96.314)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 1.1768 (1.1342)\tAcc@1 57.812 (57.846)\tAcc@5 98.438 (96.310)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 1.2002 (1.1358)\tAcc@1 56.250 (57.771)\tAcc@5 100.000 (96.296)\tMem 455MB\n",
      " * Acc@1 57.750 Acc@5 96.250\n",
      "Accuracy of the network on the 10000 test images: 57.8%\n",
      "Max accuracy: 57.75%\n",
      "Train: [13/100][0/625]\teta 0:00:25 lr 0.000974\t wd 0.0100\ttime 0.0404 (0.0404)\tloss 1.1953 (1.1953)\tgrad_norm 2.1972 (2.1972)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][10/625]\teta 0:00:21 lr 0.000974\t wd 0.0100\ttime 0.0355 (0.0353)\tloss 1.0146 (1.1345)\tgrad_norm 3.1534 (2.3324)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][20/625]\teta 0:00:21 lr 0.000974\t wd 0.0100\ttime 0.0347 (0.0356)\tloss 0.9443 (1.1290)\tgrad_norm 1.9140 (2.6848)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][30/625]\teta 0:00:21 lr 0.000974\t wd 0.0100\ttime 0.0341 (0.0356)\tloss 1.1455 (1.1654)\tgrad_norm 2.8929 (2.7206)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][40/625]\teta 0:00:20 lr 0.000974\t wd 0.0100\ttime 0.0324 (0.0354)\tloss 1.4307 (1.1718)\tgrad_norm 3.1456 (2.7066)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][50/625]\teta 0:00:20 lr 0.000974\t wd 0.0100\ttime 0.0329 (0.0351)\tloss 1.2129 (1.1846)\tgrad_norm 2.6149 (2.7128)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][60/625]\teta 0:00:19 lr 0.000974\t wd 0.0100\ttime 0.0345 (0.0349)\tloss 1.0371 (1.1921)\tgrad_norm 1.9175 (2.6937)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][70/625]\teta 0:00:19 lr 0.000974\t wd 0.0100\ttime 0.0321 (0.0347)\tloss 1.0859 (1.1984)\tgrad_norm 3.0750 (2.7206)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][80/625]\teta 0:00:18 lr 0.000974\t wd 0.0100\ttime 0.0322 (0.0346)\tloss 1.3848 (1.1975)\tgrad_norm 2.8601 (2.7540)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][90/625]\teta 0:00:18 lr 0.000974\t wd 0.0100\ttime 0.0327 (0.0345)\tloss 1.0908 (1.1934)\tgrad_norm 3.2942 (2.7243)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][100/625]\teta 0:00:18 lr 0.000973\t wd 0.0100\ttime 0.0325 (0.0345)\tloss 1.3232 (1.1975)\tgrad_norm 2.8601 (2.6985)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][110/625]\teta 0:00:17 lr 0.000973\t wd 0.0100\ttime 0.0322 (0.0344)\tloss 1.4072 (1.1979)\tgrad_norm 2.1786 (2.6894)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][120/625]\teta 0:00:17 lr 0.000973\t wd 0.0100\ttime 0.0326 (0.0343)\tloss 1.2305 (1.1966)\tgrad_norm 1.6375 (2.6565)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][130/625]\teta 0:00:16 lr 0.000973\t wd 0.0100\ttime 0.0354 (0.0343)\tloss 1.2842 (1.1954)\tgrad_norm 2.3911 (2.6265)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][140/625]\teta 0:00:16 lr 0.000973\t wd 0.0100\ttime 0.0322 (0.0343)\tloss 1.0791 (1.1920)\tgrad_norm 1.9914 (2.6178)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][150/625]\teta 0:00:16 lr 0.000973\t wd 0.0100\ttime 0.0322 (0.0342)\tloss 1.0869 (1.1862)\tgrad_norm 2.7619 (2.6112)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][160/625]\teta 0:00:15 lr 0.000973\t wd 0.0100\ttime 0.0367 (0.0341)\tloss 1.1846 (1.1886)\tgrad_norm 2.3223 (2.6006)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][170/625]\teta 0:00:15 lr 0.000973\t wd 0.0100\ttime 0.0339 (0.0341)\tloss 1.0488 (1.1855)\tgrad_norm 2.3881 (2.5679)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][180/625]\teta 0:00:15 lr 0.000973\t wd 0.0100\ttime 0.0329 (0.0341)\tloss 1.1885 (1.1852)\tgrad_norm 4.4245 (2.5623)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][190/625]\teta 0:00:14 lr 0.000973\t wd 0.0100\ttime 0.0327 (0.0341)\tloss 1.5439 (1.1850)\tgrad_norm 2.0960 (2.5634)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][200/625]\teta 0:00:14 lr 0.000973\t wd 0.0100\ttime 0.0331 (0.0341)\tloss 1.1016 (1.1829)\tgrad_norm 1.9414 (2.5489)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][210/625]\teta 0:00:14 lr 0.000973\t wd 0.0100\ttime 0.0331 (0.0340)\tloss 1.0703 (1.1824)\tgrad_norm 2.0837 (2.5379)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][220/625]\teta 0:00:13 lr 0.000972\t wd 0.0100\ttime 0.0367 (0.0341)\tloss 1.2871 (1.1850)\tgrad_norm 2.9626 (2.5339)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][230/625]\teta 0:00:13 lr 0.000972\t wd 0.0100\ttime 0.0374 (0.0341)\tloss 1.1445 (1.1850)\tgrad_norm 2.4253 (2.5442)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][240/625]\teta 0:00:13 lr 0.000972\t wd 0.0100\ttime 0.0325 (0.0341)\tloss 1.1846 (1.1869)\tgrad_norm 2.4091 (2.5494)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][250/625]\teta 0:00:12 lr 0.000972\t wd 0.0100\ttime 0.0336 (0.0340)\tloss 1.2100 (1.1859)\tgrad_norm 1.7535 (2.5370)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][260/625]\teta 0:00:12 lr 0.000972\t wd 0.0100\ttime 0.0330 (0.0340)\tloss 1.2002 (1.1838)\tgrad_norm 3.2183 (2.5369)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][270/625]\teta 0:00:12 lr 0.000972\t wd 0.0100\ttime 0.0327 (0.0340)\tloss 1.3887 (1.1814)\tgrad_norm 3.6324 (2.5329)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][280/625]\teta 0:00:11 lr 0.000972\t wd 0.0100\ttime 0.0341 (0.0340)\tloss 1.1680 (1.1796)\tgrad_norm 2.0729 (2.5223)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][290/625]\teta 0:00:11 lr 0.000972\t wd 0.0100\ttime 0.0330 (0.0339)\tloss 1.5459 (1.1802)\tgrad_norm 3.5028 (2.5128)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][300/625]\teta 0:00:11 lr 0.000972\t wd 0.0100\ttime 0.0325 (0.0339)\tloss 1.0332 (1.1791)\tgrad_norm 2.6058 (2.5007)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][310/625]\teta 0:00:10 lr 0.000972\t wd 0.0100\ttime 0.0324 (0.0338)\tloss 1.1270 (1.1791)\tgrad_norm 2.0723 (2.4989)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][320/625]\teta 0:00:10 lr 0.000972\t wd 0.0100\ttime 0.0327 (0.0338)\tloss 1.2295 (1.1794)\tgrad_norm 2.2804 (2.5082)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][330/625]\teta 0:00:09 lr 0.000972\t wd 0.0100\ttime 0.0368 (0.0338)\tloss 1.0879 (1.1808)\tgrad_norm 2.2924 (2.5110)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][340/625]\teta 0:00:09 lr 0.000971\t wd 0.0100\ttime 0.0325 (0.0338)\tloss 1.2891 (1.1817)\tgrad_norm 2.6031 (2.5154)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][350/625]\teta 0:00:09 lr 0.000971\t wd 0.0100\ttime 0.0327 (0.0338)\tloss 1.0771 (1.1809)\tgrad_norm 2.0896 (2.5126)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][360/625]\teta 0:00:08 lr 0.000971\t wd 0.0100\ttime 0.0325 (0.0338)\tloss 1.1035 (1.1808)\tgrad_norm 2.3480 (2.5189)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][370/625]\teta 0:00:08 lr 0.000971\t wd 0.0100\ttime 0.0330 (0.0337)\tloss 1.2842 (1.1818)\tgrad_norm 2.4083 (2.5221)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][380/625]\teta 0:00:08 lr 0.000971\t wd 0.0100\ttime 0.0333 (0.0337)\tloss 0.8682 (1.1811)\tgrad_norm 1.9860 (2.5272)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][390/625]\teta 0:00:07 lr 0.000971\t wd 0.0100\ttime 0.0331 (0.0337)\tloss 1.1504 (1.1839)\tgrad_norm 2.2665 (2.5387)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][400/625]\teta 0:00:07 lr 0.000971\t wd 0.0100\ttime 0.0324 (0.0338)\tloss 1.3242 (1.1830)\tgrad_norm 3.5827 (2.5555)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][410/625]\teta 0:00:07 lr 0.000971\t wd 0.0100\ttime 0.0324 (0.0337)\tloss 1.0811 (1.1838)\tgrad_norm 2.1760 (2.5620)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][420/625]\teta 0:00:06 lr 0.000971\t wd 0.0100\ttime 0.0366 (0.0337)\tloss 1.0420 (1.1840)\tgrad_norm 2.0920 (2.5648)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][430/625]\teta 0:00:06 lr 0.000971\t wd 0.0100\ttime 0.0324 (0.0337)\tloss 1.2402 (1.1852)\tgrad_norm 2.7733 (2.5637)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][440/625]\teta 0:00:06 lr 0.000971\t wd 0.0100\ttime 0.0337 (0.0337)\tloss 1.3809 (1.1841)\tgrad_norm 3.1483 (2.5710)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][450/625]\teta 0:00:05 lr 0.000970\t wd 0.0100\ttime 0.0357 (0.0337)\tloss 1.1426 (1.1860)\tgrad_norm 1.9531 (2.5681)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][460/625]\teta 0:00:05 lr 0.000970\t wd 0.0100\ttime 0.0327 (0.0337)\tloss 1.0518 (1.1867)\tgrad_norm 3.4134 (2.5670)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][470/625]\teta 0:00:05 lr 0.000970\t wd 0.0100\ttime 0.0327 (0.0338)\tloss 1.2891 (1.1874)\tgrad_norm 3.2753 (2.5587)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][480/625]\teta 0:00:04 lr 0.000970\t wd 0.0100\ttime 0.0321 (0.0338)\tloss 1.1104 (1.1884)\tgrad_norm 2.9078 (2.5627)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][490/625]\teta 0:00:04 lr 0.000970\t wd 0.0100\ttime 0.0333 (0.0338)\tloss 1.2227 (1.1892)\tgrad_norm 2.1388 (2.5587)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][500/625]\teta 0:00:04 lr 0.000970\t wd 0.0100\ttime 0.0324 (0.0339)\tloss 0.9897 (1.1881)\tgrad_norm 1.9578 (2.5513)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][510/625]\teta 0:00:03 lr 0.000970\t wd 0.0100\ttime 0.0386 (0.0339)\tloss 1.1416 (1.1868)\tgrad_norm 2.3543 (2.5464)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][520/625]\teta 0:00:03 lr 0.000970\t wd 0.0100\ttime 0.0394 (0.0340)\tloss 1.1270 (1.1872)\tgrad_norm 2.7343 (2.5450)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][530/625]\teta 0:00:03 lr 0.000970\t wd 0.0100\ttime 0.0329 (0.0340)\tloss 1.0664 (1.1865)\tgrad_norm 1.6429 (2.5488)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][540/625]\teta 0:00:02 lr 0.000970\t wd 0.0100\ttime 0.0356 (0.0340)\tloss 1.3662 (1.1879)\tgrad_norm 2.1108 (2.5450)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][550/625]\teta 0:00:02 lr 0.000970\t wd 0.0100\ttime 0.0357 (0.0341)\tloss 1.1182 (1.1875)\tgrad_norm 2.5309 (2.5399)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][560/625]\teta 0:00:02 lr 0.000969\t wd 0.0100\ttime 0.0356 (0.0341)\tloss 1.1260 (1.1876)\tgrad_norm 2.3760 (2.5366)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][570/625]\teta 0:00:01 lr 0.000969\t wd 0.0100\ttime 0.0338 (0.0341)\tloss 1.0801 (1.1873)\tgrad_norm 1.9540 (2.5388)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][580/625]\teta 0:00:01 lr 0.000969\t wd 0.0100\ttime 0.0335 (0.0341)\tloss 1.0205 (1.1871)\tgrad_norm 2.8375 (2.5348)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][590/625]\teta 0:00:01 lr 0.000969\t wd 0.0100\ttime 0.0354 (0.0341)\tloss 1.2969 (1.1869)\tgrad_norm 2.9702 (2.5331)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][600/625]\teta 0:00:00 lr 0.000969\t wd 0.0100\ttime 0.0338 (0.0341)\tloss 1.1377 (1.1875)\tgrad_norm 1.6466 (2.5318)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][610/625]\teta 0:00:00 lr 0.000969\t wd 0.0100\ttime 0.0393 (0.0341)\tloss 1.0410 (1.1868)\tgrad_norm 2.0070 (2.5316)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [13/100][620/625]\teta 0:00:00 lr 0.000969\t wd 0.0100\ttime 0.0383 (0.0342)\tloss 1.2158 (1.1864)\tgrad_norm 1.9788 (2.5315)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 13 training takes 0:00:21\n",
      "./model_save/ckpt_epoch_13.pth saving......\n",
      "./model_save/ckpt_epoch_13.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 1.2432 (1.2432)\tAcc@1 50.000 (50.000)\tAcc@5 98.438 (98.438)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.9507 (1.1203)\tAcc@1 68.750 (59.375)\tAcc@5 96.875 (96.165)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.016 (0.015)\tLoss 1.1709 (1.1231)\tAcc@1 60.938 (60.193)\tAcc@5 93.750 (95.759)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 1.2783 (1.1112)\tAcc@1 48.438 (60.030)\tAcc@5 95.312 (96.018)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.016 (0.015)\tLoss 1.1182 (1.1089)\tAcc@1 56.250 (60.366)\tAcc@5 98.438 (96.227)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.016 (0.015)\tLoss 1.1729 (1.1165)\tAcc@1 51.562 (59.957)\tAcc@5 98.438 (96.354)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.016 (0.015)\tLoss 1.3291 (1.1159)\tAcc@1 53.125 (59.785)\tAcc@5 92.188 (96.183)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.016 (0.016)\tLoss 1.0146 (1.1096)\tAcc@1 60.938 (59.859)\tAcc@5 93.750 (96.281)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.016)\tLoss 1.0254 (1.1110)\tAcc@1 60.938 (59.780)\tAcc@5 98.438 (96.354)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.017 (0.016)\tLoss 0.9331 (1.1087)\tAcc@1 68.750 (59.684)\tAcc@5 98.438 (96.446)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.018 (0.016)\tLoss 0.9990 (1.1090)\tAcc@1 62.500 (59.514)\tAcc@5 98.438 (96.504)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.016)\tLoss 1.2139 (1.1144)\tAcc@1 50.000 (59.319)\tAcc@5 96.875 (96.467)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.016)\tLoss 1.0273 (1.1115)\tAcc@1 59.375 (59.401)\tAcc@5 95.312 (96.501)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 1.1416 (1.1150)\tAcc@1 60.938 (59.327)\tAcc@5 96.875 (96.517)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 1.4580 (1.1202)\tAcc@1 45.312 (59.275)\tAcc@5 90.625 (96.321)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 1.3203 (1.1252)\tAcc@1 57.812 (59.065)\tAcc@5 92.188 (96.254)\tMem 455MB\n",
      " * Acc@1 59.030 Acc@5 96.220\n",
      "Accuracy of the network on the 10000 test images: 59.0%\n",
      "Max accuracy: 59.03%\n",
      "Train: [14/100][0/625]\teta 0:00:24 lr 0.000969\t wd 0.0100\ttime 0.0398 (0.0398)\tloss 1.3564 (1.3564)\tgrad_norm 2.7184 (2.7184)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][10/625]\teta 0:00:21 lr 0.000969\t wd 0.0100\ttime 0.0356 (0.0342)\tloss 1.1885 (1.1864)\tgrad_norm 2.9735 (2.8545)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][20/625]\teta 0:00:21 lr 0.000969\t wd 0.0100\ttime 0.0367 (0.0349)\tloss 1.1387 (1.1680)\tgrad_norm 2.7334 (2.7195)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][30/625]\teta 0:00:21 lr 0.000969\t wd 0.0100\ttime 0.0327 (0.0354)\tloss 0.9224 (1.1612)\tgrad_norm 2.1516 (2.6671)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][40/625]\teta 0:00:20 lr 0.000969\t wd 0.0100\ttime 0.0388 (0.0353)\tloss 1.3984 (1.1657)\tgrad_norm 2.1178 (2.5714)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][50/625]\teta 0:00:20 lr 0.000968\t wd 0.0100\ttime 0.0342 (0.0350)\tloss 1.0234 (1.1461)\tgrad_norm 1.8214 (2.5217)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][60/625]\teta 0:00:20 lr 0.000968\t wd 0.0100\ttime 0.0397 (0.0354)\tloss 0.9966 (1.1431)\tgrad_norm 2.5319 (2.5299)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][70/625]\teta 0:00:19 lr 0.000968\t wd 0.0100\ttime 0.0327 (0.0355)\tloss 1.4121 (1.1567)\tgrad_norm 3.8745 (2.5702)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][80/625]\teta 0:00:19 lr 0.000968\t wd 0.0100\ttime 0.0332 (0.0354)\tloss 0.9956 (1.1556)\tgrad_norm 2.6647 (2.5751)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][90/625]\teta 0:00:18 lr 0.000968\t wd 0.0100\ttime 0.0340 (0.0352)\tloss 1.1387 (1.1592)\tgrad_norm 1.7835 (2.5903)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][100/625]\teta 0:00:18 lr 0.000968\t wd 0.0100\ttime 0.0365 (0.0352)\tloss 1.4033 (1.1761)\tgrad_norm 2.3478 (2.5889)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][110/625]\teta 0:00:18 lr 0.000968\t wd 0.0100\ttime 0.0370 (0.0354)\tloss 1.1348 (1.1793)\tgrad_norm 2.0435 (2.5865)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][120/625]\teta 0:00:17 lr 0.000968\t wd 0.0100\ttime 0.0376 (0.0355)\tloss 1.2520 (1.1750)\tgrad_norm 2.1075 (2.5581)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][130/625]\teta 0:00:17 lr 0.000968\t wd 0.0100\ttime 0.0338 (0.0355)\tloss 1.0596 (1.1719)\tgrad_norm 2.0520 (2.5266)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][140/625]\teta 0:00:17 lr 0.000968\t wd 0.0100\ttime 0.0544 (0.0363)\tloss 1.2617 (1.1730)\tgrad_norm 1.8774 (2.5297)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][150/625]\teta 0:00:17 lr 0.000968\t wd 0.0100\ttime 0.0341 (0.0364)\tloss 1.1611 (1.1732)\tgrad_norm 2.1823 (2.5214)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][160/625]\teta 0:00:16 lr 0.000967\t wd 0.0100\ttime 0.0591 (0.0364)\tloss 1.2158 (1.1780)\tgrad_norm 2.0179 (2.4948)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][170/625]\teta 0:00:17 lr 0.000967\t wd 0.0100\ttime 0.0709 (0.0383)\tloss 0.9761 (1.1758)\tgrad_norm 1.7165 (2.4939)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][180/625]\teta 0:00:17 lr 0.000967\t wd 0.0100\ttime 0.0626 (0.0400)\tloss 1.3555 (1.1742)\tgrad_norm 2.5734 (2.4850)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][190/625]\teta 0:00:17 lr 0.000967\t wd 0.0100\ttime 0.0629 (0.0414)\tloss 1.2383 (1.1709)\tgrad_norm 1.8648 (2.4662)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][200/625]\teta 0:00:18 lr 0.000967\t wd 0.0100\ttime 0.0676 (0.0427)\tloss 1.2100 (1.1701)\tgrad_norm 2.0801 (2.4910)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][210/625]\teta 0:00:17 lr 0.000967\t wd 0.0100\ttime 0.0351 (0.0430)\tloss 1.2109 (1.1706)\tgrad_norm 3.4956 (2.4924)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][220/625]\teta 0:00:17 lr 0.000967\t wd 0.0100\ttime 0.0708 (0.0437)\tloss 1.0986 (1.1710)\tgrad_norm 2.1262 (2.4995)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][230/625]\teta 0:00:17 lr 0.000967\t wd 0.0100\ttime 0.0571 (0.0446)\tloss 1.1211 (1.1687)\tgrad_norm 2.4583 (2.4813)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][240/625]\teta 0:00:17 lr 0.000967\t wd 0.0100\ttime 0.0819 (0.0458)\tloss 1.3301 (1.1702)\tgrad_norm 2.9048 (2.4772)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][250/625]\teta 0:00:17 lr 0.000967\t wd 0.0100\ttime 0.0720 (0.0467)\tloss 1.2061 (1.1687)\tgrad_norm 2.5213 (2.4684)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][260/625]\teta 0:00:17 lr 0.000967\t wd 0.0100\ttime 0.0680 (0.0476)\tloss 1.0986 (1.1665)\tgrad_norm 1.7419 (2.4592)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][270/625]\teta 0:00:17 lr 0.000966\t wd 0.0100\ttime 0.0643 (0.0484)\tloss 0.8604 (1.1659)\tgrad_norm 1.6295 (2.4506)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][280/625]\teta 0:00:16 lr 0.000966\t wd 0.0100\ttime 0.0725 (0.0490)\tloss 0.9424 (1.1644)\tgrad_norm 2.5534 (2.4497)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][290/625]\teta 0:00:16 lr 0.000966\t wd 0.0100\ttime 0.0707 (0.0498)\tloss 1.2100 (1.1623)\tgrad_norm 2.1565 (2.4376)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][300/625]\teta 0:00:16 lr 0.000966\t wd 0.0100\ttime 0.0721 (0.0505)\tloss 0.9409 (1.1610)\tgrad_norm 2.0443 (2.4346)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][310/625]\teta 0:00:16 lr 0.000966\t wd 0.0100\ttime 0.0680 (0.0511)\tloss 1.1611 (1.1589)\tgrad_norm 2.7608 (2.4392)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][320/625]\teta 0:00:15 lr 0.000966\t wd 0.0100\ttime 0.0663 (0.0518)\tloss 1.2480 (1.1613)\tgrad_norm 2.4322 (2.4411)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][330/625]\teta 0:00:15 lr 0.000966\t wd 0.0100\ttime 0.0658 (0.0522)\tloss 1.2656 (1.1604)\tgrad_norm 2.1172 (2.4449)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][340/625]\teta 0:00:14 lr 0.000966\t wd 0.0100\ttime 0.0624 (0.0526)\tloss 1.1914 (1.1605)\tgrad_norm 2.7541 (2.4537)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][350/625]\teta 0:00:14 lr 0.000966\t wd 0.0100\ttime 0.0675 (0.0529)\tloss 1.2451 (1.1586)\tgrad_norm 2.1412 (2.4430)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][360/625]\teta 0:00:14 lr 0.000966\t wd 0.0100\ttime 0.0360 (0.0529)\tloss 1.1211 (1.1598)\tgrad_norm 1.8963 (2.4313)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][370/625]\teta 0:00:13 lr 0.000966\t wd 0.0100\ttime 0.0433 (0.0525)\tloss 1.1172 (1.1589)\tgrad_norm 2.0891 (2.4188)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][380/625]\teta 0:00:12 lr 0.000965\t wd 0.0100\ttime 0.0360 (0.0521)\tloss 1.1582 (1.1587)\tgrad_norm 2.7693 (2.4263)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][390/625]\teta 0:00:12 lr 0.000965\t wd 0.0100\ttime 0.0353 (0.0517)\tloss 1.0137 (1.1602)\tgrad_norm 2.1739 (2.4312)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][400/625]\teta 0:00:11 lr 0.000965\t wd 0.0100\ttime 0.0333 (0.0513)\tloss 1.3027 (1.1590)\tgrad_norm 3.1013 (2.4316)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][410/625]\teta 0:00:10 lr 0.000965\t wd 0.0100\ttime 0.0388 (0.0509)\tloss 1.0430 (1.1609)\tgrad_norm 2.7448 (2.4368)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][420/625]\teta 0:00:10 lr 0.000965\t wd 0.0100\ttime 0.0343 (0.0506)\tloss 1.3066 (1.1611)\tgrad_norm 2.2083 (2.4377)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][430/625]\teta 0:00:09 lr 0.000965\t wd 0.0100\ttime 0.0354 (0.0502)\tloss 1.2744 (1.1609)\tgrad_norm 2.6677 (2.4396)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][440/625]\teta 0:00:09 lr 0.000965\t wd 0.0100\ttime 0.0372 (0.0499)\tloss 1.3779 (1.1620)\tgrad_norm 2.5575 (2.4346)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][450/625]\teta 0:00:08 lr 0.000965\t wd 0.0100\ttime 0.0346 (0.0496)\tloss 1.0723 (1.1628)\tgrad_norm 2.6683 (2.4388)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][460/625]\teta 0:00:08 lr 0.000965\t wd 0.0100\ttime 0.0350 (0.0493)\tloss 1.1914 (1.1620)\tgrad_norm 2.0139 (2.4352)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][470/625]\teta 0:00:07 lr 0.000965\t wd 0.0100\ttime 0.0327 (0.0490)\tloss 0.9087 (1.1620)\tgrad_norm 2.1795 (2.4352)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][480/625]\teta 0:00:07 lr 0.000964\t wd 0.0100\ttime 0.0371 (0.0487)\tloss 1.4375 (1.1639)\tgrad_norm 2.9893 (2.4408)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][490/625]\teta 0:00:06 lr 0.000964\t wd 0.0100\ttime 0.0374 (0.0485)\tloss 1.1240 (1.1638)\tgrad_norm 2.0801 (2.4329)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][500/625]\teta 0:00:06 lr 0.000964\t wd 0.0100\ttime 0.0375 (0.0483)\tloss 1.2041 (1.1633)\tgrad_norm 2.2587 (2.4299)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][510/625]\teta 0:00:05 lr 0.000964\t wd 0.0100\ttime 0.0341 (0.0480)\tloss 1.1963 (1.1634)\tgrad_norm 2.7330 (2.4246)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][520/625]\teta 0:00:05 lr 0.000964\t wd 0.0100\ttime 0.0369 (0.0478)\tloss 1.3145 (1.1639)\tgrad_norm 2.5122 (2.4287)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][530/625]\teta 0:00:04 lr 0.000964\t wd 0.0100\ttime 0.0373 (0.0477)\tloss 1.1523 (1.1625)\tgrad_norm 1.9973 (2.4227)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][540/625]\teta 0:00:04 lr 0.000964\t wd 0.0100\ttime 0.0375 (0.0475)\tloss 1.3232 (1.1616)\tgrad_norm 2.4889 (2.4262)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][550/625]\teta 0:00:03 lr 0.000964\t wd 0.0100\ttime 0.0354 (0.0473)\tloss 1.0967 (1.1601)\tgrad_norm 3.2268 (2.4299)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][560/625]\teta 0:00:03 lr 0.000964\t wd 0.0100\ttime 0.0404 (0.0471)\tloss 0.8809 (1.1580)\tgrad_norm 2.4721 (2.4325)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][570/625]\teta 0:00:02 lr 0.000964\t wd 0.0100\ttime 0.0363 (0.0470)\tloss 1.0479 (1.1571)\tgrad_norm 2.6610 (2.4317)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][580/625]\teta 0:00:02 lr 0.000964\t wd 0.0100\ttime 0.0346 (0.0468)\tloss 0.9399 (1.1561)\tgrad_norm 1.9826 (2.4303)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][590/625]\teta 0:00:01 lr 0.000963\t wd 0.0100\ttime 0.0333 (0.0467)\tloss 0.9814 (1.1560)\tgrad_norm 2.5103 (2.4304)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][600/625]\teta 0:00:01 lr 0.000963\t wd 0.0100\ttime 0.0344 (0.0465)\tloss 1.1543 (1.1546)\tgrad_norm 2.1315 (2.4279)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][610/625]\teta 0:00:00 lr 0.000963\t wd 0.0100\ttime 0.0352 (0.0463)\tloss 1.2500 (1.1549)\tgrad_norm 1.7066 (2.4226)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [14/100][620/625]\teta 0:00:00 lr 0.000963\t wd 0.0100\ttime 0.0380 (0.0461)\tloss 1.1064 (1.1546)\tgrad_norm 1.5575 (2.4199)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 14 training takes 0:00:28\n",
      "./model_save/ckpt_epoch_14.pth saving......\n",
      "./model_save/ckpt_epoch_14.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 1.2031 (1.2031)\tAcc@1 65.625 (65.625)\tAcc@5 90.625 (90.625)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.016)\tLoss 1.4053 (1.1357)\tAcc@1 50.000 (59.517)\tAcc@5 93.750 (95.597)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.016)\tLoss 1.1113 (1.1779)\tAcc@1 57.812 (57.589)\tAcc@5 96.875 (95.387)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.016)\tLoss 1.2686 (1.1377)\tAcc@1 54.688 (58.972)\tAcc@5 96.875 (95.817)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.016)\tLoss 1.0723 (1.1224)\tAcc@1 59.375 (59.489)\tAcc@5 96.875 (95.998)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.016)\tLoss 0.9604 (1.1175)\tAcc@1 64.062 (60.110)\tAcc@5 98.438 (96.170)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.016 (0.016)\tLoss 0.8843 (1.1256)\tAcc@1 67.188 (59.554)\tAcc@5 100.000 (95.953)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.016 (0.016)\tLoss 1.1963 (1.1137)\tAcc@1 54.688 (60.101)\tAcc@5 98.438 (96.215)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.016)\tLoss 1.1641 (1.1156)\tAcc@1 53.125 (60.012)\tAcc@5 93.750 (96.142)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.016)\tLoss 1.2578 (1.1219)\tAcc@1 53.125 (59.701)\tAcc@5 95.312 (96.154)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.016)\tLoss 1.0439 (1.1224)\tAcc@1 60.938 (59.576)\tAcc@5 100.000 (96.256)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 1.1309 (1.1197)\tAcc@1 57.812 (59.671)\tAcc@5 100.000 (96.326)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 1.1201 (1.1225)\tAcc@1 62.500 (59.582)\tAcc@5 96.875 (96.320)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 1.1523 (1.1197)\tAcc@1 57.812 (59.625)\tAcc@5 93.750 (96.386)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 1.1299 (1.1133)\tAcc@1 59.375 (59.829)\tAcc@5 96.875 (96.454)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.9717 (1.1111)\tAcc@1 64.062 (59.789)\tAcc@5 98.438 (96.471)\tMem 455MB\n",
      " * Acc@1 59.830 Acc@5 96.440\n",
      "Accuracy of the network on the 10000 test images: 59.8%\n",
      "Max accuracy: 59.83%\n",
      "Train: [15/100][0/625]\teta 0:00:21 lr 0.000963\t wd 0.0100\ttime 0.0347 (0.0347)\tloss 1.2207 (1.2207)\tgrad_norm 2.2809 (2.2809)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][10/625]\teta 0:00:21 lr 0.000963\t wd 0.0100\ttime 0.0350 (0.0348)\tloss 1.0908 (1.0796)\tgrad_norm 2.2584 (2.4344)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][20/625]\teta 0:00:21 lr 0.000963\t wd 0.0100\ttime 0.0432 (0.0356)\tloss 1.3057 (1.0809)\tgrad_norm 2.0213 (2.3336)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][30/625]\teta 0:00:21 lr 0.000963\t wd 0.0100\ttime 0.0378 (0.0365)\tloss 1.2021 (1.1161)\tgrad_norm 2.3773 (2.4285)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][40/625]\teta 0:00:21 lr 0.000963\t wd 0.0100\ttime 0.0358 (0.0369)\tloss 1.0977 (1.1232)\tgrad_norm 1.8476 (2.3548)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][50/625]\teta 0:00:20 lr 0.000963\t wd 0.0100\ttime 0.0364 (0.0365)\tloss 1.0977 (1.1356)\tgrad_norm 2.4237 (2.3084)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][60/625]\teta 0:00:20 lr 0.000962\t wd 0.0100\ttime 0.0378 (0.0369)\tloss 1.1924 (1.1299)\tgrad_norm 1.7221 (2.2962)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][70/625]\teta 0:00:20 lr 0.000962\t wd 0.0100\ttime 0.0397 (0.0371)\tloss 0.9946 (1.1193)\tgrad_norm 2.3036 (2.3375)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][80/625]\teta 0:00:20 lr 0.000962\t wd 0.0100\ttime 0.0362 (0.0370)\tloss 1.0107 (1.1207)\tgrad_norm 2.2863 (2.3339)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][90/625]\teta 0:00:19 lr 0.000962\t wd 0.0100\ttime 0.0391 (0.0369)\tloss 1.0049 (1.1306)\tgrad_norm 1.6467 (2.3622)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][100/625]\teta 0:00:19 lr 0.000962\t wd 0.0100\ttime 0.0362 (0.0370)\tloss 1.1211 (1.1284)\tgrad_norm 2.6646 (2.4337)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][110/625]\teta 0:00:19 lr 0.000962\t wd 0.0100\ttime 0.0337 (0.0369)\tloss 1.0645 (1.1290)\tgrad_norm 2.3030 (2.5018)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][120/625]\teta 0:00:18 lr 0.000962\t wd 0.0100\ttime 0.0374 (0.0369)\tloss 1.2002 (1.1277)\tgrad_norm 2.0900 (2.4775)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][130/625]\teta 0:00:18 lr 0.000962\t wd 0.0100\ttime 0.0375 (0.0369)\tloss 1.0586 (1.1264)\tgrad_norm 2.0392 (2.4513)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][140/625]\teta 0:00:17 lr 0.000962\t wd 0.0100\ttime 0.0389 (0.0370)\tloss 1.2441 (1.1294)\tgrad_norm 2.7314 (2.4415)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][150/625]\teta 0:00:17 lr 0.000962\t wd 0.0100\ttime 0.0368 (0.0370)\tloss 1.1230 (1.1276)\tgrad_norm 2.5973 (2.4602)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][160/625]\teta 0:00:17 lr 0.000962\t wd 0.0100\ttime 0.0359 (0.0371)\tloss 0.9795 (1.1271)\tgrad_norm 1.8835 (2.4615)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][170/625]\teta 0:00:16 lr 0.000961\t wd 0.0100\ttime 0.0400 (0.0371)\tloss 1.2969 (1.1246)\tgrad_norm 2.1590 (2.4868)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][180/625]\teta 0:00:16 lr 0.000961\t wd 0.0100\ttime 0.0358 (0.0370)\tloss 1.0898 (1.1261)\tgrad_norm 2.0423 (2.4844)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][190/625]\teta 0:00:16 lr 0.000961\t wd 0.0100\ttime 0.0395 (0.0371)\tloss 0.9653 (1.1251)\tgrad_norm 2.5596 (2.4826)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][200/625]\teta 0:00:15 lr 0.000961\t wd 0.0100\ttime 0.0391 (0.0372)\tloss 1.0088 (1.1264)\tgrad_norm 2.1703 (2.4674)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][210/625]\teta 0:00:15 lr 0.000961\t wd 0.0100\ttime 0.0381 (0.0372)\tloss 1.3486 (1.1306)\tgrad_norm 1.6674 (2.4625)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][220/625]\teta 0:00:15 lr 0.000961\t wd 0.0100\ttime 0.0382 (0.0372)\tloss 1.0859 (1.1309)\tgrad_norm 1.8368 (2.4447)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][230/625]\teta 0:00:14 lr 0.000961\t wd 0.0100\ttime 0.0381 (0.0372)\tloss 1.3115 (1.1324)\tgrad_norm 2.5573 (2.4534)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][240/625]\teta 0:00:14 lr 0.000961\t wd 0.0100\ttime 0.0359 (0.0371)\tloss 1.0947 (1.1370)\tgrad_norm 2.3089 (2.4564)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][250/625]\teta 0:00:13 lr 0.000961\t wd 0.0100\ttime 0.0336 (0.0371)\tloss 1.1885 (1.1361)\tgrad_norm 2.2966 (2.4522)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][260/625]\teta 0:00:13 lr 0.000961\t wd 0.0100\ttime 0.0335 (0.0370)\tloss 1.1582 (1.1337)\tgrad_norm 3.2547 (2.4445)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][270/625]\teta 0:00:13 lr 0.000960\t wd 0.0100\ttime 0.0348 (0.0370)\tloss 1.0674 (1.1335)\tgrad_norm 2.3107 (2.4416)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][280/625]\teta 0:00:12 lr 0.000960\t wd 0.0100\ttime 0.0368 (0.0370)\tloss 1.0254 (1.1343)\tgrad_norm 2.0266 (2.4399)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][290/625]\teta 0:00:12 lr 0.000960\t wd 0.0100\ttime 0.0365 (0.0369)\tloss 0.9648 (1.1344)\tgrad_norm 2.1992 (2.4467)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][300/625]\teta 0:00:11 lr 0.000960\t wd 0.0100\ttime 0.0360 (0.0369)\tloss 1.3262 (1.1333)\tgrad_norm 3.0828 (2.4384)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][310/625]\teta 0:00:11 lr 0.000960\t wd 0.0100\ttime 0.0356 (0.0368)\tloss 0.9893 (1.1330)\tgrad_norm 1.9658 (2.4329)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][320/625]\teta 0:00:11 lr 0.000960\t wd 0.0100\ttime 0.0362 (0.0368)\tloss 0.8740 (1.1298)\tgrad_norm 2.4103 (2.4223)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][330/625]\teta 0:00:10 lr 0.000960\t wd 0.0100\ttime 0.0343 (0.0368)\tloss 1.3506 (1.1296)\tgrad_norm 3.4689 (2.4168)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][340/625]\teta 0:00:10 lr 0.000960\t wd 0.0100\ttime 0.0372 (0.0368)\tloss 1.3398 (1.1300)\tgrad_norm 3.1399 (2.4121)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][350/625]\teta 0:00:10 lr 0.000960\t wd 0.0100\ttime 0.0364 (0.0368)\tloss 1.1465 (1.1318)\tgrad_norm 2.3634 (2.4143)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][360/625]\teta 0:00:09 lr 0.000960\t wd 0.0100\ttime 0.0344 (0.0368)\tloss 1.3115 (1.1286)\tgrad_norm 2.0694 (2.3982)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][370/625]\teta 0:00:09 lr 0.000959\t wd 0.0100\ttime 0.0356 (0.0368)\tloss 1.0791 (1.1273)\tgrad_norm 2.1525 (2.4011)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][380/625]\teta 0:00:09 lr 0.000959\t wd 0.0100\ttime 0.0376 (0.0368)\tloss 1.0127 (1.1254)\tgrad_norm 2.1450 (2.4004)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][390/625]\teta 0:00:08 lr 0.000959\t wd 0.0100\ttime 0.0336 (0.0368)\tloss 1.3887 (1.1271)\tgrad_norm 2.5207 (2.4040)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][400/625]\teta 0:00:08 lr 0.000959\t wd 0.0100\ttime 0.0361 (0.0368)\tloss 1.0938 (1.1268)\tgrad_norm 2.4765 (2.4137)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][410/625]\teta 0:00:07 lr 0.000959\t wd 0.0100\ttime 0.0376 (0.0368)\tloss 1.0215 (1.1276)\tgrad_norm 2.4272 (2.4123)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][420/625]\teta 0:00:07 lr 0.000959\t wd 0.0100\ttime 0.0403 (0.0368)\tloss 1.2217 (1.1282)\tgrad_norm 2.6476 (2.4240)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][430/625]\teta 0:00:07 lr 0.000959\t wd 0.0100\ttime 0.0394 (0.0368)\tloss 1.2275 (1.1278)\tgrad_norm 2.5779 (2.4265)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][440/625]\teta 0:00:06 lr 0.000959\t wd 0.0100\ttime 0.0373 (0.0368)\tloss 1.2676 (1.1275)\tgrad_norm 2.1105 (2.4254)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][450/625]\teta 0:00:06 lr 0.000959\t wd 0.0100\ttime 0.0346 (0.0368)\tloss 1.2070 (1.1273)\tgrad_norm 2.5423 (2.4450)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][460/625]\teta 0:00:06 lr 0.000958\t wd 0.0100\ttime 0.0340 (0.0367)\tloss 0.7988 (1.1274)\tgrad_norm 1.7256 (2.4421)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][470/625]\teta 0:00:05 lr 0.000958\t wd 0.0100\ttime 0.0330 (0.0367)\tloss 1.0840 (1.1274)\tgrad_norm 2.6663 (2.4394)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][480/625]\teta 0:00:05 lr 0.000958\t wd 0.0100\ttime 0.0348 (0.0366)\tloss 1.0244 (1.1282)\tgrad_norm 1.8183 (2.4386)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][490/625]\teta 0:00:04 lr 0.000958\t wd 0.0100\ttime 0.0399 (0.0366)\tloss 1.0195 (1.1265)\tgrad_norm 2.0023 (2.4336)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][500/625]\teta 0:00:04 lr 0.000958\t wd 0.0100\ttime 0.0360 (0.0366)\tloss 1.2344 (1.1261)\tgrad_norm 2.1483 (2.4350)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][510/625]\teta 0:00:04 lr 0.000958\t wd 0.0100\ttime 0.0333 (0.0366)\tloss 1.2061 (1.1251)\tgrad_norm 2.5706 (2.4322)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][520/625]\teta 0:00:03 lr 0.000958\t wd 0.0100\ttime 0.0411 (0.0366)\tloss 1.5215 (1.1250)\tgrad_norm 2.6023 (2.4338)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][530/625]\teta 0:00:03 lr 0.000958\t wd 0.0100\ttime 0.0370 (0.0366)\tloss 1.3125 (1.1252)\tgrad_norm 3.1950 (2.4380)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][540/625]\teta 0:00:03 lr 0.000958\t wd 0.0100\ttime 0.0343 (0.0365)\tloss 1.5293 (1.1271)\tgrad_norm 2.4176 (2.4379)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][550/625]\teta 0:00:02 lr 0.000958\t wd 0.0100\ttime 0.0413 (0.0365)\tloss 1.3164 (1.1279)\tgrad_norm 3.3891 (2.4425)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][560/625]\teta 0:00:02 lr 0.000957\t wd 0.0100\ttime 0.0358 (0.0365)\tloss 1.1885 (1.1274)\tgrad_norm 2.4538 (2.4398)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][570/625]\teta 0:00:02 lr 0.000957\t wd 0.0100\ttime 0.0386 (0.0365)\tloss 1.0146 (1.1280)\tgrad_norm 1.8700 (2.4406)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][580/625]\teta 0:00:01 lr 0.000957\t wd 0.0100\ttime 0.0329 (0.0365)\tloss 1.0840 (1.1281)\tgrad_norm 2.4147 (2.4387)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][590/625]\teta 0:00:01 lr 0.000957\t wd 0.0100\ttime 0.0354 (0.0364)\tloss 1.2998 (1.1284)\tgrad_norm 2.6284 (2.4350)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][600/625]\teta 0:00:00 lr 0.000957\t wd 0.0100\ttime 0.0365 (0.0364)\tloss 1.1504 (1.1282)\tgrad_norm 1.9398 (2.4359)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][610/625]\teta 0:00:00 lr 0.000957\t wd 0.0100\ttime 0.0324 (0.0364)\tloss 1.2334 (1.1259)\tgrad_norm 2.0767 (2.4349)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [15/100][620/625]\teta 0:00:00 lr 0.000957\t wd 0.0100\ttime 0.0372 (0.0364)\tloss 0.9941 (1.1259)\tgrad_norm 3.1139 (2.4342)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 15 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_15.pth saving......\n",
      "./model_save/ckpt_epoch_15.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.9463 (0.9463)\tAcc@1 68.750 (68.750)\tAcc@5 93.750 (93.750)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.9082 (0.9672)\tAcc@1 68.750 (64.205)\tAcc@5 95.312 (96.591)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.7295 (1.0223)\tAcc@1 78.125 (63.244)\tAcc@5 96.875 (96.280)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.9048 (1.0303)\tAcc@1 65.625 (62.802)\tAcc@5 98.438 (96.673)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 1.0527 (1.0429)\tAcc@1 50.000 (62.348)\tAcc@5 100.000 (96.570)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.9028 (1.0525)\tAcc@1 71.875 (61.949)\tAcc@5 98.438 (96.446)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 1.1660 (1.0597)\tAcc@1 59.375 (61.603)\tAcc@5 95.312 (96.235)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.9902 (1.0711)\tAcc@1 67.188 (61.312)\tAcc@5 100.000 (96.347)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.9189 (1.0769)\tAcc@1 65.625 (61.169)\tAcc@5 96.875 (96.335)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 1.2812 (1.0855)\tAcc@1 56.250 (60.577)\tAcc@5 93.750 (96.429)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 1.2275 (1.0809)\tAcc@1 57.812 (60.798)\tAcc@5 95.312 (96.504)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 1.1963 (1.0817)\tAcc@1 53.125 (60.642)\tAcc@5 98.438 (96.509)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 1.0859 (1.0790)\tAcc@1 54.688 (60.705)\tAcc@5 100.000 (96.552)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.9790 (1.0776)\tAcc@1 70.312 (61.057)\tAcc@5 95.312 (96.434)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 1.1016 (1.0830)\tAcc@1 59.375 (60.838)\tAcc@5 93.750 (96.310)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 1.0898 (1.0823)\tAcc@1 57.812 (60.772)\tAcc@5 95.312 (96.327)\tMem 455MB\n",
      " * Acc@1 60.890 Acc@5 96.310\n",
      "Accuracy of the network on the 10000 test images: 60.9%\n",
      "Max accuracy: 60.89%\n",
      "Train: [16/100][0/625]\teta 0:00:25 lr 0.000957\t wd 0.0100\ttime 0.0401 (0.0401)\tloss 0.8979 (0.8979)\tgrad_norm 2.0400 (2.0400)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [16/100][10/625]\teta 0:00:21 lr 0.000957\t wd 0.0100\ttime 0.0350 (0.0348)\tloss 1.0068 (1.1175)\tgrad_norm 2.1887 (nan)\tloss_scale 32768.0000 (35746.9091)\tmem 455MB\n",
      "Train: [16/100][20/625]\teta 0:00:21 lr 0.000957\t wd 0.0100\ttime 0.0323 (0.0350)\tloss 1.1680 (1.1192)\tgrad_norm 2.5722 (nan)\tloss_scale 32768.0000 (34328.3810)\tmem 455MB\n",
      "Train: [16/100][30/625]\teta 0:00:20 lr 0.000956\t wd 0.0100\ttime 0.0390 (0.0350)\tloss 1.1963 (1.0991)\tgrad_norm 4.0452 (nan)\tloss_scale 32768.0000 (33825.0323)\tmem 455MB\n",
      "Train: [16/100][40/625]\teta 0:00:20 lr 0.000956\t wd 0.0100\ttime 0.0353 (0.0353)\tloss 1.1826 (1.1075)\tgrad_norm 2.1585 (nan)\tloss_scale 32768.0000 (33567.2195)\tmem 455MB\n",
      "Train: [16/100][50/625]\teta 0:00:20 lr 0.000956\t wd 0.0100\ttime 0.0325 (0.0354)\tloss 1.0029 (1.1150)\tgrad_norm 1.5684 (nan)\tloss_scale 32768.0000 (33410.5098)\tmem 455MB\n",
      "Train: [16/100][60/625]\teta 0:00:19 lr 0.000956\t wd 0.0100\ttime 0.0362 (0.0353)\tloss 1.1699 (1.1158)\tgrad_norm 2.4019 (nan)\tloss_scale 32768.0000 (33305.1803)\tmem 455MB\n",
      "Train: [16/100][70/625]\teta 0:00:19 lr 0.000956\t wd 0.0100\ttime 0.0322 (0.0353)\tloss 1.0439 (1.1103)\tgrad_norm 2.0444 (nan)\tloss_scale 32768.0000 (33229.5211)\tmem 455MB\n",
      "Train: [16/100][80/625]\teta 0:00:19 lr 0.000956\t wd 0.0100\ttime 0.0323 (0.0352)\tloss 1.0596 (1.1062)\tgrad_norm 2.0991 (nan)\tloss_scale 32768.0000 (33172.5432)\tmem 455MB\n",
      "Train: [16/100][90/625]\teta 0:00:18 lr 0.000956\t wd 0.0100\ttime 0.0322 (0.0353)\tloss 1.2227 (1.1019)\tgrad_norm 2.7404 (nan)\tloss_scale 32768.0000 (33128.0879)\tmem 455MB\n",
      "Train: [16/100][100/625]\teta 0:00:18 lr 0.000956\t wd 0.0100\ttime 0.0323 (0.0353)\tloss 1.2158 (1.1003)\tgrad_norm 2.4688 (nan)\tloss_scale 32768.0000 (33092.4356)\tmem 455MB\n",
      "Train: [16/100][110/625]\teta 0:00:18 lr 0.000956\t wd 0.0100\ttime 0.0347 (0.0353)\tloss 1.1807 (1.1043)\tgrad_norm 2.4501 (nan)\tloss_scale 32768.0000 (33063.2072)\tmem 455MB\n",
      "Train: [16/100][120/625]\teta 0:00:17 lr 0.000956\t wd 0.0100\ttime 0.0388 (0.0353)\tloss 1.0635 (1.1063)\tgrad_norm 2.4296 (nan)\tloss_scale 32768.0000 (33038.8099)\tmem 455MB\n",
      "Train: [16/100][130/625]\teta 0:00:17 lr 0.000955\t wd 0.0100\ttime 0.0379 (0.0354)\tloss 1.0879 (1.1059)\tgrad_norm 2.5343 (nan)\tloss_scale 32768.0000 (33018.1374)\tmem 455MB\n",
      "Train: [16/100][140/625]\teta 0:00:17 lr 0.000955\t wd 0.0100\ttime 0.0355 (0.0353)\tloss 1.1650 (1.1108)\tgrad_norm 2.1442 (nan)\tloss_scale 32768.0000 (33000.3972)\tmem 455MB\n",
      "Train: [16/100][150/625]\teta 0:00:16 lr 0.000955\t wd 0.0100\ttime 0.0357 (0.0353)\tloss 1.2109 (1.1115)\tgrad_norm 2.4174 (nan)\tloss_scale 32768.0000 (32985.0066)\tmem 455MB\n",
      "Train: [16/100][160/625]\teta 0:00:16 lr 0.000955\t wd 0.0100\ttime 0.0385 (0.0354)\tloss 0.9644 (1.1146)\tgrad_norm 2.6613 (nan)\tloss_scale 32768.0000 (32971.5280)\tmem 455MB\n",
      "Train: [16/100][170/625]\teta 0:00:16 lr 0.000955\t wd 0.0100\ttime 0.0360 (0.0354)\tloss 1.1523 (1.1141)\tgrad_norm 2.5367 (nan)\tloss_scale 32768.0000 (32959.6257)\tmem 455MB\n",
      "Train: [16/100][180/625]\teta 0:00:15 lr 0.000955\t wd 0.0100\ttime 0.0356 (0.0354)\tloss 0.9922 (1.1133)\tgrad_norm 2.3885 (nan)\tloss_scale 32768.0000 (32949.0387)\tmem 455MB\n",
      "Train: [16/100][190/625]\teta 0:00:15 lr 0.000955\t wd 0.0100\ttime 0.0389 (0.0354)\tloss 1.1045 (1.1093)\tgrad_norm 1.8128 (nan)\tloss_scale 32768.0000 (32939.5602)\tmem 455MB\n",
      "Train: [16/100][200/625]\teta 0:00:15 lr 0.000955\t wd 0.0100\ttime 0.0356 (0.0354)\tloss 0.9238 (1.1074)\tgrad_norm 1.9850 (nan)\tloss_scale 32768.0000 (32931.0249)\tmem 455MB\n",
      "Train: [16/100][210/625]\teta 0:00:14 lr 0.000955\t wd 0.0100\ttime 0.0360 (0.0354)\tloss 0.9854 (1.1044)\tgrad_norm 1.9553 (nan)\tloss_scale 32768.0000 (32923.2986)\tmem 455MB\n",
      "Train: [16/100][220/625]\teta 0:00:14 lr 0.000954\t wd 0.0100\ttime 0.0323 (0.0354)\tloss 1.0439 (1.1057)\tgrad_norm 3.1864 (nan)\tloss_scale 32768.0000 (32916.2715)\tmem 455MB\n",
      "Train: [16/100][230/625]\teta 0:00:13 lr 0.000954\t wd 0.0100\ttime 0.0355 (0.0354)\tloss 1.2451 (1.1059)\tgrad_norm 2.7852 (nan)\tloss_scale 32768.0000 (32909.8528)\tmem 455MB\n",
      "Train: [16/100][240/625]\teta 0:00:13 lr 0.000954\t wd 0.0100\ttime 0.0322 (0.0354)\tloss 1.1602 (1.1079)\tgrad_norm 2.8982 (nan)\tloss_scale 32768.0000 (32903.9668)\tmem 455MB\n",
      "Train: [16/100][250/625]\teta 0:00:13 lr 0.000954\t wd 0.0100\ttime 0.0323 (0.0355)\tloss 0.9478 (1.1085)\tgrad_norm 2.5024 (nan)\tloss_scale 32768.0000 (32898.5498)\tmem 455MB\n",
      "Train: [16/100][260/625]\teta 0:00:12 lr 0.000954\t wd 0.0100\ttime 0.0351 (0.0355)\tloss 1.0654 (1.1089)\tgrad_norm 2.0557 (nan)\tloss_scale 32768.0000 (32893.5479)\tmem 455MB\n",
      "Train: [16/100][270/625]\teta 0:00:12 lr 0.000954\t wd 0.0100\ttime 0.0390 (0.0355)\tloss 1.1240 (1.1087)\tgrad_norm 2.8534 (nan)\tloss_scale 32768.0000 (32888.9151)\tmem 455MB\n",
      "Train: [16/100][280/625]\teta 0:00:12 lr 0.000954\t wd 0.0100\ttime 0.0366 (0.0355)\tloss 1.1729 (1.1109)\tgrad_norm 2.1183 (nan)\tloss_scale 32768.0000 (32884.6121)\tmem 455MB\n",
      "Train: [16/100][290/625]\teta 0:00:11 lr 0.000954\t wd 0.0100\ttime 0.0366 (0.0356)\tloss 1.1709 (1.1132)\tgrad_norm 2.4205 (nan)\tloss_scale 32768.0000 (32880.6048)\tmem 455MB\n",
      "Train: [16/100][300/625]\teta 0:00:11 lr 0.000954\t wd 0.0100\ttime 0.0358 (0.0356)\tloss 1.2793 (1.1119)\tgrad_norm 2.9121 (nan)\tloss_scale 32768.0000 (32876.8638)\tmem 455MB\n",
      "Train: [16/100][310/625]\teta 0:00:11 lr 0.000953\t wd 0.0100\ttime 0.0336 (0.0356)\tloss 1.0762 (1.1131)\tgrad_norm 2.9816 (nan)\tloss_scale 32768.0000 (32873.3633)\tmem 455MB\n",
      "Train: [16/100][320/625]\teta 0:00:10 lr 0.000953\t wd 0.0100\ttime 0.0354 (0.0356)\tloss 1.0605 (1.1145)\tgrad_norm 1.6829 (nan)\tloss_scale 32768.0000 (32870.0810)\tmem 455MB\n",
      "Train: [16/100][330/625]\teta 0:00:10 lr 0.000953\t wd 0.0100\ttime 0.0333 (0.0356)\tloss 1.0342 (1.1152)\tgrad_norm 1.6606 (nan)\tloss_scale 32768.0000 (32866.9970)\tmem 455MB\n",
      "Train: [16/100][340/625]\teta 0:00:10 lr 0.000953\t wd 0.0100\ttime 0.0388 (0.0356)\tloss 1.0576 (1.1142)\tgrad_norm 1.9439 (nan)\tloss_scale 32768.0000 (32864.0938)\tmem 455MB\n",
      "Train: [16/100][350/625]\teta 0:00:09 lr 0.000953\t wd 0.0100\ttime 0.0356 (0.0357)\tloss 0.7598 (1.1128)\tgrad_norm 2.0702 (nan)\tloss_scale 32768.0000 (32861.3561)\tmem 455MB\n",
      "Train: [16/100][360/625]\teta 0:00:09 lr 0.000953\t wd 0.0100\ttime 0.0396 (0.0357)\tloss 0.9380 (1.1108)\tgrad_norm 2.1586 (nan)\tloss_scale 32768.0000 (32858.7701)\tmem 455MB\n",
      "Train: [16/100][370/625]\teta 0:00:09 lr 0.000953\t wd 0.0100\ttime 0.0328 (0.0357)\tloss 1.0908 (1.1130)\tgrad_norm 2.3643 (nan)\tloss_scale 32768.0000 (32856.3235)\tmem 455MB\n",
      "Train: [16/100][380/625]\teta 0:00:08 lr 0.000953\t wd 0.0100\ttime 0.0395 (0.0358)\tloss 1.0225 (1.1107)\tgrad_norm 2.8820 (nan)\tloss_scale 32768.0000 (32854.0052)\tmem 455MB\n",
      "Train: [16/100][390/625]\teta 0:00:08 lr 0.000953\t wd 0.0100\ttime 0.0331 (0.0357)\tloss 1.1699 (1.1105)\tgrad_norm 2.4115 (nan)\tloss_scale 32768.0000 (32851.8056)\tmem 455MB\n",
      "Train: [16/100][400/625]\teta 0:00:08 lr 0.000952\t wd 0.0100\ttime 0.0333 (0.0357)\tloss 1.0732 (1.1088)\tgrad_norm 1.9157 (nan)\tloss_scale 32768.0000 (32849.7157)\tmem 455MB\n",
      "Train: [16/100][410/625]\teta 0:00:07 lr 0.000952\t wd 0.0100\ttime 0.0329 (0.0357)\tloss 0.9077 (1.1071)\tgrad_norm 2.3757 (nan)\tloss_scale 32768.0000 (32847.7275)\tmem 455MB\n",
      "Train: [16/100][420/625]\teta 0:00:07 lr 0.000952\t wd 0.0100\ttime 0.0346 (0.0357)\tloss 1.4873 (1.1064)\tgrad_norm 2.9262 (nan)\tloss_scale 32768.0000 (32845.8337)\tmem 455MB\n",
      "Train: [16/100][430/625]\teta 0:00:06 lr 0.000952\t wd 0.0100\ttime 0.0328 (0.0357)\tloss 1.2031 (1.1076)\tgrad_norm 2.0011 (nan)\tloss_scale 32768.0000 (32844.0278)\tmem 455MB\n",
      "Train: [16/100][440/625]\teta 0:00:06 lr 0.000952\t wd 0.0100\ttime 0.0363 (0.0356)\tloss 1.2480 (1.1082)\tgrad_norm 1.9515 (nan)\tloss_scale 32768.0000 (32842.3039)\tmem 455MB\n",
      "Train: [16/100][450/625]\teta 0:00:06 lr 0.000952\t wd 0.0100\ttime 0.0328 (0.0356)\tloss 1.2148 (1.1075)\tgrad_norm 2.6758 (nan)\tloss_scale 32768.0000 (32840.6563)\tmem 455MB\n",
      "Train: [16/100][460/625]\teta 0:00:05 lr 0.000952\t wd 0.0100\ttime 0.0339 (0.0356)\tloss 1.1797 (1.1076)\tgrad_norm 1.7935 (nan)\tloss_scale 32768.0000 (32839.0803)\tmem 455MB\n",
      "Train: [16/100][470/625]\teta 0:00:05 lr 0.000952\t wd 0.0100\ttime 0.0331 (0.0356)\tloss 1.0771 (1.1073)\tgrad_norm 2.0877 (nan)\tloss_scale 32768.0000 (32837.5711)\tmem 455MB\n",
      "Train: [16/100][480/625]\teta 0:00:05 lr 0.000952\t wd 0.0100\ttime 0.0380 (0.0356)\tloss 1.1348 (1.1078)\tgrad_norm 2.0597 (nan)\tloss_scale 32768.0000 (32836.1247)\tmem 455MB\n",
      "Train: [16/100][490/625]\teta 0:00:04 lr 0.000951\t wd 0.0100\ttime 0.0372 (0.0357)\tloss 0.8687 (1.1068)\tgrad_norm 2.0714 (nan)\tloss_scale 32768.0000 (32834.7373)\tmem 455MB\n",
      "Train: [16/100][500/625]\teta 0:00:04 lr 0.000951\t wd 0.0100\ttime 0.0346 (0.0357)\tloss 1.3477 (1.1081)\tgrad_norm 3.3752 (nan)\tloss_scale 32768.0000 (32833.4052)\tmem 455MB\n",
      "Train: [16/100][510/625]\teta 0:00:04 lr 0.000951\t wd 0.0100\ttime 0.0372 (0.0358)\tloss 1.1357 (1.1085)\tgrad_norm 2.8690 (nan)\tloss_scale 32768.0000 (32832.1252)\tmem 455MB\n",
      "Train: [16/100][520/625]\teta 0:00:03 lr 0.000951\t wd 0.0100\ttime 0.0348 (0.0358)\tloss 0.9712 (1.1079)\tgrad_norm 2.3551 (nan)\tloss_scale 32768.0000 (32830.8944)\tmem 455MB\n",
      "Train: [16/100][530/625]\teta 0:00:03 lr 0.000951\t wd 0.0100\ttime 0.0390 (0.0359)\tloss 1.1758 (1.1086)\tgrad_norm 2.1763 (nan)\tloss_scale 32768.0000 (32829.7100)\tmem 455MB\n",
      "Train: [16/100][540/625]\teta 0:00:03 lr 0.000951\t wd 0.0100\ttime 0.0416 (0.0359)\tloss 0.9912 (1.1094)\tgrad_norm 1.6910 (nan)\tloss_scale 32768.0000 (32828.5693)\tmem 455MB\n",
      "Train: [16/100][550/625]\teta 0:00:02 lr 0.000951\t wd 0.0100\ttime 0.0415 (0.0359)\tloss 1.1797 (1.1104)\tgrad_norm 2.0917 (nan)\tloss_scale 32768.0000 (32827.4701)\tmem 455MB\n",
      "Train: [16/100][560/625]\teta 0:00:02 lr 0.000951\t wd 0.0100\ttime 0.0404 (0.0360)\tloss 1.2051 (1.1102)\tgrad_norm 1.9017 (nan)\tloss_scale 32768.0000 (32826.4100)\tmem 455MB\n",
      "Train: [16/100][570/625]\teta 0:00:01 lr 0.000951\t wd 0.0100\ttime 0.0411 (0.0360)\tloss 1.1709 (1.1096)\tgrad_norm 2.9634 (nan)\tloss_scale 32768.0000 (32825.3870)\tmem 455MB\n",
      "Train: [16/100][580/625]\teta 0:00:01 lr 0.000950\t wd 0.0100\ttime 0.0367 (0.0361)\tloss 1.0439 (1.1097)\tgrad_norm 2.7982 (nan)\tloss_scale 32768.0000 (32824.3993)\tmem 455MB\n",
      "Train: [16/100][590/625]\teta 0:00:01 lr 0.000950\t wd 0.0100\ttime 0.0327 (0.0361)\tloss 1.3789 (1.1115)\tgrad_norm 3.1517 (nan)\tloss_scale 32768.0000 (32823.4450)\tmem 455MB\n",
      "Train: [16/100][600/625]\teta 0:00:00 lr 0.000950\t wd 0.0100\ttime 0.0382 (0.0361)\tloss 1.0684 (1.1120)\tgrad_norm 2.5571 (nan)\tloss_scale 32768.0000 (32822.5225)\tmem 455MB\n",
      "Train: [16/100][610/625]\teta 0:00:00 lr 0.000950\t wd 0.0100\ttime 0.0362 (0.0361)\tloss 1.0400 (1.1117)\tgrad_norm 2.6785 (nan)\tloss_scale 32768.0000 (32821.6301)\tmem 455MB\n",
      "Train: [16/100][620/625]\teta 0:00:00 lr 0.000950\t wd 0.0100\ttime 0.0365 (0.0361)\tloss 0.9932 (1.1114)\tgrad_norm 2.3546 (nan)\tloss_scale 32768.0000 (32820.7665)\tmem 455MB\n",
      "EPOCH 16 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_16.pth saving......\n",
      "./model_save/ckpt_epoch_16.pth saved !!!\n",
      "Test: [0/157]\tTime 0.017 (0.017)\tLoss 0.9395 (0.9395)\tAcc@1 68.750 (68.750)\tAcc@5 96.875 (96.875)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.016)\tLoss 1.0791 (1.0216)\tAcc@1 57.812 (62.926)\tAcc@5 95.312 (97.017)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.9180 (1.0152)\tAcc@1 64.062 (63.170)\tAcc@5 96.875 (96.354)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.9580 (1.0317)\tAcc@1 64.062 (62.450)\tAcc@5 96.875 (96.220)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.8892 (1.0311)\tAcc@1 67.188 (62.386)\tAcc@5 100.000 (96.494)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 1.1445 (1.0447)\tAcc@1 56.250 (61.918)\tAcc@5 93.750 (96.293)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 1.0352 (1.0406)\tAcc@1 62.500 (62.449)\tAcc@5 98.438 (96.363)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 1.2607 (1.0464)\tAcc@1 57.812 (62.148)\tAcc@5 98.438 (96.413)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 1.1084 (1.0512)\tAcc@1 57.812 (61.921)\tAcc@5 92.188 (96.316)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 1.0020 (1.0510)\tAcc@1 62.500 (61.951)\tAcc@5 100.000 (96.343)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 1.1475 (1.0549)\tAcc@1 54.688 (61.680)\tAcc@5 95.312 (96.380)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 1.1367 (1.0484)\tAcc@1 60.938 (61.768)\tAcc@5 92.188 (96.396)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 1.1064 (1.0539)\tAcc@1 59.375 (61.544)\tAcc@5 93.750 (96.423)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 1.0918 (1.0458)\tAcc@1 59.375 (61.820)\tAcc@5 98.438 (96.577)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 1.2236 (1.0503)\tAcc@1 62.500 (61.879)\tAcc@5 92.188 (96.487)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.7422 (1.0467)\tAcc@1 82.812 (62.086)\tAcc@5 98.438 (96.471)\tMem 455MB\n",
      " * Acc@1 62.040 Acc@5 96.440\n",
      "Accuracy of the network on the 10000 test images: 62.0%\n",
      "Max accuracy: 62.04%\n",
      "Train: [17/100][0/625]\teta 0:00:21 lr 0.000950\t wd 0.0100\ttime 0.0349 (0.0349)\tloss 0.9639 (0.9639)\tgrad_norm 2.2213 (2.2213)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [17/100][10/625]\teta 0:00:21 lr 0.000950\t wd 0.0100\ttime 0.0386 (0.0357)\tloss 1.1064 (1.0704)\tgrad_norm 2.0888 (2.0607)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [17/100][20/625]\teta 0:00:21 lr 0.000950\t wd 0.0100\ttime 0.0352 (0.0360)\tloss 0.9546 (1.0753)\tgrad_norm 1.8882 (2.0988)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [17/100][30/625]\teta 0:00:21 lr 0.000950\t wd 0.0100\ttime 0.0361 (0.0357)\tloss 1.2100 (1.0846)\tgrad_norm 2.2292 (inf)\tloss_scale 16384.0000 (27482.8387)\tmem 455MB\n",
      "Train: [17/100][40/625]\teta 0:00:20 lr 0.000950\t wd 0.0100\ttime 0.0326 (0.0356)\tloss 1.1006 (1.0695)\tgrad_norm 2.0114 (inf)\tloss_scale 16384.0000 (24775.8049)\tmem 455MB\n",
      "Train: [17/100][50/625]\teta 0:00:20 lr 0.000949\t wd 0.0100\ttime 0.0373 (0.0356)\tloss 1.0332 (1.0558)\tgrad_norm 3.0398 (inf)\tloss_scale 16384.0000 (23130.3529)\tmem 455MB\n",
      "Train: [17/100][60/625]\teta 0:00:20 lr 0.000949\t wd 0.0100\ttime 0.0383 (0.0357)\tloss 1.1465 (1.0733)\tgrad_norm 2.4759 (inf)\tloss_scale 16384.0000 (22024.3934)\tmem 455MB\n",
      "Train: [17/100][70/625]\teta 0:00:19 lr 0.000949\t wd 0.0100\ttime 0.0386 (0.0358)\tloss 1.0400 (1.0764)\tgrad_norm 1.8050 (inf)\tloss_scale 16384.0000 (21229.9718)\tmem 455MB\n",
      "Train: [17/100][80/625]\teta 0:00:19 lr 0.000949\t wd 0.0100\ttime 0.0354 (0.0358)\tloss 1.3584 (1.0806)\tgrad_norm 3.3647 (inf)\tloss_scale 16384.0000 (20631.7037)\tmem 455MB\n",
      "Train: [17/100][90/625]\teta 0:00:19 lr 0.000949\t wd 0.0100\ttime 0.0362 (0.0358)\tloss 0.9697 (1.0855)\tgrad_norm 2.2510 (inf)\tloss_scale 16384.0000 (20164.9231)\tmem 455MB\n",
      "Train: [17/100][100/625]\teta 0:00:18 lr 0.000949\t wd 0.0100\ttime 0.0340 (0.0357)\tloss 1.0371 (1.0822)\tgrad_norm 1.6772 (inf)\tloss_scale 16384.0000 (19790.5743)\tmem 455MB\n",
      "Train: [17/100][110/625]\teta 0:00:18 lr 0.000949\t wd 0.0100\ttime 0.0351 (0.0357)\tloss 0.9199 (1.0773)\tgrad_norm 4.3088 (inf)\tloss_scale 16384.0000 (19483.6757)\tmem 455MB\n",
      "Train: [17/100][120/625]\teta 0:00:17 lr 0.000949\t wd 0.0100\ttime 0.0358 (0.0356)\tloss 1.0420 (1.0751)\tgrad_norm 1.6707 (inf)\tloss_scale 16384.0000 (19227.5041)\tmem 455MB\n",
      "Train: [17/100][130/625]\teta 0:00:17 lr 0.000949\t wd 0.0100\ttime 0.0338 (0.0355)\tloss 1.0791 (1.0774)\tgrad_norm 2.9279 (inf)\tloss_scale 16384.0000 (19010.4427)\tmem 455MB\n",
      "Train: [17/100][140/625]\teta 0:00:17 lr 0.000948\t wd 0.0100\ttime 0.0358 (0.0355)\tloss 1.3633 (1.0858)\tgrad_norm 3.0729 (inf)\tloss_scale 16384.0000 (18824.1702)\tmem 455MB\n",
      "Train: [17/100][150/625]\teta 0:00:16 lr 0.000948\t wd 0.0100\ttime 0.0329 (0.0356)\tloss 1.2393 (1.0893)\tgrad_norm 2.3853 (inf)\tloss_scale 16384.0000 (18662.5695)\tmem 455MB\n",
      "Train: [17/100][160/625]\teta 0:00:16 lr 0.000948\t wd 0.0100\ttime 0.0340 (0.0355)\tloss 1.0908 (1.0899)\tgrad_norm 2.7152 (inf)\tloss_scale 16384.0000 (18521.0435)\tmem 455MB\n",
      "Train: [17/100][170/625]\teta 0:00:16 lr 0.000948\t wd 0.0100\ttime 0.0356 (0.0354)\tloss 1.1963 (1.0905)\tgrad_norm 3.6993 (inf)\tloss_scale 16384.0000 (18396.0702)\tmem 455MB\n",
      "Train: [17/100][180/625]\teta 0:00:15 lr 0.000948\t wd 0.0100\ttime 0.0381 (0.0354)\tloss 0.9727 (1.0915)\tgrad_norm 1.8258 (inf)\tloss_scale 16384.0000 (18284.9061)\tmem 455MB\n",
      "Train: [17/100][190/625]\teta 0:00:15 lr 0.000948\t wd 0.0100\ttime 0.0327 (0.0354)\tloss 0.9863 (1.0931)\tgrad_norm 1.7261 (inf)\tloss_scale 16384.0000 (18185.3822)\tmem 455MB\n",
      "Train: [17/100][200/625]\teta 0:00:15 lr 0.000948\t wd 0.0100\ttime 0.0351 (0.0354)\tloss 1.0918 (1.0912)\tgrad_norm 1.8361 (inf)\tloss_scale 16384.0000 (18095.7612)\tmem 455MB\n",
      "Train: [17/100][210/625]\teta 0:00:14 lr 0.000948\t wd 0.0100\ttime 0.0346 (0.0354)\tloss 0.9570 (1.0900)\tgrad_norm 1.9965 (inf)\tloss_scale 16384.0000 (18014.6351)\tmem 455MB\n",
      "Train: [17/100][220/625]\teta 0:00:14 lr 0.000947\t wd 0.0100\ttime 0.0325 (0.0353)\tloss 1.1934 (1.0898)\tgrad_norm 2.6200 (inf)\tloss_scale 16384.0000 (17940.8507)\tmem 455MB\n",
      "Train: [17/100][230/625]\teta 0:00:13 lr 0.000947\t wd 0.0100\ttime 0.0360 (0.0353)\tloss 1.0898 (1.0887)\tgrad_norm 2.0664 (inf)\tloss_scale 16384.0000 (17873.4545)\tmem 455MB\n",
      "Train: [17/100][240/625]\teta 0:00:13 lr 0.000947\t wd 0.0100\ttime 0.0360 (0.0352)\tloss 1.1172 (1.0871)\tgrad_norm 3.1494 (inf)\tloss_scale 16384.0000 (17811.6515)\tmem 455MB\n",
      "Train: [17/100][250/625]\teta 0:00:13 lr 0.000947\t wd 0.0100\ttime 0.0353 (0.0353)\tloss 1.1924 (1.0869)\tgrad_norm 2.5399 (inf)\tloss_scale 16384.0000 (17754.7729)\tmem 455MB\n",
      "Train: [17/100][260/625]\teta 0:00:12 lr 0.000947\t wd 0.0100\ttime 0.0387 (0.0354)\tloss 1.2393 (1.0895)\tgrad_norm 2.1873 (inf)\tloss_scale 16384.0000 (17702.2529)\tmem 455MB\n",
      "Train: [17/100][270/625]\teta 0:00:12 lr 0.000947\t wd 0.0100\ttime 0.0346 (0.0354)\tloss 1.0264 (1.0876)\tgrad_norm 1.7037 (inf)\tloss_scale 16384.0000 (17653.6089)\tmem 455MB\n",
      "Train: [17/100][280/625]\teta 0:00:12 lr 0.000947\t wd 0.0100\ttime 0.0385 (0.0354)\tloss 0.9058 (1.0866)\tgrad_norm 1.9983 (inf)\tloss_scale 16384.0000 (17608.4270)\tmem 455MB\n",
      "Train: [17/100][290/625]\teta 0:00:11 lr 0.000947\t wd 0.0100\ttime 0.0372 (0.0354)\tloss 1.1191 (1.0872)\tgrad_norm 2.3912 (inf)\tloss_scale 16384.0000 (17566.3505)\tmem 455MB\n",
      "Train: [17/100][300/625]\teta 0:00:11 lr 0.000947\t wd 0.0100\ttime 0.0349 (0.0355)\tloss 1.2236 (1.0892)\tgrad_norm 2.3616 (inf)\tloss_scale 16384.0000 (17527.0698)\tmem 455MB\n",
      "Train: [17/100][310/625]\teta 0:00:11 lr 0.000946\t wd 0.0100\ttime 0.0339 (0.0354)\tloss 0.8730 (1.0915)\tgrad_norm 1.9211 (inf)\tloss_scale 16384.0000 (17490.3151)\tmem 455MB\n",
      "Train: [17/100][320/625]\teta 0:00:10 lr 0.000946\t wd 0.0100\ttime 0.0335 (0.0354)\tloss 0.9692 (1.0908)\tgrad_norm 2.1135 (inf)\tloss_scale 16384.0000 (17455.8505)\tmem 455MB\n",
      "Train: [17/100][330/625]\teta 0:00:10 lr 0.000946\t wd 0.0100\ttime 0.0348 (0.0354)\tloss 1.0879 (1.0903)\tgrad_norm 2.4024 (inf)\tloss_scale 16384.0000 (17423.4683)\tmem 455MB\n",
      "Train: [17/100][340/625]\teta 0:00:10 lr 0.000946\t wd 0.0100\ttime 0.0363 (0.0354)\tloss 1.2676 (1.0905)\tgrad_norm 2.3856 (inf)\tloss_scale 16384.0000 (17392.9853)\tmem 455MB\n",
      "Train: [17/100][350/625]\teta 0:00:09 lr 0.000946\t wd 0.0100\ttime 0.0366 (0.0354)\tloss 0.9531 (1.0912)\tgrad_norm 2.0920 (inf)\tloss_scale 16384.0000 (17364.2393)\tmem 455MB\n",
      "Train: [17/100][360/625]\teta 0:00:09 lr 0.000946\t wd 0.0100\ttime 0.0337 (0.0354)\tloss 1.0273 (1.0910)\tgrad_norm 2.2978 (inf)\tloss_scale 16384.0000 (17337.0859)\tmem 455MB\n",
      "Train: [17/100][370/625]\teta 0:00:09 lr 0.000946\t wd 0.0100\ttime 0.0365 (0.0354)\tloss 1.1523 (1.0890)\tgrad_norm 2.6194 (inf)\tloss_scale 16384.0000 (17311.3962)\tmem 455MB\n",
      "Train: [17/100][380/625]\teta 0:00:08 lr 0.000946\t wd 0.0100\ttime 0.0367 (0.0355)\tloss 1.0547 (1.0868)\tgrad_norm 2.1899 (inf)\tloss_scale 16384.0000 (17287.0551)\tmem 455MB\n",
      "Train: [17/100][390/625]\teta 0:00:08 lr 0.000946\t wd 0.0100\ttime 0.0354 (0.0355)\tloss 1.1865 (1.0872)\tgrad_norm 2.8470 (inf)\tloss_scale 16384.0000 (17263.9591)\tmem 455MB\n",
      "Train: [17/100][400/625]\teta 0:00:07 lr 0.000945\t wd 0.0100\ttime 0.0369 (0.0355)\tloss 1.1328 (1.0865)\tgrad_norm 2.6268 (inf)\tloss_scale 16384.0000 (17242.0150)\tmem 455MB\n",
      "Train: [17/100][410/625]\teta 0:00:07 lr 0.000945\t wd 0.0100\ttime 0.0399 (0.0356)\tloss 0.9487 (1.0872)\tgrad_norm 1.9255 (inf)\tloss_scale 16384.0000 (17221.1387)\tmem 455MB\n",
      "Train: [17/100][420/625]\teta 0:00:07 lr 0.000945\t wd 0.0100\ttime 0.0393 (0.0357)\tloss 1.1016 (1.0885)\tgrad_norm 3.6730 (inf)\tloss_scale 16384.0000 (17201.2542)\tmem 455MB\n",
      "Train: [17/100][430/625]\teta 0:00:06 lr 0.000945\t wd 0.0100\ttime 0.0389 (0.0357)\tloss 1.1914 (1.0889)\tgrad_norm 2.1307 (inf)\tloss_scale 16384.0000 (17182.2923)\tmem 455MB\n",
      "Train: [17/100][440/625]\teta 0:00:06 lr 0.000945\t wd 0.0100\ttime 0.0334 (0.0357)\tloss 1.2227 (1.0891)\tgrad_norm 1.9488 (inf)\tloss_scale 16384.0000 (17164.1905)\tmem 455MB\n",
      "Train: [17/100][450/625]\teta 0:00:06 lr 0.000945\t wd 0.0100\ttime 0.0400 (0.0358)\tloss 1.2227 (1.0891)\tgrad_norm 1.8719 (inf)\tloss_scale 16384.0000 (17146.8914)\tmem 455MB\n",
      "Train: [17/100][460/625]\teta 0:00:05 lr 0.000945\t wd 0.0100\ttime 0.0371 (0.0358)\tloss 0.9497 (1.0880)\tgrad_norm 2.2256 (inf)\tloss_scale 16384.0000 (17130.3427)\tmem 455MB\n",
      "Train: [17/100][470/625]\teta 0:00:05 lr 0.000945\t wd 0.0100\ttime 0.0364 (0.0358)\tloss 0.9365 (1.0854)\tgrad_norm 2.4697 (inf)\tloss_scale 16384.0000 (17114.4968)\tmem 455MB\n",
      "Train: [17/100][480/625]\teta 0:00:05 lr 0.000944\t wd 0.0100\ttime 0.0327 (0.0359)\tloss 1.1025 (1.0855)\tgrad_norm 2.6506 (inf)\tloss_scale 16384.0000 (17099.3098)\tmem 455MB\n",
      "Train: [17/100][490/625]\teta 0:00:04 lr 0.000944\t wd 0.0100\ttime 0.0361 (0.0358)\tloss 1.0576 (1.0879)\tgrad_norm 3.5966 (inf)\tloss_scale 16384.0000 (17084.7413)\tmem 455MB\n",
      "Train: [17/100][500/625]\teta 0:00:04 lr 0.000944\t wd 0.0100\ttime 0.0332 (0.0358)\tloss 1.0518 (1.0880)\tgrad_norm 1.6664 (inf)\tloss_scale 16384.0000 (17070.7545)\tmem 455MB\n",
      "Train: [17/100][510/625]\teta 0:00:04 lr 0.000944\t wd 0.0100\ttime 0.0357 (0.0358)\tloss 1.1182 (1.0878)\tgrad_norm 2.3606 (inf)\tloss_scale 16384.0000 (17057.3151)\tmem 455MB\n",
      "Train: [17/100][520/625]\teta 0:00:03 lr 0.000944\t wd 0.0100\ttime 0.0386 (0.0358)\tloss 1.3770 (1.0888)\tgrad_norm 2.3811 (inf)\tloss_scale 16384.0000 (17044.3916)\tmem 455MB\n",
      "Train: [17/100][530/625]\teta 0:00:03 lr 0.000944\t wd 0.0100\ttime 0.0327 (0.0358)\tloss 1.1533 (1.0894)\tgrad_norm 3.1278 (inf)\tloss_scale 16384.0000 (17031.9548)\tmem 455MB\n",
      "Train: [17/100][540/625]\teta 0:00:03 lr 0.000944\t wd 0.0100\ttime 0.0326 (0.0358)\tloss 0.9941 (1.0889)\tgrad_norm 2.1999 (inf)\tloss_scale 16384.0000 (17019.9778)\tmem 455MB\n",
      "Train: [17/100][550/625]\teta 0:00:02 lr 0.000944\t wd 0.0100\ttime 0.0330 (0.0358)\tloss 0.8438 (1.0890)\tgrad_norm 2.5000 (inf)\tloss_scale 16384.0000 (17008.4356)\tmem 455MB\n",
      "Train: [17/100][560/625]\teta 0:00:02 lr 0.000944\t wd 0.0100\ttime 0.0328 (0.0358)\tloss 1.1631 (1.0889)\tgrad_norm 2.2087 (inf)\tloss_scale 16384.0000 (16997.3048)\tmem 455MB\n",
      "Train: [17/100][570/625]\teta 0:00:01 lr 0.000943\t wd 0.0100\ttime 0.0397 (0.0358)\tloss 0.8945 (1.0891)\tgrad_norm 2.0498 (inf)\tloss_scale 16384.0000 (16986.5639)\tmem 455MB\n",
      "Train: [17/100][580/625]\teta 0:00:01 lr 0.000943\t wd 0.0100\ttime 0.0332 (0.0358)\tloss 1.3037 (1.0899)\tgrad_norm 2.2057 (inf)\tloss_scale 16384.0000 (16976.1928)\tmem 455MB\n",
      "Train: [17/100][590/625]\teta 0:00:01 lr 0.000943\t wd 0.0100\ttime 0.0377 (0.0358)\tloss 1.2002 (1.0905)\tgrad_norm 2.3083 (inf)\tloss_scale 16384.0000 (16966.1726)\tmem 455MB\n",
      "Train: [17/100][600/625]\teta 0:00:00 lr 0.000943\t wd 0.0100\ttime 0.0355 (0.0358)\tloss 1.0146 (1.0901)\tgrad_norm 1.5978 (inf)\tloss_scale 16384.0000 (16956.4859)\tmem 455MB\n",
      "Train: [17/100][610/625]\teta 0:00:00 lr 0.000943\t wd 0.0100\ttime 0.0331 (0.0358)\tloss 1.1045 (1.0908)\tgrad_norm 2.1035 (inf)\tloss_scale 16384.0000 (16947.1162)\tmem 455MB\n",
      "Train: [17/100][620/625]\teta 0:00:00 lr 0.000943\t wd 0.0100\ttime 0.0327 (0.0358)\tloss 1.0967 (1.0907)\tgrad_norm 2.2326 (inf)\tloss_scale 16384.0000 (16938.0483)\tmem 455MB\n",
      "EPOCH 17 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_17.pth saving......\n",
      "./model_save/ckpt_epoch_17.pth saved !!!\n",
      "Test: [0/157]\tTime 0.017 (0.017)\tLoss 0.8643 (0.8643)\tAcc@1 70.312 (70.312)\tAcc@5 98.438 (98.438)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.9199 (0.9678)\tAcc@1 59.375 (63.920)\tAcc@5 96.875 (97.727)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 1.2666 (0.9896)\tAcc@1 53.125 (63.765)\tAcc@5 92.188 (97.545)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.9863 (1.0140)\tAcc@1 64.062 (63.256)\tAcc@5 100.000 (97.228)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.8921 (1.0228)\tAcc@1 71.875 (63.072)\tAcc@5 95.312 (96.799)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.9268 (1.0081)\tAcc@1 65.625 (63.388)\tAcc@5 100.000 (96.906)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.9863 (1.0060)\tAcc@1 64.062 (63.345)\tAcc@5 100.000 (97.003)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.7783 (1.0088)\tAcc@1 70.312 (63.006)\tAcc@5 100.000 (96.985)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.9785 (1.0077)\tAcc@1 59.375 (63.175)\tAcc@5 96.875 (96.836)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 1.0752 (1.0048)\tAcc@1 68.750 (63.324)\tAcc@5 95.312 (96.875)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.018 (0.015)\tLoss 0.9961 (1.0099)\tAcc@1 64.062 (63.119)\tAcc@5 92.188 (96.782)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 1.0244 (1.0136)\tAcc@1 59.375 (63.105)\tAcc@5 98.438 (96.748)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 1.0498 (1.0102)\tAcc@1 65.625 (63.249)\tAcc@5 96.875 (96.772)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 1.0107 (1.0155)\tAcc@1 60.938 (63.120)\tAcc@5 98.438 (96.625)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.016 (0.015)\tLoss 0.9688 (1.0179)\tAcc@1 65.625 (63.032)\tAcc@5 93.750 (96.620)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.9126 (1.0224)\tAcc@1 70.312 (63.090)\tAcc@5 96.875 (96.554)\tMem 455MB\n",
      " * Acc@1 63.020 Acc@5 96.600\n",
      "Accuracy of the network on the 10000 test images: 63.0%\n",
      "Max accuracy: 63.02%\n",
      "Train: [18/100][0/625]\teta 0:00:24 lr 0.000943\t wd 0.0100\ttime 0.0387 (0.0387)\tloss 0.9946 (0.9946)\tgrad_norm 1.8860 (1.8860)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][10/625]\teta 0:00:22 lr 0.000943\t wd 0.0100\ttime 0.0381 (0.0367)\tloss 1.0029 (1.0504)\tgrad_norm 3.3333 (2.1080)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][20/625]\teta 0:00:21 lr 0.000942\t wd 0.0100\ttime 0.0342 (0.0358)\tloss 0.9590 (1.0597)\tgrad_norm 1.9684 (2.1652)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][30/625]\teta 0:00:21 lr 0.000942\t wd 0.0100\ttime 0.0333 (0.0359)\tloss 1.0283 (1.0705)\tgrad_norm 2.3550 (2.1694)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][40/625]\teta 0:00:21 lr 0.000942\t wd 0.0100\ttime 0.0330 (0.0359)\tloss 1.0010 (1.0642)\tgrad_norm 2.4139 (2.1981)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][50/625]\teta 0:00:20 lr 0.000942\t wd 0.0100\ttime 0.0393 (0.0358)\tloss 0.9746 (1.0828)\tgrad_norm 2.1851 (2.2403)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][60/625]\teta 0:00:20 lr 0.000942\t wd 0.0100\ttime 0.0386 (0.0361)\tloss 0.8750 (1.0773)\tgrad_norm 1.8604 (2.2386)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][70/625]\teta 0:00:20 lr 0.000942\t wd 0.0100\ttime 0.0347 (0.0361)\tloss 1.3311 (1.0769)\tgrad_norm 3.3574 (2.2600)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][80/625]\teta 0:00:19 lr 0.000942\t wd 0.0100\ttime 0.0332 (0.0362)\tloss 1.0059 (1.0724)\tgrad_norm 2.4908 (2.3502)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][90/625]\teta 0:00:19 lr 0.000942\t wd 0.0100\ttime 0.0362 (0.0363)\tloss 1.1787 (1.0743)\tgrad_norm 2.0294 (2.4132)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][100/625]\teta 0:00:19 lr 0.000942\t wd 0.0100\ttime 0.0366 (0.0364)\tloss 0.9307 (1.0743)\tgrad_norm 2.7259 (2.4299)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][110/625]\teta 0:00:18 lr 0.000941\t wd 0.0100\ttime 0.0420 (0.0366)\tloss 1.0635 (1.0744)\tgrad_norm 2.6176 (2.4453)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][120/625]\teta 0:00:18 lr 0.000941\t wd 0.0100\ttime 0.0394 (0.0367)\tloss 0.8384 (1.0750)\tgrad_norm 2.0972 (2.4381)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][130/625]\teta 0:00:18 lr 0.000941\t wd 0.0100\ttime 0.0328 (0.0368)\tloss 1.3193 (1.0796)\tgrad_norm 2.0555 (2.4264)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][140/625]\teta 0:00:17 lr 0.000941\t wd 0.0100\ttime 0.0361 (0.0368)\tloss 1.0498 (1.0767)\tgrad_norm 2.8724 (2.4354)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][150/625]\teta 0:00:17 lr 0.000941\t wd 0.0100\ttime 0.0336 (0.0368)\tloss 1.1885 (1.0770)\tgrad_norm 2.2206 (2.4443)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][160/625]\teta 0:00:17 lr 0.000941\t wd 0.0100\ttime 0.0366 (0.0368)\tloss 0.9556 (1.0764)\tgrad_norm 1.8531 (2.4557)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][170/625]\teta 0:00:16 lr 0.000941\t wd 0.0100\ttime 0.0365 (0.0367)\tloss 1.0674 (1.0770)\tgrad_norm 2.0676 (2.4401)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][180/625]\teta 0:00:16 lr 0.000941\t wd 0.0100\ttime 0.0391 (0.0367)\tloss 0.8628 (1.0743)\tgrad_norm 1.6107 (2.4352)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][190/625]\teta 0:00:15 lr 0.000940\t wd 0.0100\ttime 0.0367 (0.0366)\tloss 1.0312 (1.0734)\tgrad_norm 2.5533 (2.4239)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][200/625]\teta 0:00:15 lr 0.000940\t wd 0.0100\ttime 0.0326 (0.0365)\tloss 1.0430 (1.0758)\tgrad_norm 2.0955 (2.4310)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][210/625]\teta 0:00:15 lr 0.000940\t wd 0.0100\ttime 0.0324 (0.0364)\tloss 1.0449 (1.0758)\tgrad_norm 2.6797 (2.4427)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][220/625]\teta 0:00:14 lr 0.000940\t wd 0.0100\ttime 0.0348 (0.0363)\tloss 1.0820 (1.0784)\tgrad_norm 2.5755 (2.4408)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][230/625]\teta 0:00:14 lr 0.000940\t wd 0.0100\ttime 0.0330 (0.0362)\tloss 0.8398 (1.0773)\tgrad_norm 1.6206 (2.4291)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][240/625]\teta 0:00:13 lr 0.000940\t wd 0.0100\ttime 0.0326 (0.0361)\tloss 0.9897 (1.0782)\tgrad_norm 1.8256 (2.4136)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][250/625]\teta 0:00:13 lr 0.000940\t wd 0.0100\ttime 0.0373 (0.0361)\tloss 1.2070 (1.0838)\tgrad_norm 2.0114 (2.4283)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][260/625]\teta 0:00:13 lr 0.000940\t wd 0.0100\ttime 0.0367 (0.0360)\tloss 1.0352 (1.0827)\tgrad_norm 2.2946 (2.4215)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][270/625]\teta 0:00:12 lr 0.000939\t wd 0.0100\ttime 0.0410 (0.0361)\tloss 1.1055 (1.0803)\tgrad_norm 2.3828 (2.4250)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][280/625]\teta 0:00:12 lr 0.000939\t wd 0.0100\ttime 0.0329 (0.0361)\tloss 1.1631 (1.0807)\tgrad_norm 3.3675 (2.4350)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][290/625]\teta 0:00:12 lr 0.000939\t wd 0.0100\ttime 0.0357 (0.0361)\tloss 1.0049 (1.0775)\tgrad_norm 2.5040 (2.4363)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][300/625]\teta 0:00:11 lr 0.000939\t wd 0.0100\ttime 0.0328 (0.0361)\tloss 0.9868 (1.0759)\tgrad_norm 2.6194 (2.4418)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][310/625]\teta 0:00:11 lr 0.000939\t wd 0.0100\ttime 0.0359 (0.0361)\tloss 1.0312 (1.0747)\tgrad_norm 2.0585 (2.4382)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][320/625]\teta 0:00:10 lr 0.000939\t wd 0.0100\ttime 0.0331 (0.0360)\tloss 1.0342 (1.0758)\tgrad_norm 1.9176 (2.4359)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][330/625]\teta 0:00:10 lr 0.000939\t wd 0.0100\ttime 0.0394 (0.0360)\tloss 1.2529 (1.0753)\tgrad_norm 1.9597 (2.4281)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][340/625]\teta 0:00:10 lr 0.000939\t wd 0.0100\ttime 0.0328 (0.0360)\tloss 0.9531 (1.0757)\tgrad_norm 2.2984 (2.4244)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][350/625]\teta 0:00:09 lr 0.000938\t wd 0.0100\ttime 0.0404 (0.0361)\tloss 0.9668 (1.0745)\tgrad_norm 2.2242 (2.4148)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][360/625]\teta 0:00:09 lr 0.000938\t wd 0.0100\ttime 0.0359 (0.0361)\tloss 1.2529 (1.0741)\tgrad_norm 2.7182 (2.4144)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][370/625]\teta 0:00:09 lr 0.000938\t wd 0.0100\ttime 0.0355 (0.0362)\tloss 0.9189 (1.0735)\tgrad_norm 2.4267 (2.4116)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][380/625]\teta 0:00:08 lr 0.000938\t wd 0.0100\ttime 0.0329 (0.0362)\tloss 1.3662 (1.0734)\tgrad_norm 2.1710 (2.4132)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][390/625]\teta 0:00:08 lr 0.000938\t wd 0.0100\ttime 0.0361 (0.0362)\tloss 1.0527 (1.0738)\tgrad_norm 2.4498 (2.4239)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][400/625]\teta 0:00:08 lr 0.000938\t wd 0.0100\ttime 0.0360 (0.0362)\tloss 1.2139 (1.0754)\tgrad_norm 3.0859 (2.4241)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][410/625]\teta 0:00:07 lr 0.000938\t wd 0.0100\ttime 0.0402 (0.0361)\tloss 1.0215 (1.0764)\tgrad_norm 1.5452 (2.4161)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][420/625]\teta 0:00:07 lr 0.000938\t wd 0.0100\ttime 0.0327 (0.0361)\tloss 1.0859 (1.0758)\tgrad_norm 2.5317 (2.4165)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][430/625]\teta 0:00:07 lr 0.000937\t wd 0.0100\ttime 0.0328 (0.0361)\tloss 1.1846 (1.0761)\tgrad_norm 2.8670 (2.4143)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][440/625]\teta 0:00:06 lr 0.000937\t wd 0.0100\ttime 0.0351 (0.0361)\tloss 1.1104 (1.0747)\tgrad_norm 2.3895 (2.4143)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][450/625]\teta 0:00:06 lr 0.000937\t wd 0.0100\ttime 0.0328 (0.0361)\tloss 1.0205 (1.0759)\tgrad_norm 2.1320 (2.4168)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][460/625]\teta 0:00:05 lr 0.000937\t wd 0.0100\ttime 0.0405 (0.0362)\tloss 1.0361 (1.0751)\tgrad_norm 1.7292 (2.4139)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][470/625]\teta 0:00:05 lr 0.000937\t wd 0.0100\ttime 0.0325 (0.0361)\tloss 1.1396 (1.0755)\tgrad_norm 1.5247 (2.4067)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][480/625]\teta 0:00:05 lr 0.000937\t wd 0.0100\ttime 0.0404 (0.0361)\tloss 1.0312 (1.0748)\tgrad_norm 2.8276 (2.3995)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][490/625]\teta 0:00:04 lr 0.000937\t wd 0.0100\ttime 0.0352 (0.0361)\tloss 1.1035 (1.0751)\tgrad_norm 1.6821 (2.3978)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][500/625]\teta 0:00:04 lr 0.000937\t wd 0.0100\ttime 0.0350 (0.0361)\tloss 1.2354 (1.0761)\tgrad_norm 2.5803 (2.3999)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][510/625]\teta 0:00:04 lr 0.000936\t wd 0.0100\ttime 0.0347 (0.0361)\tloss 1.0947 (1.0737)\tgrad_norm 2.1384 (2.3968)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][520/625]\teta 0:00:03 lr 0.000936\t wd 0.0100\ttime 0.0325 (0.0361)\tloss 1.1143 (1.0733)\tgrad_norm 1.8064 (2.3940)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][530/625]\teta 0:00:03 lr 0.000936\t wd 0.0100\ttime 0.0328 (0.0361)\tloss 0.8887 (1.0722)\tgrad_norm 2.4807 (2.3922)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][540/625]\teta 0:00:03 lr 0.000936\t wd 0.0100\ttime 0.0331 (0.0360)\tloss 1.2520 (1.0731)\tgrad_norm 2.6210 (2.3897)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][550/625]\teta 0:00:02 lr 0.000936\t wd 0.0100\ttime 0.0420 (0.0360)\tloss 0.9160 (1.0729)\tgrad_norm 2.5301 (2.3876)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][560/625]\teta 0:00:02 lr 0.000936\t wd 0.0100\ttime 0.0339 (0.0361)\tloss 0.9629 (1.0732)\tgrad_norm 2.6721 (2.3911)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][570/625]\teta 0:00:01 lr 0.000936\t wd 0.0100\ttime 0.0337 (0.0361)\tloss 0.9722 (1.0728)\tgrad_norm 2.3212 (2.3883)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][580/625]\teta 0:00:01 lr 0.000936\t wd 0.0100\ttime 0.0360 (0.0361)\tloss 1.1104 (1.0731)\tgrad_norm 2.3391 (2.3840)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][590/625]\teta 0:00:01 lr 0.000935\t wd 0.0100\ttime 0.0360 (0.0361)\tloss 1.1387 (1.0734)\tgrad_norm 1.5663 (2.3773)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][600/625]\teta 0:00:00 lr 0.000935\t wd 0.0100\ttime 0.0385 (0.0362)\tloss 1.1338 (1.0729)\tgrad_norm 2.7226 (2.3803)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][610/625]\teta 0:00:00 lr 0.000935\t wd 0.0100\ttime 0.0377 (0.0362)\tloss 0.9448 (1.0721)\tgrad_norm 1.7419 (2.3743)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [18/100][620/625]\teta 0:00:00 lr 0.000935\t wd 0.0100\ttime 0.0401 (0.0362)\tloss 1.1260 (1.0715)\tgrad_norm 2.0850 (2.3725)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "EPOCH 18 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_18.pth saving......\n",
      "./model_save/ckpt_epoch_18.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 1.0508 (1.0508)\tAcc@1 57.812 (57.812)\tAcc@5 93.750 (93.750)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 1.0684 (0.9752)\tAcc@1 64.062 (63.494)\tAcc@5 98.438 (97.159)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 1.1426 (0.9915)\tAcc@1 67.188 (64.137)\tAcc@5 90.625 (96.726)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.9609 (0.9973)\tAcc@1 62.500 (64.113)\tAcc@5 98.438 (96.925)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 1.0068 (1.0105)\tAcc@1 65.625 (63.796)\tAcc@5 100.000 (96.723)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.8652 (1.0050)\tAcc@1 73.438 (64.032)\tAcc@5 95.312 (96.661)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.9287 (0.9963)\tAcc@1 68.750 (64.677)\tAcc@5 98.438 (96.773)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 1.0713 (1.0122)\tAcc@1 60.938 (63.930)\tAcc@5 95.312 (96.523)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 1.1592 (1.0062)\tAcc@1 51.562 (63.580)\tAcc@5 95.312 (96.701)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 1.0332 (1.0060)\tAcc@1 56.250 (63.513)\tAcc@5 98.438 (96.669)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 1.0938 (1.0031)\tAcc@1 65.625 (63.800)\tAcc@5 95.312 (96.751)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.9268 (1.0086)\tAcc@1 64.062 (63.542)\tAcc@5 98.438 (96.734)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.9409 (1.0127)\tAcc@1 65.625 (63.288)\tAcc@5 98.438 (96.694)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.9316 (1.0144)\tAcc@1 60.938 (63.216)\tAcc@5 100.000 (96.732)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 1.1123 (1.0154)\tAcc@1 62.500 (63.109)\tAcc@5 98.438 (96.764)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.9478 (1.0169)\tAcc@1 65.625 (62.976)\tAcc@5 96.875 (96.792)\tMem 455MB\n",
      " * Acc@1 63.060 Acc@5 96.870\n",
      "Accuracy of the network on the 10000 test images: 63.1%\n",
      "Max accuracy: 63.06%\n",
      "Train: [19/100][0/625]\teta 0:00:24 lr 0.000935\t wd 0.0100\ttime 0.0394 (0.0394)\tloss 0.9536 (0.9536)\tgrad_norm 1.7822 (1.7822)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][10/625]\teta 0:00:23 lr 0.000935\t wd 0.0100\ttime 0.0396 (0.0378)\tloss 1.1348 (1.1036)\tgrad_norm 3.0375 (2.3444)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][20/625]\teta 0:00:22 lr 0.000935\t wd 0.0100\ttime 0.0389 (0.0373)\tloss 0.7695 (1.0608)\tgrad_norm 1.7841 (2.3273)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][30/625]\teta 0:00:21 lr 0.000935\t wd 0.0100\ttime 0.0331 (0.0368)\tloss 0.8921 (1.0542)\tgrad_norm 2.7792 (2.2730)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][40/625]\teta 0:00:21 lr 0.000935\t wd 0.0100\ttime 0.0358 (0.0363)\tloss 1.0762 (1.0544)\tgrad_norm 3.2171 (2.3199)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][50/625]\teta 0:00:20 lr 0.000934\t wd 0.0100\ttime 0.0328 (0.0364)\tloss 0.9795 (1.0596)\tgrad_norm 1.7391 (2.3197)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][60/625]\teta 0:00:20 lr 0.000934\t wd 0.0100\ttime 0.0384 (0.0364)\tloss 0.9473 (1.0487)\tgrad_norm 1.8967 (2.2835)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][70/625]\teta 0:00:20 lr 0.000934\t wd 0.0100\ttime 0.0331 (0.0361)\tloss 1.1328 (1.0494)\tgrad_norm 2.1571 (2.2949)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][80/625]\teta 0:00:19 lr 0.000934\t wd 0.0100\ttime 0.0336 (0.0358)\tloss 1.0586 (1.0410)\tgrad_norm 2.2656 (2.3226)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][90/625]\teta 0:00:19 lr 0.000934\t wd 0.0100\ttime 0.0358 (0.0359)\tloss 1.2168 (1.0404)\tgrad_norm 2.6782 (2.3579)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][100/625]\teta 0:00:18 lr 0.000934\t wd 0.0100\ttime 0.0356 (0.0359)\tloss 1.0771 (1.0410)\tgrad_norm 2.1403 (2.3758)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][110/625]\teta 0:00:18 lr 0.000934\t wd 0.0100\ttime 0.0390 (0.0358)\tloss 0.9805 (1.0347)\tgrad_norm 1.9107 (2.3597)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][120/625]\teta 0:00:18 lr 0.000933\t wd 0.0100\ttime 0.0357 (0.0358)\tloss 1.2861 (1.0477)\tgrad_norm 3.1206 (2.4071)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][130/625]\teta 0:00:17 lr 0.000933\t wd 0.0100\ttime 0.0364 (0.0358)\tloss 1.0332 (1.0496)\tgrad_norm 2.3547 (2.4163)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][140/625]\teta 0:00:17 lr 0.000933\t wd 0.0100\ttime 0.0354 (0.0358)\tloss 0.9766 (1.0480)\tgrad_norm 2.1162 (2.4130)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][150/625]\teta 0:00:17 lr 0.000933\t wd 0.0100\ttime 0.0399 (0.0359)\tloss 1.0166 (1.0465)\tgrad_norm 2.1670 (2.4107)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][160/625]\teta 0:00:16 lr 0.000933\t wd 0.0100\ttime 0.0334 (0.0358)\tloss 1.0635 (1.0466)\tgrad_norm 2.5855 (2.4255)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][170/625]\teta 0:00:16 lr 0.000933\t wd 0.0100\ttime 0.0343 (0.0357)\tloss 1.1074 (1.0496)\tgrad_norm 3.4812 (2.4361)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][180/625]\teta 0:00:15 lr 0.000933\t wd 0.0100\ttime 0.0323 (0.0356)\tloss 0.9897 (1.0494)\tgrad_norm 1.6298 (2.4345)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][190/625]\teta 0:00:15 lr 0.000933\t wd 0.0100\ttime 0.0406 (0.0356)\tloss 0.9424 (1.0531)\tgrad_norm 2.8651 (2.4420)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][200/625]\teta 0:00:15 lr 0.000932\t wd 0.0100\ttime 0.0394 (0.0357)\tloss 1.1025 (1.0534)\tgrad_norm 2.9306 (2.4289)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][210/625]\teta 0:00:14 lr 0.000932\t wd 0.0100\ttime 0.0350 (0.0358)\tloss 0.9023 (1.0515)\tgrad_norm 9.9838 (2.4532)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][220/625]\teta 0:00:14 lr 0.000932\t wd 0.0100\ttime 0.0344 (0.0359)\tloss 1.0830 (1.0500)\tgrad_norm 2.0958 (2.4366)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][230/625]\teta 0:00:14 lr 0.000932\t wd 0.0100\ttime 0.0371 (0.0359)\tloss 1.1123 (1.0507)\tgrad_norm 3.0347 (2.4409)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][240/625]\teta 0:00:13 lr 0.000932\t wd 0.0100\ttime 0.0358 (0.0359)\tloss 0.8408 (1.0524)\tgrad_norm 2.3964 (2.4462)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][250/625]\teta 0:00:13 lr 0.000932\t wd 0.0100\ttime 0.0326 (0.0359)\tloss 0.8750 (1.0518)\tgrad_norm 2.0498 (2.4328)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][260/625]\teta 0:00:13 lr 0.000932\t wd 0.0100\ttime 0.0327 (0.0359)\tloss 1.3770 (1.0542)\tgrad_norm 3.4574 (2.4346)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][270/625]\teta 0:00:12 lr 0.000932\t wd 0.0100\ttime 0.0397 (0.0358)\tloss 1.0908 (1.0539)\tgrad_norm 2.0513 (2.4260)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][280/625]\teta 0:00:12 lr 0.000931\t wd 0.0100\ttime 0.0322 (0.0358)\tloss 1.0303 (1.0548)\tgrad_norm 2.6811 (2.4181)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][290/625]\teta 0:00:11 lr 0.000931\t wd 0.0100\ttime 0.0326 (0.0357)\tloss 1.0957 (1.0529)\tgrad_norm 2.0185 (2.4167)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][300/625]\teta 0:00:11 lr 0.000931\t wd 0.0100\ttime 0.0359 (0.0357)\tloss 1.1553 (1.0530)\tgrad_norm 3.2807 (2.4169)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][310/625]\teta 0:00:11 lr 0.000931\t wd 0.0100\ttime 0.0326 (0.0357)\tloss 0.9609 (1.0526)\tgrad_norm 2.0641 (2.4080)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][320/625]\teta 0:00:10 lr 0.000931\t wd 0.0100\ttime 0.0386 (0.0357)\tloss 0.9209 (1.0494)\tgrad_norm 1.9583 (2.4104)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][330/625]\teta 0:00:10 lr 0.000931\t wd 0.0100\ttime 0.0363 (0.0357)\tloss 1.0586 (1.0489)\tgrad_norm 1.8658 (2.4140)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][340/625]\teta 0:00:10 lr 0.000931\t wd 0.0100\ttime 0.0330 (0.0358)\tloss 1.1152 (1.0482)\tgrad_norm 2.6517 (2.4059)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][350/625]\teta 0:00:09 lr 0.000930\t wd 0.0100\ttime 0.0404 (0.0358)\tloss 0.9136 (1.0485)\tgrad_norm 2.1446 (2.4012)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][360/625]\teta 0:00:09 lr 0.000930\t wd 0.0100\ttime 0.0329 (0.0358)\tloss 1.0215 (1.0478)\tgrad_norm 2.3538 (2.3980)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][370/625]\teta 0:00:09 lr 0.000930\t wd 0.0100\ttime 0.0381 (0.0358)\tloss 0.9829 (1.0476)\tgrad_norm 1.8935 (2.3912)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][380/625]\teta 0:00:08 lr 0.000930\t wd 0.0100\ttime 0.0327 (0.0359)\tloss 1.0078 (1.0461)\tgrad_norm 2.2121 (2.3844)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][390/625]\teta 0:00:08 lr 0.000930\t wd 0.0100\ttime 0.0328 (0.0359)\tloss 0.7798 (1.0473)\tgrad_norm 1.6839 (2.3758)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][400/625]\teta 0:00:08 lr 0.000930\t wd 0.0100\ttime 0.0345 (0.0359)\tloss 1.2656 (1.0501)\tgrad_norm 5.1156 (2.3846)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][410/625]\teta 0:00:07 lr 0.000930\t wd 0.0100\ttime 0.0362 (0.0359)\tloss 0.9858 (1.0504)\tgrad_norm 2.2539 (2.3834)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][420/625]\teta 0:00:07 lr 0.000930\t wd 0.0100\ttime 0.0374 (0.0359)\tloss 1.0459 (1.0502)\tgrad_norm 3.2398 (2.3848)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][430/625]\teta 0:00:07 lr 0.000929\t wd 0.0100\ttime 0.0366 (0.0359)\tloss 0.9834 (1.0499)\tgrad_norm 2.1485 (2.3845)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][440/625]\teta 0:00:06 lr 0.000929\t wd 0.0100\ttime 0.0328 (0.0359)\tloss 0.9287 (1.0497)\tgrad_norm 1.9565 (2.3817)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][450/625]\teta 0:00:06 lr 0.000929\t wd 0.0100\ttime 0.0351 (0.0359)\tloss 1.2080 (1.0475)\tgrad_norm 3.4134 (2.3802)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][460/625]\teta 0:00:05 lr 0.000929\t wd 0.0100\ttime 0.0359 (0.0359)\tloss 0.8857 (1.0498)\tgrad_norm 1.9892 (2.3857)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][470/625]\teta 0:00:05 lr 0.000929\t wd 0.0100\ttime 0.0351 (0.0359)\tloss 1.2080 (1.0505)\tgrad_norm 2.5357 (2.3844)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][480/625]\teta 0:00:05 lr 0.000929\t wd 0.0100\ttime 0.0359 (0.0359)\tloss 0.7520 (1.0511)\tgrad_norm 1.5303 (2.3931)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][490/625]\teta 0:00:04 lr 0.000929\t wd 0.0100\ttime 0.0362 (0.0359)\tloss 1.0557 (1.0502)\tgrad_norm 3.3846 (2.3929)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][500/625]\teta 0:00:04 lr 0.000929\t wd 0.0100\ttime 0.0365 (0.0359)\tloss 1.1201 (1.0495)\tgrad_norm 2.4245 (2.3935)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][510/625]\teta 0:00:04 lr 0.000928\t wd 0.0100\ttime 0.0344 (0.0359)\tloss 0.8999 (1.0495)\tgrad_norm 2.3082 (2.3937)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][520/625]\teta 0:00:03 lr 0.000928\t wd 0.0100\ttime 0.0400 (0.0360)\tloss 0.8926 (1.0491)\tgrad_norm 2.5401 (2.3987)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][530/625]\teta 0:00:03 lr 0.000928\t wd 0.0100\ttime 0.0416 (0.0361)\tloss 0.9805 (1.0486)\tgrad_norm 2.1859 (2.4029)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][540/625]\teta 0:00:03 lr 0.000928\t wd 0.0100\ttime 0.0386 (0.0361)\tloss 1.0889 (1.0492)\tgrad_norm 2.7312 (2.4084)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][550/625]\teta 0:00:02 lr 0.000928\t wd 0.0100\ttime 0.0406 (0.0362)\tloss 1.1045 (1.0491)\tgrad_norm 2.4462 (2.4107)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][560/625]\teta 0:00:02 lr 0.000928\t wd 0.0100\ttime 0.0408 (0.0362)\tloss 1.0537 (1.0488)\tgrad_norm 2.4847 (2.4078)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][570/625]\teta 0:00:01 lr 0.000928\t wd 0.0100\ttime 0.0369 (0.0363)\tloss 0.9204 (1.0499)\tgrad_norm 1.9804 (2.4175)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][580/625]\teta 0:00:01 lr 0.000927\t wd 0.0100\ttime 0.0397 (0.0363)\tloss 0.8867 (1.0495)\tgrad_norm 2.3779 (2.4169)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][590/625]\teta 0:00:01 lr 0.000927\t wd 0.0100\ttime 0.0367 (0.0363)\tloss 1.0889 (1.0493)\tgrad_norm 2.6389 (2.4159)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][600/625]\teta 0:00:00 lr 0.000927\t wd 0.0100\ttime 0.0359 (0.0363)\tloss 0.9448 (1.0495)\tgrad_norm 2.0806 (2.4120)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][610/625]\teta 0:00:00 lr 0.000927\t wd 0.0100\ttime 0.0390 (0.0363)\tloss 1.0137 (1.0514)\tgrad_norm 2.1560 (2.4103)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [19/100][620/625]\teta 0:00:00 lr 0.000927\t wd 0.0100\ttime 0.0362 (0.0363)\tloss 1.0283 (1.0517)\tgrad_norm 2.2204 (2.4113)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "EPOCH 19 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_19.pth saving......\n",
      "./model_save/ckpt_epoch_19.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 1.0088 (1.0088)\tAcc@1 60.938 (60.938)\tAcc@5 96.875 (96.875)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.016 (0.016)\tLoss 0.8804 (0.9942)\tAcc@1 70.312 (66.051)\tAcc@5 96.875 (97.869)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.016)\tLoss 0.9668 (1.0128)\tAcc@1 62.500 (63.690)\tAcc@5 95.312 (97.247)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.016)\tLoss 1.2432 (1.0102)\tAcc@1 59.375 (63.710)\tAcc@5 92.188 (97.127)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.016 (0.016)\tLoss 1.0752 (1.0097)\tAcc@1 62.500 (63.643)\tAcc@5 93.750 (97.104)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.016)\tLoss 0.9448 (1.0054)\tAcc@1 67.188 (63.848)\tAcc@5 96.875 (97.120)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.016 (0.016)\tLoss 0.9473 (1.0123)\tAcc@1 67.188 (63.678)\tAcc@5 100.000 (97.106)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.016 (0.016)\tLoss 1.0752 (1.0048)\tAcc@1 60.938 (64.040)\tAcc@5 93.750 (97.117)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.016)\tLoss 0.8838 (1.0013)\tAcc@1 68.750 (64.062)\tAcc@5 100.000 (97.222)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.016)\tLoss 0.8896 (0.9970)\tAcc@1 65.625 (64.337)\tAcc@5 96.875 (97.218)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.016)\tLoss 1.1172 (0.9928)\tAcc@1 59.375 (64.480)\tAcc@5 95.312 (97.184)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.018 (0.016)\tLoss 1.0303 (0.9970)\tAcc@1 64.062 (64.189)\tAcc@5 95.312 (97.227)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.016 (0.016)\tLoss 0.9214 (0.9930)\tAcc@1 73.438 (64.308)\tAcc@5 98.438 (97.301)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.016)\tLoss 1.0566 (0.9973)\tAcc@1 60.938 (64.325)\tAcc@5 95.312 (97.269)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.016 (0.016)\tLoss 0.9214 (0.9990)\tAcc@1 68.750 (64.173)\tAcc@5 95.312 (97.252)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.018 (0.016)\tLoss 1.0371 (0.9984)\tAcc@1 59.375 (64.166)\tAcc@5 96.875 (97.268)\tMem 455MB\n",
      " * Acc@1 64.090 Acc@5 97.240\n",
      "Accuracy of the network on the 10000 test images: 64.1%\n",
      "Max accuracy: 64.09%\n",
      "Train: [20/100][0/625]\teta 0:00:24 lr 0.000927\t wd 0.0100\ttime 0.0385 (0.0385)\tloss 1.1211 (1.1211)\tgrad_norm 3.3566 (3.3566)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [20/100][10/625]\teta 0:00:23 lr 0.000927\t wd 0.0100\ttime 0.0339 (0.0385)\tloss 1.0215 (1.0783)\tgrad_norm 1.9812 (2.5230)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [20/100][20/625]\teta 0:00:22 lr 0.000927\t wd 0.0100\ttime 0.0359 (0.0378)\tloss 1.0117 (1.0610)\tgrad_norm 1.8160 (2.5253)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [20/100][30/625]\teta 0:00:22 lr 0.000926\t wd 0.0100\ttime 0.0330 (0.0370)\tloss 0.9170 (1.0561)\tgrad_norm 2.5573 (2.4633)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [20/100][40/625]\teta 0:00:21 lr 0.000926\t wd 0.0100\ttime 0.0382 (0.0373)\tloss 0.9253 (1.0610)\tgrad_norm 1.9362 (2.4773)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [20/100][50/625]\teta 0:00:21 lr 0.000926\t wd 0.0100\ttime 0.0334 (0.0370)\tloss 1.1982 (1.0577)\tgrad_norm 2.8997 (2.4275)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [20/100][60/625]\teta 0:00:20 lr 0.000926\t wd 0.0100\ttime 0.0329 (0.0365)\tloss 0.9136 (1.0395)\tgrad_norm 1.7001 (2.4160)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [20/100][70/625]\teta 0:00:20 lr 0.000926\t wd 0.0100\ttime 0.0334 (0.0369)\tloss 0.8105 (1.0458)\tgrad_norm 2.2413 (2.3958)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [20/100][80/625]\teta 0:00:20 lr 0.000926\t wd 0.0100\ttime 0.0390 (0.0369)\tloss 1.0762 (1.0412)\tgrad_norm 2.8289 (2.4021)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [20/100][90/625]\teta 0:00:19 lr 0.000926\t wd 0.0100\ttime 0.0366 (0.0367)\tloss 1.3008 (1.0507)\tgrad_norm 2.4834 (2.4096)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [20/100][100/625]\teta 0:00:19 lr 0.000925\t wd 0.0100\ttime 0.0396 (0.0367)\tloss 1.2266 (1.0521)\tgrad_norm 3.5102 (2.4553)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [20/100][110/625]\teta 0:00:18 lr 0.000925\t wd 0.0100\ttime 0.0333 (0.0366)\tloss 1.0742 (1.0522)\tgrad_norm 2.8750 (2.4838)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [20/100][120/625]\teta 0:00:18 lr 0.000925\t wd 0.0100\ttime 0.0387 (0.0366)\tloss 1.0312 (1.0510)\tgrad_norm 2.1476 (2.4669)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [20/100][130/625]\teta 0:00:18 lr 0.000925\t wd 0.0100\ttime 0.0326 (0.0366)\tloss 1.1631 (1.0532)\tgrad_norm 2.3172 (2.4458)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [20/100][140/625]\teta 0:00:17 lr 0.000925\t wd 0.0100\ttime 0.0327 (0.0366)\tloss 0.7783 (1.0451)\tgrad_norm 1.6516 (2.4188)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [20/100][150/625]\teta 0:00:17 lr 0.000925\t wd 0.0100\ttime 0.0331 (0.0366)\tloss 0.9600 (1.0385)\tgrad_norm 2.5624 (2.4127)\tloss_scale 32768.0000 (16926.5166)\tmem 455MB\n",
      "Train: [20/100][160/625]\teta 0:00:16 lr 0.000925\t wd 0.0100\ttime 0.0404 (0.0365)\tloss 0.9819 (1.0336)\tgrad_norm 2.2578 (2.4048)\tloss_scale 32768.0000 (17910.4596)\tmem 455MB\n",
      "Train: [20/100][170/625]\teta 0:00:16 lr 0.000925\t wd 0.0100\ttime 0.0334 (0.0364)\tloss 1.1904 (1.0375)\tgrad_norm 3.5562 (2.4412)\tloss_scale 32768.0000 (18779.3216)\tmem 455MB\n",
      "Train: [20/100][180/625]\teta 0:00:16 lr 0.000924\t wd 0.0100\ttime 0.0347 (0.0362)\tloss 1.1377 (1.0387)\tgrad_norm 2.4783 (2.4479)\tloss_scale 32768.0000 (19552.1768)\tmem 455MB\n",
      "Train: [20/100][190/625]\teta 0:00:15 lr 0.000924\t wd 0.0100\ttime 0.0332 (0.0362)\tloss 1.1465 (1.0377)\tgrad_norm 3.4712 (2.4549)\tloss_scale 32768.0000 (20244.1047)\tmem 455MB\n",
      "Train: [20/100][200/625]\teta 0:00:15 lr 0.000924\t wd 0.0100\ttime 0.0330 (0.0361)\tloss 1.0664 (1.0373)\tgrad_norm 2.5773 (2.4538)\tloss_scale 32768.0000 (20867.1841)\tmem 455MB\n",
      "Train: [20/100][210/625]\teta 0:00:14 lr 0.000924\t wd 0.0100\ttime 0.0328 (0.0360)\tloss 0.9746 (1.0403)\tgrad_norm 3.0046 (2.4687)\tloss_scale 32768.0000 (21431.2038)\tmem 455MB\n",
      "Train: [20/100][220/625]\teta 0:00:14 lr 0.000924\t wd 0.0100\ttime 0.0358 (0.0359)\tloss 0.9941 (1.0387)\tgrad_norm 1.8165 (2.4650)\tloss_scale 32768.0000 (21944.1810)\tmem 455MB\n",
      "Train: [20/100][230/625]\teta 0:00:14 lr 0.000924\t wd 0.0100\ttime 0.0364 (0.0359)\tloss 1.1367 (1.0384)\tgrad_norm 2.1165 (2.4679)\tloss_scale 32768.0000 (22412.7446)\tmem 455MB\n",
      "Train: [20/100][240/625]\teta 0:00:13 lr 0.000924\t wd 0.0100\ttime 0.0330 (0.0358)\tloss 0.9404 (1.0369)\tgrad_norm 2.6981 (2.4750)\tloss_scale 32768.0000 (22842.4232)\tmem 455MB\n",
      "Train: [20/100][250/625]\teta 0:00:13 lr 0.000923\t wd 0.0100\ttime 0.0370 (0.0358)\tloss 1.0547 (1.0410)\tgrad_norm 2.3268 (2.4757)\tloss_scale 32768.0000 (23237.8645)\tmem 455MB\n",
      "Train: [20/100][260/625]\teta 0:00:13 lr 0.000923\t wd 0.0100\ttime 0.0343 (0.0357)\tloss 1.2559 (1.0424)\tgrad_norm 2.1188 (inf)\tloss_scale 16384.0000 (23226.3602)\tmem 455MB\n",
      "Train: [20/100][270/625]\teta 0:00:12 lr 0.000923\t wd 0.0100\ttime 0.0341 (0.0357)\tloss 0.9556 (1.0421)\tgrad_norm 2.2534 (inf)\tloss_scale 16384.0000 (22973.8745)\tmem 455MB\n",
      "Train: [20/100][280/625]\teta 0:00:12 lr 0.000923\t wd 0.0100\ttime 0.0399 (0.0358)\tloss 0.7954 (1.0384)\tgrad_norm 1.9851 (inf)\tloss_scale 16384.0000 (22739.3594)\tmem 455MB\n",
      "Train: [20/100][290/625]\teta 0:00:12 lr 0.000923\t wd 0.0100\ttime 0.0355 (0.0359)\tloss 1.3936 (1.0371)\tgrad_norm 2.5025 (inf)\tloss_scale 16384.0000 (22520.9622)\tmem 455MB\n",
      "Train: [20/100][300/625]\teta 0:00:11 lr 0.000923\t wd 0.0100\ttime 0.0362 (0.0359)\tloss 1.0537 (1.0376)\tgrad_norm 2.5926 (inf)\tloss_scale 16384.0000 (22317.0764)\tmem 455MB\n",
      "Train: [20/100][310/625]\teta 0:00:11 lr 0.000923\t wd 0.0100\ttime 0.0330 (0.0359)\tloss 1.0957 (1.0377)\tgrad_norm 3.8973 (inf)\tloss_scale 16384.0000 (22126.3023)\tmem 455MB\n",
      "Train: [20/100][320/625]\teta 0:00:10 lr 0.000922\t wd 0.0100\ttime 0.0342 (0.0359)\tloss 1.0469 (1.0388)\tgrad_norm 2.2158 (inf)\tloss_scale 16384.0000 (21947.4143)\tmem 455MB\n",
      "Train: [20/100][330/625]\teta 0:00:10 lr 0.000922\t wd 0.0100\ttime 0.0335 (0.0358)\tloss 0.9253 (1.0383)\tgrad_norm 2.3882 (inf)\tloss_scale 16384.0000 (21779.3353)\tmem 455MB\n",
      "Train: [20/100][340/625]\teta 0:00:10 lr 0.000922\t wd 0.0100\ttime 0.0372 (0.0358)\tloss 1.2334 (1.0376)\tgrad_norm 2.9943 (inf)\tloss_scale 16384.0000 (21621.1144)\tmem 455MB\n",
      "Train: [20/100][350/625]\teta 0:00:09 lr 0.000922\t wd 0.0100\ttime 0.0328 (0.0357)\tloss 0.9990 (1.0368)\tgrad_norm 1.6285 (inf)\tloss_scale 16384.0000 (21471.9088)\tmem 455MB\n",
      "Train: [20/100][360/625]\teta 0:00:09 lr 0.000922\t wd 0.0100\ttime 0.0331 (0.0357)\tloss 0.8784 (1.0380)\tgrad_norm 2.4988 (inf)\tloss_scale 16384.0000 (21330.9695)\tmem 455MB\n",
      "Train: [20/100][370/625]\teta 0:00:09 lr 0.000922\t wd 0.0100\ttime 0.0326 (0.0356)\tloss 1.0840 (1.0378)\tgrad_norm 2.5190 (inf)\tloss_scale 16384.0000 (21197.6280)\tmem 455MB\n",
      "Train: [20/100][380/625]\teta 0:00:08 lr 0.000922\t wd 0.0100\ttime 0.0359 (0.0356)\tloss 1.2109 (1.0393)\tgrad_norm 3.0070 (inf)\tloss_scale 16384.0000 (21071.2861)\tmem 455MB\n",
      "Train: [20/100][390/625]\teta 0:00:08 lr 0.000922\t wd 0.0100\ttime 0.0331 (0.0356)\tloss 0.9365 (1.0390)\tgrad_norm 2.3398 (inf)\tloss_scale 16384.0000 (20951.4066)\tmem 455MB\n",
      "Train: [20/100][400/625]\teta 0:00:08 lr 0.000921\t wd 0.0100\ttime 0.0341 (0.0356)\tloss 1.0186 (1.0379)\tgrad_norm 2.7534 (inf)\tloss_scale 16384.0000 (20837.5062)\tmem 455MB\n",
      "Train: [20/100][410/625]\teta 0:00:07 lr 0.000921\t wd 0.0100\ttime 0.0364 (0.0356)\tloss 0.9160 (1.0360)\tgrad_norm 2.2694 (inf)\tloss_scale 16384.0000 (20729.1484)\tmem 455MB\n",
      "Train: [20/100][420/625]\teta 0:00:07 lr 0.000921\t wd 0.0100\ttime 0.0394 (0.0357)\tloss 1.0586 (1.0351)\tgrad_norm 3.2002 (inf)\tloss_scale 16384.0000 (20625.9382)\tmem 455MB\n",
      "Train: [20/100][430/625]\teta 0:00:06 lr 0.000921\t wd 0.0100\ttime 0.0355 (0.0357)\tloss 1.3135 (1.0377)\tgrad_norm 2.1423 (inf)\tloss_scale 16384.0000 (20527.5174)\tmem 455MB\n",
      "Train: [20/100][440/625]\teta 0:00:06 lr 0.000921\t wd 0.0100\ttime 0.0361 (0.0357)\tloss 1.1611 (1.0382)\tgrad_norm 3.0600 (inf)\tloss_scale 16384.0000 (20433.5601)\tmem 455MB\n",
      "Train: [20/100][450/625]\teta 0:00:06 lr 0.000921\t wd 0.0100\ttime 0.0353 (0.0357)\tloss 0.9292 (1.0393)\tgrad_norm 2.0205 (inf)\tloss_scale 16384.0000 (20343.7694)\tmem 455MB\n",
      "Train: [20/100][460/625]\teta 0:00:05 lr 0.000921\t wd 0.0100\ttime 0.0365 (0.0357)\tloss 1.0322 (1.0387)\tgrad_norm 2.6436 (inf)\tloss_scale 16384.0000 (20257.8742)\tmem 455MB\n",
      "Train: [20/100][470/625]\teta 0:00:05 lr 0.000920\t wd 0.0100\ttime 0.0327 (0.0357)\tloss 0.9160 (1.0396)\tgrad_norm 2.5047 (inf)\tloss_scale 16384.0000 (20175.6263)\tmem 455MB\n",
      "Train: [20/100][480/625]\teta 0:00:05 lr 0.000920\t wd 0.0100\ttime 0.0357 (0.0357)\tloss 1.2480 (1.0412)\tgrad_norm 2.0311 (inf)\tloss_scale 16384.0000 (20096.7983)\tmem 455MB\n",
      "Train: [20/100][490/625]\teta 0:00:04 lr 0.000920\t wd 0.0100\ttime 0.0354 (0.0357)\tloss 0.9517 (1.0392)\tgrad_norm 2.5590 (inf)\tloss_scale 16384.0000 (20021.1813)\tmem 455MB\n",
      "Train: [20/100][500/625]\teta 0:00:04 lr 0.000920\t wd 0.0100\ttime 0.0354 (0.0357)\tloss 0.8340 (1.0386)\tgrad_norm 1.6446 (inf)\tloss_scale 16384.0000 (19948.5828)\tmem 455MB\n",
      "Train: [20/100][510/625]\teta 0:00:04 lr 0.000920\t wd 0.0100\ttime 0.0392 (0.0357)\tloss 1.0791 (1.0391)\tgrad_norm 2.4209 (inf)\tloss_scale 16384.0000 (19878.8258)\tmem 455MB\n",
      "Train: [20/100][520/625]\teta 0:00:03 lr 0.000920\t wd 0.0100\ttime 0.0359 (0.0357)\tloss 0.8906 (1.0365)\tgrad_norm 1.6282 (inf)\tloss_scale 16384.0000 (19811.7466)\tmem 455MB\n",
      "Train: [20/100][530/625]\teta 0:00:03 lr 0.000920\t wd 0.0100\ttime 0.0368 (0.0357)\tloss 1.1094 (1.0356)\tgrad_norm 2.6596 (inf)\tloss_scale 16384.0000 (19747.1940)\tmem 455MB\n",
      "Train: [20/100][540/625]\teta 0:00:03 lr 0.000919\t wd 0.0100\ttime 0.0330 (0.0357)\tloss 1.2324 (1.0361)\tgrad_norm 2.9813 (inf)\tloss_scale 16384.0000 (19685.0277)\tmem 455MB\n",
      "Train: [20/100][550/625]\teta 0:00:02 lr 0.000919\t wd 0.0100\ttime 0.0364 (0.0357)\tloss 1.0264 (1.0347)\tgrad_norm 1.7505 (inf)\tloss_scale 16384.0000 (19625.1180)\tmem 455MB\n",
      "Train: [20/100][560/625]\teta 0:00:02 lr 0.000919\t wd 0.0100\ttime 0.0369 (0.0357)\tloss 1.0889 (1.0347)\tgrad_norm 2.5372 (inf)\tloss_scale 16384.0000 (19567.3440)\tmem 455MB\n",
      "Train: [20/100][570/625]\teta 0:00:01 lr 0.000919\t wd 0.0100\ttime 0.0364 (0.0357)\tloss 0.8140 (1.0349)\tgrad_norm 2.6118 (inf)\tloss_scale 16384.0000 (19511.5937)\tmem 455MB\n",
      "Train: [20/100][580/625]\teta 0:00:01 lr 0.000919\t wd 0.0100\ttime 0.0371 (0.0357)\tloss 1.0518 (1.0341)\tgrad_norm 2.7155 (inf)\tloss_scale 16384.0000 (19457.7625)\tmem 455MB\n",
      "Train: [20/100][590/625]\teta 0:00:01 lr 0.000919\t wd 0.0100\ttime 0.0389 (0.0357)\tloss 1.0195 (1.0330)\tgrad_norm 2.2691 (inf)\tloss_scale 16384.0000 (19405.7530)\tmem 455MB\n",
      "Train: [20/100][600/625]\teta 0:00:00 lr 0.000919\t wd 0.0100\ttime 0.0394 (0.0357)\tloss 1.0723 (1.0328)\tgrad_norm 2.2006 (inf)\tloss_scale 16384.0000 (19355.4742)\tmem 455MB\n",
      "Train: [20/100][610/625]\teta 0:00:00 lr 0.000918\t wd 0.0100\ttime 0.0333 (0.0357)\tloss 1.0928 (1.0326)\tgrad_norm 1.9021 (inf)\tloss_scale 16384.0000 (19306.8412)\tmem 455MB\n",
      "Train: [20/100][620/625]\teta 0:00:00 lr 0.000918\t wd 0.0100\ttime 0.0357 (0.0357)\tloss 0.7891 (1.0324)\tgrad_norm 2.0593 (inf)\tloss_scale 16384.0000 (19259.7746)\tmem 455MB\n",
      "EPOCH 20 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_20.pth saving......\n",
      "./model_save/ckpt_epoch_20.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 1.2070 (1.2070)\tAcc@1 53.125 (53.125)\tAcc@5 98.438 (98.438)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.016 (0.016)\tLoss 1.0674 (1.0089)\tAcc@1 64.062 (61.790)\tAcc@5 96.875 (96.875)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.016)\tLoss 0.8604 (0.9779)\tAcc@1 71.875 (63.616)\tAcc@5 95.312 (96.280)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.016)\tLoss 0.9746 (0.9770)\tAcc@1 64.062 (63.609)\tAcc@5 95.312 (96.623)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.016)\tLoss 0.8184 (0.9930)\tAcc@1 68.750 (63.377)\tAcc@5 98.438 (96.494)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.016)\tLoss 0.9019 (0.9881)\tAcc@1 71.875 (63.940)\tAcc@5 96.875 (96.538)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 1.1523 (0.9936)\tAcc@1 57.812 (63.909)\tAcc@5 92.188 (96.542)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.8398 (0.9804)\tAcc@1 68.750 (64.393)\tAcc@5 98.438 (96.699)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 1.0459 (0.9723)\tAcc@1 64.062 (64.931)\tAcc@5 93.750 (96.759)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.7373 (0.9679)\tAcc@1 75.000 (65.110)\tAcc@5 96.875 (96.806)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.9800 (0.9690)\tAcc@1 64.062 (65.114)\tAcc@5 96.875 (96.937)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 1.2627 (0.9771)\tAcc@1 53.125 (64.977)\tAcc@5 96.875 (96.903)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 1.1963 (0.9769)\tAcc@1 56.250 (64.966)\tAcc@5 93.750 (96.901)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.7427 (0.9733)\tAcc@1 76.562 (65.076)\tAcc@5 100.000 (97.054)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.9326 (0.9699)\tAcc@1 68.750 (65.049)\tAcc@5 98.438 (97.097)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.9141 (0.9676)\tAcc@1 70.312 (65.284)\tAcc@5 96.875 (97.061)\tMem 455MB\n",
      " * Acc@1 65.270 Acc@5 97.100\n",
      "Accuracy of the network on the 10000 test images: 65.3%\n",
      "Max accuracy: 65.27%\n",
      "Train: [21/100][0/625]\teta 0:00:23 lr 0.000918\t wd 0.0100\ttime 0.0378 (0.0378)\tloss 1.1875 (1.1875)\tgrad_norm 3.4928 (3.4928)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][10/625]\teta 0:00:21 lr 0.000918\t wd 0.0100\ttime 0.0328 (0.0352)\tloss 0.9717 (1.0175)\tgrad_norm 2.5749 (2.7565)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][20/625]\teta 0:00:21 lr 0.000918\t wd 0.0100\ttime 0.0382 (0.0355)\tloss 0.8394 (1.0326)\tgrad_norm 1.8361 (2.6656)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][30/625]\teta 0:00:21 lr 0.000918\t wd 0.0100\ttime 0.0379 (0.0359)\tloss 1.0840 (1.0236)\tgrad_norm 2.9768 (2.6249)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][40/625]\teta 0:00:21 lr 0.000918\t wd 0.0100\ttime 0.0397 (0.0364)\tloss 1.0303 (1.0203)\tgrad_norm 2.7880 (2.6519)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][50/625]\teta 0:00:20 lr 0.000918\t wd 0.0100\ttime 0.0362 (0.0365)\tloss 0.9355 (1.0092)\tgrad_norm 2.2943 (2.6315)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][60/625]\teta 0:00:20 lr 0.000917\t wd 0.0100\ttime 0.0332 (0.0363)\tloss 0.9946 (0.9999)\tgrad_norm 2.4160 (2.5644)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][70/625]\teta 0:00:20 lr 0.000917\t wd 0.0100\ttime 0.0338 (0.0366)\tloss 1.0781 (0.9996)\tgrad_norm 3.0867 (2.5966)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][80/625]\teta 0:00:19 lr 0.000917\t wd 0.0100\ttime 0.0351 (0.0366)\tloss 0.9897 (1.0003)\tgrad_norm 2.3449 (2.6287)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][90/625]\teta 0:00:19 lr 0.000917\t wd 0.0100\ttime 0.0358 (0.0366)\tloss 0.7451 (1.0027)\tgrad_norm 1.7346 (2.5945)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][100/625]\teta 0:00:19 lr 0.000917\t wd 0.0100\ttime 0.0328 (0.0366)\tloss 0.7910 (1.0049)\tgrad_norm 1.8175 (2.5503)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][110/625]\teta 0:00:18 lr 0.000917\t wd 0.0100\ttime 0.0347 (0.0366)\tloss 0.7261 (1.0074)\tgrad_norm 2.3289 (2.5478)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][120/625]\teta 0:00:18 lr 0.000917\t wd 0.0100\ttime 0.0354 (0.0366)\tloss 1.0332 (1.0074)\tgrad_norm 2.5701 (2.5269)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][130/625]\teta 0:00:18 lr 0.000916\t wd 0.0100\ttime 0.0397 (0.0365)\tloss 1.0752 (1.0091)\tgrad_norm 2.8199 (2.5449)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][140/625]\teta 0:00:17 lr 0.000916\t wd 0.0100\ttime 0.0409 (0.0365)\tloss 0.7578 (1.0094)\tgrad_norm 1.9528 (2.5403)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][150/625]\teta 0:00:17 lr 0.000916\t wd 0.0100\ttime 0.0354 (0.0365)\tloss 1.0059 (1.0091)\tgrad_norm 2.3792 (2.5288)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][160/625]\teta 0:00:17 lr 0.000916\t wd 0.0100\ttime 0.0371 (0.0366)\tloss 0.8818 (1.0091)\tgrad_norm 2.3450 (2.5232)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][170/625]\teta 0:00:16 lr 0.000916\t wd 0.0100\ttime 0.0397 (0.0366)\tloss 1.2764 (1.0103)\tgrad_norm 3.1578 (2.5258)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][180/625]\teta 0:00:16 lr 0.000916\t wd 0.0100\ttime 0.0338 (0.0366)\tloss 1.0996 (1.0090)\tgrad_norm 2.2856 (2.5158)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][190/625]\teta 0:00:15 lr 0.000916\t wd 0.0100\ttime 0.0354 (0.0366)\tloss 0.9468 (1.0091)\tgrad_norm 1.9326 (2.4973)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][200/625]\teta 0:00:15 lr 0.000915\t wd 0.0100\ttime 0.0386 (0.0366)\tloss 1.1846 (1.0119)\tgrad_norm 2.7062 (2.4836)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][210/625]\teta 0:00:15 lr 0.000915\t wd 0.0100\ttime 0.0341 (0.0366)\tloss 1.1855 (1.0146)\tgrad_norm 1.8747 (2.4709)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][220/625]\teta 0:00:14 lr 0.000915\t wd 0.0100\ttime 0.0405 (0.0367)\tloss 1.0361 (1.0173)\tgrad_norm 1.9585 (2.4568)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][230/625]\teta 0:00:14 lr 0.000915\t wd 0.0100\ttime 0.0388 (0.0367)\tloss 1.0586 (1.0167)\tgrad_norm 1.6948 (2.4360)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][240/625]\teta 0:00:14 lr 0.000915\t wd 0.0100\ttime 0.0364 (0.0367)\tloss 0.7876 (1.0178)\tgrad_norm 2.4751 (2.4346)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][250/625]\teta 0:00:13 lr 0.000915\t wd 0.0100\ttime 0.0372 (0.0367)\tloss 1.0273 (1.0200)\tgrad_norm 2.2753 (2.4357)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][260/625]\teta 0:00:13 lr 0.000915\t wd 0.0100\ttime 0.0399 (0.0367)\tloss 1.0947 (1.0231)\tgrad_norm 2.0944 (2.4309)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][270/625]\teta 0:00:13 lr 0.000914\t wd 0.0100\ttime 0.0331 (0.0367)\tloss 0.8799 (1.0221)\tgrad_norm 2.1143 (2.4265)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][280/625]\teta 0:00:12 lr 0.000914\t wd 0.0100\ttime 0.0359 (0.0367)\tloss 1.1582 (1.0227)\tgrad_norm 2.7311 (2.4168)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][290/625]\teta 0:00:12 lr 0.000914\t wd 0.0100\ttime 0.0389 (0.0367)\tloss 0.9932 (1.0245)\tgrad_norm 2.2676 (2.4145)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][300/625]\teta 0:00:11 lr 0.000914\t wd 0.0100\ttime 0.0327 (0.0367)\tloss 1.3447 (1.0249)\tgrad_norm 2.0182 (2.4079)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][310/625]\teta 0:00:11 lr 0.000914\t wd 0.0100\ttime 0.0329 (0.0366)\tloss 1.0498 (1.0258)\tgrad_norm 1.7450 (2.4019)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][320/625]\teta 0:00:11 lr 0.000914\t wd 0.0100\ttime 0.0332 (0.0366)\tloss 1.0127 (1.0256)\tgrad_norm 2.1919 (2.4017)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][330/625]\teta 0:00:10 lr 0.000914\t wd 0.0100\ttime 0.0356 (0.0365)\tloss 1.1816 (1.0239)\tgrad_norm 3.0285 (2.3967)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][340/625]\teta 0:00:10 lr 0.000913\t wd 0.0100\ttime 0.0414 (0.0365)\tloss 1.0654 (1.0255)\tgrad_norm 1.9135 (2.4008)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][350/625]\teta 0:00:10 lr 0.000913\t wd 0.0100\ttime 0.0360 (0.0365)\tloss 0.7080 (1.0260)\tgrad_norm 1.7403 (2.3987)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][360/625]\teta 0:00:09 lr 0.000913\t wd 0.0100\ttime 0.0331 (0.0364)\tloss 0.8491 (1.0246)\tgrad_norm 1.9090 (2.3949)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][370/625]\teta 0:00:09 lr 0.000913\t wd 0.0100\ttime 0.0325 (0.0364)\tloss 1.0078 (1.0245)\tgrad_norm 1.5881 (2.3980)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][380/625]\teta 0:00:08 lr 0.000913\t wd 0.0100\ttime 0.0329 (0.0363)\tloss 0.8882 (1.0243)\tgrad_norm 3.8431 (2.4037)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][390/625]\teta 0:00:08 lr 0.000913\t wd 0.0100\ttime 0.0371 (0.0363)\tloss 0.9238 (1.0247)\tgrad_norm 1.8792 (2.4146)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][400/625]\teta 0:00:08 lr 0.000913\t wd 0.0100\ttime 0.0330 (0.0362)\tloss 1.2207 (1.0247)\tgrad_norm 2.5733 (2.4092)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][410/625]\teta 0:00:07 lr 0.000912\t wd 0.0100\ttime 0.0349 (0.0362)\tloss 0.8989 (1.0244)\tgrad_norm 2.1853 (2.4046)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][420/625]\teta 0:00:07 lr 0.000912\t wd 0.0100\ttime 0.0375 (0.0362)\tloss 1.0830 (1.0236)\tgrad_norm 2.3489 (2.4062)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][430/625]\teta 0:00:07 lr 0.000912\t wd 0.0100\ttime 0.0372 (0.0363)\tloss 0.9146 (1.0228)\tgrad_norm 3.4438 (2.3993)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][440/625]\teta 0:00:06 lr 0.000912\t wd 0.0100\ttime 0.0329 (0.0363)\tloss 1.0449 (1.0209)\tgrad_norm 2.0084 (2.3973)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][450/625]\teta 0:00:06 lr 0.000912\t wd 0.0100\ttime 0.0402 (0.0363)\tloss 1.5117 (1.0212)\tgrad_norm 3.0457 (2.3918)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][460/625]\teta 0:00:05 lr 0.000912\t wd 0.0100\ttime 0.0377 (0.0363)\tloss 1.2285 (1.0221)\tgrad_norm 2.5442 (2.3955)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][470/625]\teta 0:00:05 lr 0.000911\t wd 0.0100\ttime 0.0330 (0.0363)\tloss 1.0039 (1.0209)\tgrad_norm 1.9289 (2.3945)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][480/625]\teta 0:00:05 lr 0.000911\t wd 0.0100\ttime 0.0387 (0.0363)\tloss 1.1797 (1.0211)\tgrad_norm 2.3575 (2.3944)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][490/625]\teta 0:00:04 lr 0.000911\t wd 0.0100\ttime 0.0361 (0.0363)\tloss 0.8511 (1.0208)\tgrad_norm 1.7757 (2.3941)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][500/625]\teta 0:00:04 lr 0.000911\t wd 0.0100\ttime 0.0329 (0.0362)\tloss 1.0723 (1.0204)\tgrad_norm 2.3354 (2.3897)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][510/625]\teta 0:00:04 lr 0.000911\t wd 0.0100\ttime 0.0333 (0.0362)\tloss 1.0098 (1.0202)\tgrad_norm 2.3050 (2.3859)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][520/625]\teta 0:00:03 lr 0.000911\t wd 0.0100\ttime 0.0327 (0.0361)\tloss 0.9170 (1.0189)\tgrad_norm 1.7273 (2.3809)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][530/625]\teta 0:00:03 lr 0.000911\t wd 0.0100\ttime 0.0328 (0.0361)\tloss 0.8940 (1.0181)\tgrad_norm 1.7438 (2.3729)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][540/625]\teta 0:00:03 lr 0.000910\t wd 0.0100\ttime 0.0361 (0.0361)\tloss 0.9116 (1.0171)\tgrad_norm 2.1998 (2.3710)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][550/625]\teta 0:00:02 lr 0.000910\t wd 0.0100\ttime 0.0327 (0.0360)\tloss 0.8486 (1.0170)\tgrad_norm 1.7800 (2.3659)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][560/625]\teta 0:00:02 lr 0.000910\t wd 0.0100\ttime 0.0348 (0.0361)\tloss 0.7759 (1.0161)\tgrad_norm 1.8139 (2.3676)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][570/625]\teta 0:00:01 lr 0.000910\t wd 0.0100\ttime 0.0355 (0.0361)\tloss 0.8789 (1.0161)\tgrad_norm 2.9834 (2.3713)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][580/625]\teta 0:00:01 lr 0.000910\t wd 0.0100\ttime 0.0363 (0.0360)\tloss 1.1807 (1.0173)\tgrad_norm 3.5059 (2.3783)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][590/625]\teta 0:00:01 lr 0.000910\t wd 0.0100\ttime 0.0328 (0.0360)\tloss 0.9609 (1.0172)\tgrad_norm 2.3287 (2.3824)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][600/625]\teta 0:00:00 lr 0.000910\t wd 0.0100\ttime 0.0387 (0.0360)\tloss 1.1738 (1.0170)\tgrad_norm 2.5679 (2.3780)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][610/625]\teta 0:00:00 lr 0.000909\t wd 0.0100\ttime 0.0362 (0.0360)\tloss 0.8618 (1.0168)\tgrad_norm 2.5992 (2.3789)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [21/100][620/625]\teta 0:00:00 lr 0.000909\t wd 0.0100\ttime 0.0407 (0.0361)\tloss 1.2246 (1.0177)\tgrad_norm 2.3238 (2.3904)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "EPOCH 21 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_21.pth saving......\n",
      "./model_save/ckpt_epoch_21.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 1.1289 (1.1289)\tAcc@1 57.812 (57.812)\tAcc@5 100.000 (100.000)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.016 (0.016)\tLoss 0.9580 (0.9908)\tAcc@1 67.188 (63.210)\tAcc@5 96.875 (97.301)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.016)\tLoss 1.0732 (1.0148)\tAcc@1 60.938 (63.839)\tAcc@5 93.750 (96.205)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.8960 (1.0009)\tAcc@1 64.062 (64.315)\tAcc@5 98.438 (96.472)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.8306 (0.9802)\tAcc@1 71.875 (65.015)\tAcc@5 95.312 (96.913)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 1.1377 (1.0044)\tAcc@1 54.688 (64.185)\tAcc@5 96.875 (96.844)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.7837 (0.9966)\tAcc@1 75.000 (64.703)\tAcc@5 100.000 (97.029)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.8857 (0.9903)\tAcc@1 68.750 (64.833)\tAcc@5 96.875 (97.095)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.9844 (0.9946)\tAcc@1 65.625 (64.815)\tAcc@5 95.312 (96.933)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 1.1543 (0.9889)\tAcc@1 60.938 (64.938)\tAcc@5 95.312 (96.909)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.8198 (0.9859)\tAcc@1 70.312 (64.759)\tAcc@5 100.000 (96.999)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.8315 (0.9835)\tAcc@1 65.625 (64.555)\tAcc@5 96.875 (97.044)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 1.0352 (0.9875)\tAcc@1 62.500 (64.514)\tAcc@5 98.438 (96.991)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.8198 (0.9883)\tAcc@1 75.000 (64.647)\tAcc@5 100.000 (96.970)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 1.0684 (0.9871)\tAcc@1 57.812 (64.683)\tAcc@5 98.438 (97.008)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.8477 (0.9795)\tAcc@1 73.438 (64.952)\tAcc@5 96.875 (97.082)\tMem 455MB\n",
      " * Acc@1 64.960 Acc@5 97.110\n",
      "Accuracy of the network on the 10000 test images: 65.0%\n",
      "Max accuracy: 65.27%\n",
      "Train: [22/100][0/625]\teta 0:00:23 lr 0.000909\t wd 0.0100\ttime 0.0378 (0.0378)\tloss 1.2783 (1.2783)\tgrad_norm 3.5370 (3.5370)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][10/625]\teta 0:00:21 lr 0.000909\t wd 0.0100\ttime 0.0331 (0.0353)\tloss 1.2617 (1.0612)\tgrad_norm 1.8391 (2.6151)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][20/625]\teta 0:00:21 lr 0.000909\t wd 0.0100\ttime 0.0399 (0.0357)\tloss 0.9775 (0.9977)\tgrad_norm 2.7188 (2.6166)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][30/625]\teta 0:00:21 lr 0.000909\t wd 0.0100\ttime 0.0394 (0.0359)\tloss 0.9512 (0.9868)\tgrad_norm 1.8370 (2.4833)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][40/625]\teta 0:00:20 lr 0.000909\t wd 0.0100\ttime 0.0358 (0.0358)\tloss 1.0439 (0.9998)\tgrad_norm 1.7661 (2.4545)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][50/625]\teta 0:00:20 lr 0.000908\t wd 0.0100\ttime 0.0390 (0.0358)\tloss 1.0303 (1.0183)\tgrad_norm 1.9387 (2.4396)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][60/625]\teta 0:00:20 lr 0.000908\t wd 0.0100\ttime 0.0365 (0.0357)\tloss 1.0098 (1.0078)\tgrad_norm 2.4354 (2.4338)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][70/625]\teta 0:00:19 lr 0.000908\t wd 0.0100\ttime 0.0327 (0.0356)\tloss 0.9453 (1.0072)\tgrad_norm 1.8740 (2.4416)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][80/625]\teta 0:00:19 lr 0.000908\t wd 0.0100\ttime 0.0329 (0.0356)\tloss 1.0000 (1.0011)\tgrad_norm 1.9258 (2.4242)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][90/625]\teta 0:00:19 lr 0.000908\t wd 0.0100\ttime 0.0365 (0.0356)\tloss 0.9062 (1.0018)\tgrad_norm 2.5689 (2.4181)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][100/625]\teta 0:00:18 lr 0.000908\t wd 0.0100\ttime 0.0345 (0.0357)\tloss 1.1338 (1.0060)\tgrad_norm 2.6428 (2.4262)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][110/625]\teta 0:00:18 lr 0.000908\t wd 0.0100\ttime 0.0402 (0.0360)\tloss 0.9355 (1.0060)\tgrad_norm 2.0002 (2.4279)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][120/625]\teta 0:00:18 lr 0.000907\t wd 0.0100\ttime 0.0331 (0.0360)\tloss 0.9854 (1.0071)\tgrad_norm 4.1105 (2.4416)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][130/625]\teta 0:00:17 lr 0.000907\t wd 0.0100\ttime 0.0334 (0.0360)\tloss 0.8887 (1.0073)\tgrad_norm 1.5643 (2.4423)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][140/625]\teta 0:00:17 lr 0.000907\t wd 0.0100\ttime 0.0360 (0.0360)\tloss 0.6860 (1.0088)\tgrad_norm 2.4459 (2.4684)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][150/625]\teta 0:00:17 lr 0.000907\t wd 0.0100\ttime 0.0361 (0.0360)\tloss 0.9551 (1.0084)\tgrad_norm 1.8842 (2.4606)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][160/625]\teta 0:00:16 lr 0.000907\t wd 0.0100\ttime 0.0368 (0.0360)\tloss 1.0459 (1.0062)\tgrad_norm 2.3045 (2.4530)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][170/625]\teta 0:00:16 lr 0.000907\t wd 0.0100\ttime 0.0385 (0.0360)\tloss 0.9434 (1.0040)\tgrad_norm 2.2598 (2.4457)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][180/625]\teta 0:00:16 lr 0.000907\t wd 0.0100\ttime 0.0345 (0.0361)\tloss 0.9810 (1.0058)\tgrad_norm 2.3445 (2.4339)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][190/625]\teta 0:00:15 lr 0.000906\t wd 0.0100\ttime 0.0363 (0.0361)\tloss 0.9653 (1.0045)\tgrad_norm 1.9482 (2.4281)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][200/625]\teta 0:00:15 lr 0.000906\t wd 0.0100\ttime 0.0326 (0.0361)\tloss 1.0137 (1.0035)\tgrad_norm 2.4049 (2.4256)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][210/625]\teta 0:00:14 lr 0.000906\t wd 0.0100\ttime 0.0330 (0.0361)\tloss 0.9785 (1.0019)\tgrad_norm 2.3387 (2.4253)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][220/625]\teta 0:00:14 lr 0.000906\t wd 0.0100\ttime 0.0339 (0.0362)\tloss 0.8521 (0.9995)\tgrad_norm 2.1735 (2.4158)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][230/625]\teta 0:00:14 lr 0.000906\t wd 0.0100\ttime 0.0359 (0.0361)\tloss 1.0732 (1.0004)\tgrad_norm 2.0591 (2.4174)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][240/625]\teta 0:00:13 lr 0.000906\t wd 0.0100\ttime 0.0391 (0.0362)\tloss 1.0176 (0.9993)\tgrad_norm 2.6289 (2.4372)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][250/625]\teta 0:00:13 lr 0.000905\t wd 0.0100\ttime 0.0359 (0.0361)\tloss 0.8159 (0.9986)\tgrad_norm 2.2119 (2.4582)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][260/625]\teta 0:00:13 lr 0.000905\t wd 0.0100\ttime 0.0327 (0.0362)\tloss 1.1328 (0.9995)\tgrad_norm 2.7517 (2.4574)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][270/625]\teta 0:00:12 lr 0.000905\t wd 0.0100\ttime 0.0333 (0.0362)\tloss 0.9819 (0.9982)\tgrad_norm 3.0874 (2.4460)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][280/625]\teta 0:00:12 lr 0.000905\t wd 0.0100\ttime 0.0333 (0.0362)\tloss 0.9663 (0.9961)\tgrad_norm 2.4889 (2.4347)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][290/625]\teta 0:00:12 lr 0.000905\t wd 0.0100\ttime 0.0395 (0.0362)\tloss 1.3115 (0.9983)\tgrad_norm 5.5740 (2.4465)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][300/625]\teta 0:00:11 lr 0.000905\t wd 0.0100\ttime 0.0329 (0.0362)\tloss 1.0264 (0.9994)\tgrad_norm 2.0030 (2.4388)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][310/625]\teta 0:00:11 lr 0.000905\t wd 0.0100\ttime 0.0387 (0.0362)\tloss 0.9448 (1.0007)\tgrad_norm 2.6468 (2.4414)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][320/625]\teta 0:00:11 lr 0.000904\t wd 0.0100\ttime 0.0398 (0.0362)\tloss 0.9238 (1.0023)\tgrad_norm 2.9333 (2.4435)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][330/625]\teta 0:00:10 lr 0.000904\t wd 0.0100\ttime 0.0342 (0.0362)\tloss 0.8730 (1.0017)\tgrad_norm 2.7854 (2.4415)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][340/625]\teta 0:00:10 lr 0.000904\t wd 0.0100\ttime 0.0354 (0.0362)\tloss 0.9141 (1.0016)\tgrad_norm 2.5795 (2.4359)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][350/625]\teta 0:00:09 lr 0.000904\t wd 0.0100\ttime 0.0365 (0.0363)\tloss 0.9229 (1.0027)\tgrad_norm 2.3086 (2.4314)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][360/625]\teta 0:00:09 lr 0.000904\t wd 0.0100\ttime 0.0332 (0.0362)\tloss 1.3516 (1.0026)\tgrad_norm 2.3565 (2.4230)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][370/625]\teta 0:00:09 lr 0.000904\t wd 0.0100\ttime 0.0369 (0.0363)\tloss 0.9604 (1.0019)\tgrad_norm 2.0195 (2.4133)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][380/625]\teta 0:00:08 lr 0.000903\t wd 0.0100\ttime 0.0364 (0.0363)\tloss 0.9702 (1.0008)\tgrad_norm 2.3088 (2.4026)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][390/625]\teta 0:00:08 lr 0.000903\t wd 0.0100\ttime 0.0360 (0.0363)\tloss 1.0010 (1.0022)\tgrad_norm 2.2047 (2.4056)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][400/625]\teta 0:00:08 lr 0.000903\t wd 0.0100\ttime 0.0326 (0.0362)\tloss 0.9819 (1.0015)\tgrad_norm 2.6315 (2.4015)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][410/625]\teta 0:00:07 lr 0.000903\t wd 0.0100\ttime 0.0329 (0.0362)\tloss 0.9053 (1.0016)\tgrad_norm 2.2774 (2.4013)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][420/625]\teta 0:00:07 lr 0.000903\t wd 0.0100\ttime 0.0328 (0.0362)\tloss 0.9897 (1.0017)\tgrad_norm 1.9598 (2.3940)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][430/625]\teta 0:00:07 lr 0.000903\t wd 0.0100\ttime 0.0356 (0.0361)\tloss 0.8906 (1.0018)\tgrad_norm 2.3026 (2.3941)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][440/625]\teta 0:00:06 lr 0.000903\t wd 0.0100\ttime 0.0357 (0.0362)\tloss 0.9644 (0.9986)\tgrad_norm 2.8316 (2.3948)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][450/625]\teta 0:00:06 lr 0.000902\t wd 0.0100\ttime 0.0348 (0.0361)\tloss 0.9370 (0.9990)\tgrad_norm 1.6513 (2.3856)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][460/625]\teta 0:00:05 lr 0.000902\t wd 0.0100\ttime 0.0328 (0.0361)\tloss 1.0430 (0.9979)\tgrad_norm 2.2503 (2.3788)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][470/625]\teta 0:00:05 lr 0.000902\t wd 0.0100\ttime 0.0371 (0.0361)\tloss 0.9702 (0.9981)\tgrad_norm 1.8144 (2.3768)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][480/625]\teta 0:00:05 lr 0.000902\t wd 0.0100\ttime 0.0324 (0.0361)\tloss 1.2080 (0.9996)\tgrad_norm 2.2184 (2.3723)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][490/625]\teta 0:00:04 lr 0.000902\t wd 0.0100\ttime 0.0334 (0.0361)\tloss 1.1523 (0.9994)\tgrad_norm 2.9622 (2.3706)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][500/625]\teta 0:00:04 lr 0.000902\t wd 0.0100\ttime 0.0356 (0.0360)\tloss 0.9951 (1.0000)\tgrad_norm 2.2191 (2.3714)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][510/625]\teta 0:00:04 lr 0.000902\t wd 0.0100\ttime 0.0324 (0.0360)\tloss 1.0244 (0.9990)\tgrad_norm 2.4634 (2.3684)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][520/625]\teta 0:00:03 lr 0.000901\t wd 0.0100\ttime 0.0392 (0.0360)\tloss 0.9414 (0.9977)\tgrad_norm 2.1967 (2.3648)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][530/625]\teta 0:00:03 lr 0.000901\t wd 0.0100\ttime 0.0367 (0.0360)\tloss 0.9058 (0.9971)\tgrad_norm 1.9567 (2.3651)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][540/625]\teta 0:00:03 lr 0.000901\t wd 0.0100\ttime 0.0375 (0.0360)\tloss 0.9629 (0.9961)\tgrad_norm 1.9370 (2.3598)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][550/625]\teta 0:00:02 lr 0.000901\t wd 0.0100\ttime 0.0377 (0.0360)\tloss 0.9751 (0.9958)\tgrad_norm 2.0800 (2.3570)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][560/625]\teta 0:00:02 lr 0.000901\t wd 0.0100\ttime 0.0323 (0.0360)\tloss 1.0615 (0.9947)\tgrad_norm 2.0038 (2.3590)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][570/625]\teta 0:00:01 lr 0.000901\t wd 0.0100\ttime 0.0326 (0.0359)\tloss 1.1436 (0.9944)\tgrad_norm 1.6709 (2.3524)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][580/625]\teta 0:00:01 lr 0.000900\t wd 0.0100\ttime 0.0327 (0.0359)\tloss 1.0303 (0.9956)\tgrad_norm 2.6159 (2.3579)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][590/625]\teta 0:00:01 lr 0.000900\t wd 0.0100\ttime 0.0323 (0.0359)\tloss 1.0498 (0.9961)\tgrad_norm 2.1740 (2.3572)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][600/625]\teta 0:00:00 lr 0.000900\t wd 0.0100\ttime 0.0361 (0.0358)\tloss 0.9053 (0.9950)\tgrad_norm 2.1865 (2.3596)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][610/625]\teta 0:00:00 lr 0.000900\t wd 0.0100\ttime 0.0381 (0.0358)\tloss 0.9995 (0.9950)\tgrad_norm 2.6732 (2.3599)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [22/100][620/625]\teta 0:00:00 lr 0.000900\t wd 0.0100\ttime 0.0364 (0.0358)\tloss 0.9995 (0.9960)\tgrad_norm 2.2283 (2.3593)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "EPOCH 22 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_22.pth saving......\n",
      "./model_save/ckpt_epoch_22.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 1.0020 (1.0020)\tAcc@1 67.188 (67.188)\tAcc@5 98.438 (98.438)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.8936 (0.9796)\tAcc@1 60.938 (63.352)\tAcc@5 98.438 (98.153)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.7837 (0.9863)\tAcc@1 75.000 (63.244)\tAcc@5 98.438 (97.917)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.9297 (0.9840)\tAcc@1 65.625 (63.609)\tAcc@5 98.438 (97.833)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 1.0898 (0.9840)\tAcc@1 59.375 (63.605)\tAcc@5 92.188 (97.637)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 1.1475 (0.9862)\tAcc@1 60.938 (63.634)\tAcc@5 95.312 (97.763)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.9312 (0.9837)\tAcc@1 68.750 (63.858)\tAcc@5 96.875 (97.669)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.7866 (0.9736)\tAcc@1 71.875 (64.371)\tAcc@5 100.000 (97.711)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 1.0352 (0.9692)\tAcc@1 65.625 (64.660)\tAcc@5 93.750 (97.569)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 1.0342 (0.9795)\tAcc@1 65.625 (64.663)\tAcc@5 93.750 (97.373)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.8721 (0.9796)\tAcc@1 71.875 (64.805)\tAcc@5 98.438 (97.324)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.016 (0.015)\tLoss 1.2344 (0.9863)\tAcc@1 48.438 (64.710)\tAcc@5 96.875 (97.354)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.016 (0.015)\tLoss 1.1113 (0.9845)\tAcc@1 60.938 (64.695)\tAcc@5 93.750 (97.340)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.7222 (0.9864)\tAcc@1 71.875 (64.552)\tAcc@5 98.438 (97.328)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.8677 (0.9865)\tAcc@1 65.625 (64.506)\tAcc@5 95.312 (97.318)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.9951 (0.9862)\tAcc@1 65.625 (64.528)\tAcc@5 96.875 (97.268)\tMem 455MB\n",
      " * Acc@1 64.700 Acc@5 97.320\n",
      "Accuracy of the network on the 10000 test images: 64.7%\n",
      "Max accuracy: 65.27%\n",
      "Train: [23/100][0/625]\teta 0:00:23 lr 0.000900\t wd 0.0100\ttime 0.0380 (0.0380)\tloss 1.1299 (1.1299)\tgrad_norm 2.1028 (2.1028)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [23/100][10/625]\teta 0:00:22 lr 0.000900\t wd 0.0100\ttime 0.0363 (0.0363)\tloss 0.8936 (1.0023)\tgrad_norm 1.7299 (2.1397)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [23/100][20/625]\teta 0:00:21 lr 0.000899\t wd 0.0100\ttime 0.0356 (0.0358)\tloss 0.8325 (0.9878)\tgrad_norm 2.1118 (2.2391)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [23/100][30/625]\teta 0:00:21 lr 0.000899\t wd 0.0100\ttime 0.0374 (0.0359)\tloss 1.0566 (1.0104)\tgrad_norm 2.3386 (2.3093)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [23/100][40/625]\teta 0:00:21 lr 0.000899\t wd 0.0100\ttime 0.0402 (0.0364)\tloss 0.8931 (0.9981)\tgrad_norm 1.9317 (2.2538)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [23/100][50/625]\teta 0:00:21 lr 0.000899\t wd 0.0100\ttime 0.0370 (0.0367)\tloss 0.9937 (0.9983)\tgrad_norm 2.3828 (2.2345)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [23/100][60/625]\teta 0:00:20 lr 0.000899\t wd 0.0100\ttime 0.0367 (0.0369)\tloss 1.1250 (1.0002)\tgrad_norm 2.0934 (2.2234)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [23/100][70/625]\teta 0:00:20 lr 0.000899\t wd 0.0100\ttime 0.0362 (0.0371)\tloss 1.0762 (0.9974)\tgrad_norm 2.8064 (2.2744)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [23/100][80/625]\teta 0:00:20 lr 0.000898\t wd 0.0100\ttime 0.0360 (0.0368)\tloss 0.8188 (0.9977)\tgrad_norm 3.2881 (2.3374)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [23/100][90/625]\teta 0:00:19 lr 0.000898\t wd 0.0100\ttime 0.0352 (0.0367)\tloss 0.8340 (0.9952)\tgrad_norm 2.1013 (2.3389)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [23/100][100/625]\teta 0:00:19 lr 0.000898\t wd 0.0100\ttime 0.0389 (0.0368)\tloss 0.8560 (0.9999)\tgrad_norm 2.0608 (2.3272)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [23/100][110/625]\teta 0:00:18 lr 0.000898\t wd 0.0100\ttime 0.0357 (0.0368)\tloss 1.0195 (0.9995)\tgrad_norm 2.0086 (2.2986)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [23/100][120/625]\teta 0:00:18 lr 0.000898\t wd 0.0100\ttime 0.0361 (0.0369)\tloss 0.9570 (0.9977)\tgrad_norm 1.9919 (2.3089)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [23/100][130/625]\teta 0:00:18 lr 0.000898\t wd 0.0100\ttime 0.0353 (0.0370)\tloss 1.1514 (1.0005)\tgrad_norm 2.0686 (2.2803)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [23/100][140/625]\teta 0:00:17 lr 0.000898\t wd 0.0100\ttime 0.0326 (0.0369)\tloss 1.0107 (0.9952)\tgrad_norm 2.7432 (2.2799)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [23/100][150/625]\teta 0:00:17 lr 0.000897\t wd 0.0100\ttime 0.0326 (0.0368)\tloss 0.8325 (0.9884)\tgrad_norm 2.5066 (2.2651)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [23/100][160/625]\teta 0:00:17 lr 0.000897\t wd 0.0100\ttime 0.0363 (0.0368)\tloss 1.0186 (0.9911)\tgrad_norm 1.9245 (2.2734)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [23/100][170/625]\teta 0:00:16 lr 0.000897\t wd 0.0100\ttime 0.0327 (0.0367)\tloss 0.9536 (0.9905)\tgrad_norm 2.7120 (2.2878)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [23/100][180/625]\teta 0:00:16 lr 0.000897\t wd 0.0100\ttime 0.0357 (0.0366)\tloss 1.2910 (0.9928)\tgrad_norm 3.6374 (2.3154)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [23/100][190/625]\teta 0:00:15 lr 0.000897\t wd 0.0100\ttime 0.0324 (0.0365)\tloss 0.9834 (0.9919)\tgrad_norm 1.7629 (2.3055)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [23/100][200/625]\teta 0:00:15 lr 0.000897\t wd 0.0100\ttime 0.0365 (0.0364)\tloss 0.7759 (0.9912)\tgrad_norm 1.7070 (2.3013)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [23/100][210/625]\teta 0:00:15 lr 0.000896\t wd 0.0100\ttime 0.0329 (0.0363)\tloss 0.8105 (0.9865)\tgrad_norm 2.4157 (2.3329)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [23/100][220/625]\teta 0:00:14 lr 0.000896\t wd 0.0100\ttime 0.0356 (0.0362)\tloss 0.6372 (0.9855)\tgrad_norm 2.0201 (2.3260)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [23/100][230/625]\teta 0:00:14 lr 0.000896\t wd 0.0100\ttime 0.0383 (0.0362)\tloss 0.9014 (0.9841)\tgrad_norm 2.0207 (2.3337)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [23/100][240/625]\teta 0:00:13 lr 0.000896\t wd 0.0100\ttime 0.0334 (0.0362)\tloss 1.0791 (0.9831)\tgrad_norm 3.3663 (2.3341)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [23/100][250/625]\teta 0:00:13 lr 0.000896\t wd 0.0100\ttime 0.0325 (0.0362)\tloss 1.0840 (0.9839)\tgrad_norm 2.3935 (2.3263)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [23/100][260/625]\teta 0:00:13 lr 0.000896\t wd 0.0100\ttime 0.0364 (0.0362)\tloss 0.9668 (0.9820)\tgrad_norm 1.8446 (2.3194)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [23/100][270/625]\teta 0:00:12 lr 0.000896\t wd 0.0100\ttime 0.0328 (0.0362)\tloss 1.1836 (0.9838)\tgrad_norm 3.2995 (2.3161)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [23/100][280/625]\teta 0:00:12 lr 0.000895\t wd 0.0100\ttime 0.0377 (0.0362)\tloss 0.9780 (0.9851)\tgrad_norm 1.9978 (2.3075)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [23/100][290/625]\teta 0:00:12 lr 0.000895\t wd 0.0100\ttime 0.0356 (0.0363)\tloss 1.0449 (0.9829)\tgrad_norm 1.4701 (2.2963)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [23/100][300/625]\teta 0:00:11 lr 0.000895\t wd 0.0100\ttime 0.0360 (0.0362)\tloss 0.8706 (0.9822)\tgrad_norm 2.8455 (2.2901)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [23/100][310/625]\teta 0:00:11 lr 0.000895\t wd 0.0100\ttime 0.0388 (0.0362)\tloss 0.9858 (0.9826)\tgrad_norm 2.6069 (2.2935)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [23/100][320/625]\teta 0:00:11 lr 0.000895\t wd 0.0100\ttime 0.0399 (0.0362)\tloss 1.0625 (0.9815)\tgrad_norm 2.2426 (2.2954)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [23/100][330/625]\teta 0:00:10 lr 0.000895\t wd 0.0100\ttime 0.0356 (0.0362)\tloss 1.0176 (0.9813)\tgrad_norm 1.9992 (2.2948)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [23/100][340/625]\teta 0:00:10 lr 0.000894\t wd 0.0100\ttime 0.0331 (0.0362)\tloss 1.2207 (0.9799)\tgrad_norm 1.8336 (2.2912)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [23/100][350/625]\teta 0:00:09 lr 0.000894\t wd 0.0100\ttime 0.0328 (0.0362)\tloss 1.0908 (0.9789)\tgrad_norm 2.0283 (2.2898)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [23/100][360/625]\teta 0:00:09 lr 0.000894\t wd 0.0100\ttime 0.0396 (0.0362)\tloss 0.9263 (0.9812)\tgrad_norm 1.9035 (2.2906)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [23/100][370/625]\teta 0:00:09 lr 0.000894\t wd 0.0100\ttime 0.0327 (0.0361)\tloss 0.9429 (0.9814)\tgrad_norm 2.3248 (2.2907)\tloss_scale 16384.0000 (16384.0000)\tmem 455MB\n",
      "Train: [23/100][380/625]\teta 0:00:08 lr 0.000894\t wd 0.0100\ttime 0.0396 (0.0361)\tloss 0.8682 (0.9816)\tgrad_norm 2.0830 (2.2826)\tloss_scale 32768.0000 (16427.0026)\tmem 455MB\n",
      "Train: [23/100][390/625]\teta 0:00:08 lr 0.000894\t wd 0.0100\ttime 0.0360 (0.0361)\tloss 1.0986 (0.9833)\tgrad_norm 3.2771 (2.2851)\tloss_scale 32768.0000 (16844.9309)\tmem 455MB\n",
      "Train: [23/100][400/625]\teta 0:00:08 lr 0.000893\t wd 0.0100\ttime 0.0367 (0.0361)\tloss 0.9141 (0.9838)\tgrad_norm 1.8820 (2.2930)\tloss_scale 32768.0000 (17242.0150)\tmem 455MB\n",
      "Train: [23/100][410/625]\teta 0:00:07 lr 0.000893\t wd 0.0100\ttime 0.0327 (0.0361)\tloss 0.9258 (0.9838)\tgrad_norm 2.2660 (2.2905)\tloss_scale 32768.0000 (17619.7762)\tmem 455MB\n",
      "Train: [23/100][420/625]\teta 0:00:07 lr 0.000893\t wd 0.0100\ttime 0.0323 (0.0360)\tloss 1.0820 (0.9853)\tgrad_norm 2.3474 (2.2899)\tloss_scale 32768.0000 (17979.5914)\tmem 455MB\n",
      "Train: [23/100][430/625]\teta 0:00:07 lr 0.000893\t wd 0.0100\ttime 0.0330 (0.0360)\tloss 0.9868 (0.9868)\tgrad_norm 2.9177 (2.2904)\tloss_scale 32768.0000 (18322.7100)\tmem 455MB\n",
      "Train: [23/100][440/625]\teta 0:00:06 lr 0.000893\t wd 0.0100\ttime 0.0355 (0.0360)\tloss 1.0283 (0.9868)\tgrad_norm 1.9477 (2.2873)\tloss_scale 32768.0000 (18650.2676)\tmem 455MB\n",
      "Train: [23/100][450/625]\teta 0:00:06 lr 0.000893\t wd 0.0100\ttime 0.0397 (0.0359)\tloss 0.9463 (0.9863)\tgrad_norm 2.2360 (2.2842)\tloss_scale 32768.0000 (18963.2993)\tmem 455MB\n",
      "Train: [23/100][460/625]\teta 0:00:05 lr 0.000893\t wd 0.0100\ttime 0.0392 (0.0360)\tloss 1.1748 (0.9864)\tgrad_norm 2.3971 (2.2789)\tloss_scale 32768.0000 (19262.7505)\tmem 455MB\n",
      "Train: [23/100][470/625]\teta 0:00:05 lr 0.000892\t wd 0.0100\ttime 0.0362 (0.0360)\tloss 1.1230 (0.9863)\tgrad_norm 2.5219 (2.2737)\tloss_scale 32768.0000 (19549.4862)\tmem 455MB\n",
      "Train: [23/100][480/625]\teta 0:00:05 lr 0.000892\t wd 0.0100\ttime 0.0399 (0.0360)\tloss 0.9492 (0.9868)\tgrad_norm 1.4971 (2.2681)\tloss_scale 32768.0000 (19824.2994)\tmem 455MB\n",
      "Train: [23/100][490/625]\teta 0:00:04 lr 0.000892\t wd 0.0100\ttime 0.0331 (0.0360)\tloss 1.0215 (0.9873)\tgrad_norm 1.5591 (2.2653)\tloss_scale 32768.0000 (20087.9185)\tmem 455MB\n",
      "Train: [23/100][500/625]\teta 0:00:04 lr 0.000892\t wd 0.0100\ttime 0.0366 (0.0360)\tloss 0.8081 (0.9866)\tgrad_norm 1.6973 (2.2607)\tloss_scale 32768.0000 (20341.0140)\tmem 455MB\n",
      "Train: [23/100][510/625]\teta 0:00:04 lr 0.000892\t wd 0.0100\ttime 0.0369 (0.0360)\tloss 1.2100 (0.9864)\tgrad_norm 2.6448 (2.2584)\tloss_scale 32768.0000 (20584.2035)\tmem 455MB\n",
      "Train: [23/100][520/625]\teta 0:00:03 lr 0.000892\t wd 0.0100\ttime 0.0365 (0.0361)\tloss 0.9922 (0.9862)\tgrad_norm 1.8730 (2.2585)\tloss_scale 32768.0000 (20818.0576)\tmem 455MB\n",
      "Train: [23/100][530/625]\teta 0:00:03 lr 0.000891\t wd 0.0100\ttime 0.0399 (0.0361)\tloss 0.7881 (0.9859)\tgrad_norm 2.2384 (2.2540)\tloss_scale 32768.0000 (21043.1036)\tmem 455MB\n",
      "Train: [23/100][540/625]\teta 0:00:03 lr 0.000891\t wd 0.0100\ttime 0.0396 (0.0361)\tloss 1.0898 (0.9857)\tgrad_norm 2.0512 (2.2487)\tloss_scale 32768.0000 (21259.8299)\tmem 455MB\n",
      "Train: [23/100][550/625]\teta 0:00:02 lr 0.000891\t wd 0.0100\ttime 0.0393 (0.0361)\tloss 0.7676 (0.9852)\tgrad_norm 1.7572 (2.2492)\tloss_scale 32768.0000 (21468.6897)\tmem 455MB\n",
      "Train: [23/100][560/625]\teta 0:00:02 lr 0.000891\t wd 0.0100\ttime 0.0360 (0.0361)\tloss 0.9258 (0.9841)\tgrad_norm 2.8733 (2.2454)\tloss_scale 32768.0000 (21670.1034)\tmem 455MB\n",
      "Train: [23/100][570/625]\teta 0:00:01 lr 0.000891\t wd 0.0100\ttime 0.0359 (0.0361)\tloss 1.0625 (0.9842)\tgrad_norm 2.5883 (2.2426)\tloss_scale 32768.0000 (21864.4623)\tmem 455MB\n",
      "Train: [23/100][580/625]\teta 0:00:01 lr 0.000891\t wd 0.0100\ttime 0.0369 (0.0361)\tloss 0.8120 (0.9845)\tgrad_norm 2.1201 (2.2388)\tloss_scale 32768.0000 (22052.1308)\tmem 455MB\n",
      "Train: [23/100][590/625]\teta 0:00:01 lr 0.000890\t wd 0.0100\ttime 0.0374 (0.0361)\tloss 1.1660 (0.9843)\tgrad_norm 2.4271 (2.2347)\tloss_scale 32768.0000 (22233.4484)\tmem 455MB\n",
      "Train: [23/100][600/625]\teta 0:00:00 lr 0.000890\t wd 0.0100\ttime 0.0342 (0.0361)\tloss 0.8877 (0.9833)\tgrad_norm 2.3727 (2.2298)\tloss_scale 32768.0000 (22408.7321)\tmem 455MB\n",
      "Train: [23/100][610/625]\teta 0:00:00 lr 0.000890\t wd 0.0100\ttime 0.0364 (0.0361)\tloss 0.8887 (0.9826)\tgrad_norm 2.1141 (2.2279)\tloss_scale 32768.0000 (22578.2782)\tmem 455MB\n",
      "Train: [23/100][620/625]\teta 0:00:00 lr 0.000890\t wd 0.0100\ttime 0.0328 (0.0361)\tloss 1.1016 (0.9841)\tgrad_norm 2.5808 (2.2294)\tloss_scale 32768.0000 (22742.3639)\tmem 455MB\n",
      "EPOCH 23 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_23.pth saving......\n",
      "./model_save/ckpt_epoch_23.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.9258 (0.9258)\tAcc@1 73.438 (73.438)\tAcc@5 98.438 (98.438)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.9194 (0.9069)\tAcc@1 65.625 (67.330)\tAcc@5 98.438 (97.443)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.9146 (0.9596)\tAcc@1 64.062 (66.592)\tAcc@5 100.000 (97.396)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 1.0791 (0.9643)\tAcc@1 57.812 (65.877)\tAcc@5 96.875 (97.177)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.6606 (0.9415)\tAcc@1 79.688 (66.082)\tAcc@5 100.000 (97.218)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 1.0938 (0.9380)\tAcc@1 64.062 (65.870)\tAcc@5 98.438 (97.365)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.9399 (0.9471)\tAcc@1 62.500 (65.420)\tAcc@5 98.438 (97.310)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 1.1367 (0.9428)\tAcc@1 62.500 (65.515)\tAcc@5 96.875 (97.359)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 1.1162 (0.9526)\tAcc@1 65.625 (65.278)\tAcc@5 93.750 (97.261)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 1.0576 (0.9495)\tAcc@1 53.125 (65.367)\tAcc@5 96.875 (97.253)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.8564 (0.9482)\tAcc@1 68.750 (65.501)\tAcc@5 100.000 (97.324)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.9048 (0.9516)\tAcc@1 62.500 (65.498)\tAcc@5 100.000 (97.283)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.8726 (0.9491)\tAcc@1 70.312 (65.612)\tAcc@5 96.875 (97.353)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 1.1182 (0.9474)\tAcc@1 65.625 (65.816)\tAcc@5 92.188 (97.304)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 1.0303 (0.9526)\tAcc@1 59.375 (65.481)\tAcc@5 95.312 (97.307)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.9375 (0.9487)\tAcc@1 62.500 (65.573)\tAcc@5 98.438 (97.289)\tMem 455MB\n",
      " * Acc@1 65.720 Acc@5 97.260\n",
      "Accuracy of the network on the 10000 test images: 65.7%\n",
      "Max accuracy: 65.72%\n",
      "Train: [24/100][0/625]\teta 0:00:22 lr 0.000890\t wd 0.0100\ttime 0.0368 (0.0368)\tloss 0.7681 (0.7681)\tgrad_norm 1.8984 (1.8984)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][10/625]\teta 0:00:21 lr 0.000890\t wd 0.0100\ttime 0.0371 (0.0343)\tloss 0.8105 (0.9516)\tgrad_norm 1.8854 (2.1729)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][20/625]\teta 0:00:20 lr 0.000890\t wd 0.0100\ttime 0.0332 (0.0341)\tloss 0.8271 (0.9319)\tgrad_norm 2.7064 (2.1495)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][30/625]\teta 0:00:20 lr 0.000889\t wd 0.0100\ttime 0.0336 (0.0338)\tloss 0.8433 (0.9311)\tgrad_norm 2.9849 (2.1838)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][40/625]\teta 0:00:19 lr 0.000889\t wd 0.0100\ttime 0.0331 (0.0337)\tloss 0.8530 (0.9241)\tgrad_norm 2.4116 (2.1933)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][50/625]\teta 0:00:19 lr 0.000889\t wd 0.0100\ttime 0.0374 (0.0338)\tloss 0.9395 (0.9406)\tgrad_norm 2.4663 (2.2712)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][60/625]\teta 0:00:19 lr 0.000889\t wd 0.0100\ttime 0.0323 (0.0337)\tloss 1.0986 (0.9484)\tgrad_norm 4.0749 (2.2821)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][70/625]\teta 0:00:18 lr 0.000889\t wd 0.0100\ttime 0.0366 (0.0338)\tloss 0.9790 (0.9581)\tgrad_norm 2.5818 (2.3465)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][80/625]\teta 0:00:18 lr 0.000889\t wd 0.0100\ttime 0.0380 (0.0339)\tloss 1.1387 (0.9645)\tgrad_norm 1.9821 (2.3166)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][90/625]\teta 0:00:18 lr 0.000888\t wd 0.0100\ttime 0.0333 (0.0340)\tloss 1.0557 (0.9617)\tgrad_norm 2.3252 (2.3336)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][100/625]\teta 0:00:18 lr 0.000888\t wd 0.0100\ttime 0.0356 (0.0343)\tloss 0.8486 (0.9581)\tgrad_norm 1.9985 (2.3400)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][110/625]\teta 0:00:17 lr 0.000888\t wd 0.0100\ttime 0.0328 (0.0345)\tloss 0.7773 (0.9553)\tgrad_norm 2.1774 (2.3358)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][120/625]\teta 0:00:17 lr 0.000888\t wd 0.0100\ttime 0.0354 (0.0346)\tloss 0.8198 (0.9519)\tgrad_norm 2.1312 (2.3151)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][130/625]\teta 0:00:17 lr 0.000888\t wd 0.0100\ttime 0.0359 (0.0347)\tloss 1.0498 (0.9494)\tgrad_norm 2.3063 (2.3019)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][140/625]\teta 0:00:16 lr 0.000888\t wd 0.0100\ttime 0.0330 (0.0347)\tloss 1.1689 (0.9515)\tgrad_norm 2.7564 (2.2896)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][150/625]\teta 0:00:16 lr 0.000887\t wd 0.0100\ttime 0.0362 (0.0347)\tloss 0.8154 (0.9543)\tgrad_norm 1.8795 (2.2894)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][160/625]\teta 0:00:16 lr 0.000887\t wd 0.0100\ttime 0.0397 (0.0348)\tloss 1.2207 (0.9538)\tgrad_norm 2.0891 (2.2814)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][170/625]\teta 0:00:15 lr 0.000887\t wd 0.0100\ttime 0.0352 (0.0350)\tloss 0.9634 (0.9562)\tgrad_norm 1.8348 (2.2733)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][180/625]\teta 0:00:15 lr 0.000887\t wd 0.0100\ttime 0.0398 (0.0351)\tloss 0.8311 (0.9569)\tgrad_norm 2.1917 (2.2657)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][190/625]\teta 0:00:15 lr 0.000887\t wd 0.0100\ttime 0.0356 (0.0351)\tloss 0.8027 (0.9571)\tgrad_norm 1.4567 (2.2551)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][200/625]\teta 0:00:14 lr 0.000887\t wd 0.0100\ttime 0.0326 (0.0351)\tloss 1.1338 (0.9613)\tgrad_norm 2.7180 (2.2951)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][210/625]\teta 0:00:14 lr 0.000886\t wd 0.0100\ttime 0.0355 (0.0351)\tloss 1.0176 (0.9631)\tgrad_norm 3.3566 (2.2934)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][220/625]\teta 0:00:14 lr 0.000886\t wd 0.0100\ttime 0.0328 (0.0351)\tloss 0.9570 (0.9631)\tgrad_norm 1.6813 (2.2711)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][230/625]\teta 0:00:13 lr 0.000886\t wd 0.0100\ttime 0.0335 (0.0351)\tloss 0.7109 (0.9621)\tgrad_norm 2.0428 (2.2769)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][240/625]\teta 0:00:13 lr 0.000886\t wd 0.0100\ttime 0.0413 (0.0352)\tloss 1.0459 (0.9621)\tgrad_norm 2.1197 (2.2674)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][250/625]\teta 0:00:13 lr 0.000886\t wd 0.0100\ttime 0.0331 (0.0353)\tloss 0.8428 (0.9621)\tgrad_norm 2.9780 (2.2677)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][260/625]\teta 0:00:12 lr 0.000886\t wd 0.0100\ttime 0.0361 (0.0352)\tloss 0.7993 (0.9610)\tgrad_norm 2.0575 (2.2597)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][270/625]\teta 0:00:12 lr 0.000885\t wd 0.0100\ttime 0.0326 (0.0352)\tloss 1.1631 (0.9611)\tgrad_norm 2.3871 (2.2741)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][280/625]\teta 0:00:12 lr 0.000885\t wd 0.0100\ttime 0.0407 (0.0353)\tloss 0.9619 (0.9602)\tgrad_norm 1.9267 (2.2767)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][290/625]\teta 0:00:11 lr 0.000885\t wd 0.0100\ttime 0.0363 (0.0354)\tloss 0.9570 (0.9617)\tgrad_norm 2.0298 (2.2805)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][300/625]\teta 0:00:11 lr 0.000885\t wd 0.0100\ttime 0.0352 (0.0354)\tloss 1.1875 (0.9614)\tgrad_norm 2.6046 (2.2789)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][310/625]\teta 0:00:11 lr 0.000885\t wd 0.0100\ttime 0.0370 (0.0355)\tloss 0.8765 (0.9618)\tgrad_norm 1.9499 (2.2796)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][320/625]\teta 0:00:10 lr 0.000885\t wd 0.0100\ttime 0.0325 (0.0355)\tloss 1.0273 (0.9640)\tgrad_norm 3.0226 (2.2743)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][330/625]\teta 0:00:10 lr 0.000884\t wd 0.0100\ttime 0.0392 (0.0355)\tloss 1.1104 (0.9633)\tgrad_norm 2.1817 (2.2670)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][340/625]\teta 0:00:10 lr 0.000884\t wd 0.0100\ttime 0.0356 (0.0356)\tloss 1.0586 (0.9619)\tgrad_norm 2.2792 (2.2597)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][350/625]\teta 0:00:09 lr 0.000884\t wd 0.0100\ttime 0.0327 (0.0356)\tloss 0.7407 (0.9613)\tgrad_norm 1.9292 (2.2545)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][360/625]\teta 0:00:09 lr 0.000884\t wd 0.0100\ttime 0.0355 (0.0356)\tloss 1.3701 (0.9618)\tgrad_norm 2.8059 (2.2538)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][370/625]\teta 0:00:09 lr 0.000884\t wd 0.0100\ttime 0.0376 (0.0356)\tloss 1.1475 (0.9617)\tgrad_norm 2.2155 (2.2439)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][380/625]\teta 0:00:08 lr 0.000884\t wd 0.0100\ttime 0.0379 (0.0356)\tloss 0.9160 (0.9622)\tgrad_norm 3.1656 (2.2549)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][390/625]\teta 0:00:08 lr 0.000883\t wd 0.0100\ttime 0.0380 (0.0357)\tloss 1.0000 (0.9619)\tgrad_norm 2.3776 (2.2560)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][400/625]\teta 0:00:08 lr 0.000883\t wd 0.0100\ttime 0.0330 (0.0356)\tloss 0.7646 (0.9645)\tgrad_norm 1.4447 (2.2567)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][410/625]\teta 0:00:07 lr 0.000883\t wd 0.0100\ttime 0.0328 (0.0355)\tloss 0.8403 (0.9637)\tgrad_norm 1.7227 (2.2576)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][420/625]\teta 0:00:07 lr 0.000883\t wd 0.0100\ttime 0.0332 (0.0355)\tloss 0.9619 (0.9638)\tgrad_norm 1.9048 (2.2600)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][430/625]\teta 0:00:06 lr 0.000883\t wd 0.0100\ttime 0.0369 (0.0354)\tloss 0.9819 (0.9633)\tgrad_norm 1.9767 (2.2563)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][440/625]\teta 0:00:06 lr 0.000883\t wd 0.0100\ttime 0.0323 (0.0354)\tloss 1.0713 (0.9628)\tgrad_norm 2.5946 (2.2529)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][450/625]\teta 0:00:06 lr 0.000882\t wd 0.0100\ttime 0.0368 (0.0354)\tloss 0.8486 (0.9631)\tgrad_norm 2.3592 (2.2519)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][460/625]\teta 0:00:05 lr 0.000882\t wd 0.0100\ttime 0.0323 (0.0354)\tloss 1.0244 (0.9636)\tgrad_norm 2.7396 (2.2578)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][470/625]\teta 0:00:05 lr 0.000882\t wd 0.0100\ttime 0.0352 (0.0353)\tloss 0.9556 (0.9625)\tgrad_norm 1.8329 (2.2518)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][480/625]\teta 0:00:05 lr 0.000882\t wd 0.0100\ttime 0.0336 (0.0353)\tloss 0.6885 (0.9639)\tgrad_norm 1.5607 (2.2447)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][490/625]\teta 0:00:04 lr 0.000882\t wd 0.0100\ttime 0.0358 (0.0353)\tloss 1.0645 (0.9646)\tgrad_norm 2.0164 (2.2433)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][500/625]\teta 0:00:04 lr 0.000882\t wd 0.0100\ttime 0.0341 (0.0352)\tloss 0.9297 (0.9637)\tgrad_norm 1.6376 (2.2405)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][510/625]\teta 0:00:04 lr 0.000881\t wd 0.0100\ttime 0.0355 (0.0353)\tloss 1.0742 (0.9636)\tgrad_norm 2.8713 (2.2418)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][520/625]\teta 0:00:03 lr 0.000881\t wd 0.0100\ttime 0.0358 (0.0353)\tloss 0.9351 (0.9631)\tgrad_norm 2.2525 (2.2422)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][530/625]\teta 0:00:03 lr 0.000881\t wd 0.0100\ttime 0.0323 (0.0352)\tloss 0.9482 (0.9616)\tgrad_norm 2.1051 (2.2352)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][540/625]\teta 0:00:02 lr 0.000881\t wd 0.0100\ttime 0.0356 (0.0352)\tloss 0.8735 (0.9609)\tgrad_norm 1.5388 (2.2267)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][550/625]\teta 0:00:02 lr 0.000881\t wd 0.0100\ttime 0.0322 (0.0352)\tloss 0.7935 (0.9609)\tgrad_norm 1.8008 (2.2252)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][560/625]\teta 0:00:02 lr 0.000881\t wd 0.0100\ttime 0.0327 (0.0352)\tloss 0.8955 (0.9603)\tgrad_norm 2.7345 (2.2325)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][570/625]\teta 0:00:01 lr 0.000880\t wd 0.0100\ttime 0.0358 (0.0352)\tloss 0.8198 (0.9601)\tgrad_norm 1.8295 (2.2336)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][580/625]\teta 0:00:01 lr 0.000880\t wd 0.0100\ttime 0.0322 (0.0352)\tloss 1.1143 (0.9603)\tgrad_norm 2.3173 (2.2344)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][590/625]\teta 0:00:01 lr 0.000880\t wd 0.0100\ttime 0.0326 (0.0351)\tloss 0.8896 (0.9592)\tgrad_norm 2.3209 (2.2302)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][600/625]\teta 0:00:00 lr 0.000880\t wd 0.0100\ttime 0.0326 (0.0351)\tloss 1.1270 (0.9596)\tgrad_norm 2.9270 (2.2314)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][610/625]\teta 0:00:00 lr 0.000880\t wd 0.0100\ttime 0.0332 (0.0351)\tloss 0.8872 (0.9585)\tgrad_norm 1.7417 (2.2282)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [24/100][620/625]\teta 0:00:00 lr 0.000880\t wd 0.0100\ttime 0.0326 (0.0351)\tloss 1.1025 (0.9596)\tgrad_norm 2.4261 (2.2300)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 24 training takes 0:00:21\n",
      "./model_save/ckpt_epoch_24.pth saving......\n",
      "./model_save/ckpt_epoch_24.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.8306 (0.8306)\tAcc@1 68.750 (68.750)\tAcc@5 98.438 (98.438)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 1.0381 (0.8777)\tAcc@1 64.062 (68.608)\tAcc@5 93.750 (97.017)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 1.0273 (0.8973)\tAcc@1 57.812 (67.708)\tAcc@5 98.438 (97.098)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.7686 (0.9014)\tAcc@1 70.312 (67.540)\tAcc@5 98.438 (97.429)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.9194 (0.9092)\tAcc@1 64.062 (67.302)\tAcc@5 96.875 (97.523)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.9150 (0.8942)\tAcc@1 71.875 (67.862)\tAcc@5 95.312 (97.672)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.8804 (0.8999)\tAcc@1 68.750 (67.572)\tAcc@5 98.438 (97.669)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.8687 (0.8990)\tAcc@1 68.750 (67.540)\tAcc@5 96.875 (97.711)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 1.0977 (0.9035)\tAcc@1 57.812 (67.496)\tAcc@5 93.750 (97.608)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.8950 (0.9155)\tAcc@1 68.750 (67.050)\tAcc@5 98.438 (97.527)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 1.0557 (0.9151)\tAcc@1 57.812 (66.801)\tAcc@5 98.438 (97.618)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.7832 (0.9122)\tAcc@1 73.438 (66.948)\tAcc@5 98.438 (97.677)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 1.0039 (0.9146)\tAcc@1 59.375 (66.813)\tAcc@5 96.875 (97.585)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.6724 (0.9057)\tAcc@1 76.562 (66.973)\tAcc@5 100.000 (97.686)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.017 (0.015)\tLoss 1.2168 (0.9053)\tAcc@1 53.125 (66.888)\tAcc@5 100.000 (97.773)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.9053 (0.9057)\tAcc@1 67.188 (66.856)\tAcc@5 96.875 (97.755)\tMem 455MB\n",
      " * Acc@1 66.730 Acc@5 97.730\n",
      "Accuracy of the network on the 10000 test images: 66.7%\n",
      "Max accuracy: 66.73%\n",
      "Train: [25/100][0/625]\teta 0:00:26 lr 0.000880\t wd 0.0100\ttime 0.0425 (0.0425)\tloss 1.0479 (1.0479)\tgrad_norm 1.7113 (1.7113)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][10/625]\teta 0:00:22 lr 0.000879\t wd 0.0100\ttime 0.0331 (0.0359)\tloss 1.4199 (0.9734)\tgrad_norm 2.4283 (1.9040)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][20/625]\teta 0:00:21 lr 0.000879\t wd 0.0100\ttime 0.0400 (0.0363)\tloss 1.1787 (0.9580)\tgrad_norm 2.5874 (1.9927)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][30/625]\teta 0:00:21 lr 0.000879\t wd 0.0100\ttime 0.0388 (0.0367)\tloss 1.0557 (0.9723)\tgrad_norm 2.5174 (2.1168)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][40/625]\teta 0:00:21 lr 0.000879\t wd 0.0100\ttime 0.0334 (0.0365)\tloss 0.7578 (0.9480)\tgrad_norm 1.6994 (2.1333)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][50/625]\teta 0:00:21 lr 0.000879\t wd 0.0100\ttime 0.0382 (0.0366)\tloss 1.0781 (0.9537)\tgrad_norm 2.0154 (2.1632)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][60/625]\teta 0:00:20 lr 0.000879\t wd 0.0100\ttime 0.0372 (0.0367)\tloss 0.8706 (0.9440)\tgrad_norm 2.4073 (2.1917)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][70/625]\teta 0:00:20 lr 0.000878\t wd 0.0100\ttime 0.0368 (0.0366)\tloss 1.1445 (0.9344)\tgrad_norm 3.1381 (2.1736)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][80/625]\teta 0:00:19 lr 0.000878\t wd 0.0100\ttime 0.0333 (0.0365)\tloss 0.8325 (0.9387)\tgrad_norm 2.1621 (2.1590)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][90/625]\teta 0:00:19 lr 0.000878\t wd 0.0100\ttime 0.0336 (0.0367)\tloss 0.7822 (0.9330)\tgrad_norm 1.2535 (2.1587)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][100/625]\teta 0:00:19 lr 0.000878\t wd 0.0100\ttime 0.0349 (0.0366)\tloss 1.0400 (0.9366)\tgrad_norm 2.9010 (2.1671)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][110/625]\teta 0:00:18 lr 0.000878\t wd 0.0100\ttime 0.0330 (0.0364)\tloss 0.9155 (0.9333)\tgrad_norm 1.7897 (2.1767)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][120/625]\teta 0:00:18 lr 0.000878\t wd 0.0100\ttime 0.0402 (0.0364)\tloss 1.0977 (0.9373)\tgrad_norm 2.4260 (2.1748)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][130/625]\teta 0:00:18 lr 0.000877\t wd 0.0100\ttime 0.0335 (0.0364)\tloss 0.8916 (0.9409)\tgrad_norm 1.9429 (2.1762)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][140/625]\teta 0:00:17 lr 0.000877\t wd 0.0100\ttime 0.0354 (0.0363)\tloss 0.8545 (0.9438)\tgrad_norm 1.9761 (2.1667)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][150/625]\teta 0:00:17 lr 0.000877\t wd 0.0100\ttime 0.0363 (0.0362)\tloss 1.3164 (0.9448)\tgrad_norm 2.3901 (2.1660)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][160/625]\teta 0:00:16 lr 0.000877\t wd 0.0100\ttime 0.0401 (0.0362)\tloss 0.9487 (0.9469)\tgrad_norm 2.4871 (2.1588)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][170/625]\teta 0:00:16 lr 0.000877\t wd 0.0100\ttime 0.0329 (0.0362)\tloss 0.9019 (0.9436)\tgrad_norm 1.4350 (2.1464)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][180/625]\teta 0:00:16 lr 0.000877\t wd 0.0100\ttime 0.0368 (0.0363)\tloss 0.7964 (0.9432)\tgrad_norm 1.7772 (2.1353)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][190/625]\teta 0:00:15 lr 0.000876\t wd 0.0100\ttime 0.0328 (0.0363)\tloss 0.9434 (0.9415)\tgrad_norm 1.9789 (2.1394)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][200/625]\teta 0:00:15 lr 0.000876\t wd 0.0100\ttime 0.0380 (0.0364)\tloss 0.8730 (0.9435)\tgrad_norm 2.2530 (2.1420)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][210/625]\teta 0:00:15 lr 0.000876\t wd 0.0100\ttime 0.0372 (0.0364)\tloss 0.8232 (0.9448)\tgrad_norm 1.6516 (2.1408)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][220/625]\teta 0:00:14 lr 0.000876\t wd 0.0100\ttime 0.0353 (0.0365)\tloss 0.8042 (0.9429)\tgrad_norm 1.4238 (2.1352)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][230/625]\teta 0:00:14 lr 0.000876\t wd 0.0100\ttime 0.0375 (0.0366)\tloss 1.0039 (0.9391)\tgrad_norm 3.0177 (2.1329)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][240/625]\teta 0:00:14 lr 0.000876\t wd 0.0100\ttime 0.0404 (0.0366)\tloss 0.8384 (0.9378)\tgrad_norm 1.8055 (2.1301)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][250/625]\teta 0:00:13 lr 0.000875\t wd 0.0100\ttime 0.0329 (0.0367)\tloss 0.9263 (0.9374)\tgrad_norm 2.0539 (2.1301)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][260/625]\teta 0:00:13 lr 0.000875\t wd 0.0100\ttime 0.0356 (0.0365)\tloss 0.9102 (0.9365)\tgrad_norm 2.0899 (2.1307)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][270/625]\teta 0:00:12 lr 0.000875\t wd 0.0100\ttime 0.0343 (0.0366)\tloss 0.9404 (0.9368)\tgrad_norm 2.1050 (2.1338)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][280/625]\teta 0:00:12 lr 0.000875\t wd 0.0100\ttime 0.0340 (0.0365)\tloss 1.0537 (0.9363)\tgrad_norm 1.8425 (2.1312)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][290/625]\teta 0:00:12 lr 0.000875\t wd 0.0100\ttime 0.0403 (0.0365)\tloss 1.0957 (0.9360)\tgrad_norm 2.9815 (2.1299)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][300/625]\teta 0:00:11 lr 0.000874\t wd 0.0100\ttime 0.0359 (0.0365)\tloss 1.0273 (0.9363)\tgrad_norm 1.6763 (2.1230)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][310/625]\teta 0:00:11 lr 0.000874\t wd 0.0100\ttime 0.0353 (0.0365)\tloss 1.0391 (0.9370)\tgrad_norm 1.6894 (2.1135)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][320/625]\teta 0:00:11 lr 0.000874\t wd 0.0100\ttime 0.0326 (0.0365)\tloss 0.9185 (0.9382)\tgrad_norm 2.2855 (2.1245)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][330/625]\teta 0:00:10 lr 0.000874\t wd 0.0100\ttime 0.0393 (0.0365)\tloss 0.9219 (0.9383)\tgrad_norm 1.9639 (2.1236)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][340/625]\teta 0:00:10 lr 0.000874\t wd 0.0100\ttime 0.0330 (0.0364)\tloss 1.1006 (0.9401)\tgrad_norm 1.9017 (2.1274)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][350/625]\teta 0:00:10 lr 0.000874\t wd 0.0100\ttime 0.0410 (0.0364)\tloss 1.1035 (0.9419)\tgrad_norm 2.0610 (2.1263)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][360/625]\teta 0:00:09 lr 0.000873\t wd 0.0100\ttime 0.0367 (0.0365)\tloss 1.0918 (0.9428)\tgrad_norm 2.0305 (2.1215)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][370/625]\teta 0:00:09 lr 0.000873\t wd 0.0100\ttime 0.0329 (0.0364)\tloss 1.1055 (0.9442)\tgrad_norm 2.4317 (2.1189)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][380/625]\teta 0:00:08 lr 0.000873\t wd 0.0100\ttime 0.0355 (0.0364)\tloss 0.8403 (0.9444)\tgrad_norm 1.6915 (2.1149)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][390/625]\teta 0:00:08 lr 0.000873\t wd 0.0100\ttime 0.0324 (0.0364)\tloss 1.0820 (0.9449)\tgrad_norm 2.2334 (2.1140)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][400/625]\teta 0:00:08 lr 0.000873\t wd 0.0100\ttime 0.0397 (0.0364)\tloss 1.1533 (0.9459)\tgrad_norm 2.0571 (2.1065)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][410/625]\teta 0:00:07 lr 0.000873\t wd 0.0100\ttime 0.0362 (0.0364)\tloss 0.7651 (0.9454)\tgrad_norm 2.2694 (2.1044)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][420/625]\teta 0:00:07 lr 0.000872\t wd 0.0100\ttime 0.0363 (0.0364)\tloss 0.8848 (0.9446)\tgrad_norm 1.8943 (2.1014)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][430/625]\teta 0:00:07 lr 0.000872\t wd 0.0100\ttime 0.0369 (0.0365)\tloss 0.8975 (0.9447)\tgrad_norm 1.9691 (2.1008)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][440/625]\teta 0:00:06 lr 0.000872\t wd 0.0100\ttime 0.0358 (0.0365)\tloss 0.9873 (0.9428)\tgrad_norm 1.7054 (2.1021)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][450/625]\teta 0:00:06 lr 0.000872\t wd 0.0100\ttime 0.0360 (0.0365)\tloss 0.7852 (0.9426)\tgrad_norm 1.8963 (2.1025)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][460/625]\teta 0:00:06 lr 0.000872\t wd 0.0100\ttime 0.0354 (0.0364)\tloss 1.0508 (0.9429)\tgrad_norm 2.0588 (2.1030)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][470/625]\teta 0:00:05 lr 0.000872\t wd 0.0100\ttime 0.0361 (0.0365)\tloss 1.0400 (0.9436)\tgrad_norm 2.5572 (2.1081)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][480/625]\teta 0:00:05 lr 0.000871\t wd 0.0100\ttime 0.0359 (0.0365)\tloss 0.8657 (0.9427)\tgrad_norm 1.8078 (2.1051)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][490/625]\teta 0:00:04 lr 0.000871\t wd 0.0100\ttime 0.0346 (0.0365)\tloss 1.0371 (0.9420)\tgrad_norm 2.6440 (2.1023)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][500/625]\teta 0:00:04 lr 0.000871\t wd 0.0100\ttime 0.0396 (0.0365)\tloss 1.0303 (0.9418)\tgrad_norm 2.1417 (2.1039)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][510/625]\teta 0:00:04 lr 0.000871\t wd 0.0100\ttime 0.0326 (0.0365)\tloss 0.8379 (0.9404)\tgrad_norm 2.1663 (2.1003)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][520/625]\teta 0:00:03 lr 0.000871\t wd 0.0100\ttime 0.0399 (0.0365)\tloss 1.0156 (0.9406)\tgrad_norm 2.2816 (2.1069)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][530/625]\teta 0:00:03 lr 0.000871\t wd 0.0100\ttime 0.0391 (0.0365)\tloss 1.0654 (0.9405)\tgrad_norm 1.6906 (2.1062)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][540/625]\teta 0:00:03 lr 0.000870\t wd 0.0100\ttime 0.0324 (0.0365)\tloss 0.8276 (0.9402)\tgrad_norm 3.1150 (2.1065)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][550/625]\teta 0:00:02 lr 0.000870\t wd 0.0100\ttime 0.0333 (0.0364)\tloss 0.9082 (0.9409)\tgrad_norm 2.2543 (2.1069)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][560/625]\teta 0:00:02 lr 0.000870\t wd 0.0100\ttime 0.0379 (0.0364)\tloss 1.0498 (0.9420)\tgrad_norm 2.5814 (2.1098)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][570/625]\teta 0:00:02 lr 0.000870\t wd 0.0100\ttime 0.0383 (0.0364)\tloss 1.2930 (0.9440)\tgrad_norm 3.0898 (2.1150)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][580/625]\teta 0:00:01 lr 0.000870\t wd 0.0100\ttime 0.0337 (0.0364)\tloss 1.1475 (0.9449)\tgrad_norm 2.9510 (2.1182)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][590/625]\teta 0:00:01 lr 0.000870\t wd 0.0100\ttime 0.0325 (0.0363)\tloss 0.7515 (0.9444)\tgrad_norm 2.6687 (2.1184)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][600/625]\teta 0:00:00 lr 0.000869\t wd 0.0100\ttime 0.0405 (0.0364)\tloss 1.0088 (0.9450)\tgrad_norm 2.4166 (2.1209)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][610/625]\teta 0:00:00 lr 0.000869\t wd 0.0100\ttime 0.0393 (0.0364)\tloss 0.7832 (0.9444)\tgrad_norm 1.9708 (2.1238)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [25/100][620/625]\teta 0:00:00 lr 0.000869\t wd 0.0100\ttime 0.0326 (0.0364)\tloss 1.0420 (0.9441)\tgrad_norm 2.1366 (2.1253)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 25 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_25.pth saving......\n",
      "./model_save/ckpt_epoch_25.pth saved !!!\n",
      "Test: [0/157]\tTime 0.017 (0.017)\tLoss 0.6753 (0.6753)\tAcc@1 79.688 (79.688)\tAcc@5 98.438 (98.438)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 1.0195 (0.9041)\tAcc@1 67.188 (70.028)\tAcc@5 96.875 (98.153)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.9150 (0.9222)\tAcc@1 71.875 (68.452)\tAcc@5 96.875 (97.842)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.8008 (0.9244)\tAcc@1 73.438 (67.742)\tAcc@5 96.875 (97.732)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.6582 (0.9194)\tAcc@1 79.688 (67.721)\tAcc@5 96.875 (97.637)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.8613 (0.9154)\tAcc@1 68.750 (67.739)\tAcc@5 100.000 (97.855)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.8374 (0.9154)\tAcc@1 65.625 (67.239)\tAcc@5 96.875 (97.823)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.9038 (0.9138)\tAcc@1 59.375 (66.967)\tAcc@5 98.438 (97.865)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.8428 (0.9099)\tAcc@1 70.312 (67.130)\tAcc@5 100.000 (97.666)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.7500 (0.9109)\tAcc@1 73.438 (67.188)\tAcc@5 96.875 (97.579)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.7881 (0.9096)\tAcc@1 67.188 (67.157)\tAcc@5 100.000 (97.571)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 1.1572 (0.9163)\tAcc@1 59.375 (67.061)\tAcc@5 100.000 (97.565)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.8232 (0.9217)\tAcc@1 73.438 (66.839)\tAcc@5 100.000 (97.456)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 1.0293 (0.9224)\tAcc@1 64.062 (66.889)\tAcc@5 95.312 (97.459)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.8774 (0.9201)\tAcc@1 71.875 (66.933)\tAcc@5 96.875 (97.440)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.7583 (0.9276)\tAcc@1 68.750 (66.660)\tAcc@5 100.000 (97.413)\tMem 455MB\n",
      " * Acc@1 66.530 Acc@5 97.390\n",
      "Accuracy of the network on the 10000 test images: 66.5%\n",
      "Max accuracy: 66.73%\n",
      "Train: [26/100][0/625]\teta 0:00:22 lr 0.000869\t wd 0.0100\ttime 0.0355 (0.0355)\tloss 0.8970 (0.8970)\tgrad_norm 3.0271 (3.0271)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][10/625]\teta 0:00:20 lr 0.000869\t wd 0.0100\ttime 0.0327 (0.0339)\tloss 0.8735 (0.8643)\tgrad_norm 2.1565 (2.1919)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][20/625]\teta 0:00:20 lr 0.000869\t wd 0.0100\ttime 0.0326 (0.0337)\tloss 1.2197 (0.9126)\tgrad_norm 2.6524 (2.2549)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][30/625]\teta 0:00:20 lr 0.000868\t wd 0.0100\ttime 0.0325 (0.0340)\tloss 1.0283 (0.9246)\tgrad_norm 2.3873 (2.3265)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][40/625]\teta 0:00:19 lr 0.000868\t wd 0.0100\ttime 0.0367 (0.0342)\tloss 0.7031 (0.9063)\tgrad_norm 2.0650 (2.2607)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][50/625]\teta 0:00:19 lr 0.000868\t wd 0.0100\ttime 0.0329 (0.0340)\tloss 0.8774 (0.9051)\tgrad_norm 2.0549 (2.2666)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][60/625]\teta 0:00:19 lr 0.000868\t wd 0.0100\ttime 0.0355 (0.0340)\tloss 1.0908 (0.9036)\tgrad_norm 2.3086 (2.2512)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][70/625]\teta 0:00:18 lr 0.000868\t wd 0.0100\ttime 0.0383 (0.0340)\tloss 0.9077 (0.8966)\tgrad_norm 1.6908 (2.2035)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][80/625]\teta 0:00:18 lr 0.000868\t wd 0.0100\ttime 0.0325 (0.0342)\tloss 0.7573 (0.8992)\tgrad_norm 1.9593 (2.1550)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][90/625]\teta 0:00:18 lr 0.000867\t wd 0.0100\ttime 0.0396 (0.0345)\tloss 0.7798 (0.8959)\tgrad_norm 2.0441 (2.1447)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][100/625]\teta 0:00:18 lr 0.000867\t wd 0.0100\ttime 0.0396 (0.0347)\tloss 0.8833 (0.9000)\tgrad_norm 1.8730 (2.1403)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][110/625]\teta 0:00:17 lr 0.000867\t wd 0.0100\ttime 0.0325 (0.0347)\tloss 1.0547 (0.8966)\tgrad_norm 3.2928 (2.1557)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][120/625]\teta 0:00:17 lr 0.000867\t wd 0.0100\ttime 0.0335 (0.0347)\tloss 0.9131 (0.9005)\tgrad_norm 2.5942 (2.1592)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][130/625]\teta 0:00:17 lr 0.000867\t wd 0.0100\ttime 0.0324 (0.0346)\tloss 0.9995 (0.9012)\tgrad_norm 2.0582 (2.1366)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][140/625]\teta 0:00:16 lr 0.000866\t wd 0.0100\ttime 0.0325 (0.0346)\tloss 0.9897 (0.9050)\tgrad_norm 2.6305 (2.1439)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][150/625]\teta 0:00:16 lr 0.000866\t wd 0.0100\ttime 0.0351 (0.0346)\tloss 0.7500 (0.9097)\tgrad_norm 1.7917 (2.1454)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][160/625]\teta 0:00:16 lr 0.000866\t wd 0.0100\ttime 0.0327 (0.0348)\tloss 0.8423 (0.9145)\tgrad_norm 1.6881 (2.1468)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][170/625]\teta 0:00:15 lr 0.000866\t wd 0.0100\ttime 0.0328 (0.0348)\tloss 0.9844 (0.9151)\tgrad_norm 1.7003 (2.1344)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][180/625]\teta 0:00:15 lr 0.000866\t wd 0.0100\ttime 0.0330 (0.0349)\tloss 0.8496 (0.9142)\tgrad_norm 1.5654 (2.1231)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][190/625]\teta 0:00:15 lr 0.000866\t wd 0.0100\ttime 0.0346 (0.0349)\tloss 1.0312 (0.9130)\tgrad_norm 2.0146 (2.1320)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][200/625]\teta 0:00:14 lr 0.000865\t wd 0.0100\ttime 0.0327 (0.0349)\tloss 0.8613 (0.9130)\tgrad_norm 1.4982 (2.1352)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][210/625]\teta 0:00:14 lr 0.000865\t wd 0.0100\ttime 0.0326 (0.0349)\tloss 0.9312 (0.9144)\tgrad_norm 2.0710 (2.1261)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][220/625]\teta 0:00:14 lr 0.000865\t wd 0.0100\ttime 0.0360 (0.0350)\tloss 0.7573 (0.9151)\tgrad_norm 2.1222 (2.1211)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][230/625]\teta 0:00:13 lr 0.000865\t wd 0.0100\ttime 0.0327 (0.0350)\tloss 1.1240 (0.9178)\tgrad_norm 2.4168 (2.1266)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][240/625]\teta 0:00:13 lr 0.000865\t wd 0.0100\ttime 0.0364 (0.0350)\tloss 0.9590 (0.9191)\tgrad_norm 1.6630 (2.1278)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][250/625]\teta 0:00:13 lr 0.000865\t wd 0.0100\ttime 0.0325 (0.0351)\tloss 0.9141 (0.9182)\tgrad_norm 2.7575 (2.1273)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][260/625]\teta 0:00:12 lr 0.000864\t wd 0.0100\ttime 0.0341 (0.0351)\tloss 0.9336 (0.9196)\tgrad_norm 1.9880 (2.1283)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][270/625]\teta 0:00:12 lr 0.000864\t wd 0.0100\ttime 0.0367 (0.0351)\tloss 0.9380 (0.9191)\tgrad_norm 3.1751 (2.1322)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][280/625]\teta 0:00:12 lr 0.000864\t wd 0.0100\ttime 0.0327 (0.0351)\tloss 1.1250 (0.9221)\tgrad_norm 1.8797 (2.1473)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][290/625]\teta 0:00:11 lr 0.000864\t wd 0.0100\ttime 0.0355 (0.0352)\tloss 0.8604 (0.9219)\tgrad_norm 1.5660 (2.1493)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][300/625]\teta 0:00:11 lr 0.000864\t wd 0.0100\ttime 0.0400 (0.0351)\tloss 0.9624 (0.9233)\tgrad_norm 1.6814 (2.1417)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][310/625]\teta 0:00:11 lr 0.000863\t wd 0.0100\ttime 0.0358 (0.0352)\tloss 0.7578 (0.9233)\tgrad_norm 1.6924 (2.1362)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][320/625]\teta 0:00:10 lr 0.000863\t wd 0.0100\ttime 0.0397 (0.0352)\tloss 1.0166 (0.9243)\tgrad_norm 2.7535 (2.1412)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][330/625]\teta 0:00:10 lr 0.000863\t wd 0.0100\ttime 0.0357 (0.0353)\tloss 1.0850 (0.9254)\tgrad_norm 1.8869 (2.1342)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][340/625]\teta 0:00:10 lr 0.000863\t wd 0.0100\ttime 0.0397 (0.0353)\tloss 1.0078 (0.9256)\tgrad_norm 2.2542 (2.1313)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][350/625]\teta 0:00:09 lr 0.000863\t wd 0.0100\ttime 0.0327 (0.0353)\tloss 1.0010 (0.9256)\tgrad_norm 1.4668 (2.1211)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][360/625]\teta 0:00:09 lr 0.000863\t wd 0.0100\ttime 0.0392 (0.0353)\tloss 0.7017 (0.9254)\tgrad_norm 1.4828 (2.1184)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][370/625]\teta 0:00:09 lr 0.000862\t wd 0.0100\ttime 0.0410 (0.0354)\tloss 0.6782 (0.9262)\tgrad_norm 1.5010 (2.1182)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][380/625]\teta 0:00:08 lr 0.000862\t wd 0.0100\ttime 0.0325 (0.0354)\tloss 0.8594 (0.9264)\tgrad_norm 2.2409 (2.1179)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][390/625]\teta 0:00:08 lr 0.000862\t wd 0.0100\ttime 0.0352 (0.0354)\tloss 1.2324 (0.9280)\tgrad_norm 2.3759 (2.1233)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][400/625]\teta 0:00:07 lr 0.000862\t wd 0.0100\ttime 0.0392 (0.0354)\tloss 0.9453 (0.9292)\tgrad_norm 1.4086 (2.1183)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][410/625]\teta 0:00:07 lr 0.000862\t wd 0.0100\ttime 0.0328 (0.0354)\tloss 0.7817 (0.9299)\tgrad_norm 1.9887 (2.1139)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][420/625]\teta 0:00:07 lr 0.000862\t wd 0.0100\ttime 0.0325 (0.0354)\tloss 1.0879 (0.9312)\tgrad_norm 2.4259 (2.1112)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][430/625]\teta 0:00:06 lr 0.000861\t wd 0.0100\ttime 0.0323 (0.0353)\tloss 0.8438 (0.9319)\tgrad_norm 1.9496 (2.1116)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][440/625]\teta 0:00:06 lr 0.000861\t wd 0.0100\ttime 0.0328 (0.0353)\tloss 0.9004 (0.9321)\tgrad_norm 2.0163 (2.1254)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][450/625]\teta 0:00:06 lr 0.000861\t wd 0.0100\ttime 0.0322 (0.0352)\tloss 0.7852 (0.9332)\tgrad_norm 2.5672 (2.1263)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][460/625]\teta 0:00:05 lr 0.000861\t wd 0.0100\ttime 0.0324 (0.0352)\tloss 0.8662 (0.9327)\tgrad_norm 1.9037 (2.1264)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][470/625]\teta 0:00:05 lr 0.000861\t wd 0.0100\ttime 0.0329 (0.0352)\tloss 0.9224 (0.9325)\tgrad_norm 2.0500 (2.1261)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][480/625]\teta 0:00:05 lr 0.000860\t wd 0.0100\ttime 0.0356 (0.0351)\tloss 1.2373 (0.9320)\tgrad_norm 2.6237 (2.1264)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][490/625]\teta 0:00:04 lr 0.000860\t wd 0.0100\ttime 0.0324 (0.0352)\tloss 1.1279 (0.9337)\tgrad_norm 2.4286 (2.1285)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][500/625]\teta 0:00:04 lr 0.000860\t wd 0.0100\ttime 0.0415 (0.0352)\tloss 1.0342 (0.9337)\tgrad_norm 2.0328 (2.1338)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [26/100][510/625]\teta 0:00:04 lr 0.000860\t wd 0.0100\ttime 0.0330 (0.0352)\tloss 0.9829 (0.9336)\tgrad_norm 1.5759 (nan)\tloss_scale 32768.0000 (32832.1252)\tmem 455MB\n",
      "Train: [26/100][520/625]\teta 0:00:03 lr 0.000860\t wd 0.0100\ttime 0.0358 (0.0352)\tloss 0.8164 (0.9327)\tgrad_norm 2.3388 (nan)\tloss_scale 32768.0000 (32830.8944)\tmem 455MB\n",
      "Train: [26/100][530/625]\teta 0:00:03 lr 0.000860\t wd 0.0100\ttime 0.0382 (0.0352)\tloss 0.9092 (0.9327)\tgrad_norm 2.3071 (nan)\tloss_scale 32768.0000 (32829.7100)\tmem 455MB\n",
      "Train: [26/100][540/625]\teta 0:00:03 lr 0.000859\t wd 0.0100\ttime 0.0380 (0.0353)\tloss 1.0703 (0.9319)\tgrad_norm 2.5464 (nan)\tloss_scale 32768.0000 (32828.5693)\tmem 455MB\n",
      "Train: [26/100][550/625]\teta 0:00:02 lr 0.000859\t wd 0.0100\ttime 0.0346 (0.0353)\tloss 1.1045 (0.9315)\tgrad_norm 1.7613 (nan)\tloss_scale 32768.0000 (32827.4701)\tmem 455MB\n",
      "Train: [26/100][560/625]\teta 0:00:02 lr 0.000859\t wd 0.0100\ttime 0.0326 (0.0354)\tloss 0.7300 (0.9316)\tgrad_norm 2.1959 (nan)\tloss_scale 32768.0000 (32826.4100)\tmem 455MB\n",
      "Train: [26/100][570/625]\teta 0:00:01 lr 0.000859\t wd 0.0100\ttime 0.0359 (0.0354)\tloss 0.9795 (0.9314)\tgrad_norm 2.0127 (nan)\tloss_scale 32768.0000 (32825.3870)\tmem 455MB\n",
      "Train: [26/100][580/625]\teta 0:00:01 lr 0.000859\t wd 0.0100\ttime 0.0400 (0.0354)\tloss 0.9697 (0.9325)\tgrad_norm 2.0652 (nan)\tloss_scale 32768.0000 (32824.3993)\tmem 455MB\n",
      "Train: [26/100][590/625]\teta 0:00:01 lr 0.000858\t wd 0.0100\ttime 0.0365 (0.0355)\tloss 1.1377 (0.9337)\tgrad_norm 2.3203 (nan)\tloss_scale 32768.0000 (32823.4450)\tmem 455MB\n",
      "Train: [26/100][600/625]\teta 0:00:00 lr 0.000858\t wd 0.0100\ttime 0.0368 (0.0355)\tloss 1.0537 (0.9344)\tgrad_norm 1.9697 (nan)\tloss_scale 32768.0000 (32822.5225)\tmem 455MB\n",
      "Train: [26/100][610/625]\teta 0:00:00 lr 0.000858\t wd 0.0100\ttime 0.0357 (0.0355)\tloss 0.8398 (0.9342)\tgrad_norm 1.5441 (nan)\tloss_scale 32768.0000 (32821.6301)\tmem 455MB\n",
      "Train: [26/100][620/625]\teta 0:00:00 lr 0.000858\t wd 0.0100\ttime 0.0363 (0.0355)\tloss 0.8525 (0.9329)\tgrad_norm 1.6931 (nan)\tloss_scale 32768.0000 (32820.7665)\tmem 455MB\n",
      "EPOCH 26 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_26.pth saving......\n",
      "./model_save/ckpt_epoch_26.pth saved !!!\n",
      "Test: [0/157]\tTime 0.017 (0.017)\tLoss 1.0205 (1.0205)\tAcc@1 65.625 (65.625)\tAcc@5 96.875 (96.875)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.6924 (0.8738)\tAcc@1 75.000 (69.034)\tAcc@5 100.000 (98.153)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 1.0674 (0.9119)\tAcc@1 60.938 (67.708)\tAcc@5 96.875 (97.991)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.9814 (0.9021)\tAcc@1 62.500 (68.196)\tAcc@5 98.438 (97.530)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.9751 (0.9101)\tAcc@1 65.625 (67.645)\tAcc@5 96.875 (97.370)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.7461 (0.9024)\tAcc@1 75.000 (67.800)\tAcc@5 98.438 (97.580)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 1.0400 (0.9090)\tAcc@1 62.500 (67.674)\tAcc@5 95.312 (97.387)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.9858 (0.9152)\tAcc@1 64.062 (67.298)\tAcc@5 96.875 (97.381)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 1.0264 (0.9083)\tAcc@1 67.188 (67.361)\tAcc@5 98.438 (97.357)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.9116 (0.9055)\tAcc@1 67.188 (67.548)\tAcc@5 98.438 (97.390)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.8882 (0.8950)\tAcc@1 70.312 (67.837)\tAcc@5 95.312 (97.463)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.7036 (0.8887)\tAcc@1 78.125 (68.201)\tAcc@5 100.000 (97.466)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.021 (0.015)\tLoss 0.7524 (0.8845)\tAcc@1 67.188 (68.298)\tAcc@5 98.438 (97.495)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.9414 (0.8859)\tAcc@1 64.062 (67.963)\tAcc@5 95.312 (97.507)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.016 (0.015)\tLoss 0.9858 (0.8869)\tAcc@1 65.625 (67.808)\tAcc@5 95.312 (97.551)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.016 (0.015)\tLoss 0.8389 (0.8886)\tAcc@1 68.750 (67.684)\tAcc@5 98.438 (97.548)\tMem 455MB\n",
      " * Acc@1 67.490 Acc@5 97.540\n",
      "Accuracy of the network on the 10000 test images: 67.5%\n",
      "Max accuracy: 67.49%\n",
      "Train: [27/100][0/625]\teta 0:00:25 lr 0.000858\t wd 0.0100\ttime 0.0405 (0.0405)\tloss 0.9810 (0.9810)\tgrad_norm 2.1071 (2.1071)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][10/625]\teta 0:00:22 lr 0.000858\t wd 0.0100\ttime 0.0353 (0.0371)\tloss 0.9341 (0.9097)\tgrad_norm 1.5424 (2.3431)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][20/625]\teta 0:00:22 lr 0.000857\t wd 0.0100\ttime 0.0413 (0.0374)\tloss 0.8096 (0.9039)\tgrad_norm 1.8487 (2.2466)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][30/625]\teta 0:00:21 lr 0.000857\t wd 0.0100\ttime 0.0327 (0.0364)\tloss 0.7217 (0.8935)\tgrad_norm 1.7967 (2.1765)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][40/625]\teta 0:00:20 lr 0.000857\t wd 0.0100\ttime 0.0325 (0.0357)\tloss 1.0459 (0.9001)\tgrad_norm 2.5965 (2.1637)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][50/625]\teta 0:00:20 lr 0.000857\t wd 0.0100\ttime 0.0400 (0.0360)\tloss 0.9404 (0.8935)\tgrad_norm 3.4895 (2.2318)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][60/625]\teta 0:00:20 lr 0.000857\t wd 0.0100\ttime 0.0329 (0.0360)\tloss 0.8843 (0.8942)\tgrad_norm 2.5117 (2.3046)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][70/625]\teta 0:00:20 lr 0.000857\t wd 0.0100\ttime 0.0358 (0.0361)\tloss 0.9658 (0.9014)\tgrad_norm 2.8052 (2.3262)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][80/625]\teta 0:00:19 lr 0.000856\t wd 0.0100\ttime 0.0349 (0.0360)\tloss 0.8584 (0.9054)\tgrad_norm 1.7628 (2.3199)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][90/625]\teta 0:00:19 lr 0.000856\t wd 0.0100\ttime 0.0351 (0.0358)\tloss 0.9399 (0.9126)\tgrad_norm 2.1926 (2.3225)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][100/625]\teta 0:00:18 lr 0.000856\t wd 0.0100\ttime 0.0394 (0.0357)\tloss 1.0127 (0.9158)\tgrad_norm 1.7295 (2.2861)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][110/625]\teta 0:00:18 lr 0.000856\t wd 0.0100\ttime 0.0322 (0.0357)\tloss 0.9453 (0.9212)\tgrad_norm 1.4414 (2.2541)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][120/625]\teta 0:00:17 lr 0.000856\t wd 0.0100\ttime 0.0350 (0.0355)\tloss 1.0557 (0.9153)\tgrad_norm 1.7258 (2.2111)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][130/625]\teta 0:00:17 lr 0.000855\t wd 0.0100\ttime 0.0353 (0.0354)\tloss 0.7744 (0.9166)\tgrad_norm 1.5323 (2.2084)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][140/625]\teta 0:00:17 lr 0.000855\t wd 0.0100\ttime 0.0363 (0.0353)\tloss 0.9829 (0.9150)\tgrad_norm 1.6429 (2.2116)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][150/625]\teta 0:00:16 lr 0.000855\t wd 0.0100\ttime 0.0355 (0.0352)\tloss 1.0234 (0.9140)\tgrad_norm 2.2536 (2.2232)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][160/625]\teta 0:00:16 lr 0.000855\t wd 0.0100\ttime 0.0357 (0.0352)\tloss 0.9990 (0.9153)\tgrad_norm 2.2328 (2.2231)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][170/625]\teta 0:00:15 lr 0.000855\t wd 0.0100\ttime 0.0324 (0.0351)\tloss 0.9468 (0.9160)\tgrad_norm 2.5772 (2.2203)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][180/625]\teta 0:00:15 lr 0.000855\t wd 0.0100\ttime 0.0357 (0.0350)\tloss 0.7871 (0.9132)\tgrad_norm 1.5857 (2.2084)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][190/625]\teta 0:00:15 lr 0.000854\t wd 0.0100\ttime 0.0357 (0.0349)\tloss 0.9429 (0.9149)\tgrad_norm 1.8974 (2.2190)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][200/625]\teta 0:00:14 lr 0.000854\t wd 0.0100\ttime 0.0396 (0.0349)\tloss 1.2412 (0.9164)\tgrad_norm 2.3815 (2.2322)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][210/625]\teta 0:00:14 lr 0.000854\t wd 0.0100\ttime 0.0407 (0.0350)\tloss 1.0889 (0.9173)\tgrad_norm 2.1397 (2.2320)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][220/625]\teta 0:00:14 lr 0.000854\t wd 0.0100\ttime 0.0395 (0.0350)\tloss 0.9224 (0.9189)\tgrad_norm 2.4879 (2.2280)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][230/625]\teta 0:00:13 lr 0.000854\t wd 0.0100\ttime 0.0350 (0.0351)\tloss 0.8301 (0.9208)\tgrad_norm 2.8896 (2.2351)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][240/625]\teta 0:00:13 lr 0.000853\t wd 0.0100\ttime 0.0325 (0.0351)\tloss 1.0244 (0.9197)\tgrad_norm 2.6820 (2.2344)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][250/625]\teta 0:00:13 lr 0.000853\t wd 0.0100\ttime 0.0393 (0.0352)\tloss 1.0762 (0.9210)\tgrad_norm 2.7491 (2.2332)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][260/625]\teta 0:00:12 lr 0.000853\t wd 0.0100\ttime 0.0324 (0.0352)\tloss 0.9126 (0.9225)\tgrad_norm 1.6971 (2.2215)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][270/625]\teta 0:00:12 lr 0.000853\t wd 0.0100\ttime 0.0356 (0.0352)\tloss 1.1270 (0.9224)\tgrad_norm 2.2653 (2.2133)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][280/625]\teta 0:00:12 lr 0.000853\t wd 0.0100\ttime 0.0363 (0.0353)\tloss 1.1680 (0.9200)\tgrad_norm 2.5894 (2.2110)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][290/625]\teta 0:00:11 lr 0.000853\t wd 0.0100\ttime 0.0333 (0.0353)\tloss 0.9800 (0.9219)\tgrad_norm 2.4012 (2.2224)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][300/625]\teta 0:00:11 lr 0.000852\t wd 0.0100\ttime 0.0328 (0.0353)\tloss 1.1426 (0.9238)\tgrad_norm 3.9262 (2.2294)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][310/625]\teta 0:00:11 lr 0.000852\t wd 0.0100\ttime 0.0360 (0.0354)\tloss 0.8208 (0.9263)\tgrad_norm 2.2274 (2.2290)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][320/625]\teta 0:00:10 lr 0.000852\t wd 0.0100\ttime 0.0343 (0.0354)\tloss 0.7847 (0.9262)\tgrad_norm 1.8847 (2.2265)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][330/625]\teta 0:00:10 lr 0.000852\t wd 0.0100\ttime 0.0339 (0.0353)\tloss 0.8794 (0.9257)\tgrad_norm 3.1649 (2.2251)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][340/625]\teta 0:00:10 lr 0.000852\t wd 0.0100\ttime 0.0330 (0.0354)\tloss 0.8799 (0.9241)\tgrad_norm 2.5040 (2.2276)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][350/625]\teta 0:00:09 lr 0.000851\t wd 0.0100\ttime 0.0355 (0.0354)\tloss 1.1211 (0.9255)\tgrad_norm 2.4198 (2.2238)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][360/625]\teta 0:00:09 lr 0.000851\t wd 0.0100\ttime 0.0351 (0.0354)\tloss 0.9912 (0.9257)\tgrad_norm 2.3226 (2.2250)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][370/625]\teta 0:00:09 lr 0.000851\t wd 0.0100\ttime 0.0356 (0.0353)\tloss 1.0166 (0.9254)\tgrad_norm 3.3135 (2.2276)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][380/625]\teta 0:00:08 lr 0.000851\t wd 0.0100\ttime 0.0323 (0.0353)\tloss 0.9326 (0.9247)\tgrad_norm 2.2722 (2.2242)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][390/625]\teta 0:00:08 lr 0.000851\t wd 0.0100\ttime 0.0369 (0.0353)\tloss 0.7510 (0.9247)\tgrad_norm 1.6629 (2.2245)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][400/625]\teta 0:00:07 lr 0.000851\t wd 0.0100\ttime 0.0391 (0.0353)\tloss 0.7700 (0.9230)\tgrad_norm 2.0985 (2.2221)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][410/625]\teta 0:00:07 lr 0.000850\t wd 0.0100\ttime 0.0384 (0.0353)\tloss 1.0430 (0.9235)\tgrad_norm 2.8239 (2.2176)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][420/625]\teta 0:00:07 lr 0.000850\t wd 0.0100\ttime 0.0358 (0.0353)\tloss 0.6860 (0.9230)\tgrad_norm 1.6012 (2.2143)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][430/625]\teta 0:00:06 lr 0.000850\t wd 0.0100\ttime 0.0357 (0.0354)\tloss 0.8628 (0.9229)\tgrad_norm 2.0038 (2.2146)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][440/625]\teta 0:00:06 lr 0.000850\t wd 0.0100\ttime 0.0395 (0.0354)\tloss 0.8765 (0.9241)\tgrad_norm 2.3479 (2.2188)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][450/625]\teta 0:00:06 lr 0.000850\t wd 0.0100\ttime 0.0359 (0.0354)\tloss 0.9126 (0.9222)\tgrad_norm 1.9612 (2.2143)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][460/625]\teta 0:00:05 lr 0.000849\t wd 0.0100\ttime 0.0325 (0.0354)\tloss 0.8140 (0.9226)\tgrad_norm 1.6723 (2.2135)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][470/625]\teta 0:00:05 lr 0.000849\t wd 0.0100\ttime 0.0325 (0.0354)\tloss 0.6528 (0.9218)\tgrad_norm 1.6734 (2.2093)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][480/625]\teta 0:00:05 lr 0.000849\t wd 0.0100\ttime 0.0339 (0.0355)\tloss 0.5732 (0.9205)\tgrad_norm 1.4863 (2.2046)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][490/625]\teta 0:00:04 lr 0.000849\t wd 0.0100\ttime 0.0329 (0.0354)\tloss 0.9482 (0.9196)\tgrad_norm 1.9097 (2.2045)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][500/625]\teta 0:00:04 lr 0.000849\t wd 0.0100\ttime 0.0330 (0.0354)\tloss 0.9189 (0.9196)\tgrad_norm 2.3467 (2.2174)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][510/625]\teta 0:00:04 lr 0.000849\t wd 0.0100\ttime 0.0346 (0.0354)\tloss 0.9497 (0.9194)\tgrad_norm 2.3135 (2.2159)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][520/625]\teta 0:00:03 lr 0.000848\t wd 0.0100\ttime 0.0385 (0.0354)\tloss 1.0088 (0.9192)\tgrad_norm 2.4506 (2.2161)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][530/625]\teta 0:00:03 lr 0.000848\t wd 0.0100\ttime 0.0336 (0.0354)\tloss 1.1289 (0.9195)\tgrad_norm 3.2613 (2.2154)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][540/625]\teta 0:00:03 lr 0.000848\t wd 0.0100\ttime 0.0357 (0.0355)\tloss 1.0869 (0.9198)\tgrad_norm 1.9188 (2.2173)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][550/625]\teta 0:00:02 lr 0.000848\t wd 0.0100\ttime 0.0326 (0.0355)\tloss 0.8618 (0.9199)\tgrad_norm 1.4059 (2.2184)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][560/625]\teta 0:00:02 lr 0.000848\t wd 0.0100\ttime 0.0356 (0.0355)\tloss 0.7793 (0.9196)\tgrad_norm 1.8783 (2.2133)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][570/625]\teta 0:00:01 lr 0.000847\t wd 0.0100\ttime 0.0324 (0.0355)\tloss 1.0117 (0.9208)\tgrad_norm 2.4173 (2.2127)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][580/625]\teta 0:00:01 lr 0.000847\t wd 0.0100\ttime 0.0330 (0.0355)\tloss 0.8711 (0.9194)\tgrad_norm 2.2039 (2.2079)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][590/625]\teta 0:00:01 lr 0.000847\t wd 0.0100\ttime 0.0359 (0.0355)\tloss 1.0479 (0.9201)\tgrad_norm 2.5247 (2.2041)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][600/625]\teta 0:00:00 lr 0.000847\t wd 0.0100\ttime 0.0388 (0.0355)\tloss 0.7866 (0.9196)\tgrad_norm 3.4308 (2.2011)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][610/625]\teta 0:00:00 lr 0.000847\t wd 0.0100\ttime 0.0362 (0.0355)\tloss 1.0156 (0.9201)\tgrad_norm 2.7532 (2.2027)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [27/100][620/625]\teta 0:00:00 lr 0.000847\t wd 0.0100\ttime 0.0349 (0.0355)\tloss 0.8628 (0.9200)\tgrad_norm 2.0880 (2.2020)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 27 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_27.pth saving......\n",
      "./model_save/ckpt_epoch_27.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.7612 (0.7612)\tAcc@1 71.875 (71.875)\tAcc@5 100.000 (100.000)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 1.0146 (0.9007)\tAcc@1 68.750 (67.188)\tAcc@5 98.438 (97.585)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.8477 (0.9107)\tAcc@1 65.625 (67.113)\tAcc@5 98.438 (97.619)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 1.0361 (0.8838)\tAcc@1 60.938 (67.893)\tAcc@5 96.875 (97.833)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.016 (0.015)\tLoss 0.8755 (0.8812)\tAcc@1 62.500 (68.255)\tAcc@5 96.875 (97.790)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.016 (0.015)\tLoss 0.6260 (0.8730)\tAcc@1 81.250 (68.627)\tAcc@5 93.750 (97.794)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.5664 (0.8806)\tAcc@1 79.688 (68.519)\tAcc@5 100.000 (97.746)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.7100 (0.8768)\tAcc@1 78.125 (68.662)\tAcc@5 100.000 (97.865)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.7949 (0.8730)\tAcc@1 73.438 (68.808)\tAcc@5 95.312 (97.917)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.7866 (0.8726)\tAcc@1 70.312 (68.630)\tAcc@5 98.438 (97.854)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 1.0117 (0.8672)\tAcc@1 71.875 (68.920)\tAcc@5 93.750 (97.881)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.9746 (0.8628)\tAcc@1 65.625 (69.060)\tAcc@5 100.000 (97.945)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 1.1113 (0.8637)\tAcc@1 62.500 (69.047)\tAcc@5 93.750 (97.947)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.8931 (0.8645)\tAcc@1 73.438 (69.084)\tAcc@5 93.750 (97.901)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 1.1211 (0.8667)\tAcc@1 64.062 (68.983)\tAcc@5 95.312 (97.928)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.7075 (0.8705)\tAcc@1 70.312 (68.874)\tAcc@5 100.000 (97.930)\tMem 455MB\n",
      " * Acc@1 69.010 Acc@5 97.920\n",
      "Accuracy of the network on the 10000 test images: 69.0%\n",
      "Max accuracy: 69.01%\n",
      "Train: [28/100][0/625]\teta 0:00:26 lr 0.000846\t wd 0.0100\ttime 0.0419 (0.0419)\tloss 0.9043 (0.9043)\tgrad_norm 2.2490 (2.2490)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][10/625]\teta 0:00:21 lr 0.000846\t wd 0.0100\ttime 0.0330 (0.0352)\tloss 0.8979 (0.9058)\tgrad_norm 2.2524 (2.1575)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][20/625]\teta 0:00:21 lr 0.000846\t wd 0.0100\ttime 0.0358 (0.0357)\tloss 0.8877 (0.9008)\tgrad_norm 1.7595 (2.2252)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][30/625]\teta 0:00:21 lr 0.000846\t wd 0.0100\ttime 0.0388 (0.0360)\tloss 0.5918 (0.8918)\tgrad_norm 1.8167 (2.2851)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][40/625]\teta 0:00:20 lr 0.000846\t wd 0.0100\ttime 0.0335 (0.0357)\tloss 0.8979 (0.8810)\tgrad_norm 1.9259 (2.2330)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][50/625]\teta 0:00:20 lr 0.000845\t wd 0.0100\ttime 0.0391 (0.0357)\tloss 0.7349 (0.8861)\tgrad_norm 2.0467 (2.2414)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][60/625]\teta 0:00:20 lr 0.000845\t wd 0.0100\ttime 0.0359 (0.0356)\tloss 1.0391 (0.8939)\tgrad_norm 2.0722 (2.2396)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][70/625]\teta 0:00:19 lr 0.000845\t wd 0.0100\ttime 0.0392 (0.0356)\tloss 0.8135 (0.8973)\tgrad_norm 1.7922 (2.2356)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][80/625]\teta 0:00:19 lr 0.000845\t wd 0.0100\ttime 0.0356 (0.0353)\tloss 0.6680 (0.8900)\tgrad_norm 1.6371 (2.2223)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][90/625]\teta 0:00:18 lr 0.000845\t wd 0.0100\ttime 0.0327 (0.0351)\tloss 0.7690 (0.8924)\tgrad_norm 1.5908 (2.1976)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][100/625]\teta 0:00:18 lr 0.000845\t wd 0.0100\ttime 0.0326 (0.0349)\tloss 1.0049 (0.8910)\tgrad_norm 2.8657 (2.1902)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][110/625]\teta 0:00:17 lr 0.000844\t wd 0.0100\ttime 0.0325 (0.0347)\tloss 1.0889 (0.8939)\tgrad_norm 2.9086 (2.2077)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][120/625]\teta 0:00:17 lr 0.000844\t wd 0.0100\ttime 0.0326 (0.0347)\tloss 0.6914 (0.8880)\tgrad_norm 1.6909 (2.1999)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][130/625]\teta 0:00:17 lr 0.000844\t wd 0.0100\ttime 0.0327 (0.0346)\tloss 0.7905 (0.8852)\tgrad_norm 1.9540 (2.1821)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][140/625]\teta 0:00:16 lr 0.000844\t wd 0.0100\ttime 0.0349 (0.0346)\tloss 1.0215 (0.8879)\tgrad_norm 3.2227 (2.1789)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][150/625]\teta 0:00:16 lr 0.000844\t wd 0.0100\ttime 0.0323 (0.0346)\tloss 0.7983 (0.8885)\tgrad_norm 2.5894 (2.1861)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][160/625]\teta 0:00:16 lr 0.000843\t wd 0.0100\ttime 0.0325 (0.0346)\tloss 0.7969 (0.8934)\tgrad_norm 2.4012 (2.2066)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][170/625]\teta 0:00:15 lr 0.000843\t wd 0.0100\ttime 0.0353 (0.0346)\tloss 0.9219 (0.8976)\tgrad_norm 2.8367 (2.2253)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][180/625]\teta 0:00:15 lr 0.000843\t wd 0.0100\ttime 0.0397 (0.0345)\tloss 0.8511 (0.8961)\tgrad_norm 1.9241 (2.2120)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][190/625]\teta 0:00:15 lr 0.000843\t wd 0.0100\ttime 0.0393 (0.0347)\tloss 0.7695 (0.8947)\tgrad_norm 1.6099 (2.2108)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][200/625]\teta 0:00:14 lr 0.000843\t wd 0.0100\ttime 0.0327 (0.0346)\tloss 0.8594 (0.8920)\tgrad_norm 2.2968 (2.2052)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][210/625]\teta 0:00:14 lr 0.000842\t wd 0.0100\ttime 0.0324 (0.0346)\tloss 0.7900 (0.8940)\tgrad_norm 1.9465 (2.2110)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][220/625]\teta 0:00:14 lr 0.000842\t wd 0.0100\ttime 0.0356 (0.0347)\tloss 0.8101 (0.8958)\tgrad_norm 2.3285 (2.2087)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][230/625]\teta 0:00:13 lr 0.000842\t wd 0.0100\ttime 0.0326 (0.0348)\tloss 0.8999 (0.8953)\tgrad_norm 2.2101 (2.2062)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][240/625]\teta 0:00:13 lr 0.000842\t wd 0.0100\ttime 0.0323 (0.0348)\tloss 0.9624 (0.8977)\tgrad_norm 1.8456 (2.2017)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][250/625]\teta 0:00:13 lr 0.000842\t wd 0.0100\ttime 0.0326 (0.0348)\tloss 1.0029 (0.8988)\tgrad_norm 1.9195 (2.1977)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][260/625]\teta 0:00:12 lr 0.000842\t wd 0.0100\ttime 0.0359 (0.0348)\tloss 1.0234 (0.8995)\tgrad_norm 2.7754 (2.1975)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][270/625]\teta 0:00:12 lr 0.000841\t wd 0.0100\ttime 0.0322 (0.0348)\tloss 0.9126 (0.8998)\tgrad_norm 1.5938 (2.1904)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][280/625]\teta 0:00:11 lr 0.000841\t wd 0.0100\ttime 0.0365 (0.0348)\tloss 0.8013 (0.8997)\tgrad_norm 2.1650 (2.1963)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][290/625]\teta 0:00:11 lr 0.000841\t wd 0.0100\ttime 0.0393 (0.0348)\tloss 0.7988 (0.8994)\tgrad_norm 1.8729 (2.1946)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][300/625]\teta 0:00:11 lr 0.000841\t wd 0.0100\ttime 0.0321 (0.0348)\tloss 0.9531 (0.8987)\tgrad_norm 2.0045 (2.1961)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][310/625]\teta 0:00:10 lr 0.000841\t wd 0.0100\ttime 0.0357 (0.0348)\tloss 0.6846 (0.8992)\tgrad_norm 1.7053 (2.1893)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][320/625]\teta 0:00:10 lr 0.000840\t wd 0.0100\ttime 0.0364 (0.0348)\tloss 0.9990 (0.8997)\tgrad_norm 2.0758 (2.1904)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][330/625]\teta 0:00:10 lr 0.000840\t wd 0.0100\ttime 0.0329 (0.0348)\tloss 1.0332 (0.8995)\tgrad_norm 2.1124 (2.1862)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][340/625]\teta 0:00:09 lr 0.000840\t wd 0.0100\ttime 0.0393 (0.0349)\tloss 0.8330 (0.9002)\tgrad_norm 2.5429 (2.1844)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][350/625]\teta 0:00:09 lr 0.000840\t wd 0.0100\ttime 0.0391 (0.0349)\tloss 0.8965 (0.8999)\tgrad_norm 1.8438 (2.1806)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][360/625]\teta 0:00:09 lr 0.000840\t wd 0.0100\ttime 0.0391 (0.0349)\tloss 0.7729 (0.8969)\tgrad_norm 2.1337 (2.1742)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][370/625]\teta 0:00:08 lr 0.000839\t wd 0.0100\ttime 0.0399 (0.0349)\tloss 0.9453 (0.8954)\tgrad_norm 1.8205 (2.1702)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][380/625]\teta 0:00:08 lr 0.000839\t wd 0.0100\ttime 0.0330 (0.0350)\tloss 1.1006 (0.8969)\tgrad_norm 3.1227 (2.1754)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][390/625]\teta 0:00:08 lr 0.000839\t wd 0.0100\ttime 0.0381 (0.0350)\tloss 0.9854 (0.8988)\tgrad_norm 1.8559 (2.1700)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][400/625]\teta 0:00:07 lr 0.000839\t wd 0.0100\ttime 0.0359 (0.0350)\tloss 0.9458 (0.8976)\tgrad_norm 2.4219 (2.1670)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][410/625]\teta 0:00:07 lr 0.000839\t wd 0.0100\ttime 0.0324 (0.0350)\tloss 1.0273 (0.8971)\tgrad_norm 2.4254 (2.1627)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][420/625]\teta 0:00:07 lr 0.000839\t wd 0.0100\ttime 0.0356 (0.0350)\tloss 1.2334 (0.8980)\tgrad_norm 1.9533 (2.1671)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][430/625]\teta 0:00:06 lr 0.000838\t wd 0.0100\ttime 0.0326 (0.0350)\tloss 0.8325 (0.8974)\tgrad_norm 2.1032 (2.1653)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][440/625]\teta 0:00:06 lr 0.000838\t wd 0.0100\ttime 0.0359 (0.0350)\tloss 0.8350 (0.8977)\tgrad_norm 1.9369 (2.1675)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][450/625]\teta 0:00:06 lr 0.000838\t wd 0.0100\ttime 0.0327 (0.0350)\tloss 1.1836 (0.8993)\tgrad_norm 2.7699 (2.1705)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][460/625]\teta 0:00:05 lr 0.000838\t wd 0.0100\ttime 0.0323 (0.0350)\tloss 0.8745 (0.9004)\tgrad_norm 2.3706 (2.1748)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][470/625]\teta 0:00:05 lr 0.000838\t wd 0.0100\ttime 0.0353 (0.0350)\tloss 0.9399 (0.9006)\tgrad_norm 2.3268 (2.1732)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][480/625]\teta 0:00:05 lr 0.000837\t wd 0.0100\ttime 0.0321 (0.0349)\tloss 0.7017 (0.9010)\tgrad_norm 1.8622 (2.1733)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][490/625]\teta 0:00:04 lr 0.000837\t wd 0.0100\ttime 0.0367 (0.0349)\tloss 0.8530 (0.9009)\tgrad_norm 1.9674 (2.1750)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][500/625]\teta 0:00:04 lr 0.000837\t wd 0.0100\ttime 0.0320 (0.0349)\tloss 1.0879 (0.9019)\tgrad_norm 2.5759 (2.1796)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][510/625]\teta 0:00:04 lr 0.000837\t wd 0.0100\ttime 0.0322 (0.0349)\tloss 0.9526 (0.9031)\tgrad_norm 2.1196 (2.1891)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][520/625]\teta 0:00:03 lr 0.000837\t wd 0.0100\ttime 0.0368 (0.0349)\tloss 1.0205 (0.9037)\tgrad_norm 2.4076 (2.1873)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][530/625]\teta 0:00:03 lr 0.000836\t wd 0.0100\ttime 0.0360 (0.0348)\tloss 0.9741 (0.9039)\tgrad_norm 2.0458 (2.1848)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][540/625]\teta 0:00:02 lr 0.000836\t wd 0.0100\ttime 0.0321 (0.0348)\tloss 0.7324 (0.9039)\tgrad_norm 2.1441 (2.1839)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][550/625]\teta 0:00:02 lr 0.000836\t wd 0.0100\ttime 0.0321 (0.0348)\tloss 0.8135 (0.9053)\tgrad_norm 1.7922 (2.1844)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][560/625]\teta 0:00:02 lr 0.000836\t wd 0.0100\ttime 0.0355 (0.0347)\tloss 1.0039 (0.9049)\tgrad_norm 1.4665 (2.1788)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][570/625]\teta 0:00:01 lr 0.000836\t wd 0.0100\ttime 0.0326 (0.0347)\tloss 0.6729 (0.9039)\tgrad_norm 2.1887 (2.1788)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][580/625]\teta 0:00:01 lr 0.000835\t wd 0.0100\ttime 0.0325 (0.0347)\tloss 0.7583 (0.9033)\tgrad_norm 1.9175 (2.1764)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][590/625]\teta 0:00:01 lr 0.000835\t wd 0.0100\ttime 0.0333 (0.0347)\tloss 0.8882 (0.9034)\tgrad_norm 2.3670 (2.1801)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][600/625]\teta 0:00:00 lr 0.000835\t wd 0.0100\ttime 0.0334 (0.0346)\tloss 1.0498 (0.9049)\tgrad_norm 2.1054 (2.1809)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][610/625]\teta 0:00:00 lr 0.000835\t wd 0.0100\ttime 0.0323 (0.0346)\tloss 1.1689 (0.9055)\tgrad_norm 1.5880 (2.1809)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [28/100][620/625]\teta 0:00:00 lr 0.000835\t wd 0.0100\ttime 0.0342 (0.0346)\tloss 0.9141 (0.9052)\tgrad_norm 2.3206 (2.1851)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 28 training takes 0:00:21\n",
      "./model_save/ckpt_epoch_28.pth saving......\n",
      "./model_save/ckpt_epoch_28.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 1.1016 (1.1016)\tAcc@1 59.375 (59.375)\tAcc@5 98.438 (98.438)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.7788 (0.9459)\tAcc@1 73.438 (65.767)\tAcc@5 98.438 (98.295)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 1.0723 (0.9015)\tAcc@1 60.938 (67.783)\tAcc@5 95.312 (97.842)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 1.2207 (0.8800)\tAcc@1 57.812 (68.851)\tAcc@5 92.188 (97.782)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.8818 (0.8803)\tAcc@1 71.875 (68.559)\tAcc@5 98.438 (97.713)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.6763 (0.8717)\tAcc@1 79.688 (68.627)\tAcc@5 93.750 (97.733)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.9819 (0.8741)\tAcc@1 70.312 (68.724)\tAcc@5 95.312 (97.720)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.8569 (0.8697)\tAcc@1 70.312 (69.102)\tAcc@5 100.000 (97.777)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 1.0879 (0.8705)\tAcc@1 64.062 (68.866)\tAcc@5 93.750 (97.782)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.016 (0.015)\tLoss 0.8081 (0.8748)\tAcc@1 68.750 (68.733)\tAcc@5 100.000 (97.837)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.016 (0.015)\tLoss 0.8447 (0.8758)\tAcc@1 75.000 (68.657)\tAcc@5 96.875 (97.896)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 1.0156 (0.8734)\tAcc@1 67.188 (68.849)\tAcc@5 98.438 (97.889)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 1.0059 (0.8721)\tAcc@1 60.938 (68.815)\tAcc@5 96.875 (97.895)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 1.0762 (0.8704)\tAcc@1 62.500 (68.655)\tAcc@5 95.312 (97.877)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.8335 (0.8676)\tAcc@1 71.875 (68.794)\tAcc@5 100.000 (97.895)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.7080 (0.8649)\tAcc@1 79.688 (68.947)\tAcc@5 98.438 (97.868)\tMem 455MB\n",
      " * Acc@1 68.930 Acc@5 97.810\n",
      "Accuracy of the network on the 10000 test images: 68.9%\n",
      "Max accuracy: 69.01%\n",
      "Train: [29/100][0/625]\teta 0:00:21 lr 0.000835\t wd 0.0100\ttime 0.0341 (0.0341)\tloss 0.8037 (0.8037)\tgrad_norm 1.8790 (1.8790)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][10/625]\teta 0:00:21 lr 0.000834\t wd 0.0100\ttime 0.0350 (0.0345)\tloss 0.8687 (0.8291)\tgrad_norm 1.6419 (1.9242)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][20/625]\teta 0:00:20 lr 0.000834\t wd 0.0100\ttime 0.0368 (0.0342)\tloss 1.0381 (0.8611)\tgrad_norm 2.0094 (2.0745)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][30/625]\teta 0:00:20 lr 0.000834\t wd 0.0100\ttime 0.0358 (0.0337)\tloss 0.7363 (0.8933)\tgrad_norm 1.8265 (2.1531)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][40/625]\teta 0:00:19 lr 0.000834\t wd 0.0100\ttime 0.0322 (0.0336)\tloss 0.8618 (0.9010)\tgrad_norm 2.1252 (2.0880)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][50/625]\teta 0:00:19 lr 0.000834\t wd 0.0100\ttime 0.0320 (0.0336)\tloss 0.8804 (0.9033)\tgrad_norm 2.1896 (2.0564)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][60/625]\teta 0:00:18 lr 0.000833\t wd 0.0100\ttime 0.0348 (0.0336)\tloss 1.0156 (0.9080)\tgrad_norm 1.9883 (2.0317)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][70/625]\teta 0:00:18 lr 0.000833\t wd 0.0100\ttime 0.0319 (0.0336)\tloss 0.9771 (0.9074)\tgrad_norm 1.9755 (2.0254)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][80/625]\teta 0:00:18 lr 0.000833\t wd 0.0100\ttime 0.0320 (0.0337)\tloss 0.8613 (0.9034)\tgrad_norm 1.8205 (2.0315)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][90/625]\teta 0:00:18 lr 0.000833\t wd 0.0100\ttime 0.0321 (0.0337)\tloss 1.0107 (0.8915)\tgrad_norm 2.3281 (2.0147)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][100/625]\teta 0:00:17 lr 0.000833\t wd 0.0100\ttime 0.0322 (0.0337)\tloss 0.8223 (0.8878)\tgrad_norm 1.6761 (2.0232)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][110/625]\teta 0:00:17 lr 0.000833\t wd 0.0100\ttime 0.0327 (0.0336)\tloss 0.8921 (0.8927)\tgrad_norm 1.7957 (2.0618)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][120/625]\teta 0:00:16 lr 0.000832\t wd 0.0100\ttime 0.0327 (0.0336)\tloss 0.9814 (0.8955)\tgrad_norm 2.0141 (2.0787)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][130/625]\teta 0:00:16 lr 0.000832\t wd 0.0100\ttime 0.0327 (0.0335)\tloss 0.9429 (0.8986)\tgrad_norm 2.5408 (2.0780)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][140/625]\teta 0:00:16 lr 0.000832\t wd 0.0100\ttime 0.0325 (0.0334)\tloss 1.0479 (0.8992)\tgrad_norm 2.3482 (2.0725)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][150/625]\teta 0:00:15 lr 0.000832\t wd 0.0100\ttime 0.0327 (0.0334)\tloss 0.7192 (0.8984)\tgrad_norm 2.1120 (2.0740)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][160/625]\teta 0:00:15 lr 0.000832\t wd 0.0100\ttime 0.0327 (0.0334)\tloss 0.8843 (0.8979)\tgrad_norm 2.0437 (2.0776)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][170/625]\teta 0:00:15 lr 0.000831\t wd 0.0100\ttime 0.0323 (0.0334)\tloss 0.8779 (0.8986)\tgrad_norm 1.9293 (2.0770)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][180/625]\teta 0:00:14 lr 0.000831\t wd 0.0100\ttime 0.0323 (0.0334)\tloss 0.7778 (0.8973)\tgrad_norm 1.3524 (2.0717)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][190/625]\teta 0:00:14 lr 0.000831\t wd 0.0100\ttime 0.0324 (0.0334)\tloss 0.9463 (0.8987)\tgrad_norm 2.6978 (2.0891)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][200/625]\teta 0:00:14 lr 0.000831\t wd 0.0100\ttime 0.0376 (0.0334)\tloss 0.9590 (0.8983)\tgrad_norm 2.4677 (2.1207)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][210/625]\teta 0:00:13 lr 0.000831\t wd 0.0100\ttime 0.0321 (0.0335)\tloss 0.8291 (0.8981)\tgrad_norm 1.7126 (2.1252)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][220/625]\teta 0:00:13 lr 0.000830\t wd 0.0100\ttime 0.0350 (0.0335)\tloss 0.8828 (0.8971)\tgrad_norm 2.2214 (2.1247)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][230/625]\teta 0:00:13 lr 0.000830\t wd 0.0100\ttime 0.0354 (0.0335)\tloss 0.9521 (0.8952)\tgrad_norm 2.1211 (2.1194)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][240/625]\teta 0:00:12 lr 0.000830\t wd 0.0100\ttime 0.0355 (0.0335)\tloss 0.7383 (0.8943)\tgrad_norm 2.3551 (2.1246)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][250/625]\teta 0:00:12 lr 0.000830\t wd 0.0100\ttime 0.0326 (0.0335)\tloss 0.9546 (0.8960)\tgrad_norm 2.6677 (2.1265)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][260/625]\teta 0:00:12 lr 0.000830\t wd 0.0100\ttime 0.0340 (0.0335)\tloss 0.8994 (0.8949)\tgrad_norm 2.6703 (2.1344)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][270/625]\teta 0:00:11 lr 0.000829\t wd 0.0100\ttime 0.0324 (0.0335)\tloss 0.8560 (0.8911)\tgrad_norm 2.5784 (2.1315)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][280/625]\teta 0:00:11 lr 0.000829\t wd 0.0100\ttime 0.0359 (0.0336)\tloss 0.7603 (0.8924)\tgrad_norm 1.5978 (2.1294)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][290/625]\teta 0:00:11 lr 0.000829\t wd 0.0100\ttime 0.0357 (0.0337)\tloss 1.1162 (0.8925)\tgrad_norm 1.9206 (2.1307)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][300/625]\teta 0:00:10 lr 0.000829\t wd 0.0100\ttime 0.0358 (0.0337)\tloss 0.8779 (0.8921)\tgrad_norm 2.3793 (2.1350)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][310/625]\teta 0:00:10 lr 0.000829\t wd 0.0100\ttime 0.0363 (0.0338)\tloss 0.7202 (0.8903)\tgrad_norm 1.7349 (2.1358)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][320/625]\teta 0:00:10 lr 0.000828\t wd 0.0100\ttime 0.0404 (0.0339)\tloss 1.0684 (0.8914)\tgrad_norm 1.9653 (2.1363)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][330/625]\teta 0:00:10 lr 0.000828\t wd 0.0100\ttime 0.0333 (0.0339)\tloss 0.7212 (0.8923)\tgrad_norm 1.4359 (2.1358)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][340/625]\teta 0:00:09 lr 0.000828\t wd 0.0100\ttime 0.0323 (0.0340)\tloss 0.9624 (0.8922)\tgrad_norm 2.0192 (2.1356)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][350/625]\teta 0:00:09 lr 0.000828\t wd 0.0100\ttime 0.0326 (0.0340)\tloss 0.8496 (0.8919)\tgrad_norm 2.3879 (2.1420)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][360/625]\teta 0:00:08 lr 0.000828\t wd 0.0100\ttime 0.0323 (0.0340)\tloss 0.9634 (0.8917)\tgrad_norm 1.8182 (2.1439)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][370/625]\teta 0:00:08 lr 0.000827\t wd 0.0100\ttime 0.0348 (0.0339)\tloss 0.8672 (0.8928)\tgrad_norm 1.8867 (2.1449)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][380/625]\teta 0:00:08 lr 0.000827\t wd 0.0100\ttime 0.0323 (0.0339)\tloss 1.0195 (0.8937)\tgrad_norm 2.7453 (2.1542)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][390/625]\teta 0:00:07 lr 0.000827\t wd 0.0100\ttime 0.0394 (0.0340)\tloss 1.0654 (0.8947)\tgrad_norm 2.3155 (2.1526)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][400/625]\teta 0:00:07 lr 0.000827\t wd 0.0100\ttime 0.0397 (0.0340)\tloss 0.8115 (0.8960)\tgrad_norm 1.5100 (2.1438)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][410/625]\teta 0:00:07 lr 0.000827\t wd 0.0100\ttime 0.0370 (0.0341)\tloss 0.6821 (0.8946)\tgrad_norm 1.6555 (2.1427)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][420/625]\teta 0:00:06 lr 0.000827\t wd 0.0100\ttime 0.0361 (0.0341)\tloss 0.8984 (0.8940)\tgrad_norm 1.9078 (2.1378)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][430/625]\teta 0:00:06 lr 0.000826\t wd 0.0100\ttime 0.0330 (0.0342)\tloss 0.7539 (0.8936)\tgrad_norm 2.5398 (2.1409)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][440/625]\teta 0:00:06 lr 0.000826\t wd 0.0100\ttime 0.0381 (0.0342)\tloss 0.6943 (0.8932)\tgrad_norm 1.7458 (2.1378)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][450/625]\teta 0:00:05 lr 0.000826\t wd 0.0100\ttime 0.0357 (0.0343)\tloss 0.9614 (0.8926)\tgrad_norm 2.2645 (2.1370)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][460/625]\teta 0:00:05 lr 0.000826\t wd 0.0100\ttime 0.0324 (0.0343)\tloss 0.8794 (0.8935)\tgrad_norm 1.7664 (2.1394)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][470/625]\teta 0:00:05 lr 0.000826\t wd 0.0100\ttime 0.0406 (0.0344)\tloss 0.9121 (0.8929)\tgrad_norm 2.1991 (2.1369)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][480/625]\teta 0:00:05 lr 0.000825\t wd 0.0100\ttime 0.0353 (0.0345)\tloss 0.9834 (0.8936)\tgrad_norm 1.5908 (2.1369)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][490/625]\teta 0:00:04 lr 0.000825\t wd 0.0100\ttime 0.0371 (0.0346)\tloss 0.8584 (0.8935)\tgrad_norm 2.1664 (2.1343)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][500/625]\teta 0:00:04 lr 0.000825\t wd 0.0100\ttime 0.0398 (0.0346)\tloss 0.9771 (0.8936)\tgrad_norm 1.7468 (2.1312)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][510/625]\teta 0:00:03 lr 0.000825\t wd 0.0100\ttime 0.0329 (0.0346)\tloss 1.0117 (0.8932)\tgrad_norm 2.0656 (2.1278)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][520/625]\teta 0:00:03 lr 0.000825\t wd 0.0100\ttime 0.0361 (0.0346)\tloss 0.6616 (0.8930)\tgrad_norm 1.6288 (2.1269)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][530/625]\teta 0:00:03 lr 0.000824\t wd 0.0100\ttime 0.0323 (0.0346)\tloss 1.0420 (0.8932)\tgrad_norm 2.4971 (2.1289)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][540/625]\teta 0:00:02 lr 0.000824\t wd 0.0100\ttime 0.0393 (0.0346)\tloss 1.0332 (0.8935)\tgrad_norm 2.0994 (2.1295)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][550/625]\teta 0:00:02 lr 0.000824\t wd 0.0100\ttime 0.0343 (0.0347)\tloss 0.6992 (0.8923)\tgrad_norm 2.4101 (2.1271)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][560/625]\teta 0:00:02 lr 0.000824\t wd 0.0100\ttime 0.0325 (0.0347)\tloss 0.7334 (0.8920)\tgrad_norm 2.0340 (2.1234)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][570/625]\teta 0:00:01 lr 0.000824\t wd 0.0100\ttime 0.0401 (0.0347)\tloss 0.9634 (0.8911)\tgrad_norm 2.1203 (2.1247)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][580/625]\teta 0:00:01 lr 0.000823\t wd 0.0100\ttime 0.0371 (0.0347)\tloss 0.9570 (0.8902)\tgrad_norm 1.7992 (2.1242)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][590/625]\teta 0:00:01 lr 0.000823\t wd 0.0100\ttime 0.0392 (0.0348)\tloss 0.9629 (0.8901)\tgrad_norm 2.3693 (2.1218)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][600/625]\teta 0:00:00 lr 0.000823\t wd 0.0100\ttime 0.0362 (0.0348)\tloss 0.7266 (0.8887)\tgrad_norm 1.6522 (2.1193)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][610/625]\teta 0:00:00 lr 0.000823\t wd 0.0100\ttime 0.0359 (0.0348)\tloss 1.0977 (0.8889)\tgrad_norm 2.3431 (2.1247)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [29/100][620/625]\teta 0:00:00 lr 0.000823\t wd 0.0100\ttime 0.0352 (0.0348)\tloss 0.9268 (0.8886)\tgrad_norm 2.0254 (2.1219)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 29 training takes 0:00:21\n",
      "./model_save/ckpt_epoch_29.pth saving......\n",
      "./model_save/ckpt_epoch_29.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 1.0645 (1.0645)\tAcc@1 60.938 (60.938)\tAcc@5 93.750 (93.750)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 1.1680 (0.9060)\tAcc@1 62.500 (68.040)\tAcc@5 95.312 (97.301)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.6514 (0.8765)\tAcc@1 79.688 (68.899)\tAcc@5 100.000 (97.619)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.8701 (0.8813)\tAcc@1 62.500 (68.851)\tAcc@5 100.000 (97.984)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.8848 (0.8899)\tAcc@1 68.750 (68.559)\tAcc@5 98.438 (97.828)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.9912 (0.8729)\tAcc@1 67.188 (69.179)\tAcc@5 98.438 (97.917)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 1.0732 (0.8874)\tAcc@1 67.188 (68.468)\tAcc@5 93.750 (97.746)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 1.0254 (0.8918)\tAcc@1 65.625 (68.398)\tAcc@5 98.438 (97.755)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.8687 (0.8883)\tAcc@1 75.000 (68.480)\tAcc@5 95.312 (97.840)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.6196 (0.8802)\tAcc@1 75.000 (68.716)\tAcc@5 100.000 (97.888)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 1.0303 (0.8769)\tAcc@1 67.188 (68.874)\tAcc@5 93.750 (97.865)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.9609 (0.8792)\tAcc@1 68.750 (68.961)\tAcc@5 96.875 (97.748)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.8027 (0.8834)\tAcc@1 70.312 (68.866)\tAcc@5 98.438 (97.727)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.6841 (0.8781)\tAcc@1 79.688 (69.203)\tAcc@5 100.000 (97.734)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.9268 (0.8778)\tAcc@1 65.625 (69.005)\tAcc@5 95.312 (97.739)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.8721 (0.8800)\tAcc@1 68.750 (68.998)\tAcc@5 100.000 (97.744)\tMem 455MB\n",
      " * Acc@1 68.900 Acc@5 97.750\n",
      "Accuracy of the network on the 10000 test images: 68.9%\n",
      "Max accuracy: 69.01%\n",
      "Train: [30/100][0/625]\teta 0:00:25 lr 0.000822\t wd 0.0100\ttime 0.0403 (0.0403)\tloss 0.6880 (0.6880)\tgrad_norm 1.4166 (1.4166)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [30/100][10/625]\teta 0:00:21 lr 0.000822\t wd 0.0100\ttime 0.0323 (0.0355)\tloss 0.7080 (0.8387)\tgrad_norm 1.9372 (nan)\tloss_scale 32768.0000 (35746.9091)\tmem 455MB\n",
      "Train: [30/100][20/625]\teta 0:00:20 lr 0.000822\t wd 0.0100\ttime 0.0324 (0.0346)\tloss 1.2334 (0.8910)\tgrad_norm 2.8831 (nan)\tloss_scale 32768.0000 (34328.3810)\tmem 455MB\n",
      "Train: [30/100][30/625]\teta 0:00:20 lr 0.000822\t wd 0.0100\ttime 0.0334 (0.0351)\tloss 0.8325 (0.9093)\tgrad_norm 1.8996 (nan)\tloss_scale 32768.0000 (33825.0323)\tmem 455MB\n",
      "Train: [30/100][40/625]\teta 0:00:20 lr 0.000822\t wd 0.0100\ttime 0.0349 (0.0350)\tloss 0.9219 (0.9001)\tgrad_norm 1.9283 (nan)\tloss_scale 32768.0000 (33567.2195)\tmem 455MB\n",
      "Train: [30/100][50/625]\teta 0:00:20 lr 0.000822\t wd 0.0100\ttime 0.0324 (0.0350)\tloss 1.1611 (0.8939)\tgrad_norm 2.0806 (nan)\tloss_scale 32768.0000 (33410.5098)\tmem 455MB\n",
      "Train: [30/100][60/625]\teta 0:00:19 lr 0.000821\t wd 0.0100\ttime 0.0391 (0.0351)\tloss 0.8706 (0.8966)\tgrad_norm 1.9930 (nan)\tloss_scale 32768.0000 (33305.1803)\tmem 455MB\n",
      "Train: [30/100][70/625]\teta 0:00:19 lr 0.000821\t wd 0.0100\ttime 0.0391 (0.0353)\tloss 0.8994 (0.8873)\tgrad_norm 2.5785 (nan)\tloss_scale 32768.0000 (33229.5211)\tmem 455MB\n",
      "Train: [30/100][80/625]\teta 0:00:19 lr 0.000821\t wd 0.0100\ttime 0.0362 (0.0352)\tloss 0.7886 (0.8800)\tgrad_norm 1.4347 (nan)\tloss_scale 32768.0000 (33172.5432)\tmem 455MB\n",
      "Train: [30/100][90/625]\teta 0:00:18 lr 0.000821\t wd 0.0100\ttime 0.0367 (0.0353)\tloss 0.6567 (0.8824)\tgrad_norm 1.6679 (nan)\tloss_scale 32768.0000 (33128.0879)\tmem 455MB\n",
      "Train: [30/100][100/625]\teta 0:00:18 lr 0.000821\t wd 0.0100\ttime 0.0393 (0.0354)\tloss 0.9136 (0.8805)\tgrad_norm 2.2863 (nan)\tloss_scale 32768.0000 (33092.4356)\tmem 455MB\n",
      "Train: [30/100][110/625]\teta 0:00:18 lr 0.000820\t wd 0.0100\ttime 0.0329 (0.0354)\tloss 0.6904 (0.8830)\tgrad_norm 2.3034 (nan)\tloss_scale 32768.0000 (33063.2072)\tmem 455MB\n",
      "Train: [30/100][120/625]\teta 0:00:17 lr 0.000820\t wd 0.0100\ttime 0.0328 (0.0354)\tloss 0.7329 (0.8854)\tgrad_norm 2.3414 (nan)\tloss_scale 32768.0000 (33038.8099)\tmem 455MB\n",
      "Train: [30/100][130/625]\teta 0:00:17 lr 0.000820\t wd 0.0100\ttime 0.0385 (0.0355)\tloss 0.7837 (0.8890)\tgrad_norm 2.6005 (nan)\tloss_scale 32768.0000 (33018.1374)\tmem 455MB\n",
      "Train: [30/100][140/625]\teta 0:00:17 lr 0.000820\t wd 0.0100\ttime 0.0325 (0.0354)\tloss 1.2109 (0.8930)\tgrad_norm 2.5820 (nan)\tloss_scale 32768.0000 (33000.3972)\tmem 455MB\n",
      "Train: [30/100][150/625]\teta 0:00:16 lr 0.000820\t wd 0.0100\ttime 0.0328 (0.0354)\tloss 0.7617 (0.8898)\tgrad_norm 1.4282 (nan)\tloss_scale 32768.0000 (32985.0066)\tmem 455MB\n",
      "Train: [30/100][160/625]\teta 0:00:16 lr 0.000819\t wd 0.0100\ttime 0.0394 (0.0353)\tloss 0.7896 (0.8839)\tgrad_norm 2.0078 (nan)\tloss_scale 32768.0000 (32971.5280)\tmem 455MB\n",
      "Train: [30/100][170/625]\teta 0:00:16 lr 0.000819\t wd 0.0100\ttime 0.0326 (0.0353)\tloss 0.9028 (0.8828)\tgrad_norm 2.4689 (nan)\tloss_scale 32768.0000 (32959.6257)\tmem 455MB\n",
      "Train: [30/100][180/625]\teta 0:00:15 lr 0.000819\t wd 0.0100\ttime 0.0340 (0.0352)\tloss 0.9150 (0.8834)\tgrad_norm 2.2611 (nan)\tloss_scale 32768.0000 (32949.0387)\tmem 455MB\n",
      "Train: [30/100][190/625]\teta 0:00:15 lr 0.000819\t wd 0.0100\ttime 0.0322 (0.0351)\tloss 1.0088 (0.8861)\tgrad_norm 2.0704 (nan)\tloss_scale 32768.0000 (32939.5602)\tmem 455MB\n",
      "Train: [30/100][200/625]\teta 0:00:14 lr 0.000819\t wd 0.0100\ttime 0.0325 (0.0351)\tloss 0.9497 (0.8887)\tgrad_norm 1.9853 (nan)\tloss_scale 32768.0000 (32931.0249)\tmem 455MB\n",
      "Train: [30/100][210/625]\teta 0:00:14 lr 0.000818\t wd 0.0100\ttime 0.0322 (0.0350)\tloss 0.8403 (0.8855)\tgrad_norm 1.7851 (nan)\tloss_scale 32768.0000 (32923.2986)\tmem 455MB\n",
      "Train: [30/100][220/625]\teta 0:00:14 lr 0.000818\t wd 0.0100\ttime 0.0338 (0.0349)\tloss 0.9683 (0.8859)\tgrad_norm 2.2231 (nan)\tloss_scale 32768.0000 (32916.2715)\tmem 455MB\n",
      "Train: [30/100][230/625]\teta 0:00:13 lr 0.000818\t wd 0.0100\ttime 0.0325 (0.0349)\tloss 0.8647 (0.8868)\tgrad_norm 1.7878 (nan)\tloss_scale 32768.0000 (32909.8528)\tmem 455MB\n",
      "Train: [30/100][240/625]\teta 0:00:13 lr 0.000818\t wd 0.0100\ttime 0.0331 (0.0349)\tloss 0.7783 (0.8860)\tgrad_norm 1.9821 (nan)\tloss_scale 32768.0000 (32903.9668)\tmem 455MB\n",
      "Train: [30/100][250/625]\teta 0:00:13 lr 0.000818\t wd 0.0100\ttime 0.0324 (0.0348)\tloss 0.8691 (0.8868)\tgrad_norm 3.1197 (nan)\tloss_scale 32768.0000 (32898.5498)\tmem 455MB\n",
      "Train: [30/100][260/625]\teta 0:00:12 lr 0.000817\t wd 0.0100\ttime 0.0330 (0.0347)\tloss 0.7944 (0.8841)\tgrad_norm 2.3355 (nan)\tloss_scale 32768.0000 (32893.5479)\tmem 455MB\n",
      "Train: [30/100][270/625]\teta 0:00:12 lr 0.000817\t wd 0.0100\ttime 0.0330 (0.0347)\tloss 0.8857 (0.8825)\tgrad_norm 1.8141 (nan)\tloss_scale 32768.0000 (32888.9151)\tmem 455MB\n",
      "Train: [30/100][280/625]\teta 0:00:11 lr 0.000817\t wd 0.0100\ttime 0.0322 (0.0346)\tloss 1.0420 (0.8856)\tgrad_norm 2.7432 (nan)\tloss_scale 32768.0000 (32884.6121)\tmem 455MB\n",
      "Train: [30/100][290/625]\teta 0:00:11 lr 0.000817\t wd 0.0100\ttime 0.0332 (0.0346)\tloss 0.7500 (0.8841)\tgrad_norm 1.7191 (nan)\tloss_scale 32768.0000 (32880.6048)\tmem 455MB\n",
      "Train: [30/100][300/625]\teta 0:00:11 lr 0.000817\t wd 0.0100\ttime 0.0351 (0.0347)\tloss 0.8789 (0.8838)\tgrad_norm 1.6799 (nan)\tloss_scale 32768.0000 (32876.8638)\tmem 455MB\n",
      "Train: [30/100][310/625]\teta 0:00:10 lr 0.000816\t wd 0.0100\ttime 0.0327 (0.0347)\tloss 0.8740 (0.8832)\tgrad_norm 1.6514 (nan)\tloss_scale 32768.0000 (32873.3633)\tmem 455MB\n",
      "Train: [30/100][320/625]\teta 0:00:10 lr 0.000816\t wd 0.0100\ttime 0.0398 (0.0348)\tloss 0.8394 (0.8822)\tgrad_norm 1.8862 (nan)\tloss_scale 32768.0000 (32870.0810)\tmem 455MB\n",
      "Train: [30/100][330/625]\teta 0:00:10 lr 0.000816\t wd 0.0100\ttime 0.0354 (0.0348)\tloss 0.9937 (0.8807)\tgrad_norm 2.4615 (nan)\tloss_scale 32768.0000 (32866.9970)\tmem 455MB\n",
      "Train: [30/100][340/625]\teta 0:00:09 lr 0.000816\t wd 0.0100\ttime 0.0394 (0.0349)\tloss 0.9189 (0.8817)\tgrad_norm 2.2246 (nan)\tloss_scale 32768.0000 (32864.0938)\tmem 455MB\n",
      "Train: [30/100][350/625]\teta 0:00:09 lr 0.000816\t wd 0.0100\ttime 0.0326 (0.0350)\tloss 0.7427 (0.8833)\tgrad_norm 1.6959 (nan)\tloss_scale 32768.0000 (32861.3561)\tmem 455MB\n",
      "Train: [30/100][360/625]\teta 0:00:09 lr 0.000815\t wd 0.0100\ttime 0.0326 (0.0350)\tloss 0.8877 (0.8825)\tgrad_norm 1.7192 (nan)\tloss_scale 32768.0000 (32858.7701)\tmem 455MB\n",
      "Train: [30/100][370/625]\teta 0:00:08 lr 0.000815\t wd 0.0100\ttime 0.0395 (0.0351)\tloss 0.7979 (0.8828)\tgrad_norm 2.0430 (nan)\tloss_scale 32768.0000 (32856.3235)\tmem 455MB\n",
      "Train: [30/100][380/625]\teta 0:00:08 lr 0.000815\t wd 0.0100\ttime 0.0328 (0.0351)\tloss 0.6548 (0.8820)\tgrad_norm 1.4355 (nan)\tloss_scale 32768.0000 (32854.0052)\tmem 455MB\n",
      "Train: [30/100][390/625]\teta 0:00:08 lr 0.000815\t wd 0.0100\ttime 0.0328 (0.0351)\tloss 1.0205 (0.8815)\tgrad_norm 2.0156 (nan)\tloss_scale 32768.0000 (32851.8056)\tmem 455MB\n",
      "Train: [30/100][400/625]\teta 0:00:07 lr 0.000815\t wd 0.0100\ttime 0.0349 (0.0351)\tloss 0.8828 (0.8813)\tgrad_norm 1.6294 (nan)\tloss_scale 32768.0000 (32849.7157)\tmem 455MB\n",
      "Train: [30/100][410/625]\teta 0:00:07 lr 0.000814\t wd 0.0100\ttime 0.0421 (0.0351)\tloss 0.8662 (0.8796)\tgrad_norm 2.2087 (nan)\tloss_scale 32768.0000 (32847.7275)\tmem 455MB\n",
      "Train: [30/100][420/625]\teta 0:00:07 lr 0.000814\t wd 0.0100\ttime 0.0336 (0.0352)\tloss 0.8286 (0.8786)\tgrad_norm 2.0397 (nan)\tloss_scale 32768.0000 (32845.8337)\tmem 455MB\n",
      "Train: [30/100][430/625]\teta 0:00:06 lr 0.000814\t wd 0.0100\ttime 0.0361 (0.0352)\tloss 1.0225 (0.8796)\tgrad_norm 2.0913 (nan)\tloss_scale 32768.0000 (32844.0278)\tmem 455MB\n",
      "Train: [30/100][440/625]\teta 0:00:06 lr 0.000814\t wd 0.0100\ttime 0.0358 (0.0352)\tloss 1.1045 (0.8783)\tgrad_norm 2.3491 (nan)\tloss_scale 32768.0000 (32842.3039)\tmem 455MB\n",
      "Train: [30/100][450/625]\teta 0:00:06 lr 0.000814\t wd 0.0100\ttime 0.0360 (0.0351)\tloss 1.0127 (0.8782)\tgrad_norm 2.1087 (nan)\tloss_scale 32768.0000 (32840.6563)\tmem 455MB\n",
      "Train: [30/100][460/625]\teta 0:00:05 lr 0.000813\t wd 0.0100\ttime 0.0327 (0.0351)\tloss 0.9160 (0.8776)\tgrad_norm 2.0994 (nan)\tloss_scale 32768.0000 (32839.0803)\tmem 455MB\n",
      "Train: [30/100][470/625]\teta 0:00:05 lr 0.000813\t wd 0.0100\ttime 0.0330 (0.0351)\tloss 0.9746 (0.8779)\tgrad_norm 3.9728 (nan)\tloss_scale 32768.0000 (32837.5711)\tmem 455MB\n",
      "Train: [30/100][480/625]\teta 0:00:05 lr 0.000813\t wd 0.0100\ttime 0.0324 (0.0350)\tloss 0.8296 (0.8778)\tgrad_norm 2.0649 (nan)\tloss_scale 32768.0000 (32836.1247)\tmem 455MB\n",
      "Train: [30/100][490/625]\teta 0:00:04 lr 0.000813\t wd 0.0100\ttime 0.0325 (0.0350)\tloss 0.9507 (0.8778)\tgrad_norm 2.4466 (nan)\tloss_scale 32768.0000 (32834.7373)\tmem 455MB\n",
      "Train: [30/100][500/625]\teta 0:00:04 lr 0.000813\t wd 0.0100\ttime 0.0360 (0.0350)\tloss 1.0576 (0.8786)\tgrad_norm 1.5661 (nan)\tloss_scale 32768.0000 (32833.4052)\tmem 455MB\n",
      "Train: [30/100][510/625]\teta 0:00:04 lr 0.000812\t wd 0.0100\ttime 0.0360 (0.0350)\tloss 0.9175 (0.8790)\tgrad_norm 2.2445 (nan)\tloss_scale 32768.0000 (32832.1252)\tmem 455MB\n",
      "Train: [30/100][520/625]\teta 0:00:03 lr 0.000812\t wd 0.0100\ttime 0.0391 (0.0351)\tloss 0.9155 (0.8782)\tgrad_norm 2.0397 (nan)\tloss_scale 32768.0000 (32830.8944)\tmem 455MB\n",
      "Train: [30/100][530/625]\teta 0:00:03 lr 0.000812\t wd 0.0100\ttime 0.0334 (0.0351)\tloss 0.7344 (0.8776)\tgrad_norm 1.7154 (nan)\tloss_scale 32768.0000 (32829.7100)\tmem 455MB\n",
      "Train: [30/100][540/625]\teta 0:00:02 lr 0.000812\t wd 0.0100\ttime 0.0330 (0.0351)\tloss 0.6919 (0.8771)\tgrad_norm 1.5755 (nan)\tloss_scale 32768.0000 (32828.5693)\tmem 455MB\n",
      "Train: [30/100][550/625]\teta 0:00:02 lr 0.000812\t wd 0.0100\ttime 0.0346 (0.0351)\tloss 0.9219 (0.8764)\tgrad_norm 2.7164 (nan)\tloss_scale 32768.0000 (32827.4701)\tmem 455MB\n",
      "Train: [30/100][560/625]\teta 0:00:02 lr 0.000811\t wd 0.0100\ttime 0.0370 (0.0351)\tloss 1.0957 (0.8766)\tgrad_norm 3.0119 (nan)\tloss_scale 32768.0000 (32826.4100)\tmem 455MB\n",
      "Train: [30/100][570/625]\teta 0:00:01 lr 0.000811\t wd 0.0100\ttime 0.0331 (0.0352)\tloss 0.8130 (0.8755)\tgrad_norm 2.8616 (nan)\tloss_scale 32768.0000 (32825.3870)\tmem 455MB\n",
      "Train: [30/100][580/625]\teta 0:00:01 lr 0.000811\t wd 0.0100\ttime 0.0356 (0.0352)\tloss 0.8711 (0.8742)\tgrad_norm 2.7733 (nan)\tloss_scale 32768.0000 (32824.3993)\tmem 455MB\n",
      "Train: [30/100][590/625]\teta 0:00:01 lr 0.000811\t wd 0.0100\ttime 0.0350 (0.0351)\tloss 0.7646 (0.8747)\tgrad_norm 1.8080 (nan)\tloss_scale 32768.0000 (32823.4450)\tmem 455MB\n",
      "Train: [30/100][600/625]\teta 0:00:00 lr 0.000811\t wd 0.0100\ttime 0.0357 (0.0351)\tloss 1.1768 (0.8750)\tgrad_norm 2.4872 (nan)\tloss_scale 32768.0000 (32822.5225)\tmem 455MB\n",
      "Train: [30/100][610/625]\teta 0:00:00 lr 0.000810\t wd 0.0100\ttime 0.0326 (0.0351)\tloss 0.8311 (0.8753)\tgrad_norm 2.0374 (nan)\tloss_scale 32768.0000 (32821.6301)\tmem 455MB\n",
      "Train: [30/100][620/625]\teta 0:00:00 lr 0.000810\t wd 0.0100\ttime 0.0356 (0.0352)\tloss 0.6650 (0.8751)\tgrad_norm 1.5442 (nan)\tloss_scale 32768.0000 (32820.7665)\tmem 455MB\n",
      "EPOCH 30 training takes 0:00:21\n",
      "./model_save/ckpt_epoch_30.pth saving......\n",
      "./model_save/ckpt_epoch_30.pth saved !!!\n",
      "Test: [0/157]\tTime 0.021 (0.021)\tLoss 0.8857 (0.8857)\tAcc@1 65.625 (65.625)\tAcc@5 92.188 (92.188)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.016)\tLoss 0.9678 (0.8191)\tAcc@1 62.500 (71.875)\tAcc@5 98.438 (97.443)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.7983 (0.8286)\tAcc@1 70.312 (70.982)\tAcc@5 96.875 (97.991)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.6699 (0.8374)\tAcc@1 78.125 (70.615)\tAcc@5 98.438 (97.984)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 1.1562 (0.8462)\tAcc@1 53.125 (69.970)\tAcc@5 98.438 (98.056)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.6660 (0.8467)\tAcc@1 78.125 (69.700)\tAcc@5 100.000 (97.978)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.9058 (0.8549)\tAcc@1 68.750 (69.647)\tAcc@5 98.438 (97.772)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.8574 (0.8621)\tAcc@1 64.062 (69.410)\tAcc@5 98.438 (97.843)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.9878 (0.8651)\tAcc@1 62.500 (69.464)\tAcc@5 98.438 (97.897)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.9941 (0.8659)\tAcc@1 70.312 (69.540)\tAcc@5 96.875 (97.888)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.7964 (0.8678)\tAcc@1 67.188 (69.508)\tAcc@5 100.000 (97.942)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 1.3066 (0.8646)\tAcc@1 53.125 (69.510)\tAcc@5 93.750 (97.931)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 1.1982 (0.8704)\tAcc@1 57.812 (69.215)\tAcc@5 92.188 (97.831)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.8301 (0.8742)\tAcc@1 68.750 (69.060)\tAcc@5 98.438 (97.805)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.8984 (0.8686)\tAcc@1 71.875 (69.404)\tAcc@5 98.438 (97.817)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.9209 (0.8706)\tAcc@1 67.188 (69.371)\tAcc@5 96.875 (97.796)\tMem 455MB\n",
      " * Acc@1 69.310 Acc@5 97.760\n",
      "Accuracy of the network on the 10000 test images: 69.3%\n",
      "Max accuracy: 69.31%\n",
      "Train: [31/100][0/625]\teta 0:00:24 lr 0.000810\t wd 0.0100\ttime 0.0398 (0.0398)\tloss 1.0195 (1.0195)\tgrad_norm 2.3748 (2.3748)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][10/625]\teta 0:00:21 lr 0.000810\t wd 0.0100\ttime 0.0327 (0.0354)\tloss 1.0156 (0.8867)\tgrad_norm 1.7108 (2.0909)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][20/625]\teta 0:00:21 lr 0.000810\t wd 0.0100\ttime 0.0353 (0.0359)\tloss 0.9219 (0.8941)\tgrad_norm 2.9682 (2.4910)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][30/625]\teta 0:00:21 lr 0.000809\t wd 0.0100\ttime 0.0399 (0.0364)\tloss 0.9106 (0.9039)\tgrad_norm 1.9149 (2.4605)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][40/625]\teta 0:00:21 lr 0.000809\t wd 0.0100\ttime 0.0352 (0.0365)\tloss 0.9839 (0.8969)\tgrad_norm 2.0083 (2.3315)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][50/625]\teta 0:00:20 lr 0.000809\t wd 0.0100\ttime 0.0360 (0.0363)\tloss 0.6836 (0.8975)\tgrad_norm 2.0960 (2.2783)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][60/625]\teta 0:00:20 lr 0.000809\t wd 0.0100\ttime 0.0328 (0.0362)\tloss 1.0205 (0.9058)\tgrad_norm 2.0250 (2.2792)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][70/625]\teta 0:00:20 lr 0.000809\t wd 0.0100\ttime 0.0323 (0.0362)\tloss 0.7236 (0.8858)\tgrad_norm 1.1720 (2.2278)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][80/625]\teta 0:00:19 lr 0.000808\t wd 0.0100\ttime 0.0360 (0.0360)\tloss 0.8525 (0.8775)\tgrad_norm 2.1767 (2.1913)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][90/625]\teta 0:00:19 lr 0.000808\t wd 0.0100\ttime 0.0337 (0.0358)\tloss 0.9209 (0.8700)\tgrad_norm 1.9285 (2.1774)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][100/625]\teta 0:00:18 lr 0.000808\t wd 0.0100\ttime 0.0348 (0.0358)\tloss 0.9082 (0.8709)\tgrad_norm 2.1970 (2.1693)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][110/625]\teta 0:00:18 lr 0.000808\t wd 0.0100\ttime 0.0357 (0.0359)\tloss 1.0176 (0.8759)\tgrad_norm 1.6616 (2.1388)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][120/625]\teta 0:00:18 lr 0.000808\t wd 0.0100\ttime 0.0374 (0.0360)\tloss 1.1270 (0.8798)\tgrad_norm 2.1436 (2.1222)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][130/625]\teta 0:00:17 lr 0.000807\t wd 0.0100\ttime 0.0334 (0.0360)\tloss 0.8530 (0.8792)\tgrad_norm 1.5589 (2.1082)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][140/625]\teta 0:00:17 lr 0.000807\t wd 0.0100\ttime 0.0363 (0.0360)\tloss 0.9502 (0.8832)\tgrad_norm 1.8502 (2.1143)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][150/625]\teta 0:00:17 lr 0.000807\t wd 0.0100\ttime 0.0355 (0.0361)\tloss 0.8433 (0.8830)\tgrad_norm 1.8198 (2.1199)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][160/625]\teta 0:00:16 lr 0.000807\t wd 0.0100\ttime 0.0389 (0.0362)\tloss 1.0312 (0.8856)\tgrad_norm 2.7251 (2.1204)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][170/625]\teta 0:00:16 lr 0.000807\t wd 0.0100\ttime 0.0360 (0.0362)\tloss 0.9717 (0.8854)\tgrad_norm 2.3718 (2.1273)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][180/625]\teta 0:00:16 lr 0.000806\t wd 0.0100\ttime 0.0353 (0.0362)\tloss 0.8730 (0.8889)\tgrad_norm 1.7144 (2.1152)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][190/625]\teta 0:00:15 lr 0.000806\t wd 0.0100\ttime 0.0363 (0.0363)\tloss 0.7939 (0.8865)\tgrad_norm 1.9713 (2.1019)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][200/625]\teta 0:00:15 lr 0.000806\t wd 0.0100\ttime 0.0383 (0.0363)\tloss 0.6714 (0.8834)\tgrad_norm 1.6176 (2.1040)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][210/625]\teta 0:00:15 lr 0.000806\t wd 0.0100\ttime 0.0326 (0.0362)\tloss 0.7275 (0.8816)\tgrad_norm 1.5480 (2.0938)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][220/625]\teta 0:00:14 lr 0.000806\t wd 0.0100\ttime 0.0328 (0.0362)\tloss 0.7593 (0.8772)\tgrad_norm 2.0765 (2.0961)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][230/625]\teta 0:00:14 lr 0.000805\t wd 0.0100\ttime 0.0352 (0.0362)\tloss 0.9170 (0.8780)\tgrad_norm 2.1074 (2.0951)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][240/625]\teta 0:00:13 lr 0.000805\t wd 0.0100\ttime 0.0383 (0.0362)\tloss 1.0459 (0.8766)\tgrad_norm 1.8326 (2.0907)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][250/625]\teta 0:00:13 lr 0.000805\t wd 0.0100\ttime 0.0406 (0.0362)\tloss 0.7031 (0.8759)\tgrad_norm 1.7151 (2.0867)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][260/625]\teta 0:00:13 lr 0.000805\t wd 0.0100\ttime 0.0342 (0.0363)\tloss 0.5884 (0.8752)\tgrad_norm 1.4014 (2.0857)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][270/625]\teta 0:00:12 lr 0.000805\t wd 0.0100\ttime 0.0331 (0.0363)\tloss 0.8008 (0.8742)\tgrad_norm 1.6186 (2.0777)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][280/625]\teta 0:00:12 lr 0.000804\t wd 0.0100\ttime 0.0330 (0.0363)\tloss 0.7300 (0.8721)\tgrad_norm 1.9373 (2.0784)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][290/625]\teta 0:00:12 lr 0.000804\t wd 0.0100\ttime 0.0338 (0.0363)\tloss 0.7461 (0.8709)\tgrad_norm 2.2137 (2.0819)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][300/625]\teta 0:00:11 lr 0.000804\t wd 0.0100\ttime 0.0363 (0.0363)\tloss 0.8276 (0.8715)\tgrad_norm 1.7265 (2.0861)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][310/625]\teta 0:00:11 lr 0.000804\t wd 0.0100\ttime 0.0333 (0.0363)\tloss 1.0186 (0.8725)\tgrad_norm 2.7496 (2.0924)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][320/625]\teta 0:00:11 lr 0.000804\t wd 0.0100\ttime 0.0338 (0.0363)\tloss 0.9741 (0.8721)\tgrad_norm 1.6521 (2.0920)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][330/625]\teta 0:00:10 lr 0.000803\t wd 0.0100\ttime 0.0353 (0.0363)\tloss 0.7812 (0.8725)\tgrad_norm 2.5412 (2.0971)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][340/625]\teta 0:00:10 lr 0.000803\t wd 0.0100\ttime 0.0333 (0.0363)\tloss 0.6943 (0.8704)\tgrad_norm 1.3046 (2.0863)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][350/625]\teta 0:00:09 lr 0.000803\t wd 0.0100\ttime 0.0353 (0.0362)\tloss 0.8892 (0.8706)\tgrad_norm 2.0692 (2.0817)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][360/625]\teta 0:00:09 lr 0.000803\t wd 0.0100\ttime 0.0338 (0.0362)\tloss 0.6851 (0.8692)\tgrad_norm 2.3503 (2.0857)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][370/625]\teta 0:00:09 lr 0.000803\t wd 0.0100\ttime 0.0341 (0.0362)\tloss 0.7891 (0.8679)\tgrad_norm 2.1339 (2.0847)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][380/625]\teta 0:00:08 lr 0.000802\t wd 0.0100\ttime 0.0381 (0.0361)\tloss 0.9189 (0.8694)\tgrad_norm 2.6384 (2.0980)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][390/625]\teta 0:00:08 lr 0.000802\t wd 0.0100\ttime 0.0357 (0.0362)\tloss 0.9463 (0.8699)\tgrad_norm 2.3084 (2.0979)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][400/625]\teta 0:00:08 lr 0.000802\t wd 0.0100\ttime 0.0358 (0.0362)\tloss 0.7793 (0.8702)\tgrad_norm 1.7911 (2.0963)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][410/625]\teta 0:00:07 lr 0.000802\t wd 0.0100\ttime 0.0338 (0.0362)\tloss 0.6411 (0.8703)\tgrad_norm 1.3974 (2.0909)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][420/625]\teta 0:00:07 lr 0.000801\t wd 0.0100\ttime 0.0359 (0.0363)\tloss 1.0898 (0.8705)\tgrad_norm 2.1991 (2.0888)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][430/625]\teta 0:00:07 lr 0.000801\t wd 0.0100\ttime 0.0391 (0.0363)\tloss 0.9160 (0.8696)\tgrad_norm 1.9251 (2.0896)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][440/625]\teta 0:00:06 lr 0.000801\t wd 0.0100\ttime 0.0379 (0.0363)\tloss 0.7476 (0.8698)\tgrad_norm 1.5782 (2.0982)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][450/625]\teta 0:00:06 lr 0.000801\t wd 0.0100\ttime 0.0355 (0.0363)\tloss 0.8369 (0.8670)\tgrad_norm 1.8294 (2.0962)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][460/625]\teta 0:00:05 lr 0.000801\t wd 0.0100\ttime 0.0332 (0.0363)\tloss 0.6797 (0.8656)\tgrad_norm 1.5735 (2.0917)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][470/625]\teta 0:00:05 lr 0.000800\t wd 0.0100\ttime 0.0335 (0.0362)\tloss 0.9648 (0.8660)\tgrad_norm 1.7604 (2.0958)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][480/625]\teta 0:00:05 lr 0.000800\t wd 0.0100\ttime 0.0379 (0.0362)\tloss 0.8682 (0.8664)\tgrad_norm 2.5105 (2.0942)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][490/625]\teta 0:00:04 lr 0.000800\t wd 0.0100\ttime 0.0420 (0.0363)\tloss 0.6934 (0.8681)\tgrad_norm 1.9562 (2.0973)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][500/625]\teta 0:00:04 lr 0.000800\t wd 0.0100\ttime 0.0394 (0.0363)\tloss 0.7417 (0.8670)\tgrad_norm 1.5529 (2.0937)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][510/625]\teta 0:00:04 lr 0.000800\t wd 0.0100\ttime 0.0375 (0.0363)\tloss 0.9409 (0.8667)\tgrad_norm 2.3783 (2.0942)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][520/625]\teta 0:00:03 lr 0.000799\t wd 0.0100\ttime 0.0367 (0.0363)\tloss 0.6875 (0.8665)\tgrad_norm 1.7074 (2.0929)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][530/625]\teta 0:00:03 lr 0.000799\t wd 0.0100\ttime 0.0331 (0.0363)\tloss 0.9365 (0.8676)\tgrad_norm 1.8536 (2.0950)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][540/625]\teta 0:00:03 lr 0.000799\t wd 0.0100\ttime 0.0353 (0.0362)\tloss 0.8999 (0.8676)\tgrad_norm 2.0431 (2.0929)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][550/625]\teta 0:00:02 lr 0.000799\t wd 0.0100\ttime 0.0366 (0.0362)\tloss 1.0176 (0.8682)\tgrad_norm 2.7402 (2.0910)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][560/625]\teta 0:00:02 lr 0.000799\t wd 0.0100\ttime 0.0382 (0.0362)\tloss 0.9375 (0.8682)\tgrad_norm 2.1320 (2.0871)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][570/625]\teta 0:00:01 lr 0.000798\t wd 0.0100\ttime 0.0390 (0.0363)\tloss 0.9346 (0.8685)\tgrad_norm 2.1516 (2.0844)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][580/625]\teta 0:00:01 lr 0.000798\t wd 0.0100\ttime 0.0381 (0.0363)\tloss 0.8716 (0.8685)\tgrad_norm 2.7730 (2.0871)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][590/625]\teta 0:00:01 lr 0.000798\t wd 0.0100\ttime 0.0368 (0.0363)\tloss 0.8691 (0.8693)\tgrad_norm 2.2214 (2.0855)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][600/625]\teta 0:00:00 lr 0.000798\t wd 0.0100\ttime 0.0372 (0.0363)\tloss 0.9414 (0.8697)\tgrad_norm 2.4315 (2.0836)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][610/625]\teta 0:00:00 lr 0.000798\t wd 0.0100\ttime 0.0399 (0.0363)\tloss 0.9336 (0.8697)\tgrad_norm 2.2023 (2.0847)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [31/100][620/625]\teta 0:00:00 lr 0.000797\t wd 0.0100\ttime 0.0360 (0.0363)\tloss 0.7085 (0.8685)\tgrad_norm 1.6027 (2.0785)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 31 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_31.pth saving......\n",
      "./model_save/ckpt_epoch_31.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.7300 (0.7300)\tAcc@1 78.125 (78.125)\tAcc@5 98.438 (98.438)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.016)\tLoss 0.8760 (0.7961)\tAcc@1 71.875 (72.585)\tAcc@5 100.000 (98.438)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.8179 (0.8174)\tAcc@1 68.750 (71.354)\tAcc@5 98.438 (98.512)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.7500 (0.8076)\tAcc@1 68.750 (71.825)\tAcc@5 100.000 (98.438)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.7866 (0.8171)\tAcc@1 75.000 (71.723)\tAcc@5 98.438 (98.399)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.8462 (0.8040)\tAcc@1 64.062 (72.059)\tAcc@5 98.438 (98.407)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.8442 (0.8094)\tAcc@1 67.188 (71.721)\tAcc@5 96.875 (98.233)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.7378 (0.8069)\tAcc@1 68.750 (71.743)\tAcc@5 98.438 (98.173)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.7163 (0.8083)\tAcc@1 70.312 (71.431)\tAcc@5 98.438 (98.206)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.016 (0.015)\tLoss 0.7446 (0.8081)\tAcc@1 67.188 (71.274)\tAcc@5 100.000 (98.249)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.7930 (0.8114)\tAcc@1 70.312 (71.055)\tAcc@5 98.438 (98.236)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.8022 (0.8137)\tAcc@1 70.312 (70.890)\tAcc@5 98.438 (98.255)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.8457 (0.8096)\tAcc@1 68.750 (71.023)\tAcc@5 96.875 (98.218)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.9238 (0.8164)\tAcc@1 59.375 (70.766)\tAcc@5 100.000 (98.127)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.9570 (0.8202)\tAcc@1 71.875 (70.634)\tAcc@5 96.875 (98.083)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.8794 (0.8189)\tAcc@1 68.750 (70.602)\tAcc@5 96.875 (98.117)\tMem 455MB\n",
      " * Acc@1 70.620 Acc@5 98.130\n",
      "Accuracy of the network on the 10000 test images: 70.6%\n",
      "Max accuracy: 70.62%\n",
      "Train: [32/100][0/625]\teta 0:00:25 lr 0.000797\t wd 0.0100\ttime 0.0410 (0.0410)\tloss 0.9150 (0.9150)\tgrad_norm 2.6742 (2.6742)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][10/625]\teta 0:00:23 lr 0.000797\t wd 0.0100\ttime 0.0379 (0.0375)\tloss 0.7246 (0.8222)\tgrad_norm 1.9805 (2.0522)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][20/625]\teta 0:00:22 lr 0.000797\t wd 0.0100\ttime 0.0394 (0.0373)\tloss 1.0283 (0.8381)\tgrad_norm 2.0927 (2.0690)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][30/625]\teta 0:00:22 lr 0.000797\t wd 0.0100\ttime 0.0397 (0.0371)\tloss 0.9595 (0.8312)\tgrad_norm 1.7833 (2.0103)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][40/625]\teta 0:00:21 lr 0.000796\t wd 0.0100\ttime 0.0364 (0.0370)\tloss 0.7715 (0.8266)\tgrad_norm 2.8222 (2.0300)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][50/625]\teta 0:00:21 lr 0.000796\t wd 0.0100\ttime 0.0358 (0.0372)\tloss 0.9312 (0.8403)\tgrad_norm 2.3882 (2.0620)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][60/625]\teta 0:00:21 lr 0.000796\t wd 0.0100\ttime 0.0372 (0.0373)\tloss 0.5449 (0.8206)\tgrad_norm 1.5143 (2.0423)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][70/625]\teta 0:00:20 lr 0.000796\t wd 0.0100\ttime 0.0371 (0.0372)\tloss 0.7349 (0.8180)\tgrad_norm 1.8578 (2.0292)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][80/625]\teta 0:00:20 lr 0.000796\t wd 0.0100\ttime 0.0389 (0.0371)\tloss 0.8555 (0.8190)\tgrad_norm 2.2658 (2.0679)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][90/625]\teta 0:00:19 lr 0.000795\t wd 0.0100\ttime 0.0353 (0.0372)\tloss 0.9434 (0.8143)\tgrad_norm 2.0643 (2.0699)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][100/625]\teta 0:00:19 lr 0.000795\t wd 0.0100\ttime 0.0397 (0.0373)\tloss 0.9014 (0.8236)\tgrad_norm 1.9392 (2.0805)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][110/625]\teta 0:00:19 lr 0.000795\t wd 0.0100\ttime 0.0359 (0.0373)\tloss 0.8784 (0.8298)\tgrad_norm 2.7495 (2.1332)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][120/625]\teta 0:00:18 lr 0.000795\t wd 0.0100\ttime 0.0336 (0.0371)\tloss 0.8389 (0.8362)\tgrad_norm 2.1955 (2.1572)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][130/625]\teta 0:00:18 lr 0.000795\t wd 0.0100\ttime 0.0360 (0.0371)\tloss 0.9097 (0.8421)\tgrad_norm 2.0689 (2.1522)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][140/625]\teta 0:00:17 lr 0.000794\t wd 0.0100\ttime 0.0333 (0.0370)\tloss 0.9077 (0.8472)\tgrad_norm 2.5315 (2.1532)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][150/625]\teta 0:00:17 lr 0.000794\t wd 0.0100\ttime 0.0329 (0.0368)\tloss 0.7085 (0.8483)\tgrad_norm 2.8754 (2.1584)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][160/625]\teta 0:00:17 lr 0.000794\t wd 0.0100\ttime 0.0324 (0.0367)\tloss 1.0605 (0.8500)\tgrad_norm 2.6992 (2.1636)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][170/625]\teta 0:00:16 lr 0.000794\t wd 0.0100\ttime 0.0334 (0.0365)\tloss 0.6680 (0.8480)\tgrad_norm 1.9458 (2.1466)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][180/625]\teta 0:00:16 lr 0.000794\t wd 0.0100\ttime 0.0325 (0.0364)\tloss 0.9209 (0.8455)\tgrad_norm 1.7059 (2.1437)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][190/625]\teta 0:00:15 lr 0.000793\t wd 0.0100\ttime 0.0357 (0.0363)\tloss 0.8716 (0.8450)\tgrad_norm 1.6561 (2.1357)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][200/625]\teta 0:00:15 lr 0.000793\t wd 0.0100\ttime 0.0330 (0.0362)\tloss 0.7588 (0.8422)\tgrad_norm 2.1288 (2.1238)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][210/625]\teta 0:00:14 lr 0.000793\t wd 0.0100\ttime 0.0330 (0.0360)\tloss 0.7939 (0.8402)\tgrad_norm 2.2253 (2.1118)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][220/625]\teta 0:00:14 lr 0.000793\t wd 0.0100\ttime 0.0364 (0.0360)\tloss 0.7935 (0.8378)\tgrad_norm 2.7897 (2.1186)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][230/625]\teta 0:00:14 lr 0.000792\t wd 0.0100\ttime 0.0329 (0.0359)\tloss 0.7852 (0.8383)\tgrad_norm 1.9682 (2.1123)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][240/625]\teta 0:00:13 lr 0.000792\t wd 0.0100\ttime 0.0357 (0.0359)\tloss 0.9614 (0.8413)\tgrad_norm 2.4038 (2.1132)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][250/625]\teta 0:00:13 lr 0.000792\t wd 0.0100\ttime 0.0362 (0.0358)\tloss 1.0215 (0.8403)\tgrad_norm 3.4372 (2.1139)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][260/625]\teta 0:00:13 lr 0.000792\t wd 0.0100\ttime 0.0399 (0.0359)\tloss 0.6367 (0.8434)\tgrad_norm 2.1311 (2.1266)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][270/625]\teta 0:00:12 lr 0.000792\t wd 0.0100\ttime 0.0325 (0.0358)\tloss 0.5312 (0.8469)\tgrad_norm 1.4131 (2.1371)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][280/625]\teta 0:00:12 lr 0.000791\t wd 0.0100\ttime 0.0362 (0.0358)\tloss 0.8071 (0.8460)\tgrad_norm 1.8310 (2.1306)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][290/625]\teta 0:00:12 lr 0.000791\t wd 0.0100\ttime 0.0404 (0.0359)\tloss 1.0098 (0.8461)\tgrad_norm 2.3492 (2.1303)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][300/625]\teta 0:00:11 lr 0.000791\t wd 0.0100\ttime 0.0359 (0.0359)\tloss 1.0342 (0.8458)\tgrad_norm 2.2800 (2.1347)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][310/625]\teta 0:00:11 lr 0.000791\t wd 0.0100\ttime 0.0352 (0.0360)\tloss 0.9712 (0.8447)\tgrad_norm 1.9738 (2.1334)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][320/625]\teta 0:00:10 lr 0.000791\t wd 0.0100\ttime 0.0357 (0.0359)\tloss 0.8989 (0.8444)\tgrad_norm 2.5755 (2.1361)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][330/625]\teta 0:00:10 lr 0.000790\t wd 0.0100\ttime 0.0350 (0.0359)\tloss 1.0723 (0.8450)\tgrad_norm 2.2819 (2.1432)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][340/625]\teta 0:00:10 lr 0.000790\t wd 0.0100\ttime 0.0355 (0.0359)\tloss 0.8374 (0.8471)\tgrad_norm 2.3100 (2.1634)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][350/625]\teta 0:00:09 lr 0.000790\t wd 0.0100\ttime 0.0392 (0.0359)\tloss 0.6855 (0.8472)\tgrad_norm 1.4777 (2.1574)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][360/625]\teta 0:00:09 lr 0.000790\t wd 0.0100\ttime 0.0391 (0.0359)\tloss 0.7334 (0.8463)\tgrad_norm 1.5691 (2.1576)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][370/625]\teta 0:00:09 lr 0.000790\t wd 0.0100\ttime 0.0397 (0.0359)\tloss 0.6445 (0.8458)\tgrad_norm 1.6437 (2.1563)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][380/625]\teta 0:00:08 lr 0.000789\t wd 0.0100\ttime 0.0354 (0.0359)\tloss 0.7754 (0.8460)\tgrad_norm 1.3882 (2.1472)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][390/625]\teta 0:00:08 lr 0.000789\t wd 0.0100\ttime 0.0387 (0.0359)\tloss 0.8828 (0.8460)\tgrad_norm 2.1700 (2.1451)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][400/625]\teta 0:00:08 lr 0.000789\t wd 0.0100\ttime 0.0389 (0.0359)\tloss 0.7725 (0.8458)\tgrad_norm 2.0670 (2.1435)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][410/625]\teta 0:00:07 lr 0.000789\t wd 0.0100\ttime 0.0382 (0.0359)\tloss 0.6562 (0.8458)\tgrad_norm 1.7159 (2.1457)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][420/625]\teta 0:00:07 lr 0.000788\t wd 0.0100\ttime 0.0325 (0.0359)\tloss 0.9736 (0.8476)\tgrad_norm 2.4790 (2.1530)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][430/625]\teta 0:00:06 lr 0.000788\t wd 0.0100\ttime 0.0361 (0.0359)\tloss 0.8706 (0.8483)\tgrad_norm 2.4074 (2.1527)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][440/625]\teta 0:00:06 lr 0.000788\t wd 0.0100\ttime 0.0401 (0.0359)\tloss 0.8760 (0.8485)\tgrad_norm 2.0592 (2.1486)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][450/625]\teta 0:00:06 lr 0.000788\t wd 0.0100\ttime 0.0324 (0.0359)\tloss 0.8936 (0.8478)\tgrad_norm 1.9697 (2.1465)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][460/625]\teta 0:00:05 lr 0.000788\t wd 0.0100\ttime 0.0322 (0.0358)\tloss 0.9819 (0.8498)\tgrad_norm 3.7293 (2.1485)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][470/625]\teta 0:00:05 lr 0.000787\t wd 0.0100\ttime 0.0351 (0.0358)\tloss 0.9224 (0.8513)\tgrad_norm 2.0414 (2.1420)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][480/625]\teta 0:00:05 lr 0.000787\t wd 0.0100\ttime 0.0328 (0.0358)\tloss 0.8496 (0.8504)\tgrad_norm 2.2600 (2.1378)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][490/625]\teta 0:00:04 lr 0.000787\t wd 0.0100\ttime 0.0323 (0.0358)\tloss 0.8696 (0.8504)\tgrad_norm 2.0962 (2.1389)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][500/625]\teta 0:00:04 lr 0.000787\t wd 0.0100\ttime 0.0369 (0.0358)\tloss 0.8418 (0.8519)\tgrad_norm 2.2689 (2.1453)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][510/625]\teta 0:00:04 lr 0.000787\t wd 0.0100\ttime 0.0354 (0.0358)\tloss 0.8066 (0.8516)\tgrad_norm 2.3525 (2.1425)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][520/625]\teta 0:00:03 lr 0.000786\t wd 0.0100\ttime 0.0374 (0.0358)\tloss 0.8081 (0.8529)\tgrad_norm 1.6154 (2.1399)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][530/625]\teta 0:00:03 lr 0.000786\t wd 0.0100\ttime 0.0340 (0.0358)\tloss 0.6260 (0.8526)\tgrad_norm 1.7353 (2.1373)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][540/625]\teta 0:00:03 lr 0.000786\t wd 0.0100\ttime 0.0378 (0.0358)\tloss 0.8452 (0.8536)\tgrad_norm 1.8079 (2.1384)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][550/625]\teta 0:00:02 lr 0.000786\t wd 0.0100\ttime 0.0424 (0.0359)\tloss 0.8330 (0.8528)\tgrad_norm 2.0582 (2.1355)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][560/625]\teta 0:00:02 lr 0.000786\t wd 0.0100\ttime 0.0354 (0.0359)\tloss 0.8882 (0.8547)\tgrad_norm 3.0131 (2.1378)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][570/625]\teta 0:00:01 lr 0.000785\t wd 0.0100\ttime 0.0360 (0.0359)\tloss 0.8081 (0.8551)\tgrad_norm 2.0311 (2.1379)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][580/625]\teta 0:00:01 lr 0.000785\t wd 0.0100\ttime 0.0354 (0.0359)\tloss 0.9116 (0.8544)\tgrad_norm 1.8895 (2.1345)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][590/625]\teta 0:00:01 lr 0.000785\t wd 0.0100\ttime 0.0361 (0.0359)\tloss 1.0088 (0.8534)\tgrad_norm 2.5336 (2.1327)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][600/625]\teta 0:00:00 lr 0.000785\t wd 0.0100\ttime 0.0373 (0.0359)\tloss 1.1191 (0.8545)\tgrad_norm 2.9056 (2.1350)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][610/625]\teta 0:00:00 lr 0.000784\t wd 0.0100\ttime 0.0385 (0.0359)\tloss 0.7446 (0.8550)\tgrad_norm 1.5568 (2.1356)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [32/100][620/625]\teta 0:00:00 lr 0.000784\t wd 0.0100\ttime 0.0358 (0.0359)\tloss 1.1729 (0.8553)\tgrad_norm 1.9620 (2.1359)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 32 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_32.pth saving......\n",
      "./model_save/ckpt_epoch_32.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.7681 (0.7681)\tAcc@1 71.875 (71.875)\tAcc@5 100.000 (100.000)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.7466 (0.8280)\tAcc@1 70.312 (72.159)\tAcc@5 98.438 (97.869)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.8354 (0.8216)\tAcc@1 76.562 (72.321)\tAcc@5 96.875 (97.842)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.016 (0.015)\tLoss 0.9556 (0.8329)\tAcc@1 67.188 (71.825)\tAcc@5 98.438 (97.732)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.016 (0.015)\tLoss 0.8022 (0.8429)\tAcc@1 75.000 (71.075)\tAcc@5 100.000 (97.713)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.019 (0.015)\tLoss 0.8184 (0.8408)\tAcc@1 67.188 (70.619)\tAcc@5 100.000 (97.794)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 1.1914 (0.8429)\tAcc@1 60.938 (70.722)\tAcc@5 92.188 (97.772)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 1.0615 (0.8427)\tAcc@1 62.500 (70.665)\tAcc@5 95.312 (97.777)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.8926 (0.8475)\tAcc@1 65.625 (70.505)\tAcc@5 96.875 (97.704)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.6514 (0.8396)\tAcc@1 78.125 (70.501)\tAcc@5 96.875 (97.734)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.8032 (0.8408)\tAcc@1 75.000 (70.467)\tAcc@5 98.438 (97.772)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.8579 (0.8394)\tAcc@1 65.625 (70.453)\tAcc@5 100.000 (97.818)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 1.0674 (0.8467)\tAcc@1 60.938 (70.351)\tAcc@5 96.875 (97.766)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.9409 (0.8504)\tAcc@1 68.750 (70.193)\tAcc@5 95.312 (97.710)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.9507 (0.8519)\tAcc@1 65.625 (69.980)\tAcc@5 96.875 (97.695)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.9170 (0.8579)\tAcc@1 60.938 (69.712)\tAcc@5 98.438 (97.724)\tMem 455MB\n",
      " * Acc@1 69.690 Acc@5 97.720\n",
      "Accuracy of the network on the 10000 test images: 69.7%\n",
      "Max accuracy: 70.62%\n",
      "Train: [33/100][0/625]\teta 0:00:24 lr 0.000784\t wd 0.0100\ttime 0.0394 (0.0394)\tloss 0.7832 (0.7832)\tgrad_norm 1.8746 (1.8746)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [33/100][10/625]\teta 0:00:21 lr 0.000784\t wd 0.0100\ttime 0.0364 (0.0347)\tloss 0.6636 (0.7898)\tgrad_norm 1.6954 (1.8717)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [33/100][20/625]\teta 0:00:21 lr 0.000784\t wd 0.0100\ttime 0.0355 (0.0350)\tloss 0.8442 (0.8092)\tgrad_norm 2.2783 (1.9237)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [33/100][30/625]\teta 0:00:21 lr 0.000784\t wd 0.0100\ttime 0.0356 (0.0355)\tloss 0.8940 (0.8041)\tgrad_norm 1.9955 (1.9354)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [33/100][40/625]\teta 0:00:20 lr 0.000783\t wd 0.0100\ttime 0.0388 (0.0357)\tloss 0.9067 (0.8040)\tgrad_norm 2.0925 (1.9529)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [33/100][50/625]\teta 0:00:20 lr 0.000783\t wd 0.0100\ttime 0.0406 (0.0358)\tloss 0.9009 (0.8177)\tgrad_norm 1.7123 (1.9670)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [33/100][60/625]\teta 0:00:20 lr 0.000783\t wd 0.0100\ttime 0.0352 (0.0358)\tloss 0.7578 (0.8138)\tgrad_norm 3.5845 (2.0230)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [33/100][70/625]\teta 0:00:19 lr 0.000783\t wd 0.0100\ttime 0.0351 (0.0358)\tloss 0.9087 (0.8235)\tgrad_norm 1.6106 (2.0422)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [33/100][80/625]\teta 0:00:19 lr 0.000782\t wd 0.0100\ttime 0.0350 (0.0357)\tloss 0.7998 (0.8216)\tgrad_norm 3.0944 (2.0699)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [33/100][90/625]\teta 0:00:19 lr 0.000782\t wd 0.0100\ttime 0.0404 (0.0358)\tloss 0.8550 (0.8250)\tgrad_norm 3.3598 (2.1426)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [33/100][100/625]\teta 0:00:18 lr 0.000782\t wd 0.0100\ttime 0.0396 (0.0359)\tloss 0.8267 (0.8231)\tgrad_norm 1.6842 (2.1224)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [33/100][110/625]\teta 0:00:18 lr 0.000782\t wd 0.0100\ttime 0.0330 (0.0358)\tloss 1.0469 (0.8287)\tgrad_norm 2.3475 (2.1438)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [33/100][120/625]\teta 0:00:18 lr 0.000782\t wd 0.0100\ttime 0.0371 (0.0359)\tloss 0.6934 (0.8311)\tgrad_norm 1.7003 (2.1397)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [33/100][130/625]\teta 0:00:17 lr 0.000781\t wd 0.0100\ttime 0.0359 (0.0359)\tloss 0.8618 (0.8368)\tgrad_norm 1.6636 (2.1260)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [33/100][140/625]\teta 0:00:17 lr 0.000781\t wd 0.0100\ttime 0.0376 (0.0359)\tloss 0.6353 (0.8334)\tgrad_norm 1.5393 (nan)\tloss_scale 32768.0000 (33000.3972)\tmem 455MB\n",
      "Train: [33/100][150/625]\teta 0:00:17 lr 0.000781\t wd 0.0100\ttime 0.0327 (0.0359)\tloss 0.8784 (0.8317)\tgrad_norm 2.9019 (nan)\tloss_scale 32768.0000 (32985.0066)\tmem 455MB\n",
      "Train: [33/100][160/625]\teta 0:00:16 lr 0.000781\t wd 0.0100\ttime 0.0322 (0.0359)\tloss 0.9956 (0.8333)\tgrad_norm 2.1715 (nan)\tloss_scale 32768.0000 (32971.5280)\tmem 455MB\n",
      "Train: [33/100][170/625]\teta 0:00:16 lr 0.000781\t wd 0.0100\ttime 0.0396 (0.0360)\tloss 0.8994 (0.8361)\tgrad_norm 1.9265 (nan)\tloss_scale 32768.0000 (32959.6257)\tmem 455MB\n",
      "Train: [33/100][180/625]\teta 0:00:15 lr 0.000780\t wd 0.0100\ttime 0.0339 (0.0359)\tloss 0.8638 (0.8350)\tgrad_norm 1.9417 (nan)\tloss_scale 32768.0000 (32949.0387)\tmem 455MB\n",
      "Train: [33/100][190/625]\teta 0:00:15 lr 0.000780\t wd 0.0100\ttime 0.0386 (0.0359)\tloss 0.7524 (0.8343)\tgrad_norm 1.4892 (nan)\tloss_scale 32768.0000 (32939.5602)\tmem 455MB\n",
      "Train: [33/100][200/625]\teta 0:00:15 lr 0.000780\t wd 0.0100\ttime 0.0354 (0.0359)\tloss 1.0410 (0.8367)\tgrad_norm 2.7329 (nan)\tloss_scale 32768.0000 (32931.0249)\tmem 455MB\n",
      "Train: [33/100][210/625]\teta 0:00:14 lr 0.000780\t wd 0.0100\ttime 0.0356 (0.0359)\tloss 0.8521 (0.8346)\tgrad_norm 1.8207 (nan)\tloss_scale 32768.0000 (32923.2986)\tmem 455MB\n",
      "Train: [33/100][220/625]\teta 0:00:14 lr 0.000779\t wd 0.0100\ttime 0.0356 (0.0360)\tloss 0.7891 (0.8348)\tgrad_norm 2.3274 (nan)\tloss_scale 32768.0000 (32916.2715)\tmem 455MB\n",
      "Train: [33/100][230/625]\teta 0:00:14 lr 0.000779\t wd 0.0100\ttime 0.0356 (0.0359)\tloss 0.9380 (0.8382)\tgrad_norm 2.0431 (nan)\tloss_scale 32768.0000 (32909.8528)\tmem 455MB\n",
      "Train: [33/100][240/625]\teta 0:00:13 lr 0.000779\t wd 0.0100\ttime 0.0356 (0.0359)\tloss 0.8779 (0.8375)\tgrad_norm 1.7609 (nan)\tloss_scale 32768.0000 (32903.9668)\tmem 455MB\n",
      "Train: [33/100][250/625]\teta 0:00:13 lr 0.000779\t wd 0.0100\ttime 0.0386 (0.0359)\tloss 0.8721 (0.8374)\tgrad_norm 2.0860 (nan)\tloss_scale 32768.0000 (32898.5498)\tmem 455MB\n",
      "Train: [33/100][260/625]\teta 0:00:13 lr 0.000779\t wd 0.0100\ttime 0.0387 (0.0359)\tloss 0.8071 (0.8350)\tgrad_norm 2.3865 (nan)\tloss_scale 32768.0000 (32893.5479)\tmem 455MB\n",
      "Train: [33/100][270/625]\teta 0:00:12 lr 0.000778\t wd 0.0100\ttime 0.0365 (0.0359)\tloss 0.9521 (0.8383)\tgrad_norm 2.1100 (nan)\tloss_scale 32768.0000 (32888.9151)\tmem 455MB\n",
      "Train: [33/100][280/625]\teta 0:00:12 lr 0.000778\t wd 0.0100\ttime 0.0396 (0.0359)\tloss 0.7793 (0.8372)\tgrad_norm 2.1107 (nan)\tloss_scale 32768.0000 (32884.6121)\tmem 455MB\n",
      "Train: [33/100][290/625]\teta 0:00:12 lr 0.000778\t wd 0.0100\ttime 0.0385 (0.0359)\tloss 0.7383 (0.8376)\tgrad_norm 1.9162 (nan)\tloss_scale 32768.0000 (32880.6048)\tmem 455MB\n",
      "Train: [33/100][300/625]\teta 0:00:11 lr 0.000778\t wd 0.0100\ttime 0.0328 (0.0359)\tloss 1.0107 (0.8379)\tgrad_norm 1.7657 (nan)\tloss_scale 32768.0000 (32876.8638)\tmem 455MB\n",
      "Train: [33/100][310/625]\teta 0:00:11 lr 0.000778\t wd 0.0100\ttime 0.0348 (0.0359)\tloss 0.9219 (0.8380)\tgrad_norm 1.9846 (nan)\tloss_scale 32768.0000 (32873.3633)\tmem 455MB\n",
      "Train: [33/100][320/625]\teta 0:00:10 lr 0.000777\t wd 0.0100\ttime 0.0355 (0.0359)\tloss 0.6006 (0.8371)\tgrad_norm 2.0656 (nan)\tloss_scale 32768.0000 (32870.0810)\tmem 455MB\n",
      "Train: [33/100][330/625]\teta 0:00:10 lr 0.000777\t wd 0.0100\ttime 0.0390 (0.0359)\tloss 0.8525 (0.8355)\tgrad_norm 2.2134 (nan)\tloss_scale 32768.0000 (32866.9970)\tmem 455MB\n",
      "Train: [33/100][340/625]\teta 0:00:10 lr 0.000777\t wd 0.0100\ttime 0.0322 (0.0358)\tloss 0.8330 (0.8355)\tgrad_norm 2.2830 (nan)\tloss_scale 32768.0000 (32864.0938)\tmem 455MB\n",
      "Train: [33/100][350/625]\teta 0:00:09 lr 0.000777\t wd 0.0100\ttime 0.0331 (0.0358)\tloss 0.9658 (0.8361)\tgrad_norm 2.0829 (nan)\tloss_scale 32768.0000 (32861.3561)\tmem 455MB\n",
      "Train: [33/100][360/625]\teta 0:00:09 lr 0.000776\t wd 0.0100\ttime 0.0366 (0.0357)\tloss 1.0088 (0.8348)\tgrad_norm 2.2378 (nan)\tloss_scale 32768.0000 (32858.7701)\tmem 455MB\n",
      "Train: [33/100][370/625]\teta 0:00:09 lr 0.000776\t wd 0.0100\ttime 0.0325 (0.0356)\tloss 0.8848 (0.8360)\tgrad_norm 2.6558 (nan)\tloss_scale 32768.0000 (32856.3235)\tmem 455MB\n",
      "Train: [33/100][380/625]\teta 0:00:08 lr 0.000776\t wd 0.0100\ttime 0.0342 (0.0356)\tloss 1.0039 (0.8390)\tgrad_norm 2.4856 (nan)\tloss_scale 32768.0000 (32854.0052)\tmem 455MB\n",
      "Train: [33/100][390/625]\teta 0:00:08 lr 0.000776\t wd 0.0100\ttime 0.0331 (0.0356)\tloss 0.8008 (0.8404)\tgrad_norm 2.2064 (nan)\tloss_scale 32768.0000 (32851.8056)\tmem 455MB\n",
      "Train: [33/100][400/625]\teta 0:00:08 lr 0.000776\t wd 0.0100\ttime 0.0340 (0.0356)\tloss 1.0029 (0.8409)\tgrad_norm 2.0990 (nan)\tloss_scale 32768.0000 (32849.7157)\tmem 455MB\n",
      "Train: [33/100][410/625]\teta 0:00:07 lr 0.000775\t wd 0.0100\ttime 0.0382 (0.0357)\tloss 0.7490 (0.8406)\tgrad_norm 1.6730 (nan)\tloss_scale 32768.0000 (32847.7275)\tmem 455MB\n",
      "Train: [33/100][420/625]\teta 0:00:07 lr 0.000775\t wd 0.0100\ttime 0.0452 (0.0357)\tloss 0.6562 (0.8395)\tgrad_norm 1.8600 (nan)\tloss_scale 32768.0000 (32845.8337)\tmem 455MB\n",
      "Train: [33/100][430/625]\teta 0:00:06 lr 0.000775\t wd 0.0100\ttime 0.0378 (0.0357)\tloss 0.8052 (0.8394)\tgrad_norm 1.9616 (nan)\tloss_scale 32768.0000 (32844.0278)\tmem 455MB\n",
      "Train: [33/100][440/625]\teta 0:00:06 lr 0.000775\t wd 0.0100\ttime 0.0331 (0.0357)\tloss 0.9595 (0.8399)\tgrad_norm 2.2345 (nan)\tloss_scale 32768.0000 (32842.3039)\tmem 455MB\n",
      "Train: [33/100][450/625]\teta 0:00:06 lr 0.000775\t wd 0.0100\ttime 0.0345 (0.0357)\tloss 1.0566 (0.8418)\tgrad_norm 2.1571 (nan)\tloss_scale 32768.0000 (32840.6563)\tmem 455MB\n",
      "Train: [33/100][460/625]\teta 0:00:05 lr 0.000774\t wd 0.0100\ttime 0.0334 (0.0357)\tloss 1.0889 (0.8428)\tgrad_norm 2.9375 (nan)\tloss_scale 32768.0000 (32839.0803)\tmem 455MB\n",
      "Train: [33/100][470/625]\teta 0:00:05 lr 0.000774\t wd 0.0100\ttime 0.0326 (0.0357)\tloss 0.7212 (0.8429)\tgrad_norm 2.0450 (nan)\tloss_scale 32768.0000 (32837.5711)\tmem 455MB\n",
      "Train: [33/100][480/625]\teta 0:00:05 lr 0.000774\t wd 0.0100\ttime 0.0395 (0.0358)\tloss 0.8657 (0.8422)\tgrad_norm 2.0614 (nan)\tloss_scale 32768.0000 (32836.1247)\tmem 455MB\n",
      "Train: [33/100][490/625]\teta 0:00:04 lr 0.000774\t wd 0.0100\ttime 0.0381 (0.0358)\tloss 0.8877 (0.8423)\tgrad_norm 2.2783 (nan)\tloss_scale 32768.0000 (32834.7373)\tmem 455MB\n",
      "Train: [33/100][500/625]\teta 0:00:04 lr 0.000773\t wd 0.0100\ttime 0.0444 (0.0359)\tloss 1.0117 (0.8422)\tgrad_norm 2.2114 (nan)\tloss_scale 32768.0000 (32833.4052)\tmem 455MB\n",
      "Train: [33/100][510/625]\teta 0:00:04 lr 0.000773\t wd 0.0100\ttime 0.0357 (0.0359)\tloss 0.8237 (0.8419)\tgrad_norm 1.8446 (nan)\tloss_scale 32768.0000 (32832.1252)\tmem 455MB\n",
      "Train: [33/100][520/625]\teta 0:00:03 lr 0.000773\t wd 0.0100\ttime 0.0323 (0.0359)\tloss 0.7280 (0.8418)\tgrad_norm 1.3565 (nan)\tloss_scale 32768.0000 (32830.8944)\tmem 455MB\n",
      "Train: [33/100][530/625]\teta 0:00:03 lr 0.000773\t wd 0.0100\ttime 0.0325 (0.0359)\tloss 0.7520 (0.8420)\tgrad_norm 1.5848 (nan)\tloss_scale 32768.0000 (32829.7100)\tmem 455MB\n",
      "Train: [33/100][540/625]\teta 0:00:03 lr 0.000773\t wd 0.0100\ttime 0.0398 (0.0359)\tloss 0.8345 (0.8420)\tgrad_norm 2.0159 (nan)\tloss_scale 32768.0000 (32828.5693)\tmem 455MB\n",
      "Train: [33/100][550/625]\teta 0:00:02 lr 0.000772\t wd 0.0100\ttime 0.0334 (0.0359)\tloss 0.8311 (0.8418)\tgrad_norm 3.0932 (nan)\tloss_scale 32768.0000 (32827.4701)\tmem 455MB\n",
      "Train: [33/100][560/625]\teta 0:00:02 lr 0.000772\t wd 0.0100\ttime 0.0341 (0.0359)\tloss 0.7808 (0.8402)\tgrad_norm 1.9904 (nan)\tloss_scale 32768.0000 (32826.4100)\tmem 455MB\n",
      "Train: [33/100][570/625]\teta 0:00:01 lr 0.000772\t wd 0.0100\ttime 0.0329 (0.0358)\tloss 0.8057 (0.8395)\tgrad_norm 2.1438 (nan)\tloss_scale 32768.0000 (32825.3870)\tmem 455MB\n",
      "Train: [33/100][580/625]\teta 0:00:01 lr 0.000772\t wd 0.0100\ttime 0.0326 (0.0358)\tloss 0.7173 (0.8393)\tgrad_norm 2.4112 (nan)\tloss_scale 32768.0000 (32824.3993)\tmem 455MB\n",
      "Train: [33/100][590/625]\teta 0:00:01 lr 0.000772\t wd 0.0100\ttime 0.0328 (0.0358)\tloss 0.8403 (0.8394)\tgrad_norm 2.5382 (nan)\tloss_scale 32768.0000 (32823.4450)\tmem 455MB\n",
      "Train: [33/100][600/625]\teta 0:00:00 lr 0.000771\t wd 0.0100\ttime 0.0398 (0.0358)\tloss 0.8564 (0.8393)\tgrad_norm 2.3984 (nan)\tloss_scale 32768.0000 (32822.5225)\tmem 455MB\n",
      "Train: [33/100][610/625]\teta 0:00:00 lr 0.000771\t wd 0.0100\ttime 0.0373 (0.0358)\tloss 0.8022 (0.8382)\tgrad_norm 2.3055 (nan)\tloss_scale 32768.0000 (32821.6301)\tmem 455MB\n",
      "Train: [33/100][620/625]\teta 0:00:00 lr 0.000771\t wd 0.0100\ttime 0.0364 (0.0358)\tloss 0.9512 (0.8397)\tgrad_norm 2.7283 (nan)\tloss_scale 32768.0000 (32820.7665)\tmem 455MB\n",
      "EPOCH 33 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_33.pth saving......\n",
      "./model_save/ckpt_epoch_33.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.9644 (0.9644)\tAcc@1 65.625 (65.625)\tAcc@5 100.000 (100.000)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.9004 (0.8665)\tAcc@1 68.750 (67.756)\tAcc@5 98.438 (98.295)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.9165 (0.8277)\tAcc@1 70.312 (70.461)\tAcc@5 98.438 (98.363)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.9028 (0.8426)\tAcc@1 67.188 (69.808)\tAcc@5 96.875 (98.185)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.9722 (0.8406)\tAcc@1 67.188 (69.970)\tAcc@5 96.875 (98.247)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.6401 (0.8514)\tAcc@1 81.250 (69.914)\tAcc@5 98.438 (98.162)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.8330 (0.8473)\tAcc@1 75.000 (70.108)\tAcc@5 96.875 (98.053)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.016 (0.015)\tLoss 0.7974 (0.8485)\tAcc@1 67.188 (69.476)\tAcc@5 93.750 (98.063)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.6401 (0.8448)\tAcc@1 85.938 (69.985)\tAcc@5 100.000 (97.975)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.6978 (0.8386)\tAcc@1 79.688 (70.312)\tAcc@5 96.875 (97.974)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.7964 (0.8315)\tAcc@1 64.062 (70.421)\tAcc@5 100.000 (98.051)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.6562 (0.8347)\tAcc@1 71.875 (70.101)\tAcc@5 96.875 (98.086)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.9141 (0.8400)\tAcc@1 70.312 (70.145)\tAcc@5 98.438 (98.050)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.9702 (0.8402)\tAcc@1 67.188 (70.038)\tAcc@5 98.438 (98.092)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.6094 (0.8358)\tAcc@1 78.125 (70.058)\tAcc@5 98.438 (98.072)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.8511 (0.8337)\tAcc@1 67.188 (70.137)\tAcc@5 96.875 (98.075)\tMem 455MB\n",
      " * Acc@1 70.090 Acc@5 98.060\n",
      "Accuracy of the network on the 10000 test images: 70.1%\n",
      "Max accuracy: 70.62%\n",
      "Train: [34/100][0/625]\teta 0:00:26 lr 0.000771\t wd 0.0100\ttime 0.0417 (0.0417)\tloss 0.8535 (0.8535)\tgrad_norm 1.6627 (1.6627)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][10/625]\teta 0:00:22 lr 0.000771\t wd 0.0100\ttime 0.0323 (0.0358)\tloss 0.9775 (0.8836)\tgrad_norm 2.1050 (2.1310)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][20/625]\teta 0:00:21 lr 0.000770\t wd 0.0100\ttime 0.0326 (0.0356)\tloss 0.9072 (0.8575)\tgrad_norm 1.6914 (2.0836)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][30/625]\teta 0:00:20 lr 0.000770\t wd 0.0100\ttime 0.0354 (0.0352)\tloss 0.8555 (0.8482)\tgrad_norm 1.8251 (2.0242)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][40/625]\teta 0:00:20 lr 0.000770\t wd 0.0100\ttime 0.0352 (0.0352)\tloss 0.7578 (0.8140)\tgrad_norm 1.8375 (2.0238)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][50/625]\teta 0:00:20 lr 0.000770\t wd 0.0100\ttime 0.0331 (0.0352)\tloss 0.7241 (0.8103)\tgrad_norm 1.7637 (2.0039)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][60/625]\teta 0:00:19 lr 0.000769\t wd 0.0100\ttime 0.0345 (0.0350)\tloss 0.8247 (0.8146)\tgrad_norm 1.9970 (2.0502)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][70/625]\teta 0:00:19 lr 0.000769\t wd 0.0100\ttime 0.0348 (0.0349)\tloss 0.7544 (0.8145)\tgrad_norm 2.4423 (2.0593)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][80/625]\teta 0:00:19 lr 0.000769\t wd 0.0100\ttime 0.0356 (0.0350)\tloss 0.6841 (0.8176)\tgrad_norm 1.7120 (2.0559)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][90/625]\teta 0:00:18 lr 0.000769\t wd 0.0100\ttime 0.0379 (0.0351)\tloss 0.7842 (0.8203)\tgrad_norm 3.2580 (2.0627)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][100/625]\teta 0:00:18 lr 0.000769\t wd 0.0100\ttime 0.0393 (0.0353)\tloss 0.8384 (0.8190)\tgrad_norm 1.8105 (2.0426)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][110/625]\teta 0:00:18 lr 0.000768\t wd 0.0100\ttime 0.0351 (0.0353)\tloss 0.8545 (0.8195)\tgrad_norm 2.2795 (2.0233)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][120/625]\teta 0:00:17 lr 0.000768\t wd 0.0100\ttime 0.0324 (0.0353)\tloss 0.7212 (0.8232)\tgrad_norm 2.3263 (2.0467)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][130/625]\teta 0:00:17 lr 0.000768\t wd 0.0100\ttime 0.0361 (0.0354)\tloss 0.6787 (0.8281)\tgrad_norm 1.6188 (2.0534)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][140/625]\teta 0:00:17 lr 0.000768\t wd 0.0100\ttime 0.0324 (0.0354)\tloss 0.8447 (0.8288)\tgrad_norm 2.0403 (2.0532)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][150/625]\teta 0:00:16 lr 0.000768\t wd 0.0100\ttime 0.0343 (0.0353)\tloss 0.9785 (0.8302)\tgrad_norm 1.9741 (2.0367)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][160/625]\teta 0:00:16 lr 0.000767\t wd 0.0100\ttime 0.0330 (0.0353)\tloss 0.7866 (0.8294)\tgrad_norm 1.6170 (2.0262)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][170/625]\teta 0:00:16 lr 0.000767\t wd 0.0100\ttime 0.0361 (0.0355)\tloss 0.7090 (0.8293)\tgrad_norm 1.5309 (2.0285)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][180/625]\teta 0:00:15 lr 0.000767\t wd 0.0100\ttime 0.0329 (0.0355)\tloss 0.7930 (0.8286)\tgrad_norm 1.6341 (2.0214)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][190/625]\teta 0:00:15 lr 0.000767\t wd 0.0100\ttime 0.0325 (0.0355)\tloss 0.8716 (0.8251)\tgrad_norm 1.9345 (2.0189)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][200/625]\teta 0:00:15 lr 0.000766\t wd 0.0100\ttime 0.0397 (0.0355)\tloss 0.7285 (0.8261)\tgrad_norm 1.8288 (2.0144)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][210/625]\teta 0:00:14 lr 0.000766\t wd 0.0100\ttime 0.0406 (0.0355)\tloss 0.9160 (0.8275)\tgrad_norm 1.6441 (2.0164)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][220/625]\teta 0:00:14 lr 0.000766\t wd 0.0100\ttime 0.0326 (0.0355)\tloss 0.8882 (0.8283)\tgrad_norm 2.4239 (2.0208)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][230/625]\teta 0:00:14 lr 0.000766\t wd 0.0100\ttime 0.0413 (0.0356)\tloss 0.7144 (0.8302)\tgrad_norm 2.2528 (2.0312)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][240/625]\teta 0:00:13 lr 0.000766\t wd 0.0100\ttime 0.0383 (0.0356)\tloss 0.8311 (0.8306)\tgrad_norm 1.7938 (2.0316)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][250/625]\teta 0:00:13 lr 0.000765\t wd 0.0100\ttime 0.0364 (0.0357)\tloss 0.7539 (0.8317)\tgrad_norm 1.8127 (2.0373)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][260/625]\teta 0:00:13 lr 0.000765\t wd 0.0100\ttime 0.0374 (0.0358)\tloss 0.6719 (0.8287)\tgrad_norm 2.3495 (2.0369)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][270/625]\teta 0:00:12 lr 0.000765\t wd 0.0100\ttime 0.0332 (0.0358)\tloss 0.8623 (0.8299)\tgrad_norm 2.3341 (2.0394)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][280/625]\teta 0:00:12 lr 0.000765\t wd 0.0100\ttime 0.0391 (0.0358)\tloss 0.6938 (0.8289)\tgrad_norm 2.9837 (2.0474)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][290/625]\teta 0:00:12 lr 0.000764\t wd 0.0100\ttime 0.0333 (0.0358)\tloss 0.8472 (0.8283)\tgrad_norm 2.3273 (2.0524)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][300/625]\teta 0:00:11 lr 0.000764\t wd 0.0100\ttime 0.0329 (0.0358)\tloss 0.9775 (0.8276)\tgrad_norm 2.6884 (2.0567)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][310/625]\teta 0:00:11 lr 0.000764\t wd 0.0100\ttime 0.0355 (0.0359)\tloss 0.6226 (0.8270)\tgrad_norm 1.7805 (2.0599)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][320/625]\teta 0:00:10 lr 0.000764\t wd 0.0100\ttime 0.0366 (0.0359)\tloss 0.8101 (0.8271)\tgrad_norm 2.1200 (2.0592)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][330/625]\teta 0:00:10 lr 0.000764\t wd 0.0100\ttime 0.0336 (0.0359)\tloss 0.8916 (0.8265)\tgrad_norm 1.9432 (2.0587)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][340/625]\teta 0:00:10 lr 0.000763\t wd 0.0100\ttime 0.0397 (0.0359)\tloss 0.7559 (0.8258)\tgrad_norm 1.9619 (2.0690)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][350/625]\teta 0:00:09 lr 0.000763\t wd 0.0100\ttime 0.0341 (0.0359)\tloss 0.6646 (0.8268)\tgrad_norm 1.5455 (2.0701)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][360/625]\teta 0:00:09 lr 0.000763\t wd 0.0100\ttime 0.0324 (0.0359)\tloss 0.9375 (0.8290)\tgrad_norm 2.0067 (2.0695)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][370/625]\teta 0:00:09 lr 0.000763\t wd 0.0100\ttime 0.0405 (0.0359)\tloss 0.8711 (0.8293)\tgrad_norm 1.9876 (2.0659)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][380/625]\teta 0:00:08 lr 0.000763\t wd 0.0100\ttime 0.0390 (0.0359)\tloss 0.7378 (0.8287)\tgrad_norm 2.0665 (2.0583)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][390/625]\teta 0:00:08 lr 0.000762\t wd 0.0100\ttime 0.0368 (0.0359)\tloss 0.8726 (0.8301)\tgrad_norm 1.7730 (2.0514)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][400/625]\teta 0:00:08 lr 0.000762\t wd 0.0100\ttime 0.0361 (0.0359)\tloss 0.8589 (0.8306)\tgrad_norm 1.7823 (2.0474)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][410/625]\teta 0:00:07 lr 0.000762\t wd 0.0100\ttime 0.0382 (0.0359)\tloss 0.7290 (0.8296)\tgrad_norm 1.7758 (2.0446)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][420/625]\teta 0:00:07 lr 0.000762\t wd 0.0100\ttime 0.0367 (0.0359)\tloss 0.5586 (0.8312)\tgrad_norm 1.7119 (2.0469)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][430/625]\teta 0:00:06 lr 0.000761\t wd 0.0100\ttime 0.0331 (0.0359)\tloss 0.8555 (0.8302)\tgrad_norm 1.7483 (2.0482)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][440/625]\teta 0:00:06 lr 0.000761\t wd 0.0100\ttime 0.0396 (0.0358)\tloss 0.8384 (0.8300)\tgrad_norm 1.7018 (2.0489)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][450/625]\teta 0:00:06 lr 0.000761\t wd 0.0100\ttime 0.0401 (0.0359)\tloss 1.0107 (0.8304)\tgrad_norm 1.9345 (2.0490)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][460/625]\teta 0:00:05 lr 0.000761\t wd 0.0100\ttime 0.0330 (0.0359)\tloss 0.8262 (0.8293)\tgrad_norm 2.7552 (2.0450)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][470/625]\teta 0:00:05 lr 0.000761\t wd 0.0100\ttime 0.0328 (0.0359)\tloss 0.9238 (0.8297)\tgrad_norm 1.6744 (2.0448)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][480/625]\teta 0:00:05 lr 0.000760\t wd 0.0100\ttime 0.0352 (0.0359)\tloss 0.8467 (0.8289)\tgrad_norm 1.9233 (2.0441)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][490/625]\teta 0:00:04 lr 0.000760\t wd 0.0100\ttime 0.0338 (0.0360)\tloss 1.0400 (0.8282)\tgrad_norm 1.8587 (2.0380)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][500/625]\teta 0:00:04 lr 0.000760\t wd 0.0100\ttime 0.0387 (0.0360)\tloss 0.9653 (0.8269)\tgrad_norm 2.0098 (2.0410)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][510/625]\teta 0:00:04 lr 0.000760\t wd 0.0100\ttime 0.0389 (0.0360)\tloss 0.6787 (0.8276)\tgrad_norm 1.5389 (2.0420)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][520/625]\teta 0:00:03 lr 0.000759\t wd 0.0100\ttime 0.0345 (0.0360)\tloss 0.7891 (0.8281)\tgrad_norm 1.6481 (2.0408)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][530/625]\teta 0:00:03 lr 0.000759\t wd 0.0100\ttime 0.0404 (0.0360)\tloss 0.8394 (0.8273)\tgrad_norm 2.0806 (2.0368)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][540/625]\teta 0:00:03 lr 0.000759\t wd 0.0100\ttime 0.0365 (0.0360)\tloss 0.7690 (0.8270)\tgrad_norm 1.9668 (2.0380)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][550/625]\teta 0:00:02 lr 0.000759\t wd 0.0100\ttime 0.0412 (0.0361)\tloss 0.7578 (0.8267)\tgrad_norm 1.6185 (2.0365)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][560/625]\teta 0:00:02 lr 0.000759\t wd 0.0100\ttime 0.0383 (0.0361)\tloss 1.0186 (0.8277)\tgrad_norm 2.3263 (2.0397)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][570/625]\teta 0:00:01 lr 0.000758\t wd 0.0100\ttime 0.0346 (0.0361)\tloss 0.6562 (0.8267)\tgrad_norm 1.6558 (2.0427)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][580/625]\teta 0:00:01 lr 0.000758\t wd 0.0100\ttime 0.0346 (0.0361)\tloss 0.7188 (0.8272)\tgrad_norm 2.0117 (2.0465)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][590/625]\teta 0:00:01 lr 0.000758\t wd 0.0100\ttime 0.0406 (0.0361)\tloss 0.9341 (0.8287)\tgrad_norm 1.8933 (2.0469)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][600/625]\teta 0:00:00 lr 0.000758\t wd 0.0100\ttime 0.0398 (0.0361)\tloss 0.6938 (0.8293)\tgrad_norm 1.8972 (2.0455)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][610/625]\teta 0:00:00 lr 0.000757\t wd 0.0100\ttime 0.0407 (0.0362)\tloss 0.9146 (0.8294)\tgrad_norm 1.9635 (2.0494)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [34/100][620/625]\teta 0:00:00 lr 0.000757\t wd 0.0100\ttime 0.0360 (0.0362)\tloss 0.7290 (0.8299)\tgrad_norm 2.4825 (2.0537)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 34 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_34.pth saving......\n",
      "./model_save/ckpt_epoch_34.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.8130 (0.8130)\tAcc@1 76.562 (76.562)\tAcc@5 96.875 (96.875)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.016)\tLoss 0.6738 (0.8258)\tAcc@1 75.000 (70.455)\tAcc@5 98.438 (97.301)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.016 (0.015)\tLoss 0.7031 (0.8581)\tAcc@1 73.438 (69.420)\tAcc@5 98.438 (97.545)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.6851 (0.8411)\tAcc@1 71.875 (70.262)\tAcc@5 98.438 (97.883)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.016 (0.015)\tLoss 1.0527 (0.8310)\tAcc@1 64.062 (70.808)\tAcc@5 95.312 (97.866)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.9116 (0.8235)\tAcc@1 68.750 (70.619)\tAcc@5 98.438 (98.009)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.016 (0.015)\tLoss 0.7983 (0.8239)\tAcc@1 73.438 (70.287)\tAcc@5 98.438 (97.976)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.8018 (0.8252)\tAcc@1 70.312 (70.136)\tAcc@5 96.875 (97.975)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.7480 (0.8278)\tAcc@1 75.000 (70.042)\tAcc@5 98.438 (98.090)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.8906 (0.8318)\tAcc@1 68.750 (70.244)\tAcc@5 98.438 (98.060)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.7061 (0.8295)\tAcc@1 81.250 (70.529)\tAcc@5 96.875 (98.020)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 1.0020 (0.8290)\tAcc@1 70.312 (70.735)\tAcc@5 93.750 (97.931)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.7603 (0.8335)\tAcc@1 65.625 (70.467)\tAcc@5 100.000 (97.986)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.7183 (0.8368)\tAcc@1 73.438 (70.301)\tAcc@5 96.875 (97.972)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.9829 (0.8368)\tAcc@1 75.000 (70.401)\tAcc@5 95.312 (97.983)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.6953 (0.8335)\tAcc@1 79.688 (70.530)\tAcc@5 98.438 (98.024)\tMem 455MB\n",
      " * Acc@1 70.410 Acc@5 98.020\n",
      "Accuracy of the network on the 10000 test images: 70.4%\n",
      "Max accuracy: 70.62%\n",
      "Train: [35/100][0/625]\teta 0:00:21 lr 0.000757\t wd 0.0100\ttime 0.0340 (0.0340)\tloss 0.8398 (0.8398)\tgrad_norm 2.1054 (2.1054)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][10/625]\teta 0:00:20 lr 0.000757\t wd 0.0100\ttime 0.0326 (0.0338)\tloss 0.9590 (0.8373)\tgrad_norm 2.5938 (1.9315)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][20/625]\teta 0:00:20 lr 0.000757\t wd 0.0100\ttime 0.0385 (0.0343)\tloss 0.6812 (0.7820)\tgrad_norm 1.7504 (1.9004)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][30/625]\teta 0:00:20 lr 0.000756\t wd 0.0100\ttime 0.0337 (0.0348)\tloss 0.8979 (0.7925)\tgrad_norm 2.0565 (1.9607)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][40/625]\teta 0:00:20 lr 0.000756\t wd 0.0100\ttime 0.0397 (0.0349)\tloss 0.5610 (0.7855)\tgrad_norm 1.7490 (1.9603)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][50/625]\teta 0:00:20 lr 0.000756\t wd 0.0100\ttime 0.0359 (0.0353)\tloss 1.0381 (0.7902)\tgrad_norm 2.1884 (1.9693)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][60/625]\teta 0:00:20 lr 0.000756\t wd 0.0100\ttime 0.0349 (0.0355)\tloss 0.8633 (0.7835)\tgrad_norm 2.3394 (2.0118)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][70/625]\teta 0:00:19 lr 0.000756\t wd 0.0100\ttime 0.0364 (0.0356)\tloss 1.0732 (0.7896)\tgrad_norm 2.6606 (2.0615)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][80/625]\teta 0:00:19 lr 0.000755\t wd 0.0100\ttime 0.0388 (0.0358)\tloss 0.8369 (0.7914)\tgrad_norm 2.0987 (2.0939)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][90/625]\teta 0:00:19 lr 0.000755\t wd 0.0100\ttime 0.0355 (0.0358)\tloss 0.9092 (0.7960)\tgrad_norm 2.1688 (2.1167)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][100/625]\teta 0:00:18 lr 0.000755\t wd 0.0100\ttime 0.0353 (0.0357)\tloss 0.6187 (0.7978)\tgrad_norm 1.9019 (2.1056)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][110/625]\teta 0:00:18 lr 0.000755\t wd 0.0100\ttime 0.0341 (0.0356)\tloss 0.9648 (0.8027)\tgrad_norm 1.9173 (2.0903)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][120/625]\teta 0:00:17 lr 0.000754\t wd 0.0100\ttime 0.0329 (0.0355)\tloss 0.8765 (0.8054)\tgrad_norm 1.9667 (2.0858)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][130/625]\teta 0:00:17 lr 0.000754\t wd 0.0100\ttime 0.0337 (0.0354)\tloss 1.0127 (0.8051)\tgrad_norm 2.1602 (2.0618)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][140/625]\teta 0:00:17 lr 0.000754\t wd 0.0100\ttime 0.0329 (0.0354)\tloss 0.6445 (0.8044)\tgrad_norm 1.7255 (2.0703)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][150/625]\teta 0:00:16 lr 0.000754\t wd 0.0100\ttime 0.0380 (0.0355)\tloss 0.6929 (0.7967)\tgrad_norm 2.6879 (2.0794)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][160/625]\teta 0:00:16 lr 0.000754\t wd 0.0100\ttime 0.0348 (0.0355)\tloss 0.9390 (0.8013)\tgrad_norm 2.5715 (2.1054)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][170/625]\teta 0:00:16 lr 0.000753\t wd 0.0100\ttime 0.0330 (0.0356)\tloss 0.8960 (0.8039)\tgrad_norm 2.4889 (2.1159)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][180/625]\teta 0:00:15 lr 0.000753\t wd 0.0100\ttime 0.0333 (0.0356)\tloss 1.0410 (0.8087)\tgrad_norm 2.3984 (2.1155)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][190/625]\teta 0:00:15 lr 0.000753\t wd 0.0100\ttime 0.0347 (0.0357)\tloss 0.8188 (0.8097)\tgrad_norm 1.9357 (2.1299)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][200/625]\teta 0:00:15 lr 0.000753\t wd 0.0100\ttime 0.0351 (0.0357)\tloss 0.9175 (0.8107)\tgrad_norm 2.8806 (2.1293)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][210/625]\teta 0:00:14 lr 0.000752\t wd 0.0100\ttime 0.0355 (0.0357)\tloss 0.8325 (0.8097)\tgrad_norm 2.1662 (2.1203)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][220/625]\teta 0:00:14 lr 0.000752\t wd 0.0100\ttime 0.0354 (0.0358)\tloss 0.7188 (0.8097)\tgrad_norm 2.7074 (2.1126)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][230/625]\teta 0:00:14 lr 0.000752\t wd 0.0100\ttime 0.0326 (0.0358)\tloss 0.8433 (0.8097)\tgrad_norm 2.0576 (2.0991)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][240/625]\teta 0:00:13 lr 0.000752\t wd 0.0100\ttime 0.0357 (0.0358)\tloss 0.6299 (0.8116)\tgrad_norm 1.8132 (2.0923)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][250/625]\teta 0:00:13 lr 0.000752\t wd 0.0100\ttime 0.0359 (0.0358)\tloss 0.6938 (0.8073)\tgrad_norm 1.8491 (2.0810)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][260/625]\teta 0:00:13 lr 0.000751\t wd 0.0100\ttime 0.0326 (0.0358)\tloss 1.0391 (0.8089)\tgrad_norm 1.8136 (2.0782)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][270/625]\teta 0:00:12 lr 0.000751\t wd 0.0100\ttime 0.0396 (0.0358)\tloss 1.1631 (0.8099)\tgrad_norm 2.5952 (2.0793)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][280/625]\teta 0:00:12 lr 0.000751\t wd 0.0100\ttime 0.0357 (0.0358)\tloss 0.7539 (0.8111)\tgrad_norm 2.0793 (2.0884)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][290/625]\teta 0:00:11 lr 0.000751\t wd 0.0100\ttime 0.0389 (0.0358)\tloss 0.9004 (0.8104)\tgrad_norm 2.8390 (2.0944)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][300/625]\teta 0:00:11 lr 0.000750\t wd 0.0100\ttime 0.0334 (0.0358)\tloss 0.7744 (0.8104)\tgrad_norm 2.5072 (2.0940)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][310/625]\teta 0:00:11 lr 0.000750\t wd 0.0100\ttime 0.0349 (0.0359)\tloss 0.5674 (0.8103)\tgrad_norm 1.7072 (2.0960)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][320/625]\teta 0:00:10 lr 0.000750\t wd 0.0100\ttime 0.0396 (0.0359)\tloss 0.8052 (0.8100)\tgrad_norm 1.8010 (2.0884)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][330/625]\teta 0:00:10 lr 0.000750\t wd 0.0100\ttime 0.0362 (0.0359)\tloss 0.8301 (0.8109)\tgrad_norm 1.9097 (2.0846)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][340/625]\teta 0:00:10 lr 0.000750\t wd 0.0100\ttime 0.0394 (0.0360)\tloss 0.8237 (0.8107)\tgrad_norm 2.7392 (2.0897)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][350/625]\teta 0:00:09 lr 0.000749\t wd 0.0100\ttime 0.0411 (0.0360)\tloss 0.8652 (0.8107)\tgrad_norm 2.8841 (2.0998)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][360/625]\teta 0:00:09 lr 0.000749\t wd 0.0100\ttime 0.0374 (0.0360)\tloss 0.8721 (0.8106)\tgrad_norm 2.4327 (2.1010)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][370/625]\teta 0:00:09 lr 0.000749\t wd 0.0100\ttime 0.0361 (0.0361)\tloss 0.8857 (0.8121)\tgrad_norm 1.6399 (2.0995)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][380/625]\teta 0:00:08 lr 0.000749\t wd 0.0100\ttime 0.0369 (0.0361)\tloss 0.6963 (0.8120)\tgrad_norm 1.3655 (2.0972)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][390/625]\teta 0:00:08 lr 0.000748\t wd 0.0100\ttime 0.0331 (0.0361)\tloss 0.8613 (0.8136)\tgrad_norm 1.7410 (2.0924)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][400/625]\teta 0:00:08 lr 0.000748\t wd 0.0100\ttime 0.0419 (0.0362)\tloss 0.8623 (0.8129)\tgrad_norm 2.3385 (2.0879)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][410/625]\teta 0:00:07 lr 0.000748\t wd 0.0100\ttime 0.0367 (0.0362)\tloss 0.6509 (0.8107)\tgrad_norm 2.0023 (2.0816)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][420/625]\teta 0:00:07 lr 0.000748\t wd 0.0100\ttime 0.0360 (0.0362)\tloss 0.6768 (0.8098)\tgrad_norm 1.6803 (2.0730)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][430/625]\teta 0:00:07 lr 0.000748\t wd 0.0100\ttime 0.0356 (0.0362)\tloss 0.8950 (0.8098)\tgrad_norm 2.1334 (2.0730)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][440/625]\teta 0:00:06 lr 0.000747\t wd 0.0100\ttime 0.0365 (0.0363)\tloss 1.1201 (0.8098)\tgrad_norm 2.5554 (2.0686)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][450/625]\teta 0:00:06 lr 0.000747\t wd 0.0100\ttime 0.0399 (0.0362)\tloss 0.5923 (0.8084)\tgrad_norm 1.8912 (2.0654)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][460/625]\teta 0:00:05 lr 0.000747\t wd 0.0100\ttime 0.0386 (0.0362)\tloss 0.8154 (0.8081)\tgrad_norm 1.7151 (2.0620)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][470/625]\teta 0:00:05 lr 0.000747\t wd 0.0100\ttime 0.0380 (0.0363)\tloss 0.8779 (0.8085)\tgrad_norm 1.8500 (2.0587)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][480/625]\teta 0:00:05 lr 0.000746\t wd 0.0100\ttime 0.0360 (0.0363)\tloss 0.8853 (0.8076)\tgrad_norm 3.0216 (2.0591)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][490/625]\teta 0:00:04 lr 0.000746\t wd 0.0100\ttime 0.0353 (0.0362)\tloss 0.8623 (0.8075)\tgrad_norm 1.9762 (2.0557)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][500/625]\teta 0:00:04 lr 0.000746\t wd 0.0100\ttime 0.0385 (0.0363)\tloss 0.8013 (0.8082)\tgrad_norm 2.9518 (2.0603)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][510/625]\teta 0:00:04 lr 0.000746\t wd 0.0100\ttime 0.0357 (0.0362)\tloss 0.7954 (0.8077)\tgrad_norm 1.6169 (2.0552)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][520/625]\teta 0:00:03 lr 0.000746\t wd 0.0100\ttime 0.0327 (0.0362)\tloss 0.8540 (0.8077)\tgrad_norm 1.4667 (2.0497)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][530/625]\teta 0:00:03 lr 0.000745\t wd 0.0100\ttime 0.0329 (0.0362)\tloss 0.8062 (0.8076)\tgrad_norm 1.7735 (2.0474)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][540/625]\teta 0:00:03 lr 0.000745\t wd 0.0100\ttime 0.0330 (0.0362)\tloss 0.8867 (0.8081)\tgrad_norm 1.4163 (2.0472)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][550/625]\teta 0:00:02 lr 0.000745\t wd 0.0100\ttime 0.0395 (0.0362)\tloss 0.9546 (0.8082)\tgrad_norm 2.5906 (2.0496)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][560/625]\teta 0:00:02 lr 0.000745\t wd 0.0100\ttime 0.0380 (0.0362)\tloss 0.7319 (0.8094)\tgrad_norm 1.9367 (2.0507)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][570/625]\teta 0:00:01 lr 0.000744\t wd 0.0100\ttime 0.0355 (0.0362)\tloss 0.6987 (0.8097)\tgrad_norm 2.7633 (2.0513)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][580/625]\teta 0:00:01 lr 0.000744\t wd 0.0100\ttime 0.0328 (0.0362)\tloss 0.8569 (0.8103)\tgrad_norm 1.9502 (2.0515)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][590/625]\teta 0:00:01 lr 0.000744\t wd 0.0100\ttime 0.0330 (0.0361)\tloss 0.9355 (0.8097)\tgrad_norm 1.9590 (2.0520)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][600/625]\teta 0:00:00 lr 0.000744\t wd 0.0100\ttime 0.0362 (0.0361)\tloss 0.8970 (0.8096)\tgrad_norm 2.0086 (2.0513)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][610/625]\teta 0:00:00 lr 0.000744\t wd 0.0100\ttime 0.0398 (0.0361)\tloss 0.7529 (0.8092)\tgrad_norm 1.5881 (2.0475)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [35/100][620/625]\teta 0:00:00 lr 0.000743\t wd 0.0100\ttime 0.0361 (0.0361)\tloss 0.6895 (0.8092)\tgrad_norm 1.5023 (2.0445)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 35 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_35.pth saving......\n",
      "./model_save/ckpt_epoch_35.pth saved !!!\n",
      "Test: [0/157]\tTime 0.017 (0.017)\tLoss 0.6841 (0.6841)\tAcc@1 75.000 (75.000)\tAcc@5 98.438 (98.438)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.7910 (0.7780)\tAcc@1 67.188 (71.733)\tAcc@5 96.875 (98.295)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.5771 (0.7575)\tAcc@1 81.250 (73.438)\tAcc@5 98.438 (98.140)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.7236 (0.7588)\tAcc@1 73.438 (73.337)\tAcc@5 98.438 (98.337)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.9683 (0.7771)\tAcc@1 64.062 (72.752)\tAcc@5 100.000 (98.399)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.7988 (0.7914)\tAcc@1 68.750 (71.661)\tAcc@5 98.438 (98.192)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.7783 (0.7932)\tAcc@1 73.438 (71.516)\tAcc@5 98.438 (98.181)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.7998 (0.7999)\tAcc@1 67.188 (71.413)\tAcc@5 98.438 (98.129)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.7349 (0.7931)\tAcc@1 68.750 (71.373)\tAcc@5 100.000 (98.167)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.7910 (0.8000)\tAcc@1 71.875 (71.240)\tAcc@5 95.312 (98.077)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.5698 (0.8041)\tAcc@1 79.688 (71.071)\tAcc@5 100.000 (98.128)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.7886 (0.8015)\tAcc@1 76.562 (71.059)\tAcc@5 98.438 (98.212)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.5547 (0.8051)\tAcc@1 84.375 (70.984)\tAcc@5 96.875 (98.166)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.6709 (0.8087)\tAcc@1 78.125 (71.028)\tAcc@5 100.000 (98.139)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.7808 (0.8075)\tAcc@1 65.625 (71.144)\tAcc@5 98.438 (98.127)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.016 (0.015)\tLoss 0.8677 (0.8048)\tAcc@1 67.188 (71.099)\tAcc@5 98.438 (98.148)\tMem 455MB\n",
      " * Acc@1 70.970 Acc@5 98.110\n",
      "Accuracy of the network on the 10000 test images: 71.0%\n",
      "Max accuracy: 70.97%\n",
      "Train: [36/100][0/625]\teta 0:00:22 lr 0.000743\t wd 0.0100\ttime 0.0352 (0.0352)\tloss 0.7495 (0.7495)\tgrad_norm 2.5342 (2.5342)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [36/100][10/625]\teta 0:00:21 lr 0.000743\t wd 0.0100\ttime 0.0380 (0.0348)\tloss 0.8335 (0.7618)\tgrad_norm 2.6728 (2.0405)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [36/100][20/625]\teta 0:00:21 lr 0.000743\t wd 0.0100\ttime 0.0383 (0.0350)\tloss 0.7949 (0.8052)\tgrad_norm 1.5657 (2.0682)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [36/100][30/625]\teta 0:00:20 lr 0.000743\t wd 0.0100\ttime 0.0357 (0.0351)\tloss 0.8926 (0.8082)\tgrad_norm 2.2066 (2.1036)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [36/100][40/625]\teta 0:00:20 lr 0.000742\t wd 0.0100\ttime 0.0331 (0.0351)\tloss 0.9253 (0.8145)\tgrad_norm 2.0284 (2.1086)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [36/100][50/625]\teta 0:00:20 lr 0.000742\t wd 0.0100\ttime 0.0352 (0.0353)\tloss 0.7397 (0.8104)\tgrad_norm 2.3270 (2.1283)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [36/100][60/625]\teta 0:00:20 lr 0.000742\t wd 0.0100\ttime 0.0392 (0.0356)\tloss 0.7290 (0.8088)\tgrad_norm 3.5173 (2.1313)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [36/100][70/625]\teta 0:00:19 lr 0.000742\t wd 0.0100\ttime 0.0334 (0.0356)\tloss 0.8076 (0.8132)\tgrad_norm 2.0664 (2.1326)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [36/100][80/625]\teta 0:00:19 lr 0.000741\t wd 0.0100\ttime 0.0398 (0.0357)\tloss 0.6270 (0.8055)\tgrad_norm 1.8412 (2.1013)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [36/100][90/625]\teta 0:00:19 lr 0.000741\t wd 0.0100\ttime 0.0330 (0.0356)\tloss 0.6348 (0.8032)\tgrad_norm 2.0779 (2.1001)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [36/100][100/625]\teta 0:00:18 lr 0.000741\t wd 0.0100\ttime 0.0363 (0.0355)\tloss 0.9731 (0.7998)\tgrad_norm 2.7810 (2.1148)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [36/100][110/625]\teta 0:00:18 lr 0.000741\t wd 0.0100\ttime 0.0328 (0.0354)\tloss 0.8442 (0.8020)\tgrad_norm 2.4089 (2.1314)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [36/100][120/625]\teta 0:00:17 lr 0.000740\t wd 0.0100\ttime 0.0333 (0.0353)\tloss 0.9468 (0.8031)\tgrad_norm 2.3038 (2.1326)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [36/100][130/625]\teta 0:00:17 lr 0.000740\t wd 0.0100\ttime 0.0324 (0.0351)\tloss 0.9146 (0.8085)\tgrad_norm 1.9305 (2.1308)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [36/100][140/625]\teta 0:00:17 lr 0.000740\t wd 0.0100\ttime 0.0332 (0.0351)\tloss 0.6909 (0.8042)\tgrad_norm 1.7352 (2.1158)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [36/100][150/625]\teta 0:00:16 lr 0.000740\t wd 0.0100\ttime 0.0362 (0.0350)\tloss 1.0645 (0.8145)\tgrad_norm 2.4785 (2.1638)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [36/100][160/625]\teta 0:00:16 lr 0.000740\t wd 0.0100\ttime 0.0328 (0.0349)\tloss 0.6968 (0.8131)\tgrad_norm 1.5815 (2.1583)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [36/100][170/625]\teta 0:00:15 lr 0.000739\t wd 0.0100\ttime 0.0331 (0.0349)\tloss 0.8564 (0.8108)\tgrad_norm 1.9480 (2.1465)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [36/100][180/625]\teta 0:00:15 lr 0.000739\t wd 0.0100\ttime 0.0324 (0.0349)\tloss 0.8491 (0.8086)\tgrad_norm 2.3917 (2.1441)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [36/100][190/625]\teta 0:00:15 lr 0.000739\t wd 0.0100\ttime 0.0327 (0.0348)\tloss 0.6167 (0.8087)\tgrad_norm 1.4660 (2.1618)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [36/100][200/625]\teta 0:00:14 lr 0.000739\t wd 0.0100\ttime 0.0392 (0.0348)\tloss 0.7749 (0.8085)\tgrad_norm 1.4130 (2.1522)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [36/100][210/625]\teta 0:00:14 lr 0.000738\t wd 0.0100\ttime 0.0362 (0.0349)\tloss 0.8818 (0.8122)\tgrad_norm 1.9231 (2.1444)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [36/100][220/625]\teta 0:00:14 lr 0.000738\t wd 0.0100\ttime 0.0363 (0.0350)\tloss 0.7480 (0.8109)\tgrad_norm 1.8520 (2.1457)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [36/100][230/625]\teta 0:00:13 lr 0.000738\t wd 0.0100\ttime 0.0332 (0.0350)\tloss 0.7383 (0.8094)\tgrad_norm 1.8221 (2.1370)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [36/100][240/625]\teta 0:00:13 lr 0.000738\t wd 0.0100\ttime 0.0357 (0.0350)\tloss 0.9697 (0.8079)\tgrad_norm 2.1441 (2.1278)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [36/100][250/625]\teta 0:00:13 lr 0.000738\t wd 0.0100\ttime 0.0350 (0.0349)\tloss 0.8325 (0.8111)\tgrad_norm 2.3392 (2.1316)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [36/100][260/625]\teta 0:00:12 lr 0.000737\t wd 0.0100\ttime 0.0337 (0.0349)\tloss 0.9443 (0.8122)\tgrad_norm 1.7764 (nan)\tloss_scale 32768.0000 (32893.5479)\tmem 455MB\n",
      "Train: [36/100][270/625]\teta 0:00:12 lr 0.000737\t wd 0.0100\ttime 0.0335 (0.0349)\tloss 0.6821 (0.8098)\tgrad_norm 1.9272 (nan)\tloss_scale 32768.0000 (32888.9151)\tmem 455MB\n",
      "Train: [36/100][280/625]\teta 0:00:12 lr 0.000737\t wd 0.0100\ttime 0.0359 (0.0349)\tloss 0.8057 (0.8083)\tgrad_norm 1.8551 (nan)\tloss_scale 32768.0000 (32884.6121)\tmem 455MB\n",
      "Train: [36/100][290/625]\teta 0:00:11 lr 0.000737\t wd 0.0100\ttime 0.0399 (0.0349)\tloss 0.7378 (0.8071)\tgrad_norm 1.4840 (nan)\tloss_scale 32768.0000 (32880.6048)\tmem 455MB\n",
      "Train: [36/100][300/625]\teta 0:00:11 lr 0.000736\t wd 0.0100\ttime 0.0368 (0.0350)\tloss 0.5708 (0.8051)\tgrad_norm 1.9084 (nan)\tloss_scale 32768.0000 (32876.8638)\tmem 455MB\n",
      "Train: [36/100][310/625]\teta 0:00:11 lr 0.000736\t wd 0.0100\ttime 0.0357 (0.0350)\tloss 0.6738 (0.8047)\tgrad_norm 2.2946 (nan)\tloss_scale 32768.0000 (32873.3633)\tmem 455MB\n",
      "Train: [36/100][320/625]\teta 0:00:10 lr 0.000736\t wd 0.0100\ttime 0.0363 (0.0351)\tloss 0.6191 (0.8032)\tgrad_norm 1.6606 (nan)\tloss_scale 32768.0000 (32870.0810)\tmem 455MB\n",
      "Train: [36/100][330/625]\teta 0:00:10 lr 0.000736\t wd 0.0100\ttime 0.0327 (0.0351)\tloss 0.6826 (0.8009)\tgrad_norm 1.3681 (nan)\tloss_scale 32768.0000 (32866.9970)\tmem 455MB\n",
      "Train: [36/100][340/625]\teta 0:00:09 lr 0.000736\t wd 0.0100\ttime 0.0338 (0.0351)\tloss 0.7319 (0.7997)\tgrad_norm 2.0750 (nan)\tloss_scale 32768.0000 (32864.0938)\tmem 455MB\n",
      "Train: [36/100][350/625]\teta 0:00:09 lr 0.000735\t wd 0.0100\ttime 0.0355 (0.0351)\tloss 0.8389 (0.8018)\tgrad_norm 2.4388 (nan)\tloss_scale 32768.0000 (32861.3561)\tmem 455MB\n",
      "Train: [36/100][360/625]\teta 0:00:09 lr 0.000735\t wd 0.0100\ttime 0.0363 (0.0351)\tloss 0.7793 (0.8023)\tgrad_norm 1.9118 (nan)\tloss_scale 32768.0000 (32858.7701)\tmem 455MB\n",
      "Train: [36/100][370/625]\teta 0:00:08 lr 0.000735\t wd 0.0100\ttime 0.0393 (0.0351)\tloss 0.6143 (0.8008)\tgrad_norm 1.3898 (nan)\tloss_scale 32768.0000 (32856.3235)\tmem 455MB\n",
      "Train: [36/100][380/625]\teta 0:00:08 lr 0.000735\t wd 0.0100\ttime 0.0330 (0.0351)\tloss 0.8862 (0.8003)\tgrad_norm 2.4149 (nan)\tloss_scale 32768.0000 (32854.0052)\tmem 455MB\n",
      "Train: [36/100][390/625]\teta 0:00:08 lr 0.000734\t wd 0.0100\ttime 0.0330 (0.0351)\tloss 0.6831 (0.8005)\tgrad_norm 1.7848 (nan)\tloss_scale 32768.0000 (32851.8056)\tmem 455MB\n",
      "Train: [36/100][400/625]\teta 0:00:07 lr 0.000734\t wd 0.0100\ttime 0.0340 (0.0350)\tloss 0.7373 (0.7989)\tgrad_norm 2.5581 (nan)\tloss_scale 32768.0000 (32849.7157)\tmem 455MB\n",
      "Train: [36/100][410/625]\teta 0:00:07 lr 0.000734\t wd 0.0100\ttime 0.0400 (0.0350)\tloss 0.8506 (0.7989)\tgrad_norm 2.1257 (nan)\tloss_scale 32768.0000 (32847.7275)\tmem 455MB\n",
      "Train: [36/100][420/625]\teta 0:00:07 lr 0.000734\t wd 0.0100\ttime 0.0331 (0.0350)\tloss 0.7905 (0.8000)\tgrad_norm 1.9479 (nan)\tloss_scale 32768.0000 (32845.8337)\tmem 455MB\n",
      "Train: [36/100][430/625]\teta 0:00:06 lr 0.000733\t wd 0.0100\ttime 0.0356 (0.0351)\tloss 0.8018 (0.7986)\tgrad_norm 1.7441 (nan)\tloss_scale 32768.0000 (32844.0278)\tmem 455MB\n",
      "Train: [36/100][440/625]\teta 0:00:06 lr 0.000733\t wd 0.0100\ttime 0.0334 (0.0351)\tloss 0.6040 (0.7996)\tgrad_norm 1.9331 (nan)\tloss_scale 32768.0000 (32842.3039)\tmem 455MB\n",
      "Train: [36/100][450/625]\teta 0:00:06 lr 0.000733\t wd 0.0100\ttime 0.0385 (0.0351)\tloss 0.9463 (0.7992)\tgrad_norm 2.1747 (nan)\tloss_scale 32768.0000 (32840.6563)\tmem 455MB\n",
      "Train: [36/100][460/625]\teta 0:00:05 lr 0.000733\t wd 0.0100\ttime 0.0351 (0.0351)\tloss 0.6958 (0.7996)\tgrad_norm 2.2141 (nan)\tloss_scale 32768.0000 (32839.0803)\tmem 455MB\n",
      "Train: [36/100][470/625]\teta 0:00:05 lr 0.000733\t wd 0.0100\ttime 0.0373 (0.0352)\tloss 0.9102 (0.7990)\tgrad_norm 2.8091 (nan)\tloss_scale 32768.0000 (32837.5711)\tmem 455MB\n",
      "Train: [36/100][480/625]\teta 0:00:05 lr 0.000732\t wd 0.0100\ttime 0.0324 (0.0352)\tloss 0.7915 (0.7993)\tgrad_norm 2.3283 (nan)\tloss_scale 32768.0000 (32836.1247)\tmem 455MB\n",
      "Train: [36/100][490/625]\teta 0:00:04 lr 0.000732\t wd 0.0100\ttime 0.0336 (0.0351)\tloss 1.0566 (0.7983)\tgrad_norm 2.6735 (nan)\tloss_scale 32768.0000 (32834.7373)\tmem 455MB\n",
      "Train: [36/100][500/625]\teta 0:00:04 lr 0.000732\t wd 0.0100\ttime 0.0327 (0.0351)\tloss 0.6597 (0.7988)\tgrad_norm 1.9284 (nan)\tloss_scale 32768.0000 (32833.4052)\tmem 455MB\n",
      "Train: [36/100][510/625]\teta 0:00:04 lr 0.000732\t wd 0.0100\ttime 0.0385 (0.0351)\tloss 0.7090 (0.7982)\tgrad_norm 1.6553 (nan)\tloss_scale 32768.0000 (32832.1252)\tmem 455MB\n",
      "Train: [36/100][520/625]\teta 0:00:03 lr 0.000731\t wd 0.0100\ttime 0.0327 (0.0351)\tloss 0.9609 (0.7973)\tgrad_norm 2.1955 (nan)\tloss_scale 32768.0000 (32830.8944)\tmem 455MB\n",
      "Train: [36/100][530/625]\teta 0:00:03 lr 0.000731\t wd 0.0100\ttime 0.0326 (0.0351)\tloss 0.7510 (0.7980)\tgrad_norm 1.9223 (nan)\tloss_scale 32768.0000 (32829.7100)\tmem 455MB\n",
      "Train: [36/100][540/625]\teta 0:00:02 lr 0.000731\t wd 0.0100\ttime 0.0365 (0.0351)\tloss 0.6680 (0.7967)\tgrad_norm 1.6997 (nan)\tloss_scale 32768.0000 (32828.5693)\tmem 455MB\n",
      "Train: [36/100][550/625]\teta 0:00:02 lr 0.000731\t wd 0.0100\ttime 0.0322 (0.0351)\tloss 0.6670 (0.7972)\tgrad_norm 1.5347 (nan)\tloss_scale 32768.0000 (32827.4701)\tmem 455MB\n",
      "Train: [36/100][560/625]\teta 0:00:02 lr 0.000730\t wd 0.0100\ttime 0.0390 (0.0351)\tloss 0.7681 (0.7980)\tgrad_norm 1.7652 (nan)\tloss_scale 32768.0000 (32826.4100)\tmem 455MB\n",
      "Train: [36/100][570/625]\teta 0:00:01 lr 0.000730\t wd 0.0100\ttime 0.0361 (0.0352)\tloss 0.9834 (0.7986)\tgrad_norm 2.3902 (nan)\tloss_scale 32768.0000 (32825.3870)\tmem 455MB\n",
      "Train: [36/100][580/625]\teta 0:00:01 lr 0.000730\t wd 0.0100\ttime 0.0325 (0.0352)\tloss 0.7812 (0.7995)\tgrad_norm 1.6945 (nan)\tloss_scale 32768.0000 (32824.3993)\tmem 455MB\n",
      "Train: [36/100][590/625]\teta 0:00:01 lr 0.000730\t wd 0.0100\ttime 0.0359 (0.0352)\tloss 0.7617 (0.7999)\tgrad_norm 2.2715 (nan)\tloss_scale 32768.0000 (32823.4450)\tmem 455MB\n",
      "Train: [36/100][600/625]\teta 0:00:00 lr 0.000730\t wd 0.0100\ttime 0.0389 (0.0352)\tloss 0.5718 (0.7996)\tgrad_norm 1.6568 (nan)\tloss_scale 32768.0000 (32822.5225)\tmem 455MB\n",
      "Train: [36/100][610/625]\teta 0:00:00 lr 0.000729\t wd 0.0100\ttime 0.0394 (0.0352)\tloss 0.8647 (0.8006)\tgrad_norm 2.1044 (nan)\tloss_scale 32768.0000 (32821.6301)\tmem 455MB\n",
      "Train: [36/100][620/625]\teta 0:00:00 lr 0.000729\t wd 0.0100\ttime 0.0330 (0.0352)\tloss 0.7617 (0.8008)\tgrad_norm 1.7594 (nan)\tloss_scale 32768.0000 (32820.7665)\tmem 455MB\n",
      "EPOCH 36 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_36.pth saving......\n",
      "./model_save/ckpt_epoch_36.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 1.0049 (1.0049)\tAcc@1 67.188 (67.188)\tAcc@5 92.188 (92.188)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.7822 (0.8827)\tAcc@1 75.000 (69.176)\tAcc@5 100.000 (97.159)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.6387 (0.8191)\tAcc@1 76.562 (71.057)\tAcc@5 100.000 (97.991)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.9683 (0.8145)\tAcc@1 68.750 (71.321)\tAcc@5 96.875 (98.085)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.7041 (0.8008)\tAcc@1 73.438 (72.027)\tAcc@5 98.438 (98.209)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.7588 (0.7967)\tAcc@1 71.875 (71.998)\tAcc@5 100.000 (98.315)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 1.0205 (0.8149)\tAcc@1 65.625 (71.030)\tAcc@5 95.312 (98.233)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.9751 (0.8093)\tAcc@1 67.188 (71.325)\tAcc@5 96.875 (98.261)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.9580 (0.8193)\tAcc@1 67.188 (70.833)\tAcc@5 96.875 (98.032)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.7173 (0.8140)\tAcc@1 76.562 (71.068)\tAcc@5 98.438 (98.043)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.7900 (0.8114)\tAcc@1 78.125 (71.256)\tAcc@5 98.438 (98.082)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.8037 (0.8112)\tAcc@1 81.250 (71.101)\tAcc@5 98.438 (98.142)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 1.0039 (0.8115)\tAcc@1 62.500 (71.100)\tAcc@5 95.312 (98.089)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.5474 (0.8133)\tAcc@1 81.250 (70.957)\tAcc@5 100.000 (98.080)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.6533 (0.8132)\tAcc@1 78.125 (71.099)\tAcc@5 100.000 (98.061)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.8535 (0.8086)\tAcc@1 70.312 (71.285)\tAcc@5 92.188 (98.055)\tMem 455MB\n",
      " * Acc@1 71.290 Acc@5 98.060\n",
      "Accuracy of the network on the 10000 test images: 71.3%\n",
      "Max accuracy: 71.29%\n",
      "Train: [37/100][0/625]\teta 0:00:23 lr 0.000729\t wd 0.0100\ttime 0.0368 (0.0368)\tloss 0.7036 (0.7036)\tgrad_norm 1.6286 (1.6286)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][10/625]\teta 0:00:21 lr 0.000729\t wd 0.0100\ttime 0.0328 (0.0355)\tloss 0.7480 (0.8360)\tgrad_norm 1.4750 (2.0068)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][20/625]\teta 0:00:21 lr 0.000729\t wd 0.0100\ttime 0.0386 (0.0357)\tloss 0.7529 (0.8506)\tgrad_norm 2.4326 (2.0919)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][30/625]\teta 0:00:21 lr 0.000728\t wd 0.0100\ttime 0.0325 (0.0357)\tloss 0.8525 (0.8273)\tgrad_norm 1.5245 (1.9644)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][40/625]\teta 0:00:21 lr 0.000728\t wd 0.0100\ttime 0.0384 (0.0361)\tloss 0.6904 (0.8010)\tgrad_norm 1.7603 (1.9277)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][50/625]\teta 0:00:20 lr 0.000728\t wd 0.0100\ttime 0.0392 (0.0364)\tloss 0.8125 (0.8079)\tgrad_norm 2.2070 (1.9855)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][60/625]\teta 0:00:20 lr 0.000728\t wd 0.0100\ttime 0.0391 (0.0367)\tloss 0.7246 (0.7960)\tgrad_norm 1.5198 (1.9763)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][70/625]\teta 0:00:20 lr 0.000727\t wd 0.0100\ttime 0.0351 (0.0366)\tloss 0.8745 (0.7870)\tgrad_norm 3.0810 (2.0019)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][80/625]\teta 0:00:19 lr 0.000727\t wd 0.0100\ttime 0.0332 (0.0364)\tloss 0.9463 (0.7893)\tgrad_norm 2.2648 (2.0089)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][90/625]\teta 0:00:19 lr 0.000727\t wd 0.0100\ttime 0.0326 (0.0362)\tloss 0.8057 (0.7885)\tgrad_norm 2.4419 (2.0555)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][100/625]\teta 0:00:18 lr 0.000727\t wd 0.0100\ttime 0.0350 (0.0361)\tloss 0.6445 (0.7946)\tgrad_norm 1.2485 (2.1185)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][110/625]\teta 0:00:18 lr 0.000726\t wd 0.0100\ttime 0.0326 (0.0360)\tloss 0.8979 (0.7890)\tgrad_norm 1.7508 (2.0851)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][120/625]\teta 0:00:18 lr 0.000726\t wd 0.0100\ttime 0.0396 (0.0360)\tloss 0.9146 (0.7891)\tgrad_norm 1.8528 (2.0743)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][130/625]\teta 0:00:17 lr 0.000726\t wd 0.0100\ttime 0.0406 (0.0362)\tloss 0.6787 (0.7850)\tgrad_norm 2.8568 (2.0967)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][140/625]\teta 0:00:17 lr 0.000726\t wd 0.0100\ttime 0.0388 (0.0361)\tloss 0.8760 (0.7842)\tgrad_norm 2.8891 (2.1080)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][150/625]\teta 0:00:17 lr 0.000726\t wd 0.0100\ttime 0.0357 (0.0362)\tloss 0.6885 (0.7833)\tgrad_norm 1.6340 (2.1096)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][160/625]\teta 0:00:16 lr 0.000725\t wd 0.0100\ttime 0.0354 (0.0362)\tloss 0.7661 (0.7834)\tgrad_norm 2.2520 (2.0974)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][170/625]\teta 0:00:16 lr 0.000725\t wd 0.0100\ttime 0.0364 (0.0363)\tloss 0.7407 (0.7874)\tgrad_norm 2.2396 (2.0907)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][180/625]\teta 0:00:16 lr 0.000725\t wd 0.0100\ttime 0.0370 (0.0363)\tloss 0.7705 (0.7864)\tgrad_norm 1.8025 (2.0862)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][190/625]\teta 0:00:15 lr 0.000725\t wd 0.0100\ttime 0.0379 (0.0362)\tloss 0.6865 (0.7837)\tgrad_norm 2.0556 (2.0748)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][200/625]\teta 0:00:15 lr 0.000724\t wd 0.0100\ttime 0.0334 (0.0362)\tloss 0.8188 (0.7816)\tgrad_norm 2.2191 (2.0720)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][210/625]\teta 0:00:15 lr 0.000724\t wd 0.0100\ttime 0.0324 (0.0362)\tloss 0.8008 (0.7807)\tgrad_norm 1.7122 (2.0625)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][220/625]\teta 0:00:14 lr 0.000724\t wd 0.0100\ttime 0.0332 (0.0361)\tloss 0.7808 (0.7811)\tgrad_norm 1.9023 (2.0625)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][230/625]\teta 0:00:14 lr 0.000724\t wd 0.0100\ttime 0.0379 (0.0361)\tloss 0.9121 (0.7796)\tgrad_norm 2.7485 (2.0597)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][240/625]\teta 0:00:13 lr 0.000724\t wd 0.0100\ttime 0.0327 (0.0362)\tloss 0.5869 (0.7814)\tgrad_norm 1.4914 (2.0575)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][250/625]\teta 0:00:13 lr 0.000723\t wd 0.0100\ttime 0.0334 (0.0362)\tloss 0.6465 (0.7808)\tgrad_norm 2.2204 (2.0602)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][260/625]\teta 0:00:13 lr 0.000723\t wd 0.0100\ttime 0.0326 (0.0362)\tloss 0.6851 (0.7826)\tgrad_norm 2.0166 (2.0790)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][270/625]\teta 0:00:12 lr 0.000723\t wd 0.0100\ttime 0.0359 (0.0361)\tloss 0.9756 (0.7834)\tgrad_norm 2.6812 (2.0760)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][280/625]\teta 0:00:12 lr 0.000723\t wd 0.0100\ttime 0.0353 (0.0361)\tloss 0.6738 (0.7817)\tgrad_norm 2.0404 (2.0696)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][290/625]\teta 0:00:12 lr 0.000722\t wd 0.0100\ttime 0.0325 (0.0361)\tloss 0.6416 (0.7823)\tgrad_norm 1.8466 (2.0608)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][300/625]\teta 0:00:11 lr 0.000722\t wd 0.0100\ttime 0.0324 (0.0360)\tloss 0.7354 (0.7808)\tgrad_norm 1.8118 (2.0537)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][310/625]\teta 0:00:11 lr 0.000722\t wd 0.0100\ttime 0.0401 (0.0360)\tloss 0.6968 (0.7803)\tgrad_norm 2.2335 (2.0522)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][320/625]\teta 0:00:10 lr 0.000722\t wd 0.0100\ttime 0.0323 (0.0360)\tloss 0.7446 (0.7824)\tgrad_norm 1.6409 (2.0531)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][330/625]\teta 0:00:10 lr 0.000721\t wd 0.0100\ttime 0.0348 (0.0359)\tloss 0.7769 (0.7813)\tgrad_norm 2.3536 (2.0553)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][340/625]\teta 0:00:10 lr 0.000721\t wd 0.0100\ttime 0.0324 (0.0358)\tloss 0.8594 (0.7826)\tgrad_norm 1.7243 (2.0607)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][350/625]\teta 0:00:09 lr 0.000721\t wd 0.0100\ttime 0.0330 (0.0358)\tloss 0.4739 (0.7822)\tgrad_norm 1.6066 (2.0593)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][360/625]\teta 0:00:09 lr 0.000721\t wd 0.0100\ttime 0.0335 (0.0357)\tloss 0.6597 (0.7809)\tgrad_norm 1.8608 (2.0593)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][370/625]\teta 0:00:09 lr 0.000721\t wd 0.0100\ttime 0.0413 (0.0358)\tloss 0.8574 (0.7830)\tgrad_norm 1.7698 (2.0607)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][380/625]\teta 0:00:08 lr 0.000720\t wd 0.0100\ttime 0.0388 (0.0359)\tloss 0.6230 (0.7825)\tgrad_norm 1.4998 (2.0575)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][390/625]\teta 0:00:08 lr 0.000720\t wd 0.0100\ttime 0.0330 (0.0359)\tloss 0.8203 (0.7822)\tgrad_norm 1.8182 (2.0568)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][400/625]\teta 0:00:08 lr 0.000720\t wd 0.0100\ttime 0.0328 (0.0359)\tloss 0.9019 (0.7818)\tgrad_norm 2.0842 (2.0563)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][410/625]\teta 0:00:07 lr 0.000720\t wd 0.0100\ttime 0.0331 (0.0359)\tloss 0.6958 (0.7820)\tgrad_norm 1.9949 (2.0583)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][420/625]\teta 0:00:07 lr 0.000719\t wd 0.0100\ttime 0.0324 (0.0359)\tloss 0.9292 (0.7823)\tgrad_norm 2.3725 (2.0558)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][430/625]\teta 0:00:07 lr 0.000719\t wd 0.0100\ttime 0.0369 (0.0359)\tloss 0.8691 (0.7834)\tgrad_norm 2.0786 (2.0604)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][440/625]\teta 0:00:06 lr 0.000719\t wd 0.0100\ttime 0.0391 (0.0359)\tloss 0.7329 (0.7825)\tgrad_norm 2.2770 (2.0588)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][450/625]\teta 0:00:06 lr 0.000719\t wd 0.0100\ttime 0.0425 (0.0360)\tloss 0.7368 (0.7820)\tgrad_norm 2.5310 (2.0616)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][460/625]\teta 0:00:05 lr 0.000718\t wd 0.0100\ttime 0.0333 (0.0360)\tloss 0.8120 (0.7823)\tgrad_norm 2.1113 (2.0623)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][470/625]\teta 0:00:05 lr 0.000718\t wd 0.0100\ttime 0.0334 (0.0360)\tloss 0.6514 (0.7823)\tgrad_norm 1.9668 (2.0612)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][480/625]\teta 0:00:05 lr 0.000718\t wd 0.0100\ttime 0.0367 (0.0360)\tloss 0.7939 (0.7823)\tgrad_norm 2.0212 (2.0590)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][490/625]\teta 0:00:04 lr 0.000718\t wd 0.0100\ttime 0.0332 (0.0361)\tloss 0.7671 (0.7826)\tgrad_norm 1.4637 (2.0575)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][500/625]\teta 0:00:04 lr 0.000717\t wd 0.0100\ttime 0.0375 (0.0361)\tloss 1.0859 (0.7829)\tgrad_norm 3.3145 (2.0622)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][510/625]\teta 0:00:04 lr 0.000717\t wd 0.0100\ttime 0.0415 (0.0362)\tloss 0.8188 (0.7838)\tgrad_norm 1.7032 (2.0653)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][520/625]\teta 0:00:03 lr 0.000717\t wd 0.0100\ttime 0.0326 (0.0362)\tloss 0.6650 (0.7839)\tgrad_norm 1.8127 (2.0654)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][530/625]\teta 0:00:03 lr 0.000717\t wd 0.0100\ttime 0.0399 (0.0362)\tloss 0.8062 (0.7835)\tgrad_norm 1.6223 (2.0607)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][540/625]\teta 0:00:03 lr 0.000717\t wd 0.0100\ttime 0.0346 (0.0362)\tloss 0.8062 (0.7836)\tgrad_norm 1.6437 (2.0610)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][550/625]\teta 0:00:02 lr 0.000716\t wd 0.0100\ttime 0.0326 (0.0362)\tloss 0.5850 (0.7834)\tgrad_norm 1.5663 (2.0641)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][560/625]\teta 0:00:02 lr 0.000716\t wd 0.0100\ttime 0.0332 (0.0362)\tloss 0.7632 (0.7825)\tgrad_norm 2.1641 (2.0632)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][570/625]\teta 0:00:01 lr 0.000716\t wd 0.0100\ttime 0.0345 (0.0362)\tloss 0.9019 (0.7846)\tgrad_norm 2.5054 (2.0687)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][580/625]\teta 0:00:01 lr 0.000716\t wd 0.0100\ttime 0.0326 (0.0361)\tloss 0.7983 (0.7861)\tgrad_norm 1.9786 (2.0698)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][590/625]\teta 0:00:01 lr 0.000715\t wd 0.0100\ttime 0.0358 (0.0361)\tloss 0.9429 (0.7879)\tgrad_norm 1.6352 (2.0654)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][600/625]\teta 0:00:00 lr 0.000715\t wd 0.0100\ttime 0.0386 (0.0361)\tloss 0.6772 (0.7885)\tgrad_norm 1.9613 (2.0638)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][610/625]\teta 0:00:00 lr 0.000715\t wd 0.0100\ttime 0.0353 (0.0361)\tloss 0.8857 (0.7886)\tgrad_norm 2.1074 (2.0610)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [37/100][620/625]\teta 0:00:00 lr 0.000715\t wd 0.0100\ttime 0.0365 (0.0361)\tloss 0.7090 (0.7877)\tgrad_norm 1.8077 (2.0580)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 37 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_37.pth saving......\n",
      "./model_save/ckpt_epoch_37.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 1.0273 (1.0273)\tAcc@1 62.500 (62.500)\tAcc@5 96.875 (96.875)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.6606 (0.7694)\tAcc@1 73.438 (70.881)\tAcc@5 100.000 (98.153)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.6182 (0.7523)\tAcc@1 75.000 (71.801)\tAcc@5 98.438 (98.065)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.016 (0.015)\tLoss 1.0293 (0.7668)\tAcc@1 62.500 (71.623)\tAcc@5 96.875 (98.135)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.016)\tLoss 0.8125 (0.7762)\tAcc@1 71.875 (71.951)\tAcc@5 98.438 (98.018)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.8042 (0.7797)\tAcc@1 73.438 (71.906)\tAcc@5 100.000 (98.162)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.6538 (0.7799)\tAcc@1 78.125 (72.054)\tAcc@5 98.438 (98.130)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.8467 (0.7797)\tAcc@1 70.312 (72.073)\tAcc@5 98.438 (98.173)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.016 (0.015)\tLoss 0.6372 (0.7839)\tAcc@1 71.875 (72.029)\tAcc@5 100.000 (98.264)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.6445 (0.7854)\tAcc@1 84.375 (72.081)\tAcc@5 96.875 (98.231)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.6528 (0.7812)\tAcc@1 70.312 (72.184)\tAcc@5 100.000 (98.221)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.9097 (0.7870)\tAcc@1 68.750 (72.086)\tAcc@5 96.875 (98.170)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.8140 (0.7889)\tAcc@1 71.875 (71.901)\tAcc@5 96.875 (98.140)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.9341 (0.7858)\tAcc@1 70.312 (71.947)\tAcc@5 93.750 (98.139)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.6963 (0.7853)\tAcc@1 73.438 (71.941)\tAcc@5 100.000 (98.149)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.5698 (0.7839)\tAcc@1 79.688 (71.989)\tAcc@5 100.000 (98.168)\tMem 455MB\n",
      " * Acc@1 71.880 Acc@5 98.130\n",
      "Accuracy of the network on the 10000 test images: 71.9%\n",
      "Max accuracy: 71.88%\n",
      "Train: [38/100][0/625]\teta 0:00:26 lr 0.000715\t wd 0.0100\ttime 0.0421 (0.0421)\tloss 0.6250 (0.6250)\tgrad_norm 2.0487 (2.0487)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][10/625]\teta 0:00:22 lr 0.000714\t wd 0.0100\ttime 0.0368 (0.0370)\tloss 0.5405 (0.6920)\tgrad_norm 1.4309 (1.9771)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][20/625]\teta 0:00:22 lr 0.000714\t wd 0.0100\ttime 0.0394 (0.0374)\tloss 0.6777 (0.7204)\tgrad_norm 2.1481 (2.0010)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][30/625]\teta 0:00:22 lr 0.000714\t wd 0.0100\ttime 0.0327 (0.0370)\tloss 0.7603 (0.7200)\tgrad_norm 2.2239 (2.0234)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][40/625]\teta 0:00:21 lr 0.000714\t wd 0.0100\ttime 0.0333 (0.0362)\tloss 0.5439 (0.7276)\tgrad_norm 1.1252 (2.0472)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][50/625]\teta 0:00:20 lr 0.000713\t wd 0.0100\ttime 0.0371 (0.0360)\tloss 0.9951 (0.7454)\tgrad_norm 2.6183 (2.0477)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][60/625]\teta 0:00:20 lr 0.000713\t wd 0.0100\ttime 0.0357 (0.0364)\tloss 0.7695 (0.7478)\tgrad_norm 2.2038 (2.0651)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][70/625]\teta 0:00:20 lr 0.000713\t wd 0.0100\ttime 0.0379 (0.0365)\tloss 0.8018 (0.7468)\tgrad_norm 1.6733 (2.0344)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][80/625]\teta 0:00:19 lr 0.000713\t wd 0.0100\ttime 0.0355 (0.0365)\tloss 0.7671 (0.7484)\tgrad_norm 1.6070 (2.0286)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][90/625]\teta 0:00:19 lr 0.000713\t wd 0.0100\ttime 0.0401 (0.0366)\tloss 0.7891 (0.7442)\tgrad_norm 3.1006 (2.0213)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][100/625]\teta 0:00:19 lr 0.000712\t wd 0.0100\ttime 0.0360 (0.0366)\tloss 0.8389 (0.7518)\tgrad_norm 2.1144 (2.0281)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][110/625]\teta 0:00:18 lr 0.000712\t wd 0.0100\ttime 0.0350 (0.0365)\tloss 0.6235 (0.7504)\tgrad_norm 1.8125 (2.0476)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][120/625]\teta 0:00:18 lr 0.000712\t wd 0.0100\ttime 0.0393 (0.0365)\tloss 0.9541 (0.7530)\tgrad_norm 2.6209 (2.0658)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][130/625]\teta 0:00:18 lr 0.000712\t wd 0.0100\ttime 0.0351 (0.0364)\tloss 0.6812 (0.7477)\tgrad_norm 2.3818 (2.0750)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][140/625]\teta 0:00:17 lr 0.000711\t wd 0.0100\ttime 0.0328 (0.0364)\tloss 0.7744 (0.7486)\tgrad_norm 1.8553 (2.0827)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][150/625]\teta 0:00:17 lr 0.000711\t wd 0.0100\ttime 0.0351 (0.0364)\tloss 0.7710 (0.7479)\tgrad_norm 1.9563 (2.0931)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][160/625]\teta 0:00:16 lr 0.000711\t wd 0.0100\ttime 0.0355 (0.0363)\tloss 0.9146 (0.7520)\tgrad_norm 2.4644 (2.1142)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][170/625]\teta 0:00:16 lr 0.000711\t wd 0.0100\ttime 0.0357 (0.0363)\tloss 0.6763 (0.7531)\tgrad_norm 1.9972 (2.1181)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][180/625]\teta 0:00:16 lr 0.000710\t wd 0.0100\ttime 0.0352 (0.0363)\tloss 0.8525 (0.7552)\tgrad_norm 2.6948 (2.1186)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][190/625]\teta 0:00:15 lr 0.000710\t wd 0.0100\ttime 0.0334 (0.0362)\tloss 0.8662 (0.7576)\tgrad_norm 1.9352 (2.1347)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][200/625]\teta 0:00:15 lr 0.000710\t wd 0.0100\ttime 0.0385 (0.0362)\tloss 0.7856 (0.7558)\tgrad_norm 1.8698 (2.1324)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][210/625]\teta 0:00:15 lr 0.000710\t wd 0.0100\ttime 0.0329 (0.0362)\tloss 0.9058 (0.7561)\tgrad_norm 1.9400 (2.1163)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][220/625]\teta 0:00:14 lr 0.000709\t wd 0.0100\ttime 0.0360 (0.0362)\tloss 0.8228 (0.7562)\tgrad_norm 2.3494 (2.1067)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][230/625]\teta 0:00:14 lr 0.000709\t wd 0.0100\ttime 0.0396 (0.0363)\tloss 0.7515 (0.7573)\tgrad_norm 2.9297 (2.1109)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][240/625]\teta 0:00:13 lr 0.000709\t wd 0.0100\ttime 0.0334 (0.0363)\tloss 0.7119 (0.7587)\tgrad_norm 1.7796 (2.1186)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][250/625]\teta 0:00:13 lr 0.000709\t wd 0.0100\ttime 0.0361 (0.0362)\tloss 0.7437 (0.7609)\tgrad_norm 1.8494 (2.1203)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][260/625]\teta 0:00:13 lr 0.000709\t wd 0.0100\ttime 0.0401 (0.0362)\tloss 0.7476 (0.7633)\tgrad_norm 1.5874 (2.1210)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][270/625]\teta 0:00:12 lr 0.000708\t wd 0.0100\ttime 0.0331 (0.0362)\tloss 0.7690 (0.7645)\tgrad_norm 1.3868 (2.1135)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][280/625]\teta 0:00:12 lr 0.000708\t wd 0.0100\ttime 0.0338 (0.0361)\tloss 0.6807 (0.7650)\tgrad_norm 1.6428 (2.1030)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][290/625]\teta 0:00:12 lr 0.000708\t wd 0.0100\ttime 0.0361 (0.0361)\tloss 0.6548 (0.7666)\tgrad_norm 2.1757 (2.1017)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][300/625]\teta 0:00:11 lr 0.000708\t wd 0.0100\ttime 0.0390 (0.0361)\tloss 0.7285 (0.7657)\tgrad_norm 2.0042 (2.0934)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][310/625]\teta 0:00:11 lr 0.000707\t wd 0.0100\ttime 0.0324 (0.0360)\tloss 0.9473 (0.7668)\tgrad_norm 1.9202 (2.0949)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][320/625]\teta 0:00:10 lr 0.000707\t wd 0.0100\ttime 0.0353 (0.0360)\tloss 0.7324 (0.7671)\tgrad_norm 2.0943 (2.0943)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][330/625]\teta 0:00:10 lr 0.000707\t wd 0.0100\ttime 0.0355 (0.0360)\tloss 0.5962 (0.7669)\tgrad_norm 1.3077 (2.0882)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][340/625]\teta 0:00:10 lr 0.000707\t wd 0.0100\ttime 0.0362 (0.0360)\tloss 0.8560 (0.7674)\tgrad_norm 1.7582 (2.0835)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][350/625]\teta 0:00:09 lr 0.000706\t wd 0.0100\ttime 0.0322 (0.0359)\tloss 0.8491 (0.7691)\tgrad_norm 2.5470 (2.0813)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][360/625]\teta 0:00:09 lr 0.000706\t wd 0.0100\ttime 0.0360 (0.0358)\tloss 0.6143 (0.7684)\tgrad_norm 1.6502 (2.0754)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][370/625]\teta 0:00:09 lr 0.000706\t wd 0.0100\ttime 0.0324 (0.0358)\tloss 0.8354 (0.7699)\tgrad_norm 1.8573 (2.0737)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][380/625]\teta 0:00:08 lr 0.000706\t wd 0.0100\ttime 0.0354 (0.0357)\tloss 0.7383 (0.7696)\tgrad_norm 2.0517 (2.0706)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][390/625]\teta 0:00:08 lr 0.000705\t wd 0.0100\ttime 0.0386 (0.0357)\tloss 1.0381 (0.7723)\tgrad_norm 1.8890 (2.0629)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][400/625]\teta 0:00:08 lr 0.000705\t wd 0.0100\ttime 0.0330 (0.0357)\tloss 0.7690 (0.7720)\tgrad_norm 2.0835 (2.0577)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][410/625]\teta 0:00:07 lr 0.000705\t wd 0.0100\ttime 0.0324 (0.0357)\tloss 0.7500 (0.7725)\tgrad_norm 1.5679 (2.0541)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][420/625]\teta 0:00:07 lr 0.000705\t wd 0.0100\ttime 0.0390 (0.0357)\tloss 0.7368 (0.7737)\tgrad_norm 1.6616 (2.0540)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][430/625]\teta 0:00:06 lr 0.000705\t wd 0.0100\ttime 0.0322 (0.0357)\tloss 0.8784 (0.7737)\tgrad_norm 2.9612 (2.0563)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][440/625]\teta 0:00:06 lr 0.000704\t wd 0.0100\ttime 0.0352 (0.0357)\tloss 1.2324 (0.7748)\tgrad_norm 3.0520 (2.0561)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][450/625]\teta 0:00:06 lr 0.000704\t wd 0.0100\ttime 0.0343 (0.0357)\tloss 0.7925 (0.7761)\tgrad_norm 2.3543 (2.0520)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][460/625]\teta 0:00:05 lr 0.000704\t wd 0.0100\ttime 0.0387 (0.0356)\tloss 0.8062 (0.7762)\tgrad_norm 1.6849 (2.0512)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][470/625]\teta 0:00:05 lr 0.000704\t wd 0.0100\ttime 0.0328 (0.0356)\tloss 0.5562 (0.7761)\tgrad_norm 1.7028 (2.0468)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][480/625]\teta 0:00:05 lr 0.000703\t wd 0.0100\ttime 0.0352 (0.0356)\tloss 0.8848 (0.7772)\tgrad_norm 2.3490 (2.0474)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][490/625]\teta 0:00:04 lr 0.000703\t wd 0.0100\ttime 0.0382 (0.0356)\tloss 0.9067 (0.7772)\tgrad_norm 1.9310 (2.0439)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][500/625]\teta 0:00:04 lr 0.000703\t wd 0.0100\ttime 0.0328 (0.0356)\tloss 0.7729 (0.7777)\tgrad_norm 1.8109 (2.0414)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][510/625]\teta 0:00:04 lr 0.000703\t wd 0.0100\ttime 0.0351 (0.0356)\tloss 0.8037 (0.7770)\tgrad_norm 1.6836 (2.0367)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][520/625]\teta 0:00:03 lr 0.000702\t wd 0.0100\ttime 0.0326 (0.0356)\tloss 0.7729 (0.7771)\tgrad_norm 1.9437 (2.0369)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][530/625]\teta 0:00:03 lr 0.000702\t wd 0.0100\ttime 0.0354 (0.0356)\tloss 0.9194 (0.7770)\tgrad_norm 2.3280 (2.0390)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][540/625]\teta 0:00:03 lr 0.000702\t wd 0.0100\ttime 0.0360 (0.0356)\tloss 0.8301 (0.7774)\tgrad_norm 2.2757 (2.0454)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][550/625]\teta 0:00:02 lr 0.000702\t wd 0.0100\ttime 0.0325 (0.0356)\tloss 0.7510 (0.7777)\tgrad_norm 1.6139 (2.0492)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][560/625]\teta 0:00:02 lr 0.000701\t wd 0.0100\ttime 0.0354 (0.0355)\tloss 0.5103 (0.7770)\tgrad_norm 1.5772 (2.0468)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][570/625]\teta 0:00:01 lr 0.000701\t wd 0.0100\ttime 0.0344 (0.0355)\tloss 0.6470 (0.7774)\tgrad_norm 2.1323 (2.0496)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][580/625]\teta 0:00:01 lr 0.000701\t wd 0.0100\ttime 0.0373 (0.0355)\tloss 0.7100 (0.7765)\tgrad_norm 1.3611 (2.0449)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][590/625]\teta 0:00:01 lr 0.000701\t wd 0.0100\ttime 0.0364 (0.0355)\tloss 0.8242 (0.7772)\tgrad_norm 1.7074 (2.0435)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][600/625]\teta 0:00:00 lr 0.000701\t wd 0.0100\ttime 0.0353 (0.0355)\tloss 0.8027 (0.7774)\tgrad_norm 2.6621 (2.0418)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][610/625]\teta 0:00:00 lr 0.000700\t wd 0.0100\ttime 0.0323 (0.0355)\tloss 0.6997 (0.7775)\tgrad_norm 2.3200 (2.0409)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [38/100][620/625]\teta 0:00:00 lr 0.000700\t wd 0.0100\ttime 0.0349 (0.0355)\tloss 0.7202 (0.7772)\tgrad_norm 2.1043 (2.0377)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 38 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_38.pth saving......\n",
      "./model_save/ckpt_epoch_38.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.6401 (0.6401)\tAcc@1 78.125 (78.125)\tAcc@5 100.000 (100.000)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.7236 (0.8255)\tAcc@1 71.875 (69.176)\tAcc@5 100.000 (98.153)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.6167 (0.8121)\tAcc@1 79.688 (70.164)\tAcc@5 100.000 (98.214)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.9209 (0.8036)\tAcc@1 68.750 (70.716)\tAcc@5 95.312 (98.135)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.6201 (0.7740)\tAcc@1 76.562 (71.761)\tAcc@5 100.000 (98.361)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.7085 (0.7792)\tAcc@1 73.438 (71.569)\tAcc@5 98.438 (98.376)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.6792 (0.7763)\tAcc@1 82.812 (72.106)\tAcc@5 98.438 (98.335)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.7896 (0.7708)\tAcc@1 75.000 (72.337)\tAcc@5 98.438 (98.393)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.7295 (0.7728)\tAcc@1 81.250 (72.434)\tAcc@5 96.875 (98.341)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.7832 (0.7720)\tAcc@1 73.438 (72.201)\tAcc@5 95.312 (98.420)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.7319 (0.7663)\tAcc@1 70.312 (72.386)\tAcc@5 100.000 (98.453)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.7842 (0.7601)\tAcc@1 73.438 (72.635)\tAcc@5 98.438 (98.480)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.019 (0.015)\tLoss 0.6865 (0.7615)\tAcc@1 73.438 (72.637)\tAcc@5 100.000 (98.463)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.7690 (0.7586)\tAcc@1 70.312 (72.770)\tAcc@5 96.875 (98.449)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.6870 (0.7618)\tAcc@1 70.312 (72.540)\tAcc@5 100.000 (98.426)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.8457 (0.7640)\tAcc@1 71.875 (72.486)\tAcc@5 98.438 (98.386)\tMem 455MB\n",
      " * Acc@1 72.550 Acc@5 98.370\n",
      "Accuracy of the network on the 10000 test images: 72.5%\n",
      "Max accuracy: 72.55%\n",
      "Train: [39/100][0/625]\teta 0:00:23 lr 0.000700\t wd 0.0100\ttime 0.0372 (0.0372)\tloss 0.8760 (0.8760)\tgrad_norm 2.3824 (2.3824)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [39/100][10/625]\teta 0:00:21 lr 0.000700\t wd 0.0100\ttime 0.0342 (0.0353)\tloss 0.8022 (0.8147)\tgrad_norm 1.7448 (2.0067)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [39/100][20/625]\teta 0:00:21 lr 0.000699\t wd 0.0100\ttime 0.0370 (0.0347)\tloss 0.9219 (0.8074)\tgrad_norm 1.8075 (2.0058)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [39/100][30/625]\teta 0:00:20 lr 0.000699\t wd 0.0100\ttime 0.0322 (0.0349)\tloss 0.8677 (0.8045)\tgrad_norm 2.9465 (2.0713)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [39/100][40/625]\teta 0:00:20 lr 0.000699\t wd 0.0100\ttime 0.0326 (0.0347)\tloss 0.8662 (0.7870)\tgrad_norm 1.6954 (2.0530)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [39/100][50/625]\teta 0:00:19 lr 0.000699\t wd 0.0100\ttime 0.0398 (0.0347)\tloss 0.5698 (0.7809)\tgrad_norm 1.5977 (2.0847)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [39/100][60/625]\teta 0:00:19 lr 0.000699\t wd 0.0100\ttime 0.0398 (0.0349)\tloss 0.7827 (0.7831)\tgrad_norm 2.0169 (2.0703)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [39/100][70/625]\teta 0:00:19 lr 0.000698\t wd 0.0100\ttime 0.0390 (0.0353)\tloss 0.7964 (0.7840)\tgrad_norm 1.9397 (2.0558)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [39/100][80/625]\teta 0:00:19 lr 0.000698\t wd 0.0100\ttime 0.0393 (0.0354)\tloss 0.8057 (0.7724)\tgrad_norm 2.6570 (2.0484)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [39/100][90/625]\teta 0:00:18 lr 0.000698\t wd 0.0100\ttime 0.0348 (0.0354)\tloss 0.6270 (0.7718)\tgrad_norm 1.5941 (2.0451)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [39/100][100/625]\teta 0:00:18 lr 0.000698\t wd 0.0100\ttime 0.0322 (0.0355)\tloss 0.8052 (0.7708)\tgrad_norm 1.6119 (2.0391)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [39/100][110/625]\teta 0:00:18 lr 0.000697\t wd 0.0100\ttime 0.0361 (0.0355)\tloss 0.7847 (0.7663)\tgrad_norm 2.8233 (2.0617)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [39/100][120/625]\teta 0:00:17 lr 0.000697\t wd 0.0100\ttime 0.0327 (0.0355)\tloss 1.1250 (0.7703)\tgrad_norm 3.2032 (2.0885)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [39/100][130/625]\teta 0:00:17 lr 0.000697\t wd 0.0100\ttime 0.0399 (0.0355)\tloss 0.7437 (0.7713)\tgrad_norm 2.1485 (2.0977)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [39/100][140/625]\teta 0:00:17 lr 0.000697\t wd 0.0100\ttime 0.0391 (0.0355)\tloss 0.9131 (0.7757)\tgrad_norm 2.2094 (2.1045)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [39/100][150/625]\teta 0:00:16 lr 0.000696\t wd 0.0100\ttime 0.0361 (0.0355)\tloss 0.7749 (0.7728)\tgrad_norm 2.3443 (2.1103)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [39/100][160/625]\teta 0:00:16 lr 0.000696\t wd 0.0100\ttime 0.0387 (0.0356)\tloss 0.7412 (0.7701)\tgrad_norm 1.8519 (2.1014)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [39/100][170/625]\teta 0:00:16 lr 0.000696\t wd 0.0100\ttime 0.0346 (0.0356)\tloss 1.0723 (0.7733)\tgrad_norm 3.2209 (2.1031)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [39/100][180/625]\teta 0:00:15 lr 0.000696\t wd 0.0100\ttime 0.0356 (0.0356)\tloss 0.7925 (0.7712)\tgrad_norm 2.1956 (2.0895)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [39/100][190/625]\teta 0:00:15 lr 0.000695\t wd 0.0100\ttime 0.0329 (0.0357)\tloss 0.9009 (0.7708)\tgrad_norm 1.8071 (2.0913)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [39/100][200/625]\teta 0:00:15 lr 0.000695\t wd 0.0100\ttime 0.0355 (0.0356)\tloss 1.1250 (0.7709)\tgrad_norm 1.9232 (2.0918)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [39/100][210/625]\teta 0:00:14 lr 0.000695\t wd 0.0100\ttime 0.0329 (0.0356)\tloss 0.7280 (0.7709)\tgrad_norm 1.8982 (2.0856)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [39/100][220/625]\teta 0:00:14 lr 0.000695\t wd 0.0100\ttime 0.0384 (0.0357)\tloss 0.9102 (0.7734)\tgrad_norm 1.9878 (2.0781)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [39/100][230/625]\teta 0:00:14 lr 0.000695\t wd 0.0100\ttime 0.0330 (0.0357)\tloss 0.7710 (0.7708)\tgrad_norm 1.7217 (2.0627)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [39/100][240/625]\teta 0:00:13 lr 0.000694\t wd 0.0100\ttime 0.0383 (0.0357)\tloss 0.6543 (0.7696)\tgrad_norm 1.7435 (2.0588)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [39/100][250/625]\teta 0:00:13 lr 0.000694\t wd 0.0100\ttime 0.0328 (0.0356)\tloss 0.7388 (0.7712)\tgrad_norm 2.2071 (2.0556)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [39/100][260/625]\teta 0:00:12 lr 0.000694\t wd 0.0100\ttime 0.0353 (0.0355)\tloss 0.9502 (0.7715)\tgrad_norm 2.4146 (2.0505)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [39/100][270/625]\teta 0:00:12 lr 0.000694\t wd 0.0100\ttime 0.0327 (0.0354)\tloss 0.6973 (0.7709)\tgrad_norm 1.6333 (2.0486)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [39/100][280/625]\teta 0:00:12 lr 0.000693\t wd 0.0100\ttime 0.0327 (0.0354)\tloss 0.9458 (0.7738)\tgrad_norm 2.3536 (2.0520)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [39/100][290/625]\teta 0:00:11 lr 0.000693\t wd 0.0100\ttime 0.0356 (0.0354)\tloss 0.5840 (0.7724)\tgrad_norm 1.4975 (2.0493)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [39/100][300/625]\teta 0:00:11 lr 0.000693\t wd 0.0100\ttime 0.0364 (0.0353)\tloss 0.5708 (0.7723)\tgrad_norm 1.5217 (2.0370)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [39/100][310/625]\teta 0:00:11 lr 0.000693\t wd 0.0100\ttime 0.0406 (0.0354)\tloss 0.8330 (0.7736)\tgrad_norm 1.8935 (2.0424)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [39/100][320/625]\teta 0:00:10 lr 0.000692\t wd 0.0100\ttime 0.0355 (0.0354)\tloss 0.7251 (0.7742)\tgrad_norm 1.4539 (2.0375)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [39/100][330/625]\teta 0:00:10 lr 0.000692\t wd 0.0100\ttime 0.0324 (0.0354)\tloss 0.8872 (0.7743)\tgrad_norm 2.3117 (2.0405)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [39/100][340/625]\teta 0:00:10 lr 0.000692\t wd 0.0100\ttime 0.0328 (0.0354)\tloss 0.6880 (0.7745)\tgrad_norm 2.0621 (2.0383)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [39/100][350/625]\teta 0:00:09 lr 0.000692\t wd 0.0100\ttime 0.0389 (0.0354)\tloss 0.8706 (0.7753)\tgrad_norm 2.4892 (2.0481)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [39/100][360/625]\teta 0:00:09 lr 0.000691\t wd 0.0100\ttime 0.0387 (0.0354)\tloss 0.7524 (0.7757)\tgrad_norm 2.4929 (2.0552)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [39/100][370/625]\teta 0:00:09 lr 0.000691\t wd 0.0100\ttime 0.0359 (0.0354)\tloss 0.6143 (0.7741)\tgrad_norm 1.8932 (2.0575)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [39/100][380/625]\teta 0:00:08 lr 0.000691\t wd 0.0100\ttime 0.0360 (0.0354)\tloss 0.7822 (0.7754)\tgrad_norm 2.1772 (2.0576)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [39/100][390/625]\teta 0:00:08 lr 0.000691\t wd 0.0100\ttime 0.0361 (0.0354)\tloss 0.8052 (0.7758)\tgrad_norm 1.2768 (nan)\tloss_scale 32768.0000 (32851.8056)\tmem 455MB\n",
      "Train: [39/100][400/625]\teta 0:00:07 lr 0.000690\t wd 0.0100\ttime 0.0326 (0.0353)\tloss 0.7388 (0.7738)\tgrad_norm 2.1041 (nan)\tloss_scale 32768.0000 (32849.7157)\tmem 455MB\n",
      "Train: [39/100][410/625]\teta 0:00:07 lr 0.000690\t wd 0.0100\ttime 0.0324 (0.0353)\tloss 0.6523 (0.7737)\tgrad_norm 2.2920 (nan)\tloss_scale 32768.0000 (32847.7275)\tmem 455MB\n",
      "Train: [39/100][420/625]\teta 0:00:07 lr 0.000690\t wd 0.0100\ttime 0.0331 (0.0353)\tloss 0.8164 (0.7745)\tgrad_norm 1.7842 (nan)\tloss_scale 32768.0000 (32845.8337)\tmem 455MB\n",
      "Train: [39/100][430/625]\teta 0:00:06 lr 0.000690\t wd 0.0100\ttime 0.0357 (0.0353)\tloss 0.7314 (0.7738)\tgrad_norm 1.7298 (nan)\tloss_scale 32768.0000 (32844.0278)\tmem 455MB\n",
      "Train: [39/100][440/625]\teta 0:00:06 lr 0.000690\t wd 0.0100\ttime 0.0390 (0.0353)\tloss 0.7554 (0.7735)\tgrad_norm 2.7680 (nan)\tloss_scale 32768.0000 (32842.3039)\tmem 455MB\n",
      "Train: [39/100][450/625]\teta 0:00:06 lr 0.000689\t wd 0.0100\ttime 0.0330 (0.0353)\tloss 0.6084 (0.7728)\tgrad_norm 2.0001 (nan)\tloss_scale 32768.0000 (32840.6563)\tmem 455MB\n",
      "Train: [39/100][460/625]\teta 0:00:05 lr 0.000689\t wd 0.0100\ttime 0.0328 (0.0352)\tloss 0.3938 (0.7708)\tgrad_norm 1.3852 (nan)\tloss_scale 32768.0000 (32839.0803)\tmem 455MB\n",
      "Train: [39/100][470/625]\teta 0:00:05 lr 0.000689\t wd 0.0100\ttime 0.0388 (0.0352)\tloss 0.8022 (0.7713)\tgrad_norm 2.2030 (nan)\tloss_scale 32768.0000 (32837.5711)\tmem 455MB\n",
      "Train: [39/100][480/625]\teta 0:00:05 lr 0.000689\t wd 0.0100\ttime 0.0397 (0.0353)\tloss 0.7329 (0.7720)\tgrad_norm 2.2197 (nan)\tloss_scale 32768.0000 (32836.1247)\tmem 455MB\n",
      "Train: [39/100][490/625]\teta 0:00:04 lr 0.000688\t wd 0.0100\ttime 0.0334 (0.0353)\tloss 0.7573 (0.7721)\tgrad_norm 1.6635 (nan)\tloss_scale 32768.0000 (32834.7373)\tmem 455MB\n",
      "Train: [39/100][500/625]\teta 0:00:04 lr 0.000688\t wd 0.0100\ttime 0.0365 (0.0354)\tloss 0.6582 (0.7712)\tgrad_norm 1.5044 (nan)\tloss_scale 32768.0000 (32833.4052)\tmem 455MB\n",
      "Train: [39/100][510/625]\teta 0:00:04 lr 0.000688\t wd 0.0100\ttime 0.0341 (0.0354)\tloss 0.6235 (0.7710)\tgrad_norm 1.9303 (nan)\tloss_scale 32768.0000 (32832.1252)\tmem 455MB\n",
      "Train: [39/100][520/625]\teta 0:00:03 lr 0.000688\t wd 0.0100\ttime 0.0352 (0.0354)\tloss 0.7109 (0.7711)\tgrad_norm 1.8661 (nan)\tloss_scale 32768.0000 (32830.8944)\tmem 455MB\n",
      "Train: [39/100][530/625]\teta 0:00:03 lr 0.000687\t wd 0.0100\ttime 0.0391 (0.0354)\tloss 0.8335 (0.7729)\tgrad_norm 2.0273 (nan)\tloss_scale 32768.0000 (32829.7100)\tmem 455MB\n",
      "Train: [39/100][540/625]\teta 0:00:03 lr 0.000687\t wd 0.0100\ttime 0.0364 (0.0354)\tloss 0.6631 (0.7728)\tgrad_norm 2.2643 (nan)\tloss_scale 32768.0000 (32828.5693)\tmem 455MB\n",
      "Train: [39/100][550/625]\teta 0:00:02 lr 0.000687\t wd 0.0100\ttime 0.0320 (0.0354)\tloss 1.0557 (0.7725)\tgrad_norm 2.4695 (nan)\tloss_scale 32768.0000 (32827.4701)\tmem 455MB\n",
      "Train: [39/100][560/625]\teta 0:00:02 lr 0.000687\t wd 0.0100\ttime 0.0327 (0.0354)\tloss 0.9014 (0.7722)\tgrad_norm 2.0981 (nan)\tloss_scale 32768.0000 (32826.4100)\tmem 455MB\n",
      "Train: [39/100][570/625]\teta 0:00:01 lr 0.000686\t wd 0.0100\ttime 0.0323 (0.0354)\tloss 0.5903 (0.7711)\tgrad_norm 1.4802 (nan)\tloss_scale 32768.0000 (32825.3870)\tmem 455MB\n",
      "Train: [39/100][580/625]\teta 0:00:01 lr 0.000686\t wd 0.0100\ttime 0.0322 (0.0353)\tloss 0.8018 (0.7713)\tgrad_norm 1.9212 (nan)\tloss_scale 32768.0000 (32824.3993)\tmem 455MB\n",
      "Train: [39/100][590/625]\teta 0:00:01 lr 0.000686\t wd 0.0100\ttime 0.0341 (0.0353)\tloss 0.6914 (0.7701)\tgrad_norm 1.9657 (nan)\tloss_scale 32768.0000 (32823.4450)\tmem 455MB\n",
      "Train: [39/100][600/625]\teta 0:00:00 lr 0.000686\t wd 0.0100\ttime 0.0370 (0.0353)\tloss 0.7324 (0.7702)\tgrad_norm 1.9114 (nan)\tloss_scale 32768.0000 (32822.5225)\tmem 455MB\n",
      "Train: [39/100][610/625]\teta 0:00:00 lr 0.000685\t wd 0.0100\ttime 0.0366 (0.0353)\tloss 0.7573 (0.7696)\tgrad_norm 2.6100 (nan)\tloss_scale 32768.0000 (32821.6301)\tmem 455MB\n",
      "Train: [39/100][620/625]\teta 0:00:00 lr 0.000685\t wd 0.0100\ttime 0.0354 (0.0353)\tloss 0.8701 (0.7687)\tgrad_norm 2.6595 (nan)\tloss_scale 32768.0000 (32820.7665)\tmem 455MB\n",
      "EPOCH 39 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_39.pth saving......\n",
      "./model_save/ckpt_epoch_39.pth saved !!!\n",
      "Test: [0/157]\tTime 0.017 (0.017)\tLoss 0.7456 (0.7456)\tAcc@1 73.438 (73.438)\tAcc@5 100.000 (100.000)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.016)\tLoss 0.5645 (0.7414)\tAcc@1 78.125 (72.869)\tAcc@5 100.000 (99.148)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.016 (0.016)\tLoss 0.6494 (0.7208)\tAcc@1 73.438 (73.214)\tAcc@5 100.000 (99.182)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.016)\tLoss 0.9141 (0.7204)\tAcc@1 60.938 (73.337)\tAcc@5 93.750 (99.093)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.016)\tLoss 0.6011 (0.7225)\tAcc@1 81.250 (73.628)\tAcc@5 100.000 (99.047)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.8032 (0.7583)\tAcc@1 70.312 (72.733)\tAcc@5 96.875 (98.775)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.7744 (0.7566)\tAcc@1 73.438 (72.720)\tAcc@5 98.438 (98.770)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.6997 (0.7594)\tAcc@1 75.000 (72.755)\tAcc@5 98.438 (98.592)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.7192 (0.7707)\tAcc@1 79.688 (72.550)\tAcc@5 98.438 (98.515)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.7847 (0.7683)\tAcc@1 70.312 (72.699)\tAcc@5 96.875 (98.506)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.7559 (0.7661)\tAcc@1 78.125 (72.834)\tAcc@5 98.438 (98.561)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.016 (0.015)\tLoss 0.7373 (0.7656)\tAcc@1 73.438 (72.987)\tAcc@5 98.438 (98.592)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.7339 (0.7639)\tAcc@1 68.750 (72.921)\tAcc@5 100.000 (98.580)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.9175 (0.7647)\tAcc@1 67.188 (73.080)\tAcc@5 96.875 (98.557)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.9771 (0.7701)\tAcc@1 59.375 (72.806)\tAcc@5 96.875 (98.526)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.9136 (0.7661)\tAcc@1 71.875 (72.920)\tAcc@5 96.875 (98.520)\tMem 455MB\n",
      " * Acc@1 72.780 Acc@5 98.530\n",
      "Accuracy of the network on the 10000 test images: 72.8%\n",
      "Max accuracy: 72.78%\n",
      "Train: [40/100][0/625]\teta 0:00:21 lr 0.000685\t wd 0.0100\ttime 0.0337 (0.0337)\tloss 0.8833 (0.8833)\tgrad_norm 2.8466 (2.8466)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][10/625]\teta 0:00:20 lr 0.000685\t wd 0.0100\ttime 0.0324 (0.0339)\tloss 0.8140 (0.7375)\tgrad_norm 2.1903 (1.9906)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][20/625]\teta 0:00:20 lr 0.000685\t wd 0.0100\ttime 0.0330 (0.0340)\tloss 0.8086 (0.7408)\tgrad_norm 1.7904 (1.9634)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][30/625]\teta 0:00:20 lr 0.000684\t wd 0.0100\ttime 0.0335 (0.0346)\tloss 0.7563 (0.7427)\tgrad_norm 1.9741 (1.9584)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][40/625]\teta 0:00:20 lr 0.000684\t wd 0.0100\ttime 0.0351 (0.0347)\tloss 0.7046 (0.7440)\tgrad_norm 1.9081 (2.0131)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][50/625]\teta 0:00:20 lr 0.000684\t wd 0.0100\ttime 0.0356 (0.0350)\tloss 0.5742 (0.7372)\tgrad_norm 1.8889 (1.9851)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][60/625]\teta 0:00:19 lr 0.000684\t wd 0.0100\ttime 0.0329 (0.0351)\tloss 0.6011 (0.7367)\tgrad_norm 2.1798 (1.9946)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][70/625]\teta 0:00:19 lr 0.000683\t wd 0.0100\ttime 0.0393 (0.0354)\tloss 0.7393 (0.7422)\tgrad_norm 2.3136 (2.0350)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][80/625]\teta 0:00:19 lr 0.000683\t wd 0.0100\ttime 0.0326 (0.0355)\tloss 0.8062 (0.7424)\tgrad_norm 1.8790 (2.0521)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][90/625]\teta 0:00:19 lr 0.000683\t wd 0.0100\ttime 0.0335 (0.0355)\tloss 0.9375 (0.7502)\tgrad_norm 2.1315 (2.0530)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][100/625]\teta 0:00:18 lr 0.000683\t wd 0.0100\ttime 0.0403 (0.0358)\tloss 0.6460 (0.7438)\tgrad_norm 1.9497 (2.0283)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][110/625]\teta 0:00:18 lr 0.000683\t wd 0.0100\ttime 0.0361 (0.0358)\tloss 0.8369 (0.7452)\tgrad_norm 2.1053 (2.0095)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][120/625]\teta 0:00:18 lr 0.000682\t wd 0.0100\ttime 0.0397 (0.0359)\tloss 0.9067 (0.7448)\tgrad_norm 2.3311 (2.0007)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][130/625]\teta 0:00:17 lr 0.000682\t wd 0.0100\ttime 0.0325 (0.0359)\tloss 0.6304 (0.7425)\tgrad_norm 2.0245 (2.0134)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][140/625]\teta 0:00:17 lr 0.000682\t wd 0.0100\ttime 0.0364 (0.0358)\tloss 0.7871 (0.7454)\tgrad_norm 2.4111 (2.0290)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][150/625]\teta 0:00:16 lr 0.000682\t wd 0.0100\ttime 0.0353 (0.0358)\tloss 0.7368 (0.7473)\tgrad_norm 2.0330 (2.0341)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][160/625]\teta 0:00:16 lr 0.000681\t wd 0.0100\ttime 0.0348 (0.0358)\tloss 0.6992 (0.7460)\tgrad_norm 1.9900 (2.0359)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][170/625]\teta 0:00:16 lr 0.000681\t wd 0.0100\ttime 0.0354 (0.0358)\tloss 0.7246 (0.7469)\tgrad_norm 1.6888 (2.0381)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][180/625]\teta 0:00:15 lr 0.000681\t wd 0.0100\ttime 0.0368 (0.0358)\tloss 0.8066 (0.7466)\tgrad_norm 1.6215 (2.0297)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][190/625]\teta 0:00:15 lr 0.000681\t wd 0.0100\ttime 0.0329 (0.0358)\tloss 0.6738 (0.7446)\tgrad_norm 1.4954 (2.0284)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][200/625]\teta 0:00:15 lr 0.000680\t wd 0.0100\ttime 0.0393 (0.0358)\tloss 0.6318 (0.7494)\tgrad_norm 1.5540 (2.0342)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][210/625]\teta 0:00:14 lr 0.000680\t wd 0.0100\ttime 0.0329 (0.0357)\tloss 0.6909 (0.7472)\tgrad_norm 1.6282 (2.0372)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][220/625]\teta 0:00:14 lr 0.000680\t wd 0.0100\ttime 0.0325 (0.0357)\tloss 0.7310 (0.7463)\tgrad_norm 1.7855 (2.0369)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][230/625]\teta 0:00:14 lr 0.000680\t wd 0.0100\ttime 0.0329 (0.0357)\tloss 0.5205 (0.7463)\tgrad_norm 2.1361 (2.0408)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][240/625]\teta 0:00:13 lr 0.000679\t wd 0.0100\ttime 0.0324 (0.0357)\tloss 0.7358 (0.7470)\tgrad_norm 1.6314 (2.0411)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][250/625]\teta 0:00:13 lr 0.000679\t wd 0.0100\ttime 0.0365 (0.0357)\tloss 0.9282 (0.7476)\tgrad_norm 2.4163 (2.0357)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][260/625]\teta 0:00:13 lr 0.000679\t wd 0.0100\ttime 0.0324 (0.0357)\tloss 0.9019 (0.7480)\tgrad_norm 2.5334 (2.0341)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][270/625]\teta 0:00:12 lr 0.000679\t wd 0.0100\ttime 0.0358 (0.0357)\tloss 0.7407 (0.7501)\tgrad_norm 1.9650 (2.0348)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][280/625]\teta 0:00:12 lr 0.000678\t wd 0.0100\ttime 0.0325 (0.0357)\tloss 0.7500 (0.7492)\tgrad_norm 1.7714 (2.0270)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][290/625]\teta 0:00:11 lr 0.000678\t wd 0.0100\ttime 0.0355 (0.0357)\tloss 0.7617 (0.7496)\tgrad_norm 1.3438 (2.0245)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][300/625]\teta 0:00:11 lr 0.000678\t wd 0.0100\ttime 0.0400 (0.0357)\tloss 0.8062 (0.7499)\tgrad_norm 1.6982 (2.0141)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][310/625]\teta 0:00:11 lr 0.000678\t wd 0.0100\ttime 0.0327 (0.0357)\tloss 0.6372 (0.7504)\tgrad_norm 1.5462 (2.0145)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][320/625]\teta 0:00:10 lr 0.000677\t wd 0.0100\ttime 0.0360 (0.0357)\tloss 1.0498 (0.7517)\tgrad_norm 2.7840 (2.0170)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][330/625]\teta 0:00:10 lr 0.000677\t wd 0.0100\ttime 0.0322 (0.0357)\tloss 0.7305 (0.7517)\tgrad_norm 1.8658 (2.0241)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][340/625]\teta 0:00:10 lr 0.000677\t wd 0.0100\ttime 0.0328 (0.0357)\tloss 0.7324 (0.7518)\tgrad_norm 2.7208 (2.0279)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][350/625]\teta 0:00:09 lr 0.000677\t wd 0.0100\ttime 0.0323 (0.0356)\tloss 0.7163 (0.7504)\tgrad_norm 2.1350 (2.0231)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][360/625]\teta 0:00:09 lr 0.000677\t wd 0.0100\ttime 0.0323 (0.0355)\tloss 0.9390 (0.7510)\tgrad_norm 1.7439 (2.0205)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][370/625]\teta 0:00:09 lr 0.000676\t wd 0.0100\ttime 0.0332 (0.0355)\tloss 0.7153 (0.7518)\tgrad_norm 1.6585 (2.0178)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][380/625]\teta 0:00:08 lr 0.000676\t wd 0.0100\ttime 0.0348 (0.0354)\tloss 0.8662 (0.7518)\tgrad_norm 1.7420 (2.0146)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][390/625]\teta 0:00:08 lr 0.000676\t wd 0.0100\ttime 0.0354 (0.0354)\tloss 0.6777 (0.7534)\tgrad_norm 2.0714 (2.0172)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][400/625]\teta 0:00:07 lr 0.000676\t wd 0.0100\ttime 0.0371 (0.0354)\tloss 0.6147 (0.7531)\tgrad_norm 1.9466 (2.0170)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][410/625]\teta 0:00:07 lr 0.000675\t wd 0.0100\ttime 0.0325 (0.0353)\tloss 0.9204 (0.7536)\tgrad_norm 2.3656 (2.0117)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][420/625]\teta 0:00:07 lr 0.000675\t wd 0.0100\ttime 0.0330 (0.0353)\tloss 0.8213 (0.7529)\tgrad_norm 2.3017 (2.0116)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][430/625]\teta 0:00:06 lr 0.000675\t wd 0.0100\ttime 0.0356 (0.0354)\tloss 0.7349 (0.7528)\tgrad_norm 2.5535 (2.0182)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][440/625]\teta 0:00:06 lr 0.000675\t wd 0.0100\ttime 0.0325 (0.0353)\tloss 0.7021 (0.7526)\tgrad_norm 1.9260 (2.0212)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][450/625]\teta 0:00:06 lr 0.000674\t wd 0.0100\ttime 0.0324 (0.0353)\tloss 0.8174 (0.7541)\tgrad_norm 2.1490 (2.0238)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][460/625]\teta 0:00:05 lr 0.000674\t wd 0.0100\ttime 0.0356 (0.0353)\tloss 0.7817 (0.7531)\tgrad_norm 1.8305 (2.0221)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][470/625]\teta 0:00:05 lr 0.000674\t wd 0.0100\ttime 0.0325 (0.0353)\tloss 0.7358 (0.7524)\tgrad_norm 2.0102 (2.0173)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][480/625]\teta 0:00:05 lr 0.000674\t wd 0.0100\ttime 0.0333 (0.0353)\tloss 0.6895 (0.7525)\tgrad_norm 1.6023 (2.0183)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][490/625]\teta 0:00:04 lr 0.000673\t wd 0.0100\ttime 0.0358 (0.0353)\tloss 0.7183 (0.7517)\tgrad_norm 2.4850 (2.0204)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][500/625]\teta 0:00:04 lr 0.000673\t wd 0.0100\ttime 0.0361 (0.0353)\tloss 0.6860 (0.7520)\tgrad_norm 1.5371 (2.0203)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][510/625]\teta 0:00:04 lr 0.000673\t wd 0.0100\ttime 0.0358 (0.0353)\tloss 0.5503 (0.7529)\tgrad_norm 1.3139 (2.0187)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][520/625]\teta 0:00:03 lr 0.000673\t wd 0.0100\ttime 0.0334 (0.0353)\tloss 0.6929 (0.7536)\tgrad_norm 2.0393 (2.0170)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][530/625]\teta 0:00:03 lr 0.000672\t wd 0.0100\ttime 0.0342 (0.0353)\tloss 0.6655 (0.7536)\tgrad_norm 1.9160 (2.0177)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][540/625]\teta 0:00:03 lr 0.000672\t wd 0.0100\ttime 0.0386 (0.0353)\tloss 0.6108 (0.7543)\tgrad_norm 1.5371 (2.0171)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][550/625]\teta 0:00:02 lr 0.000672\t wd 0.0100\ttime 0.0355 (0.0353)\tloss 0.6104 (0.7542)\tgrad_norm 2.4328 (2.0162)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][560/625]\teta 0:00:02 lr 0.000672\t wd 0.0100\ttime 0.0329 (0.0353)\tloss 0.9829 (0.7539)\tgrad_norm 2.0983 (2.0156)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][570/625]\teta 0:00:01 lr 0.000671\t wd 0.0100\ttime 0.0395 (0.0354)\tloss 0.6025 (0.7539)\tgrad_norm 1.6594 (2.0146)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][580/625]\teta 0:00:01 lr 0.000671\t wd 0.0100\ttime 0.0395 (0.0354)\tloss 0.6382 (0.7551)\tgrad_norm 1.5640 (2.0196)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][590/625]\teta 0:00:01 lr 0.000671\t wd 0.0100\ttime 0.0329 (0.0354)\tloss 0.5503 (0.7550)\tgrad_norm 1.5061 (2.0181)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][600/625]\teta 0:00:00 lr 0.000671\t wd 0.0100\ttime 0.0420 (0.0355)\tloss 0.9229 (0.7557)\tgrad_norm 3.5541 (2.0196)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][610/625]\teta 0:00:00 lr 0.000670\t wd 0.0100\ttime 0.0332 (0.0355)\tloss 0.8701 (0.7560)\tgrad_norm 1.9530 (2.0180)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [40/100][620/625]\teta 0:00:00 lr 0.000670\t wd 0.0100\ttime 0.0359 (0.0355)\tloss 0.7847 (0.7565)\tgrad_norm 2.2309 (2.0203)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 40 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_40.pth saving......\n",
      "./model_save/ckpt_epoch_40.pth saved !!!\n",
      "Test: [0/157]\tTime 0.020 (0.020)\tLoss 0.8896 (0.8896)\tAcc@1 67.188 (67.188)\tAcc@5 95.312 (95.312)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.7007 (0.7814)\tAcc@1 75.000 (72.443)\tAcc@5 98.438 (98.864)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.9731 (0.8146)\tAcc@1 57.812 (71.057)\tAcc@5 98.438 (98.586)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.6406 (0.7994)\tAcc@1 79.688 (71.371)\tAcc@5 98.438 (98.438)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.8359 (0.7901)\tAcc@1 70.312 (71.456)\tAcc@5 96.875 (98.323)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.7168 (0.7930)\tAcc@1 71.875 (71.262)\tAcc@5 100.000 (98.376)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.7603 (0.7876)\tAcc@1 73.438 (71.516)\tAcc@5 100.000 (98.463)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.7324 (0.7819)\tAcc@1 76.562 (72.051)\tAcc@5 96.875 (98.415)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.8984 (0.7783)\tAcc@1 71.875 (72.299)\tAcc@5 96.875 (98.283)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.7012 (0.7741)\tAcc@1 70.312 (72.442)\tAcc@5 100.000 (98.266)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.8486 (0.7711)\tAcc@1 71.875 (72.478)\tAcc@5 100.000 (98.283)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.016 (0.015)\tLoss 0.6313 (0.7753)\tAcc@1 75.000 (72.283)\tAcc@5 100.000 (98.255)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.016 (0.015)\tLoss 0.7847 (0.7687)\tAcc@1 71.875 (72.663)\tAcc@5 96.875 (98.244)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.9014 (0.7731)\tAcc@1 65.625 (72.579)\tAcc@5 98.438 (98.259)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.7598 (0.7733)\tAcc@1 71.875 (72.562)\tAcc@5 100.000 (98.282)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.8579 (0.7706)\tAcc@1 67.188 (72.599)\tAcc@5 98.438 (98.313)\tMem 455MB\n",
      " * Acc@1 72.610 Acc@5 98.320\n",
      "Accuracy of the network on the 10000 test images: 72.6%\n",
      "Max accuracy: 72.78%\n",
      "Train: [41/100][0/625]\teta 0:00:22 lr 0.000670\t wd 0.0100\ttime 0.0362 (0.0362)\tloss 0.7998 (0.7998)\tgrad_norm 2.5716 (2.5716)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][10/625]\teta 0:00:22 lr 0.000670\t wd 0.0100\ttime 0.0365 (0.0364)\tloss 0.9204 (0.7977)\tgrad_norm 2.3946 (2.2667)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][20/625]\teta 0:00:22 lr 0.000670\t wd 0.0100\ttime 0.0366 (0.0371)\tloss 0.9609 (0.8030)\tgrad_norm 2.6772 (2.2294)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][30/625]\teta 0:00:21 lr 0.000669\t wd 0.0100\ttime 0.0360 (0.0362)\tloss 0.7627 (0.7925)\tgrad_norm 1.9933 (2.1600)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][40/625]\teta 0:00:20 lr 0.000669\t wd 0.0100\ttime 0.0328 (0.0357)\tloss 0.5791 (0.7860)\tgrad_norm 1.8137 (2.1072)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][50/625]\teta 0:00:20 lr 0.000669\t wd 0.0100\ttime 0.0359 (0.0354)\tloss 0.6978 (0.7779)\tgrad_norm 1.6847 (2.0588)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][60/625]\teta 0:00:20 lr 0.000669\t wd 0.0100\ttime 0.0353 (0.0355)\tloss 0.5776 (0.7663)\tgrad_norm 1.7233 (2.0414)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][70/625]\teta 0:00:19 lr 0.000668\t wd 0.0100\ttime 0.0326 (0.0354)\tloss 0.8110 (0.7644)\tgrad_norm 2.2049 (2.0674)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][80/625]\teta 0:00:19 lr 0.000668\t wd 0.0100\ttime 0.0354 (0.0353)\tloss 0.8252 (0.7593)\tgrad_norm 1.9355 (2.0171)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][90/625]\teta 0:00:18 lr 0.000668\t wd 0.0100\ttime 0.0330 (0.0353)\tloss 0.7539 (0.7541)\tgrad_norm 1.7725 (2.0083)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][100/625]\teta 0:00:18 lr 0.000668\t wd 0.0100\ttime 0.0343 (0.0355)\tloss 0.7236 (0.7526)\tgrad_norm 2.1549 (2.0171)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][110/625]\teta 0:00:18 lr 0.000667\t wd 0.0100\ttime 0.0329 (0.0355)\tloss 0.6431 (0.7493)\tgrad_norm 1.4074 (2.0031)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][120/625]\teta 0:00:17 lr 0.000667\t wd 0.0100\ttime 0.0359 (0.0356)\tloss 0.7437 (0.7471)\tgrad_norm 1.5810 (2.0147)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][130/625]\teta 0:00:17 lr 0.000667\t wd 0.0100\ttime 0.0338 (0.0358)\tloss 0.6826 (0.7437)\tgrad_norm 2.5134 (2.0126)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][140/625]\teta 0:00:17 lr 0.000667\t wd 0.0100\ttime 0.0330 (0.0358)\tloss 0.7080 (0.7407)\tgrad_norm 2.6475 (2.0234)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][150/625]\teta 0:00:17 lr 0.000666\t wd 0.0100\ttime 0.0399 (0.0359)\tloss 0.8149 (0.7423)\tgrad_norm 1.7035 (2.0376)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][160/625]\teta 0:00:16 lr 0.000666\t wd 0.0100\ttime 0.0419 (0.0360)\tloss 0.7412 (0.7421)\tgrad_norm 2.0284 (2.0321)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][170/625]\teta 0:00:16 lr 0.000666\t wd 0.0100\ttime 0.0388 (0.0362)\tloss 0.9990 (0.7410)\tgrad_norm 2.4978 (2.0393)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][180/625]\teta 0:00:16 lr 0.000666\t wd 0.0100\ttime 0.0362 (0.0361)\tloss 0.8428 (0.7406)\tgrad_norm 1.6819 (2.0391)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][190/625]\teta 0:00:15 lr 0.000666\t wd 0.0100\ttime 0.0398 (0.0362)\tloss 0.5142 (0.7402)\tgrad_norm 1.5385 (2.0301)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][200/625]\teta 0:00:15 lr 0.000665\t wd 0.0100\ttime 0.0393 (0.0362)\tloss 0.7085 (0.7377)\tgrad_norm 2.5563 (2.0308)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][210/625]\teta 0:00:15 lr 0.000665\t wd 0.0100\ttime 0.0332 (0.0363)\tloss 0.7607 (0.7387)\tgrad_norm 1.8241 (2.0386)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][220/625]\teta 0:00:14 lr 0.000665\t wd 0.0100\ttime 0.0395 (0.0363)\tloss 0.8506 (0.7367)\tgrad_norm 2.2513 (2.0358)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][230/625]\teta 0:00:14 lr 0.000665\t wd 0.0100\ttime 0.0332 (0.0363)\tloss 0.6611 (0.7374)\tgrad_norm 2.1215 (2.0342)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][240/625]\teta 0:00:13 lr 0.000664\t wd 0.0100\ttime 0.0367 (0.0363)\tloss 0.7256 (0.7375)\tgrad_norm 2.4592 (2.0383)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][250/625]\teta 0:00:13 lr 0.000664\t wd 0.0100\ttime 0.0380 (0.0364)\tloss 0.6172 (0.7350)\tgrad_norm 1.5307 (2.0325)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][260/625]\teta 0:00:13 lr 0.000664\t wd 0.0100\ttime 0.0392 (0.0364)\tloss 1.0674 (0.7353)\tgrad_norm 2.6862 (2.0343)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][270/625]\teta 0:00:12 lr 0.000664\t wd 0.0100\ttime 0.0360 (0.0364)\tloss 0.8101 (0.7351)\tgrad_norm 1.8296 (2.0362)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][280/625]\teta 0:00:12 lr 0.000663\t wd 0.0100\ttime 0.0360 (0.0364)\tloss 0.7798 (0.7381)\tgrad_norm 2.3848 (2.0392)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][290/625]\teta 0:00:12 lr 0.000663\t wd 0.0100\ttime 0.0372 (0.0364)\tloss 0.6597 (0.7361)\tgrad_norm 1.9088 (2.0379)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][300/625]\teta 0:00:11 lr 0.000663\t wd 0.0100\ttime 0.0328 (0.0364)\tloss 0.7231 (0.7349)\tgrad_norm 1.6215 (2.0330)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][310/625]\teta 0:00:11 lr 0.000663\t wd 0.0100\ttime 0.0342 (0.0364)\tloss 0.8921 (0.7380)\tgrad_norm 2.4456 (2.0312)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][320/625]\teta 0:00:11 lr 0.000662\t wd 0.0100\ttime 0.0380 (0.0364)\tloss 0.9463 (0.7390)\tgrad_norm 2.3757 (2.0343)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][330/625]\teta 0:00:10 lr 0.000662\t wd 0.0100\ttime 0.0374 (0.0364)\tloss 0.8018 (0.7397)\tgrad_norm 1.9995 (2.0302)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][340/625]\teta 0:00:10 lr 0.000662\t wd 0.0100\ttime 0.0331 (0.0364)\tloss 0.8789 (0.7398)\tgrad_norm 2.5968 (2.0288)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][350/625]\teta 0:00:09 lr 0.000662\t wd 0.0100\ttime 0.0355 (0.0363)\tloss 0.8936 (0.7398)\tgrad_norm 2.0519 (2.0264)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][360/625]\teta 0:00:09 lr 0.000661\t wd 0.0100\ttime 0.0360 (0.0363)\tloss 0.7456 (0.7413)\tgrad_norm 1.7201 (2.0245)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][370/625]\teta 0:00:09 lr 0.000661\t wd 0.0100\ttime 0.0327 (0.0363)\tloss 0.8311 (0.7413)\tgrad_norm 2.0959 (2.0194)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][380/625]\teta 0:00:08 lr 0.000661\t wd 0.0100\ttime 0.0390 (0.0363)\tloss 0.6982 (0.7413)\tgrad_norm 1.7415 (2.0188)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][390/625]\teta 0:00:08 lr 0.000661\t wd 0.0100\ttime 0.0378 (0.0363)\tloss 0.5649 (0.7401)\tgrad_norm 1.8473 (2.0132)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][400/625]\teta 0:00:08 lr 0.000660\t wd 0.0100\ttime 0.0381 (0.0364)\tloss 0.7842 (0.7397)\tgrad_norm 2.7995 (2.0157)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][410/625]\teta 0:00:07 lr 0.000660\t wd 0.0100\ttime 0.0378 (0.0364)\tloss 0.7725 (0.7397)\tgrad_norm 2.4146 (2.0191)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][420/625]\teta 0:00:07 lr 0.000660\t wd 0.0100\ttime 0.0397 (0.0364)\tloss 0.6748 (0.7402)\tgrad_norm 1.7293 (2.0166)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][430/625]\teta 0:00:07 lr 0.000660\t wd 0.0100\ttime 0.0393 (0.0364)\tloss 0.8174 (0.7389)\tgrad_norm 2.4967 (2.0136)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][440/625]\teta 0:00:06 lr 0.000659\t wd 0.0100\ttime 0.0353 (0.0364)\tloss 0.5205 (0.7393)\tgrad_norm 1.4717 (2.0131)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][450/625]\teta 0:00:06 lr 0.000659\t wd 0.0100\ttime 0.0369 (0.0364)\tloss 0.7935 (0.7400)\tgrad_norm 1.9686 (2.0082)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][460/625]\teta 0:00:05 lr 0.000659\t wd 0.0100\ttime 0.0326 (0.0364)\tloss 0.9072 (0.7411)\tgrad_norm 1.9534 (2.0073)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][470/625]\teta 0:00:05 lr 0.000659\t wd 0.0100\ttime 0.0328 (0.0363)\tloss 0.5312 (0.7402)\tgrad_norm 1.3820 (2.0001)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][480/625]\teta 0:00:05 lr 0.000658\t wd 0.0100\ttime 0.0343 (0.0363)\tloss 0.7593 (0.7390)\tgrad_norm 2.0474 (1.9996)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][490/625]\teta 0:00:04 lr 0.000658\t wd 0.0100\ttime 0.0361 (0.0363)\tloss 0.8569 (0.7388)\tgrad_norm 2.5762 (2.0032)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][500/625]\teta 0:00:04 lr 0.000658\t wd 0.0100\ttime 0.0390 (0.0363)\tloss 1.0605 (0.7376)\tgrad_norm 2.4962 (2.0005)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][510/625]\teta 0:00:04 lr 0.000658\t wd 0.0100\ttime 0.0364 (0.0363)\tloss 0.8569 (0.7382)\tgrad_norm 3.6105 (2.0035)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][520/625]\teta 0:00:03 lr 0.000657\t wd 0.0100\ttime 0.0398 (0.0363)\tloss 0.7300 (0.7399)\tgrad_norm 2.2174 (2.0055)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][530/625]\teta 0:00:03 lr 0.000657\t wd 0.0100\ttime 0.0339 (0.0363)\tloss 0.7930 (0.7412)\tgrad_norm 1.6613 (2.0056)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][540/625]\teta 0:00:03 lr 0.000657\t wd 0.0100\ttime 0.0385 (0.0363)\tloss 1.0938 (0.7429)\tgrad_norm 2.1707 (2.0128)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][550/625]\teta 0:00:02 lr 0.000657\t wd 0.0100\ttime 0.0328 (0.0363)\tloss 0.6802 (0.7429)\tgrad_norm 1.8869 (2.0157)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][560/625]\teta 0:00:02 lr 0.000656\t wd 0.0100\ttime 0.0325 (0.0363)\tloss 0.6143 (0.7422)\tgrad_norm 1.4995 (2.0121)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][570/625]\teta 0:00:01 lr 0.000656\t wd 0.0100\ttime 0.0328 (0.0363)\tloss 0.8921 (0.7427)\tgrad_norm 1.9227 (2.0083)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][580/625]\teta 0:00:01 lr 0.000656\t wd 0.0100\ttime 0.0358 (0.0363)\tloss 0.4578 (0.7424)\tgrad_norm 2.0289 (2.0091)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][590/625]\teta 0:00:01 lr 0.000656\t wd 0.0100\ttime 0.0348 (0.0363)\tloss 0.5991 (0.7421)\tgrad_norm 2.4190 (2.0076)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][600/625]\teta 0:00:00 lr 0.000656\t wd 0.0100\ttime 0.0391 (0.0363)\tloss 0.8174 (0.7419)\tgrad_norm 1.9022 (2.0094)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][610/625]\teta 0:00:00 lr 0.000655\t wd 0.0100\ttime 0.0364 (0.0363)\tloss 0.4731 (0.7423)\tgrad_norm 1.9058 (2.0119)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [41/100][620/625]\teta 0:00:00 lr 0.000655\t wd 0.0100\ttime 0.0386 (0.0363)\tloss 0.7505 (0.7420)\tgrad_norm 2.0912 (2.0118)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 41 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_41.pth saving......\n",
      "./model_save/ckpt_epoch_41.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.8677 (0.8677)\tAcc@1 67.188 (67.188)\tAcc@5 96.875 (96.875)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.7290 (0.7414)\tAcc@1 65.625 (71.591)\tAcc@5 100.000 (98.722)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.8301 (0.7348)\tAcc@1 73.438 (73.512)\tAcc@5 98.438 (98.512)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.7607 (0.7524)\tAcc@1 76.562 (73.740)\tAcc@5 96.875 (98.538)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.016 (0.015)\tLoss 0.8120 (0.7587)\tAcc@1 71.875 (73.361)\tAcc@5 96.875 (98.476)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.7339 (0.7498)\tAcc@1 70.312 (73.468)\tAcc@5 96.875 (98.591)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.5347 (0.7491)\tAcc@1 81.250 (73.438)\tAcc@5 98.438 (98.566)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.7739 (0.7402)\tAcc@1 75.000 (73.878)\tAcc@5 100.000 (98.680)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.8628 (0.7444)\tAcc@1 71.875 (73.727)\tAcc@5 96.875 (98.688)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.8823 (0.7532)\tAcc@1 68.750 (73.438)\tAcc@5 98.438 (98.678)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.8647 (0.7472)\tAcc@1 68.750 (73.685)\tAcc@5 98.438 (98.654)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.8618 (0.7506)\tAcc@1 65.625 (73.452)\tAcc@5 100.000 (98.663)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.8574 (0.7520)\tAcc@1 70.312 (73.450)\tAcc@5 98.438 (98.631)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.6230 (0.7519)\tAcc@1 78.125 (73.461)\tAcc@5 100.000 (98.604)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.4814 (0.7491)\tAcc@1 84.375 (73.537)\tAcc@5 98.438 (98.637)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 1.0332 (0.7524)\tAcc@1 67.188 (73.438)\tAcc@5 100.000 (98.624)\tMem 455MB\n",
      " * Acc@1 73.460 Acc@5 98.590\n",
      "Accuracy of the network on the 10000 test images: 73.5%\n",
      "Max accuracy: 73.46%\n",
      "Train: [42/100][0/625]\teta 0:00:24 lr 0.000655\t wd 0.0100\ttime 0.0395 (0.0395)\tloss 0.7290 (0.7290)\tgrad_norm 1.5540 (1.5540)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][10/625]\teta 0:00:23 lr 0.000655\t wd 0.0100\ttime 0.0367 (0.0382)\tloss 0.7070 (0.7092)\tgrad_norm 2.2180 (1.9744)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][20/625]\teta 0:00:23 lr 0.000654\t wd 0.0100\ttime 0.0417 (0.0395)\tloss 0.7344 (0.7052)\tgrad_norm 3.1341 (2.0164)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][30/625]\teta 0:00:23 lr 0.000654\t wd 0.0100\ttime 0.0386 (0.0391)\tloss 0.5059 (0.7058)\tgrad_norm 1.5665 (2.0789)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][40/625]\teta 0:00:22 lr 0.000654\t wd 0.0100\ttime 0.0396 (0.0387)\tloss 0.4758 (0.6938)\tgrad_norm 2.1849 (2.0737)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][50/625]\teta 0:00:22 lr 0.000654\t wd 0.0100\ttime 0.0354 (0.0386)\tloss 0.7822 (0.7091)\tgrad_norm 2.2714 (2.0641)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][60/625]\teta 0:00:21 lr 0.000653\t wd 0.0100\ttime 0.0405 (0.0389)\tloss 0.7041 (0.7002)\tgrad_norm 1.4203 (2.0185)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][70/625]\teta 0:00:21 lr 0.000653\t wd 0.0100\ttime 0.0387 (0.0392)\tloss 0.7661 (0.7002)\tgrad_norm 2.4440 (2.0244)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][80/625]\teta 0:00:21 lr 0.000653\t wd 0.0100\ttime 0.0330 (0.0389)\tloss 0.8145 (0.7028)\tgrad_norm 2.6999 (2.0211)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][90/625]\teta 0:00:20 lr 0.000653\t wd 0.0100\ttime 0.0351 (0.0385)\tloss 1.0107 (0.7210)\tgrad_norm 2.0205 (2.0303)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][100/625]\teta 0:00:20 lr 0.000652\t wd 0.0100\ttime 0.0355 (0.0384)\tloss 0.7236 (0.7259)\tgrad_norm 1.7490 (2.0304)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][110/625]\teta 0:00:19 lr 0.000652\t wd 0.0100\ttime 0.0333 (0.0382)\tloss 0.8540 (0.7259)\tgrad_norm 2.0670 (2.0119)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][120/625]\teta 0:00:19 lr 0.000652\t wd 0.0100\ttime 0.0330 (0.0380)\tloss 0.6719 (0.7211)\tgrad_norm 1.7213 (1.9946)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][130/625]\teta 0:00:18 lr 0.000652\t wd 0.0100\ttime 0.0340 (0.0378)\tloss 0.6938 (0.7215)\tgrad_norm 1.5739 (1.9804)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][140/625]\teta 0:00:18 lr 0.000651\t wd 0.0100\ttime 0.0357 (0.0378)\tloss 0.6997 (0.7217)\tgrad_norm 1.8816 (1.9670)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][150/625]\teta 0:00:17 lr 0.000651\t wd 0.0100\ttime 0.0369 (0.0377)\tloss 0.6494 (0.7235)\tgrad_norm 1.5495 (1.9656)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][160/625]\teta 0:00:17 lr 0.000651\t wd 0.0100\ttime 0.0329 (0.0376)\tloss 0.6709 (0.7220)\tgrad_norm 2.1945 (1.9757)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][170/625]\teta 0:00:17 lr 0.000651\t wd 0.0100\ttime 0.0386 (0.0376)\tloss 0.8276 (0.7240)\tgrad_norm 1.4575 (1.9798)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][180/625]\teta 0:00:16 lr 0.000651\t wd 0.0100\ttime 0.0379 (0.0375)\tloss 0.8174 (0.7235)\tgrad_norm 2.4949 (1.9821)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][190/625]\teta 0:00:16 lr 0.000650\t wd 0.0100\ttime 0.0330 (0.0375)\tloss 0.8594 (0.7216)\tgrad_norm 2.1090 (1.9851)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][200/625]\teta 0:00:15 lr 0.000650\t wd 0.0100\ttime 0.0346 (0.0374)\tloss 0.5791 (0.7176)\tgrad_norm 2.2648 (1.9844)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][210/625]\teta 0:00:15 lr 0.000650\t wd 0.0100\ttime 0.0325 (0.0374)\tloss 0.5596 (0.7164)\tgrad_norm 2.0661 (1.9903)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][220/625]\teta 0:00:15 lr 0.000650\t wd 0.0100\ttime 0.0325 (0.0374)\tloss 0.6499 (0.7163)\tgrad_norm 1.7792 (1.9929)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][230/625]\teta 0:00:14 lr 0.000649\t wd 0.0100\ttime 0.0391 (0.0373)\tloss 0.7148 (0.7184)\tgrad_norm 2.5816 (1.9959)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][240/625]\teta 0:00:14 lr 0.000649\t wd 0.0100\ttime 0.0380 (0.0373)\tloss 0.9458 (0.7191)\tgrad_norm 1.9425 (2.0095)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][250/625]\teta 0:00:13 lr 0.000649\t wd 0.0100\ttime 0.0379 (0.0373)\tloss 0.7993 (0.7204)\tgrad_norm 1.6822 (2.0103)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][260/625]\teta 0:00:13 lr 0.000649\t wd 0.0100\ttime 0.0328 (0.0373)\tloss 0.4839 (0.7228)\tgrad_norm 1.6086 (2.0070)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][270/625]\teta 0:00:13 lr 0.000648\t wd 0.0100\ttime 0.0358 (0.0372)\tloss 0.8379 (0.7240)\tgrad_norm 1.8004 (1.9995)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][280/625]\teta 0:00:12 lr 0.000648\t wd 0.0100\ttime 0.0328 (0.0372)\tloss 0.7944 (0.7246)\tgrad_norm 2.0731 (1.9921)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][290/625]\teta 0:00:12 lr 0.000648\t wd 0.0100\ttime 0.0323 (0.0370)\tloss 0.5903 (0.7231)\tgrad_norm 1.9553 (1.9941)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][300/625]\teta 0:00:12 lr 0.000648\t wd 0.0100\ttime 0.0328 (0.0369)\tloss 0.7588 (0.7230)\tgrad_norm 2.0778 (1.9947)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][310/625]\teta 0:00:11 lr 0.000647\t wd 0.0100\ttime 0.0321 (0.0368)\tloss 0.8750 (0.7234)\tgrad_norm 2.0042 (1.9978)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][320/625]\teta 0:00:11 lr 0.000647\t wd 0.0100\ttime 0.0324 (0.0367)\tloss 0.8032 (0.7245)\tgrad_norm 2.0255 (1.9994)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][330/625]\teta 0:00:10 lr 0.000647\t wd 0.0100\ttime 0.0344 (0.0366)\tloss 0.5488 (0.7238)\tgrad_norm 1.3206 (1.9917)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][340/625]\teta 0:00:10 lr 0.000647\t wd 0.0100\ttime 0.0388 (0.0366)\tloss 0.6006 (0.7249)\tgrad_norm 2.1484 (1.9952)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][350/625]\teta 0:00:10 lr 0.000646\t wd 0.0100\ttime 0.0405 (0.0366)\tloss 0.6919 (0.7254)\tgrad_norm 1.9128 (1.9936)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][360/625]\teta 0:00:09 lr 0.000646\t wd 0.0100\ttime 0.0325 (0.0366)\tloss 0.8604 (0.7256)\tgrad_norm 2.1853 (1.9920)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][370/625]\teta 0:00:09 lr 0.000646\t wd 0.0100\ttime 0.0357 (0.0366)\tloss 0.8018 (0.7250)\tgrad_norm 2.0220 (1.9866)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][380/625]\teta 0:00:08 lr 0.000646\t wd 0.0100\ttime 0.0359 (0.0365)\tloss 0.5278 (0.7238)\tgrad_norm 1.9029 (1.9878)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][390/625]\teta 0:00:08 lr 0.000645\t wd 0.0100\ttime 0.0328 (0.0365)\tloss 0.8530 (0.7249)\tgrad_norm 2.0876 (1.9874)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][400/625]\teta 0:00:08 lr 0.000645\t wd 0.0100\ttime 0.0329 (0.0365)\tloss 0.6724 (0.7269)\tgrad_norm 1.6342 (1.9852)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][410/625]\teta 0:00:07 lr 0.000645\t wd 0.0100\ttime 0.0397 (0.0365)\tloss 0.6753 (0.7280)\tgrad_norm 1.8308 (1.9822)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][420/625]\teta 0:00:07 lr 0.000645\t wd 0.0100\ttime 0.0384 (0.0365)\tloss 0.7861 (0.7287)\tgrad_norm 2.0198 (1.9809)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][430/625]\teta 0:00:07 lr 0.000644\t wd 0.0100\ttime 0.0340 (0.0365)\tloss 0.7388 (0.7298)\tgrad_norm 1.4027 (1.9803)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][440/625]\teta 0:00:06 lr 0.000644\t wd 0.0100\ttime 0.0324 (0.0364)\tloss 0.7017 (0.7291)\tgrad_norm 1.6013 (1.9808)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][450/625]\teta 0:00:06 lr 0.000644\t wd 0.0100\ttime 0.0328 (0.0364)\tloss 0.5728 (0.7293)\tgrad_norm 1.8887 (1.9819)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][460/625]\teta 0:00:05 lr 0.000644\t wd 0.0100\ttime 0.0328 (0.0363)\tloss 0.7500 (0.7295)\tgrad_norm 1.8392 (1.9809)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][470/625]\teta 0:00:05 lr 0.000643\t wd 0.0100\ttime 0.0386 (0.0363)\tloss 0.5317 (0.7293)\tgrad_norm 1.4408 (1.9828)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][480/625]\teta 0:00:05 lr 0.000643\t wd 0.0100\ttime 0.0338 (0.0364)\tloss 0.8203 (0.7299)\tgrad_norm 2.1535 (1.9846)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][490/625]\teta 0:00:04 lr 0.000643\t wd 0.0100\ttime 0.0361 (0.0363)\tloss 0.7432 (0.7302)\tgrad_norm 2.3157 (1.9885)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][500/625]\teta 0:00:04 lr 0.000643\t wd 0.0100\ttime 0.0393 (0.0363)\tloss 0.6865 (0.7302)\tgrad_norm 1.9474 (1.9912)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [42/100][510/625]\teta 0:00:04 lr 0.000642\t wd 0.0100\ttime 0.0359 (0.0363)\tloss 0.8311 (0.7304)\tgrad_norm 1.6560 (1.9911)\tloss_scale 65536.0000 (32832.1252)\tmem 455MB\n",
      "Train: [42/100][520/625]\teta 0:00:03 lr 0.000642\t wd 0.0100\ttime 0.0329 (0.0363)\tloss 0.5127 (0.7302)\tgrad_norm 1.3945 (nan)\tloss_scale 32768.0000 (32830.8944)\tmem 455MB\n",
      "Train: [42/100][530/625]\teta 0:00:03 lr 0.000642\t wd 0.0100\ttime 0.0365 (0.0363)\tloss 0.6235 (0.7305)\tgrad_norm 1.9119 (nan)\tloss_scale 32768.0000 (32829.7100)\tmem 455MB\n",
      "Train: [42/100][540/625]\teta 0:00:03 lr 0.000642\t wd 0.0100\ttime 0.0356 (0.0363)\tloss 0.7363 (0.7303)\tgrad_norm 1.9094 (nan)\tloss_scale 32768.0000 (32828.5693)\tmem 455MB\n",
      "Train: [42/100][550/625]\teta 0:00:02 lr 0.000641\t wd 0.0100\ttime 0.0396 (0.0363)\tloss 0.6270 (0.7308)\tgrad_norm 2.0433 (nan)\tloss_scale 32768.0000 (32827.4701)\tmem 455MB\n",
      "Train: [42/100][560/625]\teta 0:00:02 lr 0.000641\t wd 0.0100\ttime 0.0328 (0.0363)\tloss 0.6709 (0.7302)\tgrad_norm 2.2194 (nan)\tloss_scale 32768.0000 (32826.4100)\tmem 455MB\n",
      "Train: [42/100][570/625]\teta 0:00:01 lr 0.000641\t wd 0.0100\ttime 0.0334 (0.0363)\tloss 0.9902 (0.7298)\tgrad_norm 2.1616 (nan)\tloss_scale 32768.0000 (32825.3870)\tmem 455MB\n",
      "Train: [42/100][580/625]\teta 0:00:01 lr 0.000641\t wd 0.0100\ttime 0.0328 (0.0363)\tloss 0.8716 (0.7303)\tgrad_norm 2.5692 (nan)\tloss_scale 32768.0000 (32824.3993)\tmem 455MB\n",
      "Train: [42/100][590/625]\teta 0:00:01 lr 0.000640\t wd 0.0100\ttime 0.0357 (0.0363)\tloss 0.9736 (0.7299)\tgrad_norm 2.8439 (nan)\tloss_scale 32768.0000 (32823.4450)\tmem 455MB\n",
      "Train: [42/100][600/625]\teta 0:00:00 lr 0.000640\t wd 0.0100\ttime 0.0331 (0.0362)\tloss 0.5728 (0.7286)\tgrad_norm 1.6520 (nan)\tloss_scale 32768.0000 (32822.5225)\tmem 455MB\n",
      "Train: [42/100][610/625]\teta 0:00:00 lr 0.000640\t wd 0.0100\ttime 0.0367 (0.0362)\tloss 0.5396 (0.7279)\tgrad_norm 1.8723 (nan)\tloss_scale 32768.0000 (32821.6301)\tmem 455MB\n",
      "Train: [42/100][620/625]\teta 0:00:00 lr 0.000640\t wd 0.0100\ttime 0.0329 (0.0362)\tloss 0.7388 (0.7283)\tgrad_norm 2.2837 (nan)\tloss_scale 32768.0000 (32820.7665)\tmem 455MB\n",
      "EPOCH 42 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_42.pth saving......\n",
      "./model_save/ckpt_epoch_42.pth saved !!!\n",
      "Test: [0/157]\tTime 0.017 (0.017)\tLoss 0.9561 (0.9561)\tAcc@1 64.062 (64.062)\tAcc@5 100.000 (100.000)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.5962 (0.7223)\tAcc@1 81.250 (74.148)\tAcc@5 100.000 (99.006)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.6675 (0.7064)\tAcc@1 73.438 (74.702)\tAcc@5 98.438 (98.586)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.6606 (0.7151)\tAcc@1 73.438 (74.294)\tAcc@5 100.000 (98.488)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 1.0400 (0.7384)\tAcc@1 67.188 (73.895)\tAcc@5 100.000 (98.399)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.6875 (0.7364)\tAcc@1 82.812 (73.958)\tAcc@5 96.875 (98.438)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.9136 (0.7461)\tAcc@1 70.312 (73.770)\tAcc@5 95.312 (98.258)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.7495 (0.7463)\tAcc@1 71.875 (73.834)\tAcc@5 100.000 (98.460)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.8862 (0.7451)\tAcc@1 65.625 (73.900)\tAcc@5 100.000 (98.399)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.8340 (0.7443)\tAcc@1 71.875 (73.832)\tAcc@5 100.000 (98.438)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.7427 (0.7428)\tAcc@1 71.875 (73.778)\tAcc@5 98.438 (98.422)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.7544 (0.7392)\tAcc@1 71.875 (73.958)\tAcc@5 96.875 (98.423)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.016 (0.015)\tLoss 0.7246 (0.7430)\tAcc@1 73.438 (73.735)\tAcc@5 100.000 (98.425)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.016 (0.015)\tLoss 0.8540 (0.7461)\tAcc@1 75.000 (73.533)\tAcc@5 96.875 (98.461)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.5132 (0.7408)\tAcc@1 85.938 (73.748)\tAcc@5 98.438 (98.482)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.5845 (0.7388)\tAcc@1 81.250 (73.882)\tAcc@5 98.438 (98.510)\tMem 455MB\n",
      " * Acc@1 74.070 Acc@5 98.510\n",
      "Accuracy of the network on the 10000 test images: 74.1%\n",
      "Max accuracy: 74.07%\n",
      "Train: [43/100][0/625]\teta 0:00:24 lr 0.000640\t wd 0.0100\ttime 0.0398 (0.0398)\tloss 0.6665 (0.6665)\tgrad_norm 2.0828 (2.0828)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][10/625]\teta 0:00:22 lr 0.000639\t wd 0.0100\ttime 0.0396 (0.0359)\tloss 0.6538 (0.7292)\tgrad_norm 1.3286 (1.8784)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][20/625]\teta 0:00:21 lr 0.000639\t wd 0.0100\ttime 0.0333 (0.0359)\tloss 0.5205 (0.7134)\tgrad_norm 1.9089 (1.9824)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][30/625]\teta 0:00:21 lr 0.000639\t wd 0.0100\ttime 0.0387 (0.0365)\tloss 0.7212 (0.7118)\tgrad_norm 1.9319 (1.9410)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][40/625]\teta 0:00:21 lr 0.000639\t wd 0.0100\ttime 0.0323 (0.0362)\tloss 0.8071 (0.7093)\tgrad_norm 2.2936 (1.9306)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][50/625]\teta 0:00:20 lr 0.000638\t wd 0.0100\ttime 0.0324 (0.0355)\tloss 0.5728 (0.7012)\tgrad_norm 2.0053 (1.9450)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][60/625]\teta 0:00:19 lr 0.000638\t wd 0.0100\ttime 0.0352 (0.0352)\tloss 0.6006 (0.7104)\tgrad_norm 1.2898 (1.9745)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][70/625]\teta 0:00:19 lr 0.000638\t wd 0.0100\ttime 0.0322 (0.0350)\tloss 0.7222 (0.7092)\tgrad_norm 2.3125 (1.9680)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][80/625]\teta 0:00:19 lr 0.000638\t wd 0.0100\ttime 0.0323 (0.0349)\tloss 0.7148 (0.7134)\tgrad_norm 1.7001 (1.9869)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][90/625]\teta 0:00:18 lr 0.000637\t wd 0.0100\ttime 0.0327 (0.0349)\tloss 0.5298 (0.7112)\tgrad_norm 1.8523 (2.0005)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][100/625]\teta 0:00:18 lr 0.000637\t wd 0.0100\ttime 0.0332 (0.0350)\tloss 0.6919 (0.7122)\tgrad_norm 2.3684 (2.0241)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][110/625]\teta 0:00:18 lr 0.000637\t wd 0.0100\ttime 0.0355 (0.0352)\tloss 0.8945 (0.7188)\tgrad_norm 1.6342 (2.0480)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][120/625]\teta 0:00:17 lr 0.000637\t wd 0.0100\ttime 0.0324 (0.0354)\tloss 0.6831 (0.7190)\tgrad_norm 1.5085 (2.0353)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][130/625]\teta 0:00:17 lr 0.000636\t wd 0.0100\ttime 0.0333 (0.0354)\tloss 0.6685 (0.7206)\tgrad_norm 2.1469 (2.0268)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][140/625]\teta 0:00:17 lr 0.000636\t wd 0.0100\ttime 0.0326 (0.0353)\tloss 0.6113 (0.7195)\tgrad_norm 1.6423 (2.0232)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][150/625]\teta 0:00:16 lr 0.000636\t wd 0.0100\ttime 0.0346 (0.0353)\tloss 0.6685 (0.7178)\tgrad_norm 2.1764 (2.0097)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][160/625]\teta 0:00:16 lr 0.000636\t wd 0.0100\ttime 0.0398 (0.0353)\tloss 0.7090 (0.7145)\tgrad_norm 2.2518 (2.0000)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][170/625]\teta 0:00:16 lr 0.000635\t wd 0.0100\ttime 0.0326 (0.0353)\tloss 0.6406 (0.7117)\tgrad_norm 1.5523 (1.9872)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][180/625]\teta 0:00:15 lr 0.000635\t wd 0.0100\ttime 0.0324 (0.0353)\tloss 0.7314 (0.7124)\tgrad_norm 2.2996 (1.9906)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][190/625]\teta 0:00:15 lr 0.000635\t wd 0.0100\ttime 0.0328 (0.0354)\tloss 0.5840 (0.7122)\tgrad_norm 1.4168 (2.0014)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][200/625]\teta 0:00:15 lr 0.000635\t wd 0.0100\ttime 0.0360 (0.0354)\tloss 0.8569 (0.7151)\tgrad_norm 2.2634 (2.0110)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][210/625]\teta 0:00:14 lr 0.000634\t wd 0.0100\ttime 0.0328 (0.0355)\tloss 0.6562 (0.7172)\tgrad_norm 2.1523 (2.0246)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][220/625]\teta 0:00:14 lr 0.000634\t wd 0.0100\ttime 0.0333 (0.0355)\tloss 0.6357 (0.7188)\tgrad_norm 1.7759 (2.0218)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][230/625]\teta 0:00:13 lr 0.000634\t wd 0.0100\ttime 0.0367 (0.0354)\tloss 0.8037 (0.7197)\tgrad_norm 1.7940 (2.0161)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][240/625]\teta 0:00:13 lr 0.000634\t wd 0.0100\ttime 0.0347 (0.0354)\tloss 0.6475 (0.7203)\tgrad_norm 1.6586 (2.0213)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][250/625]\teta 0:00:13 lr 0.000633\t wd 0.0100\ttime 0.0353 (0.0356)\tloss 0.6270 (0.7187)\tgrad_norm 1.3851 (2.0173)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][260/625]\teta 0:00:12 lr 0.000633\t wd 0.0100\ttime 0.0364 (0.0356)\tloss 0.9160 (0.7180)\tgrad_norm 2.2753 (2.0139)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][270/625]\teta 0:00:12 lr 0.000633\t wd 0.0100\ttime 0.0340 (0.0356)\tloss 0.4888 (0.7182)\tgrad_norm 1.2253 (2.0095)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][280/625]\teta 0:00:12 lr 0.000633\t wd 0.0100\ttime 0.0324 (0.0356)\tloss 0.8213 (0.7190)\tgrad_norm 2.1905 (2.0063)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][290/625]\teta 0:00:11 lr 0.000632\t wd 0.0100\ttime 0.0372 (0.0357)\tloss 0.6738 (0.7192)\tgrad_norm 1.4478 (2.0081)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][300/625]\teta 0:00:11 lr 0.000632\t wd 0.0100\ttime 0.0341 (0.0357)\tloss 0.6353 (0.7184)\tgrad_norm 1.3937 (2.0080)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][310/625]\teta 0:00:11 lr 0.000632\t wd 0.0100\ttime 0.0383 (0.0357)\tloss 0.5249 (0.7177)\tgrad_norm 1.3731 (2.0014)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][320/625]\teta 0:00:10 lr 0.000632\t wd 0.0100\ttime 0.0346 (0.0358)\tloss 0.7729 (0.7188)\tgrad_norm 1.6426 (2.0098)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][330/625]\teta 0:00:10 lr 0.000631\t wd 0.0100\ttime 0.0390 (0.0358)\tloss 0.5889 (0.7157)\tgrad_norm 1.6258 (2.0013)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][340/625]\teta 0:00:10 lr 0.000631\t wd 0.0100\ttime 0.0322 (0.0358)\tloss 0.7065 (0.7173)\tgrad_norm 2.1486 (2.0038)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][350/625]\teta 0:00:09 lr 0.000631\t wd 0.0100\ttime 0.0353 (0.0357)\tloss 0.5942 (0.7169)\tgrad_norm 1.4249 (2.0043)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][360/625]\teta 0:00:09 lr 0.000631\t wd 0.0100\ttime 0.0357 (0.0357)\tloss 0.5303 (0.7165)\tgrad_norm 1.2667 (2.0063)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][370/625]\teta 0:00:09 lr 0.000630\t wd 0.0100\ttime 0.0356 (0.0356)\tloss 0.6709 (0.7160)\tgrad_norm 1.5598 (2.0059)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][380/625]\teta 0:00:08 lr 0.000630\t wd 0.0100\ttime 0.0324 (0.0356)\tloss 0.2522 (0.7138)\tgrad_norm 1.0393 (2.0077)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][390/625]\teta 0:00:08 lr 0.000630\t wd 0.0100\ttime 0.0357 (0.0355)\tloss 0.6880 (0.7146)\tgrad_norm 1.7873 (2.0040)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][400/625]\teta 0:00:07 lr 0.000630\t wd 0.0100\ttime 0.0324 (0.0355)\tloss 0.6528 (0.7146)\tgrad_norm 1.9086 (2.0014)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][410/625]\teta 0:00:07 lr 0.000629\t wd 0.0100\ttime 0.0359 (0.0354)\tloss 0.7158 (0.7142)\tgrad_norm 2.1293 (1.9977)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][420/625]\teta 0:00:07 lr 0.000629\t wd 0.0100\ttime 0.0327 (0.0354)\tloss 0.7510 (0.7144)\tgrad_norm 1.8084 (1.9986)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][430/625]\teta 0:00:06 lr 0.000629\t wd 0.0100\ttime 0.0383 (0.0354)\tloss 0.7417 (0.7141)\tgrad_norm 2.0419 (1.9987)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][440/625]\teta 0:00:06 lr 0.000629\t wd 0.0100\ttime 0.0326 (0.0354)\tloss 0.7217 (0.7140)\tgrad_norm 1.5445 (1.9964)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][450/625]\teta 0:00:06 lr 0.000628\t wd 0.0100\ttime 0.0395 (0.0354)\tloss 0.7280 (0.7126)\tgrad_norm 2.6668 (1.9941)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][460/625]\teta 0:00:05 lr 0.000628\t wd 0.0100\ttime 0.0326 (0.0354)\tloss 0.6079 (0.7145)\tgrad_norm 1.6571 (1.9983)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][470/625]\teta 0:00:05 lr 0.000628\t wd 0.0100\ttime 0.0360 (0.0354)\tloss 0.8794 (0.7154)\tgrad_norm 2.2672 (1.9994)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][480/625]\teta 0:00:05 lr 0.000628\t wd 0.0100\ttime 0.0355 (0.0354)\tloss 1.2607 (0.7166)\tgrad_norm 2.7883 (2.0012)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][490/625]\teta 0:00:04 lr 0.000627\t wd 0.0100\ttime 0.0328 (0.0354)\tloss 0.6577 (0.7163)\tgrad_norm 1.5441 (1.9997)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][500/625]\teta 0:00:04 lr 0.000627\t wd 0.0100\ttime 0.0352 (0.0354)\tloss 1.0967 (0.7170)\tgrad_norm 2.6170 (1.9981)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][510/625]\teta 0:00:04 lr 0.000627\t wd 0.0100\ttime 0.0354 (0.0354)\tloss 0.6113 (0.7173)\tgrad_norm 1.6162 (2.0015)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][520/625]\teta 0:00:03 lr 0.000627\t wd 0.0100\ttime 0.0392 (0.0354)\tloss 0.7529 (0.7183)\tgrad_norm 1.8396 (2.0049)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][530/625]\teta 0:00:03 lr 0.000626\t wd 0.0100\ttime 0.0324 (0.0354)\tloss 0.8501 (0.7205)\tgrad_norm 2.2017 (2.0078)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][540/625]\teta 0:00:03 lr 0.000626\t wd 0.0100\ttime 0.0424 (0.0354)\tloss 0.5327 (0.7191)\tgrad_norm 1.7771 (2.0061)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][550/625]\teta 0:00:02 lr 0.000626\t wd 0.0100\ttime 0.0322 (0.0354)\tloss 0.7329 (0.7195)\tgrad_norm 1.8396 (2.0098)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][560/625]\teta 0:00:02 lr 0.000626\t wd 0.0100\ttime 0.0324 (0.0355)\tloss 0.6938 (0.7201)\tgrad_norm 1.7718 (2.0142)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][570/625]\teta 0:00:01 lr 0.000625\t wd 0.0100\ttime 0.0321 (0.0354)\tloss 0.6094 (0.7198)\tgrad_norm 2.3842 (2.0123)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][580/625]\teta 0:00:01 lr 0.000625\t wd 0.0100\ttime 0.0324 (0.0354)\tloss 0.6440 (0.7209)\tgrad_norm 2.1031 (2.0146)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][590/625]\teta 0:00:01 lr 0.000625\t wd 0.0100\ttime 0.0384 (0.0354)\tloss 0.9297 (0.7214)\tgrad_norm 2.1326 (2.0137)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][600/625]\teta 0:00:00 lr 0.000625\t wd 0.0100\ttime 0.0387 (0.0354)\tloss 0.6265 (0.7230)\tgrad_norm 1.7066 (2.0150)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][610/625]\teta 0:00:00 lr 0.000624\t wd 0.0100\ttime 0.0395 (0.0354)\tloss 0.7417 (0.7231)\tgrad_norm 2.4589 (2.0164)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [43/100][620/625]\teta 0:00:00 lr 0.000624\t wd 0.0100\ttime 0.0363 (0.0354)\tloss 0.5796 (0.7232)\tgrad_norm 1.5733 (2.0138)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 43 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_43.pth saving......\n",
      "./model_save/ckpt_epoch_43.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.8701 (0.8701)\tAcc@1 70.312 (70.312)\tAcc@5 98.438 (98.438)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.016)\tLoss 0.6602 (0.7225)\tAcc@1 73.438 (75.000)\tAcc@5 100.000 (98.864)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.016)\tLoss 0.4292 (0.6812)\tAcc@1 85.938 (75.967)\tAcc@5 98.438 (98.884)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.8276 (0.6867)\tAcc@1 76.562 (75.958)\tAcc@5 96.875 (98.740)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.6558 (0.6985)\tAcc@1 79.688 (75.838)\tAcc@5 96.875 (98.552)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.6016 (0.7179)\tAcc@1 78.125 (75.490)\tAcc@5 98.438 (98.438)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.6362 (0.7225)\tAcc@1 73.438 (75.102)\tAcc@5 100.000 (98.540)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.7524 (0.7247)\tAcc@1 76.562 (75.000)\tAcc@5 100.000 (98.592)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.6406 (0.7281)\tAcc@1 78.125 (74.865)\tAcc@5 100.000 (98.611)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.7100 (0.7299)\tAcc@1 75.000 (74.794)\tAcc@5 98.438 (98.541)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.8735 (0.7339)\tAcc@1 75.000 (74.752)\tAcc@5 98.438 (98.484)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.6997 (0.7330)\tAcc@1 76.562 (74.606)\tAcc@5 98.438 (98.508)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.7808 (0.7331)\tAcc@1 76.562 (74.600)\tAcc@5 98.438 (98.450)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.7676 (0.7283)\tAcc@1 75.000 (74.690)\tAcc@5 96.875 (98.461)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.6826 (0.7280)\tAcc@1 78.125 (74.723)\tAcc@5 100.000 (98.449)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.016 (0.015)\tLoss 0.6626 (0.7262)\tAcc@1 73.438 (74.700)\tAcc@5 96.875 (98.417)\tMem 455MB\n",
      " * Acc@1 74.760 Acc@5 98.440\n",
      "Accuracy of the network on the 10000 test images: 74.8%\n",
      "Max accuracy: 74.76%\n",
      "Train: [44/100][0/625]\teta 0:00:25 lr 0.000624\t wd 0.0100\ttime 0.0400 (0.0400)\tloss 0.8047 (0.8047)\tgrad_norm 2.3742 (2.3742)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][10/625]\teta 0:00:22 lr 0.000624\t wd 0.0100\ttime 0.0329 (0.0371)\tloss 0.8291 (0.6780)\tgrad_norm 1.7795 (2.1524)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][20/625]\teta 0:00:22 lr 0.000624\t wd 0.0100\ttime 0.0396 (0.0375)\tloss 0.5420 (0.6726)\tgrad_norm 1.7720 (2.0640)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][30/625]\teta 0:00:22 lr 0.000623\t wd 0.0100\ttime 0.0390 (0.0375)\tloss 0.8242 (0.6876)\tgrad_norm 1.5570 (2.0062)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][40/625]\teta 0:00:21 lr 0.000623\t wd 0.0100\ttime 0.0351 (0.0368)\tloss 0.5962 (0.6912)\tgrad_norm 1.8986 (1.9395)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][50/625]\teta 0:00:20 lr 0.000623\t wd 0.0100\ttime 0.0359 (0.0364)\tloss 0.4573 (0.6817)\tgrad_norm 1.5810 (1.9356)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][60/625]\teta 0:00:20 lr 0.000623\t wd 0.0100\ttime 0.0329 (0.0363)\tloss 0.6152 (0.6941)\tgrad_norm 2.4129 (1.9475)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][70/625]\teta 0:00:20 lr 0.000622\t wd 0.0100\ttime 0.0355 (0.0362)\tloss 0.5947 (0.6859)\tgrad_norm 1.7127 (1.9308)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][80/625]\teta 0:00:19 lr 0.000622\t wd 0.0100\ttime 0.0344 (0.0362)\tloss 0.4700 (0.6816)\tgrad_norm 1.3865 (1.9520)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][90/625]\teta 0:00:19 lr 0.000622\t wd 0.0100\ttime 0.0390 (0.0361)\tloss 0.5400 (0.6891)\tgrad_norm 1.3186 (1.9564)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][100/625]\teta 0:00:18 lr 0.000622\t wd 0.0100\ttime 0.0358 (0.0360)\tloss 0.7559 (0.6924)\tgrad_norm 2.6995 (1.9776)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][110/625]\teta 0:00:18 lr 0.000621\t wd 0.0100\ttime 0.0325 (0.0359)\tloss 0.7354 (0.6970)\tgrad_norm 1.3254 (1.9958)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][120/625]\teta 0:00:18 lr 0.000621\t wd 0.0100\ttime 0.0352 (0.0358)\tloss 0.6885 (0.7005)\tgrad_norm 1.9017 (2.0003)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][130/625]\teta 0:00:17 lr 0.000621\t wd 0.0100\ttime 0.0325 (0.0358)\tloss 0.9570 (0.7052)\tgrad_norm 2.4854 (2.0211)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][140/625]\teta 0:00:17 lr 0.000621\t wd 0.0100\ttime 0.0327 (0.0359)\tloss 0.8765 (0.7051)\tgrad_norm 2.0416 (2.0120)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][150/625]\teta 0:00:17 lr 0.000620\t wd 0.0100\ttime 0.0358 (0.0359)\tloss 0.6670 (0.7042)\tgrad_norm 1.7766 (2.0140)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][160/625]\teta 0:00:16 lr 0.000620\t wd 0.0100\ttime 0.0371 (0.0359)\tloss 0.7803 (0.7082)\tgrad_norm 2.2132 (2.0228)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][170/625]\teta 0:00:16 lr 0.000620\t wd 0.0100\ttime 0.0327 (0.0358)\tloss 0.8599 (0.7079)\tgrad_norm 1.9975 (2.0236)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][180/625]\teta 0:00:15 lr 0.000620\t wd 0.0100\ttime 0.0323 (0.0358)\tloss 0.6909 (0.7090)\tgrad_norm 2.6280 (2.0296)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][190/625]\teta 0:00:15 lr 0.000619\t wd 0.0100\ttime 0.0331 (0.0358)\tloss 0.5381 (0.7095)\tgrad_norm 1.7656 (2.0298)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][200/625]\teta 0:00:15 lr 0.000619\t wd 0.0100\ttime 0.0327 (0.0357)\tloss 0.7158 (0.7064)\tgrad_norm 1.9213 (2.0301)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][210/625]\teta 0:00:14 lr 0.000619\t wd 0.0100\ttime 0.0360 (0.0358)\tloss 0.5439 (0.7069)\tgrad_norm 1.7424 (2.0264)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][220/625]\teta 0:00:14 lr 0.000619\t wd 0.0100\ttime 0.0357 (0.0358)\tloss 0.7217 (0.7071)\tgrad_norm 1.6705 (2.0273)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][230/625]\teta 0:00:14 lr 0.000618\t wd 0.0100\ttime 0.0325 (0.0357)\tloss 0.5786 (0.7066)\tgrad_norm 1.9686 (2.0290)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][240/625]\teta 0:00:13 lr 0.000618\t wd 0.0100\ttime 0.0353 (0.0356)\tloss 0.5371 (0.7065)\tgrad_norm 2.1126 (2.0323)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][250/625]\teta 0:00:13 lr 0.000618\t wd 0.0100\ttime 0.0358 (0.0357)\tloss 0.6929 (0.7055)\tgrad_norm 2.0372 (2.0246)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][260/625]\teta 0:00:13 lr 0.000618\t wd 0.0100\ttime 0.0327 (0.0357)\tloss 0.5806 (0.7072)\tgrad_norm 1.7254 (2.0274)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][270/625]\teta 0:00:12 lr 0.000617\t wd 0.0100\ttime 0.0327 (0.0356)\tloss 0.6021 (0.7080)\tgrad_norm 2.8464 (2.0384)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][280/625]\teta 0:00:12 lr 0.000617\t wd 0.0100\ttime 0.0321 (0.0355)\tloss 0.7275 (0.7068)\tgrad_norm 2.4341 (2.0384)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][290/625]\teta 0:00:11 lr 0.000617\t wd 0.0100\ttime 0.0369 (0.0354)\tloss 1.0234 (0.7091)\tgrad_norm 3.3781 (2.0545)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][300/625]\teta 0:00:11 lr 0.000617\t wd 0.0100\ttime 0.0328 (0.0354)\tloss 0.6948 (0.7111)\tgrad_norm 1.9433 (2.0593)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][310/625]\teta 0:00:11 lr 0.000616\t wd 0.0100\ttime 0.0361 (0.0354)\tloss 0.6465 (0.7103)\tgrad_norm 1.9120 (2.0576)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][320/625]\teta 0:00:10 lr 0.000616\t wd 0.0100\ttime 0.0353 (0.0354)\tloss 0.7231 (0.7090)\tgrad_norm 1.7385 (2.0527)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][330/625]\teta 0:00:10 lr 0.000616\t wd 0.0100\ttime 0.0361 (0.0354)\tloss 1.0029 (0.7095)\tgrad_norm 2.3868 (2.0611)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][340/625]\teta 0:00:10 lr 0.000616\t wd 0.0100\ttime 0.0350 (0.0354)\tloss 0.6567 (0.7091)\tgrad_norm 1.9000 (2.0605)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][350/625]\teta 0:00:09 lr 0.000615\t wd 0.0100\ttime 0.0332 (0.0354)\tloss 0.5854 (0.7082)\tgrad_norm 1.8830 (2.0535)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][360/625]\teta 0:00:09 lr 0.000615\t wd 0.0100\ttime 0.0323 (0.0354)\tloss 0.7192 (0.7088)\tgrad_norm 1.7371 (2.0523)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][370/625]\teta 0:00:09 lr 0.000615\t wd 0.0100\ttime 0.0354 (0.0354)\tloss 0.5435 (0.7080)\tgrad_norm 1.6233 (2.0546)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][380/625]\teta 0:00:08 lr 0.000615\t wd 0.0100\ttime 0.0325 (0.0354)\tloss 0.6328 (0.7058)\tgrad_norm 2.0188 (2.0522)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][390/625]\teta 0:00:08 lr 0.000614\t wd 0.0100\ttime 0.0353 (0.0354)\tloss 0.7886 (0.7049)\tgrad_norm 2.5077 (2.0520)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][400/625]\teta 0:00:07 lr 0.000614\t wd 0.0100\ttime 0.0391 (0.0354)\tloss 0.7773 (0.7048)\tgrad_norm 1.7983 (2.0550)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][410/625]\teta 0:00:07 lr 0.000614\t wd 0.0100\ttime 0.0350 (0.0354)\tloss 0.7031 (0.7029)\tgrad_norm 1.7627 (2.0488)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][420/625]\teta 0:00:07 lr 0.000614\t wd 0.0100\ttime 0.0326 (0.0354)\tloss 0.8457 (0.7032)\tgrad_norm 2.6646 (2.0500)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][430/625]\teta 0:00:06 lr 0.000613\t wd 0.0100\ttime 0.0360 (0.0354)\tloss 0.6768 (0.7044)\tgrad_norm 1.6976 (2.0481)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][440/625]\teta 0:00:06 lr 0.000613\t wd 0.0100\ttime 0.0359 (0.0354)\tloss 0.6577 (0.7041)\tgrad_norm 2.4799 (2.0479)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][450/625]\teta 0:00:06 lr 0.000613\t wd 0.0100\ttime 0.0350 (0.0354)\tloss 0.8853 (0.7047)\tgrad_norm 2.7133 (2.0487)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][460/625]\teta 0:00:05 lr 0.000613\t wd 0.0100\ttime 0.0337 (0.0354)\tloss 0.6636 (0.7038)\tgrad_norm 1.5942 (2.0463)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][470/625]\teta 0:00:05 lr 0.000612\t wd 0.0100\ttime 0.0325 (0.0354)\tloss 0.8252 (0.7033)\tgrad_norm 2.8772 (2.0477)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][480/625]\teta 0:00:05 lr 0.000612\t wd 0.0100\ttime 0.0355 (0.0354)\tloss 0.8154 (0.7037)\tgrad_norm 2.1824 (2.0473)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][490/625]\teta 0:00:04 lr 0.000612\t wd 0.0100\ttime 0.0324 (0.0354)\tloss 0.8315 (0.7048)\tgrad_norm 1.8495 (2.0504)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][500/625]\teta 0:00:04 lr 0.000612\t wd 0.0100\ttime 0.0326 (0.0354)\tloss 0.5513 (0.7054)\tgrad_norm 1.6873 (2.0506)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][510/625]\teta 0:00:04 lr 0.000611\t wd 0.0100\ttime 0.0333 (0.0354)\tloss 0.6636 (0.7069)\tgrad_norm 2.4391 (2.0528)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][520/625]\teta 0:00:03 lr 0.000611\t wd 0.0100\ttime 0.0326 (0.0355)\tloss 0.7471 (0.7067)\tgrad_norm 1.6926 (2.0522)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][530/625]\teta 0:00:03 lr 0.000611\t wd 0.0100\ttime 0.0343 (0.0354)\tloss 0.7437 (0.7074)\tgrad_norm 2.3739 (2.0509)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][540/625]\teta 0:00:03 lr 0.000611\t wd 0.0100\ttime 0.0326 (0.0354)\tloss 0.6885 (0.7083)\tgrad_norm 1.8430 (2.0511)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][550/625]\teta 0:00:02 lr 0.000610\t wd 0.0100\ttime 0.0322 (0.0353)\tloss 0.8584 (0.7098)\tgrad_norm 1.9904 (2.0510)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][560/625]\teta 0:00:02 lr 0.000610\t wd 0.0100\ttime 0.0325 (0.0353)\tloss 0.6841 (0.7103)\tgrad_norm 2.2386 (2.0495)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][570/625]\teta 0:00:01 lr 0.000610\t wd 0.0100\ttime 0.0326 (0.0353)\tloss 0.5063 (0.7101)\tgrad_norm 1.7788 (2.0458)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][580/625]\teta 0:00:01 lr 0.000610\t wd 0.0100\ttime 0.0322 (0.0353)\tloss 0.7949 (0.7109)\tgrad_norm 2.0026 (2.0453)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][590/625]\teta 0:00:01 lr 0.000609\t wd 0.0100\ttime 0.0355 (0.0353)\tloss 0.8594 (0.7117)\tgrad_norm 2.0571 (2.0472)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][600/625]\teta 0:00:00 lr 0.000609\t wd 0.0100\ttime 0.0323 (0.0352)\tloss 0.6138 (0.7121)\tgrad_norm 1.5346 (2.0470)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][610/625]\teta 0:00:00 lr 0.000609\t wd 0.0100\ttime 0.0321 (0.0352)\tloss 1.0586 (0.7123)\tgrad_norm 2.6504 (2.0496)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [44/100][620/625]\teta 0:00:00 lr 0.000609\t wd 0.0100\ttime 0.0329 (0.0352)\tloss 0.6968 (0.7122)\tgrad_norm 1.4336 (2.0452)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 44 training takes 0:00:21\n",
      "./model_save/ckpt_epoch_44.pth saving......\n",
      "./model_save/ckpt_epoch_44.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.6655 (0.6655)\tAcc@1 75.000 (75.000)\tAcc@5 98.438 (98.438)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.016)\tLoss 0.9185 (0.6754)\tAcc@1 68.750 (75.710)\tAcc@5 96.875 (99.006)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.6499 (0.6775)\tAcc@1 71.875 (75.744)\tAcc@5 100.000 (99.033)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.016 (0.015)\tLoss 0.7417 (0.7079)\tAcc@1 78.125 (74.849)\tAcc@5 98.438 (98.891)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.5684 (0.7150)\tAcc@1 81.250 (74.581)\tAcc@5 98.438 (98.742)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.7119 (0.7210)\tAcc@1 76.562 (74.112)\tAcc@5 98.438 (98.805)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.6870 (0.7166)\tAcc@1 78.125 (74.488)\tAcc@5 96.875 (98.770)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.7603 (0.7260)\tAcc@1 73.438 (74.274)\tAcc@5 96.875 (98.702)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.6870 (0.7219)\tAcc@1 76.562 (74.344)\tAcc@5 100.000 (98.765)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.4714 (0.7188)\tAcc@1 81.250 (74.536)\tAcc@5 100.000 (98.781)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.7437 (0.7143)\tAcc@1 75.000 (74.783)\tAcc@5 96.875 (98.731)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.7764 (0.7118)\tAcc@1 71.875 (75.042)\tAcc@5 98.438 (98.635)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.6377 (0.7065)\tAcc@1 73.438 (75.168)\tAcc@5 98.438 (98.644)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.6172 (0.7066)\tAcc@1 73.438 (75.072)\tAcc@5 98.438 (98.616)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.6963 (0.7068)\tAcc@1 81.250 (75.122)\tAcc@5 98.438 (98.582)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.8062 (0.7089)\tAcc@1 71.875 (75.041)\tAcc@5 96.875 (98.572)\tMem 455MB\n",
      " * Acc@1 74.970 Acc@5 98.560\n",
      "Accuracy of the network on the 10000 test images: 75.0%\n",
      "Max accuracy: 74.97%\n",
      "Train: [45/100][0/625]\teta 0:00:21 lr 0.000608\t wd 0.0100\ttime 0.0343 (0.0343)\tloss 0.7275 (0.7275)\tgrad_norm 1.8663 (1.8663)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][10/625]\teta 0:00:20 lr 0.000608\t wd 0.0100\ttime 0.0357 (0.0339)\tloss 0.5244 (0.6274)\tgrad_norm 1.2443 (1.7321)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][20/625]\teta 0:00:20 lr 0.000608\t wd 0.0100\ttime 0.0328 (0.0338)\tloss 0.5293 (0.6395)\tgrad_norm 1.7222 (1.8503)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][30/625]\teta 0:00:19 lr 0.000608\t wd 0.0100\ttime 0.0329 (0.0336)\tloss 0.6021 (0.6679)\tgrad_norm 2.1573 (1.9330)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][40/625]\teta 0:00:19 lr 0.000607\t wd 0.0100\ttime 0.0328 (0.0335)\tloss 0.7046 (0.6714)\tgrad_norm 1.8802 (1.9244)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][50/625]\teta 0:00:19 lr 0.000607\t wd 0.0100\ttime 0.0359 (0.0336)\tloss 0.5303 (0.6661)\tgrad_norm 1.7464 (1.9220)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][60/625]\teta 0:00:18 lr 0.000607\t wd 0.0100\ttime 0.0335 (0.0335)\tloss 0.5122 (0.6734)\tgrad_norm 1.4869 (1.9614)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][70/625]\teta 0:00:18 lr 0.000607\t wd 0.0100\ttime 0.0326 (0.0334)\tloss 0.7729 (0.6782)\tgrad_norm 2.9421 (1.9723)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][80/625]\teta 0:00:18 lr 0.000606\t wd 0.0100\ttime 0.0320 (0.0335)\tloss 0.6660 (0.6817)\tgrad_norm 1.8433 (1.9839)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][90/625]\teta 0:00:17 lr 0.000606\t wd 0.0100\ttime 0.0330 (0.0335)\tloss 0.7476 (0.6828)\tgrad_norm 2.0112 (1.9774)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][100/625]\teta 0:00:17 lr 0.000606\t wd 0.0100\ttime 0.0361 (0.0335)\tloss 0.6416 (0.6800)\tgrad_norm 1.8676 (1.9730)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][110/625]\teta 0:00:17 lr 0.000606\t wd 0.0100\ttime 0.0327 (0.0335)\tloss 0.6567 (0.6793)\tgrad_norm 2.3296 (1.9732)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][120/625]\teta 0:00:16 lr 0.000605\t wd 0.0100\ttime 0.0328 (0.0336)\tloss 0.5151 (0.6836)\tgrad_norm 1.8853 (1.9754)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][130/625]\teta 0:00:16 lr 0.000605\t wd 0.0100\ttime 0.0366 (0.0338)\tloss 0.6709 (0.6858)\tgrad_norm 1.8239 (1.9748)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][140/625]\teta 0:00:16 lr 0.000605\t wd 0.0100\ttime 0.0361 (0.0339)\tloss 0.4207 (0.6886)\tgrad_norm 1.4305 (1.9806)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][150/625]\teta 0:00:16 lr 0.000605\t wd 0.0100\ttime 0.0325 (0.0339)\tloss 0.6709 (0.6869)\tgrad_norm 2.0667 (1.9874)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][160/625]\teta 0:00:15 lr 0.000604\t wd 0.0100\ttime 0.0325 (0.0340)\tloss 0.7261 (0.6866)\tgrad_norm 2.9387 (1.9901)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][170/625]\teta 0:00:15 lr 0.000604\t wd 0.0100\ttime 0.0359 (0.0342)\tloss 0.9268 (0.6869)\tgrad_norm 2.8924 (1.9904)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][180/625]\teta 0:00:15 lr 0.000604\t wd 0.0100\ttime 0.0401 (0.0342)\tloss 0.6055 (0.6829)\tgrad_norm 2.2797 (1.9918)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][190/625]\teta 0:00:14 lr 0.000604\t wd 0.0100\ttime 0.0331 (0.0344)\tloss 0.7310 (0.6857)\tgrad_norm 2.8109 (2.0020)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][200/625]\teta 0:00:14 lr 0.000603\t wd 0.0100\ttime 0.0328 (0.0343)\tloss 0.7241 (0.6861)\tgrad_norm 2.8844 (2.0133)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][210/625]\teta 0:00:14 lr 0.000603\t wd 0.0100\ttime 0.0333 (0.0343)\tloss 0.7427 (0.6846)\tgrad_norm 1.4436 (2.0114)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][220/625]\teta 0:00:13 lr 0.000603\t wd 0.0100\ttime 0.0338 (0.0343)\tloss 0.5205 (0.6851)\tgrad_norm 1.7877 (2.0030)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][230/625]\teta 0:00:13 lr 0.000603\t wd 0.0100\ttime 0.0329 (0.0343)\tloss 0.5923 (0.6843)\tgrad_norm 1.8381 (2.0023)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][240/625]\teta 0:00:13 lr 0.000602\t wd 0.0100\ttime 0.0364 (0.0343)\tloss 0.5869 (0.6858)\tgrad_norm 1.6237 (2.0139)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][250/625]\teta 0:00:12 lr 0.000602\t wd 0.0100\ttime 0.0327 (0.0344)\tloss 0.7129 (0.6850)\tgrad_norm 1.2108 (2.0133)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][260/625]\teta 0:00:12 lr 0.000602\t wd 0.0100\ttime 0.0404 (0.0344)\tloss 0.7339 (0.6851)\tgrad_norm 2.0638 (2.0136)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][270/625]\teta 0:00:12 lr 0.000602\t wd 0.0100\ttime 0.0352 (0.0345)\tloss 0.6890 (0.6877)\tgrad_norm 1.8755 (2.0201)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][280/625]\teta 0:00:11 lr 0.000601\t wd 0.0100\ttime 0.0324 (0.0345)\tloss 0.5474 (0.6897)\tgrad_norm 1.6706 (2.0243)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][290/625]\teta 0:00:11 lr 0.000601\t wd 0.0100\ttime 0.0326 (0.0345)\tloss 0.6147 (0.6906)\tgrad_norm 2.0599 (2.0306)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][300/625]\teta 0:00:11 lr 0.000601\t wd 0.0100\ttime 0.0354 (0.0345)\tloss 0.5601 (0.6900)\tgrad_norm 1.8348 (2.0366)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][310/625]\teta 0:00:10 lr 0.000601\t wd 0.0100\ttime 0.0355 (0.0346)\tloss 0.5195 (0.6908)\tgrad_norm 1.9262 (2.0420)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][320/625]\teta 0:00:10 lr 0.000600\t wd 0.0100\ttime 0.0392 (0.0346)\tloss 0.8706 (0.6912)\tgrad_norm 1.9656 (2.0418)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][330/625]\teta 0:00:10 lr 0.000600\t wd 0.0100\ttime 0.0359 (0.0346)\tloss 0.5352 (0.6925)\tgrad_norm 1.9107 (2.0438)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][340/625]\teta 0:00:09 lr 0.000600\t wd 0.0100\ttime 0.0400 (0.0347)\tloss 0.7544 (0.6939)\tgrad_norm 2.6204 (2.0505)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][350/625]\teta 0:00:09 lr 0.000600\t wd 0.0100\ttime 0.0331 (0.0347)\tloss 0.8940 (0.6927)\tgrad_norm 1.8296 (2.0463)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][360/625]\teta 0:00:09 lr 0.000599\t wd 0.0100\ttime 0.0323 (0.0346)\tloss 0.7207 (0.6939)\tgrad_norm 2.5684 (2.0503)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][370/625]\teta 0:00:08 lr 0.000599\t wd 0.0100\ttime 0.0400 (0.0347)\tloss 0.8047 (0.6925)\tgrad_norm 2.0206 (2.0494)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][380/625]\teta 0:00:08 lr 0.000599\t wd 0.0100\ttime 0.0360 (0.0347)\tloss 0.5449 (0.6923)\tgrad_norm 2.2220 (2.0512)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][390/625]\teta 0:00:08 lr 0.000599\t wd 0.0100\ttime 0.0330 (0.0347)\tloss 0.6807 (0.6914)\tgrad_norm 2.8120 (2.0469)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][400/625]\teta 0:00:07 lr 0.000598\t wd 0.0100\ttime 0.0323 (0.0347)\tloss 0.5029 (0.6915)\tgrad_norm 1.7816 (2.0464)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][410/625]\teta 0:00:07 lr 0.000598\t wd 0.0100\ttime 0.0341 (0.0347)\tloss 0.6069 (0.6924)\tgrad_norm 1.7472 (2.0425)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][420/625]\teta 0:00:07 lr 0.000598\t wd 0.0100\ttime 0.0356 (0.0347)\tloss 0.7407 (0.6931)\tgrad_norm 2.0778 (2.0397)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][430/625]\teta 0:00:06 lr 0.000598\t wd 0.0100\ttime 0.0360 (0.0347)\tloss 0.5693 (0.6912)\tgrad_norm 1.5080 (2.0331)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][440/625]\teta 0:00:06 lr 0.000597\t wd 0.0100\ttime 0.0325 (0.0347)\tloss 0.5352 (0.6917)\tgrad_norm 1.3847 (2.0332)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][450/625]\teta 0:00:06 lr 0.000597\t wd 0.0100\ttime 0.0359 (0.0347)\tloss 0.5122 (0.6925)\tgrad_norm 1.5581 (2.0357)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][460/625]\teta 0:00:05 lr 0.000597\t wd 0.0100\ttime 0.0326 (0.0347)\tloss 0.8394 (0.6933)\tgrad_norm 2.5824 (2.0342)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][470/625]\teta 0:00:05 lr 0.000597\t wd 0.0100\ttime 0.0382 (0.0347)\tloss 0.8086 (0.6931)\tgrad_norm 2.3450 (2.0317)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][480/625]\teta 0:00:05 lr 0.000596\t wd 0.0100\ttime 0.0325 (0.0347)\tloss 0.4788 (0.6932)\tgrad_norm 1.7194 (2.0282)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][490/625]\teta 0:00:04 lr 0.000596\t wd 0.0100\ttime 0.0324 (0.0347)\tloss 0.6978 (0.6926)\tgrad_norm 1.5850 (2.0260)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][500/625]\teta 0:00:04 lr 0.000596\t wd 0.0100\ttime 0.0325 (0.0347)\tloss 0.5923 (0.6929)\tgrad_norm 1.7458 (2.0291)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][510/625]\teta 0:00:03 lr 0.000596\t wd 0.0100\ttime 0.0353 (0.0347)\tloss 0.6221 (0.6935)\tgrad_norm 1.6394 (2.0278)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][520/625]\teta 0:00:03 lr 0.000595\t wd 0.0100\ttime 0.0346 (0.0348)\tloss 0.5767 (0.6946)\tgrad_norm 3.1325 (2.0331)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][530/625]\teta 0:00:03 lr 0.000595\t wd 0.0100\ttime 0.0330 (0.0348)\tloss 0.6411 (0.6964)\tgrad_norm 1.6559 (2.0342)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][540/625]\teta 0:00:02 lr 0.000595\t wd 0.0100\ttime 0.0350 (0.0348)\tloss 0.7021 (0.6967)\tgrad_norm 2.1189 (2.0344)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][550/625]\teta 0:00:02 lr 0.000595\t wd 0.0100\ttime 0.0391 (0.0348)\tloss 0.6611 (0.6974)\tgrad_norm 1.6848 (2.0348)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][560/625]\teta 0:00:02 lr 0.000594\t wd 0.0100\ttime 0.0354 (0.0349)\tloss 0.7529 (0.6976)\tgrad_norm 1.9269 (2.0371)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][570/625]\teta 0:00:01 lr 0.000594\t wd 0.0100\ttime 0.0354 (0.0348)\tloss 0.4370 (0.6970)\tgrad_norm 2.0697 (2.0411)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][580/625]\teta 0:00:01 lr 0.000594\t wd 0.0100\ttime 0.0325 (0.0348)\tloss 0.6196 (0.6973)\tgrad_norm 2.3109 (2.0438)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][590/625]\teta 0:00:01 lr 0.000594\t wd 0.0100\ttime 0.0323 (0.0349)\tloss 0.7036 (0.6970)\tgrad_norm 2.1503 (2.0450)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][600/625]\teta 0:00:00 lr 0.000593\t wd 0.0100\ttime 0.0336 (0.0349)\tloss 0.6143 (0.6965)\tgrad_norm 2.2335 (2.0445)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][610/625]\teta 0:00:00 lr 0.000593\t wd 0.0100\ttime 0.0328 (0.0349)\tloss 0.6211 (0.6951)\tgrad_norm 1.5663 (2.0433)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [45/100][620/625]\teta 0:00:00 lr 0.000593\t wd 0.0100\ttime 0.0331 (0.0349)\tloss 0.8247 (0.6953)\tgrad_norm 1.7352 (2.0416)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 45 training takes 0:00:21\n",
      "./model_save/ckpt_epoch_45.pth saving......\n",
      "./model_save/ckpt_epoch_45.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.9414 (0.9414)\tAcc@1 65.625 (65.625)\tAcc@5 95.312 (95.312)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.9683 (0.8347)\tAcc@1 71.875 (71.875)\tAcc@5 95.312 (97.869)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.016 (0.015)\tLoss 0.6963 (0.7647)\tAcc@1 73.438 (73.884)\tAcc@5 100.000 (98.438)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.016 (0.016)\tLoss 0.7598 (0.7633)\tAcc@1 73.438 (74.042)\tAcc@5 96.875 (98.286)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.016 (0.016)\tLoss 0.9756 (0.7583)\tAcc@1 70.312 (74.085)\tAcc@5 93.750 (98.285)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.016 (0.016)\tLoss 0.7139 (0.7507)\tAcc@1 76.562 (73.928)\tAcc@5 98.438 (98.254)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.016)\tLoss 0.6104 (0.7554)\tAcc@1 75.000 (73.796)\tAcc@5 98.438 (98.156)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.016)\tLoss 0.7041 (0.7490)\tAcc@1 75.000 (74.076)\tAcc@5 93.750 (98.217)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.016)\tLoss 0.8110 (0.7481)\tAcc@1 67.188 (74.093)\tAcc@5 96.875 (98.206)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.9058 (0.7438)\tAcc@1 70.312 (74.021)\tAcc@5 96.875 (98.266)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.016 (0.015)\tLoss 0.3420 (0.7339)\tAcc@1 87.500 (74.350)\tAcc@5 100.000 (98.376)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.016)\tLoss 0.6440 (0.7299)\tAcc@1 76.562 (74.423)\tAcc@5 98.438 (98.353)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.7656 (0.7313)\tAcc@1 79.688 (74.354)\tAcc@5 95.312 (98.334)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.7954 (0.7287)\tAcc@1 65.625 (74.296)\tAcc@5 98.438 (98.354)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.6558 (0.7310)\tAcc@1 81.250 (74.136)\tAcc@5 96.875 (98.393)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.9531 (0.7339)\tAcc@1 70.312 (73.986)\tAcc@5 95.312 (98.375)\tMem 455MB\n",
      " * Acc@1 73.900 Acc@5 98.370\n",
      "Accuracy of the network on the 10000 test images: 73.9%\n",
      "Max accuracy: 74.97%\n",
      "Train: [46/100][0/625]\teta 0:00:25 lr 0.000593\t wd 0.0100\ttime 0.0405 (0.0405)\tloss 0.7568 (0.7568)\tgrad_norm 2.4469 (2.4469)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [46/100][10/625]\teta 0:00:21 lr 0.000592\t wd 0.0100\ttime 0.0329 (0.0353)\tloss 0.8120 (0.6983)\tgrad_norm 3.5957 (2.2913)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [46/100][20/625]\teta 0:00:21 lr 0.000592\t wd 0.0100\ttime 0.0332 (0.0357)\tloss 0.5400 (0.6923)\tgrad_norm 1.7138 (nan)\tloss_scale 32768.0000 (34328.3810)\tmem 455MB\n",
      "Train: [46/100][30/625]\teta 0:00:21 lr 0.000592\t wd 0.0100\ttime 0.0387 (0.0361)\tloss 0.8462 (0.6769)\tgrad_norm 2.5104 (nan)\tloss_scale 32768.0000 (33825.0323)\tmem 455MB\n",
      "Train: [46/100][40/625]\teta 0:00:21 lr 0.000592\t wd 0.0100\ttime 0.0328 (0.0360)\tloss 0.5483 (0.6814)\tgrad_norm 1.7851 (nan)\tloss_scale 32768.0000 (33567.2195)\tmem 455MB\n",
      "Train: [46/100][50/625]\teta 0:00:20 lr 0.000591\t wd 0.0100\ttime 0.0356 (0.0357)\tloss 0.5356 (0.6858)\tgrad_norm 1.4418 (nan)\tloss_scale 32768.0000 (33410.5098)\tmem 455MB\n",
      "Train: [46/100][60/625]\teta 0:00:20 lr 0.000591\t wd 0.0100\ttime 0.0393 (0.0359)\tloss 0.8271 (0.6884)\tgrad_norm 1.6899 (nan)\tloss_scale 32768.0000 (33305.1803)\tmem 455MB\n",
      "Train: [46/100][70/625]\teta 0:00:19 lr 0.000591\t wd 0.0100\ttime 0.0333 (0.0359)\tloss 0.6226 (0.6935)\tgrad_norm 2.1705 (nan)\tloss_scale 32768.0000 (33229.5211)\tmem 455MB\n",
      "Train: [46/100][80/625]\teta 0:00:19 lr 0.000591\t wd 0.0100\ttime 0.0333 (0.0356)\tloss 0.7329 (0.6894)\tgrad_norm 1.9395 (nan)\tloss_scale 32768.0000 (33172.5432)\tmem 455MB\n",
      "Train: [46/100][90/625]\teta 0:00:18 lr 0.000590\t wd 0.0100\ttime 0.0326 (0.0354)\tloss 0.6797 (0.6850)\tgrad_norm 1.9102 (nan)\tloss_scale 32768.0000 (33128.0879)\tmem 455MB\n",
      "Train: [46/100][100/625]\teta 0:00:18 lr 0.000590\t wd 0.0100\ttime 0.0329 (0.0353)\tloss 0.5537 (0.6778)\tgrad_norm 1.6556 (nan)\tloss_scale 32768.0000 (33092.4356)\tmem 455MB\n",
      "Train: [46/100][110/625]\teta 0:00:18 lr 0.000590\t wd 0.0100\ttime 0.0327 (0.0353)\tloss 0.6880 (0.6828)\tgrad_norm 2.0817 (nan)\tloss_scale 32768.0000 (33063.2072)\tmem 455MB\n",
      "Train: [46/100][120/625]\teta 0:00:17 lr 0.000590\t wd 0.0100\ttime 0.0331 (0.0355)\tloss 0.8472 (0.6874)\tgrad_norm 1.8816 (nan)\tloss_scale 32768.0000 (33038.8099)\tmem 455MB\n",
      "Train: [46/100][130/625]\teta 0:00:17 lr 0.000589\t wd 0.0100\ttime 0.0366 (0.0354)\tloss 0.6812 (0.6829)\tgrad_norm 2.3434 (nan)\tloss_scale 32768.0000 (33018.1374)\tmem 455MB\n",
      "Train: [46/100][140/625]\teta 0:00:17 lr 0.000589\t wd 0.0100\ttime 0.0333 (0.0353)\tloss 0.7549 (0.6796)\tgrad_norm 2.8261 (nan)\tloss_scale 32768.0000 (33000.3972)\tmem 455MB\n",
      "Train: [46/100][150/625]\teta 0:00:16 lr 0.000589\t wd 0.0100\ttime 0.0357 (0.0353)\tloss 0.8994 (0.6798)\tgrad_norm 3.7608 (nan)\tloss_scale 32768.0000 (32985.0066)\tmem 455MB\n",
      "Train: [46/100][160/625]\teta 0:00:16 lr 0.000589\t wd 0.0100\ttime 0.0359 (0.0353)\tloss 0.9585 (0.6828)\tgrad_norm 2.5445 (nan)\tloss_scale 32768.0000 (32971.5280)\tmem 455MB\n",
      "Train: [46/100][170/625]\teta 0:00:16 lr 0.000588\t wd 0.0100\ttime 0.0347 (0.0355)\tloss 0.7900 (0.6851)\tgrad_norm 1.9229 (nan)\tloss_scale 32768.0000 (32959.6257)\tmem 455MB\n",
      "Train: [46/100][180/625]\teta 0:00:15 lr 0.000588\t wd 0.0100\ttime 0.0327 (0.0356)\tloss 0.4678 (0.6819)\tgrad_norm 1.5660 (nan)\tloss_scale 32768.0000 (32949.0387)\tmem 455MB\n",
      "Train: [46/100][190/625]\teta 0:00:15 lr 0.000588\t wd 0.0100\ttime 0.0377 (0.0357)\tloss 0.8389 (0.6840)\tgrad_norm 2.1846 (nan)\tloss_scale 32768.0000 (32939.5602)\tmem 455MB\n",
      "Train: [46/100][200/625]\teta 0:00:15 lr 0.000588\t wd 0.0100\ttime 0.0408 (0.0358)\tloss 0.4507 (0.6804)\tgrad_norm 1.4282 (nan)\tloss_scale 32768.0000 (32931.0249)\tmem 455MB\n",
      "Train: [46/100][210/625]\teta 0:00:14 lr 0.000587\t wd 0.0100\ttime 0.0329 (0.0358)\tloss 0.3601 (0.6783)\tgrad_norm 1.2828 (nan)\tloss_scale 32768.0000 (32923.2986)\tmem 455MB\n",
      "Train: [46/100][220/625]\teta 0:00:14 lr 0.000587\t wd 0.0100\ttime 0.0361 (0.0359)\tloss 0.5317 (0.6791)\tgrad_norm 1.5379 (nan)\tloss_scale 32768.0000 (32916.2715)\tmem 455MB\n",
      "Train: [46/100][230/625]\teta 0:00:14 lr 0.000587\t wd 0.0100\ttime 0.0399 (0.0359)\tloss 0.4570 (0.6780)\tgrad_norm 1.4801 (nan)\tloss_scale 32768.0000 (32909.8528)\tmem 455MB\n",
      "Train: [46/100][240/625]\teta 0:00:13 lr 0.000587\t wd 0.0100\ttime 0.0327 (0.0358)\tloss 0.5874 (0.6796)\tgrad_norm 1.8162 (nan)\tloss_scale 32768.0000 (32903.9668)\tmem 455MB\n",
      "Train: [46/100][250/625]\teta 0:00:13 lr 0.000586\t wd 0.0100\ttime 0.0327 (0.0358)\tloss 0.6426 (0.6814)\tgrad_norm 2.5370 (nan)\tloss_scale 32768.0000 (32898.5498)\tmem 455MB\n",
      "Train: [46/100][260/625]\teta 0:00:13 lr 0.000586\t wd 0.0100\ttime 0.0328 (0.0357)\tloss 0.7661 (0.6816)\tgrad_norm 1.8250 (nan)\tloss_scale 32768.0000 (32893.5479)\tmem 455MB\n",
      "Train: [46/100][270/625]\teta 0:00:12 lr 0.000586\t wd 0.0100\ttime 0.0359 (0.0356)\tloss 0.7393 (0.6843)\tgrad_norm 2.4301 (nan)\tloss_scale 32768.0000 (32888.9151)\tmem 455MB\n",
      "Train: [46/100][280/625]\teta 0:00:12 lr 0.000586\t wd 0.0100\ttime 0.0367 (0.0357)\tloss 0.5889 (0.6840)\tgrad_norm 2.1427 (nan)\tloss_scale 32768.0000 (32884.6121)\tmem 455MB\n",
      "Train: [46/100][290/625]\teta 0:00:11 lr 0.000585\t wd 0.0100\ttime 0.0328 (0.0357)\tloss 0.5557 (0.6851)\tgrad_norm 1.8547 (nan)\tloss_scale 32768.0000 (32880.6048)\tmem 455MB\n",
      "Train: [46/100][300/625]\teta 0:00:11 lr 0.000585\t wd 0.0100\ttime 0.0358 (0.0356)\tloss 0.6074 (0.6864)\tgrad_norm 2.0819 (nan)\tloss_scale 32768.0000 (32876.8638)\tmem 455MB\n",
      "Train: [46/100][310/625]\teta 0:00:11 lr 0.000585\t wd 0.0100\ttime 0.0345 (0.0356)\tloss 0.8706 (0.6881)\tgrad_norm 2.0751 (nan)\tloss_scale 32768.0000 (32873.3633)\tmem 455MB\n",
      "Train: [46/100][320/625]\teta 0:00:10 lr 0.000585\t wd 0.0100\ttime 0.0325 (0.0356)\tloss 0.7817 (0.6884)\tgrad_norm 1.9328 (nan)\tloss_scale 32768.0000 (32870.0810)\tmem 455MB\n",
      "Train: [46/100][330/625]\teta 0:00:10 lr 0.000584\t wd 0.0100\ttime 0.0360 (0.0356)\tloss 0.7192 (0.6871)\tgrad_norm 2.1686 (nan)\tloss_scale 32768.0000 (32866.9970)\tmem 455MB\n",
      "Train: [46/100][340/625]\teta 0:00:10 lr 0.000584\t wd 0.0100\ttime 0.0325 (0.0356)\tloss 0.8462 (0.6887)\tgrad_norm 2.7892 (nan)\tloss_scale 32768.0000 (32864.0938)\tmem 455MB\n",
      "Train: [46/100][350/625]\teta 0:00:09 lr 0.000584\t wd 0.0100\ttime 0.0356 (0.0356)\tloss 0.4968 (0.6902)\tgrad_norm 1.8098 (nan)\tloss_scale 32768.0000 (32861.3561)\tmem 455MB\n",
      "Train: [46/100][360/625]\teta 0:00:09 lr 0.000584\t wd 0.0100\ttime 0.0330 (0.0356)\tloss 0.6250 (0.6888)\tgrad_norm 1.7478 (nan)\tloss_scale 32768.0000 (32858.7701)\tmem 455MB\n",
      "Train: [46/100][370/625]\teta 0:00:09 lr 0.000583\t wd 0.0100\ttime 0.0391 (0.0356)\tloss 0.8110 (0.6901)\tgrad_norm 2.0631 (nan)\tloss_scale 32768.0000 (32856.3235)\tmem 455MB\n",
      "Train: [46/100][380/625]\teta 0:00:08 lr 0.000583\t wd 0.0100\ttime 0.0330 (0.0357)\tloss 0.4221 (0.6893)\tgrad_norm 1.2517 (nan)\tloss_scale 32768.0000 (32854.0052)\tmem 455MB\n",
      "Train: [46/100][390/625]\teta 0:00:08 lr 0.000583\t wd 0.0100\ttime 0.0352 (0.0357)\tloss 0.7285 (0.6894)\tgrad_norm 2.0108 (nan)\tloss_scale 32768.0000 (32851.8056)\tmem 455MB\n",
      "Train: [46/100][400/625]\teta 0:00:08 lr 0.000583\t wd 0.0100\ttime 0.0358 (0.0357)\tloss 0.7744 (0.6888)\tgrad_norm 2.1420 (nan)\tloss_scale 32768.0000 (32849.7157)\tmem 455MB\n",
      "Train: [46/100][410/625]\teta 0:00:07 lr 0.000582\t wd 0.0100\ttime 0.0325 (0.0356)\tloss 0.7451 (0.6881)\tgrad_norm 2.0934 (nan)\tloss_scale 32768.0000 (32847.7275)\tmem 455MB\n",
      "Train: [46/100][420/625]\teta 0:00:07 lr 0.000582\t wd 0.0100\ttime 0.0385 (0.0356)\tloss 0.8496 (0.6898)\tgrad_norm 2.8534 (nan)\tloss_scale 32768.0000 (32845.8337)\tmem 455MB\n",
      "Train: [46/100][430/625]\teta 0:00:06 lr 0.000582\t wd 0.0100\ttime 0.0330 (0.0356)\tloss 0.8091 (0.6905)\tgrad_norm 1.8425 (nan)\tloss_scale 32768.0000 (32844.0278)\tmem 455MB\n",
      "Train: [46/100][440/625]\teta 0:00:06 lr 0.000582\t wd 0.0100\ttime 0.0381 (0.0356)\tloss 0.8667 (0.6915)\tgrad_norm 2.1645 (nan)\tloss_scale 32768.0000 (32842.3039)\tmem 455MB\n",
      "Train: [46/100][450/625]\teta 0:00:06 lr 0.000581\t wd 0.0100\ttime 0.0363 (0.0356)\tloss 0.5854 (0.6909)\tgrad_norm 1.7569 (nan)\tloss_scale 32768.0000 (32840.6563)\tmem 455MB\n",
      "Train: [46/100][460/625]\teta 0:00:05 lr 0.000581\t wd 0.0100\ttime 0.0327 (0.0357)\tloss 0.6211 (0.6911)\tgrad_norm 1.7040 (nan)\tloss_scale 32768.0000 (32839.0803)\tmem 455MB\n",
      "Train: [46/100][470/625]\teta 0:00:05 lr 0.000581\t wd 0.0100\ttime 0.0326 (0.0357)\tloss 0.6318 (0.6907)\tgrad_norm 1.7128 (nan)\tloss_scale 32768.0000 (32837.5711)\tmem 455MB\n",
      "Train: [46/100][480/625]\teta 0:00:05 lr 0.000581\t wd 0.0100\ttime 0.0325 (0.0357)\tloss 0.7607 (0.6911)\tgrad_norm 2.4070 (nan)\tloss_scale 32768.0000 (32836.1247)\tmem 455MB\n",
      "Train: [46/100][490/625]\teta 0:00:04 lr 0.000580\t wd 0.0100\ttime 0.0325 (0.0356)\tloss 0.7021 (0.6912)\tgrad_norm 1.8964 (nan)\tloss_scale 32768.0000 (32834.7373)\tmem 455MB\n",
      "Train: [46/100][500/625]\teta 0:00:04 lr 0.000580\t wd 0.0100\ttime 0.0368 (0.0357)\tloss 0.6470 (0.6893)\tgrad_norm 2.3955 (nan)\tloss_scale 32768.0000 (32833.4052)\tmem 455MB\n",
      "Train: [46/100][510/625]\teta 0:00:04 lr 0.000580\t wd 0.0100\ttime 0.0327 (0.0357)\tloss 0.8130 (0.6907)\tgrad_norm 2.5252 (nan)\tloss_scale 32768.0000 (32832.1252)\tmem 455MB\n",
      "Train: [46/100][520/625]\teta 0:00:03 lr 0.000580\t wd 0.0100\ttime 0.0361 (0.0357)\tloss 0.7319 (0.6915)\tgrad_norm 1.7821 (nan)\tloss_scale 32768.0000 (32830.8944)\tmem 455MB\n",
      "Train: [46/100][530/625]\teta 0:00:03 lr 0.000579\t wd 0.0100\ttime 0.0391 (0.0357)\tloss 0.4355 (0.6915)\tgrad_norm 1.3545 (nan)\tloss_scale 32768.0000 (32829.7100)\tmem 455MB\n",
      "Train: [46/100][540/625]\teta 0:00:03 lr 0.000579\t wd 0.0100\ttime 0.0358 (0.0357)\tloss 0.6230 (0.6924)\tgrad_norm 1.9037 (nan)\tloss_scale 32768.0000 (32828.5693)\tmem 455MB\n",
      "Train: [46/100][550/625]\teta 0:00:02 lr 0.000579\t wd 0.0100\ttime 0.0321 (0.0357)\tloss 0.6060 (0.6935)\tgrad_norm 2.0776 (nan)\tloss_scale 32768.0000 (32827.4701)\tmem 455MB\n",
      "Train: [46/100][560/625]\teta 0:00:02 lr 0.000579\t wd 0.0100\ttime 0.0352 (0.0356)\tloss 0.5859 (0.6938)\tgrad_norm 1.5986 (nan)\tloss_scale 32768.0000 (32826.4100)\tmem 455MB\n",
      "Train: [46/100][570/625]\teta 0:00:01 lr 0.000578\t wd 0.0100\ttime 0.0326 (0.0356)\tloss 0.6533 (0.6943)\tgrad_norm 1.7654 (nan)\tloss_scale 32768.0000 (32825.3870)\tmem 455MB\n",
      "Train: [46/100][580/625]\teta 0:00:01 lr 0.000578\t wd 0.0100\ttime 0.0322 (0.0355)\tloss 0.7617 (0.6947)\tgrad_norm 1.7587 (nan)\tloss_scale 32768.0000 (32824.3993)\tmem 455MB\n",
      "Train: [46/100][590/625]\teta 0:00:01 lr 0.000578\t wd 0.0100\ttime 0.0382 (0.0355)\tloss 0.9272 (0.6948)\tgrad_norm 2.7803 (nan)\tloss_scale 32768.0000 (32823.4450)\tmem 455MB\n",
      "Train: [46/100][600/625]\teta 0:00:00 lr 0.000578\t wd 0.0100\ttime 0.0354 (0.0355)\tloss 0.7031 (0.6952)\tgrad_norm 2.0750 (nan)\tloss_scale 32768.0000 (32822.5225)\tmem 455MB\n",
      "Train: [46/100][610/625]\teta 0:00:00 lr 0.000577\t wd 0.0100\ttime 0.0328 (0.0355)\tloss 0.6353 (0.6952)\tgrad_norm 2.1244 (nan)\tloss_scale 32768.0000 (32821.6301)\tmem 455MB\n",
      "Train: [46/100][620/625]\teta 0:00:00 lr 0.000577\t wd 0.0100\ttime 0.0391 (0.0355)\tloss 0.8389 (0.6952)\tgrad_norm 2.0353 (nan)\tloss_scale 32768.0000 (32820.7665)\tmem 455MB\n",
      "EPOCH 46 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_46.pth saving......\n",
      "./model_save/ckpt_epoch_46.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.6572 (0.6572)\tAcc@1 76.562 (76.562)\tAcc@5 96.875 (96.875)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.9023 (0.6779)\tAcc@1 67.188 (75.710)\tAcc@5 93.750 (98.011)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.8276 (0.6637)\tAcc@1 70.312 (75.670)\tAcc@5 98.438 (98.586)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.7988 (0.6851)\tAcc@1 75.000 (74.647)\tAcc@5 96.875 (98.589)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.8149 (0.7070)\tAcc@1 67.188 (74.200)\tAcc@5 98.438 (98.476)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.7031 (0.7122)\tAcc@1 76.562 (74.173)\tAcc@5 100.000 (98.468)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.7080 (0.7109)\tAcc@1 75.000 (74.283)\tAcc@5 95.312 (98.386)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.7397 (0.7162)\tAcc@1 71.875 (73.944)\tAcc@5 98.438 (98.415)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.9360 (0.7203)\tAcc@1 60.938 (73.727)\tAcc@5 96.875 (98.457)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.8257 (0.7267)\tAcc@1 64.062 (73.729)\tAcc@5 100.000 (98.369)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.7725 (0.7247)\tAcc@1 75.000 (73.917)\tAcc@5 98.438 (98.407)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.6284 (0.7229)\tAcc@1 78.125 (74.043)\tAcc@5 98.438 (98.381)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.9253 (0.7234)\tAcc@1 73.438 (74.083)\tAcc@5 93.750 (98.308)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.7856 (0.7219)\tAcc@1 73.438 (74.213)\tAcc@5 96.875 (98.306)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.8545 (0.7256)\tAcc@1 60.938 (73.958)\tAcc@5 100.000 (98.338)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.8047 (0.7312)\tAcc@1 73.438 (73.851)\tAcc@5 100.000 (98.282)\tMem 455MB\n",
      " * Acc@1 73.830 Acc@5 98.320\n",
      "Accuracy of the network on the 10000 test images: 73.8%\n",
      "Max accuracy: 74.97%\n",
      "Train: [47/100][0/625]\teta 0:00:22 lr 0.000577\t wd 0.0100\ttime 0.0362 (0.0362)\tloss 0.7544 (0.7544)\tgrad_norm 2.0161 (2.0161)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][10/625]\teta 0:00:22 lr 0.000577\t wd 0.0100\ttime 0.0387 (0.0361)\tloss 0.6177 (0.6554)\tgrad_norm 1.7862 (2.0446)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][20/625]\teta 0:00:22 lr 0.000576\t wd 0.0100\ttime 0.0399 (0.0367)\tloss 0.7437 (0.6756)\tgrad_norm 1.8487 (2.0409)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][30/625]\teta 0:00:21 lr 0.000576\t wd 0.0100\ttime 0.0325 (0.0363)\tloss 0.6812 (0.6857)\tgrad_norm 1.9506 (2.0353)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][40/625]\teta 0:00:20 lr 0.000576\t wd 0.0100\ttime 0.0352 (0.0359)\tloss 0.6006 (0.6763)\tgrad_norm 1.7639 (1.9903)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][50/625]\teta 0:00:20 lr 0.000576\t wd 0.0100\ttime 0.0357 (0.0358)\tloss 0.6909 (0.6891)\tgrad_norm 2.7934 (2.0557)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][60/625]\teta 0:00:20 lr 0.000575\t wd 0.0100\ttime 0.0359 (0.0358)\tloss 0.5005 (0.6766)\tgrad_norm 1.7933 (2.0285)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][70/625]\teta 0:00:19 lr 0.000575\t wd 0.0100\ttime 0.0356 (0.0356)\tloss 0.8872 (0.6781)\tgrad_norm 2.8095 (2.0140)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][80/625]\teta 0:00:19 lr 0.000575\t wd 0.0100\ttime 0.0361 (0.0355)\tloss 0.6758 (0.6838)\tgrad_norm 2.1689 (2.0232)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][90/625]\teta 0:00:19 lr 0.000575\t wd 0.0100\ttime 0.0399 (0.0357)\tloss 0.8423 (0.6875)\tgrad_norm 2.3180 (2.0343)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][100/625]\teta 0:00:18 lr 0.000574\t wd 0.0100\ttime 0.0325 (0.0359)\tloss 0.7637 (0.6829)\tgrad_norm 2.3822 (2.0387)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][110/625]\teta 0:00:18 lr 0.000574\t wd 0.0100\ttime 0.0382 (0.0359)\tloss 0.7266 (0.6822)\tgrad_norm 2.3314 (2.0329)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][120/625]\teta 0:00:18 lr 0.000574\t wd 0.0100\ttime 0.0357 (0.0358)\tloss 0.6729 (0.6825)\tgrad_norm 2.5672 (2.0205)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][130/625]\teta 0:00:17 lr 0.000574\t wd 0.0100\ttime 0.0327 (0.0358)\tloss 0.5522 (0.6801)\tgrad_norm 1.7296 (2.0110)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][140/625]\teta 0:00:17 lr 0.000573\t wd 0.0100\ttime 0.0325 (0.0358)\tloss 0.7251 (0.6813)\tgrad_norm 1.5852 (2.0300)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][150/625]\teta 0:00:17 lr 0.000573\t wd 0.0100\ttime 0.0325 (0.0358)\tloss 0.6348 (0.6838)\tgrad_norm 1.6145 (2.0309)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][160/625]\teta 0:00:16 lr 0.000573\t wd 0.0100\ttime 0.0369 (0.0359)\tloss 0.6606 (0.6850)\tgrad_norm 2.0484 (2.0291)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][170/625]\teta 0:00:16 lr 0.000573\t wd 0.0100\ttime 0.0359 (0.0359)\tloss 0.6138 (0.6806)\tgrad_norm 1.8880 (2.0187)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][180/625]\teta 0:00:15 lr 0.000572\t wd 0.0100\ttime 0.0323 (0.0359)\tloss 0.6616 (0.6816)\tgrad_norm 1.8397 (2.0110)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][190/625]\teta 0:00:15 lr 0.000572\t wd 0.0100\ttime 0.0397 (0.0359)\tloss 0.8550 (0.6822)\tgrad_norm 2.2890 (2.0182)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][200/625]\teta 0:00:15 lr 0.000572\t wd 0.0100\ttime 0.0355 (0.0359)\tloss 0.6719 (0.6854)\tgrad_norm 1.6838 (2.0208)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][210/625]\teta 0:00:14 lr 0.000572\t wd 0.0100\ttime 0.0356 (0.0359)\tloss 0.6997 (0.6863)\tgrad_norm 2.0890 (2.0174)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][220/625]\teta 0:00:14 lr 0.000571\t wd 0.0100\ttime 0.0325 (0.0358)\tloss 0.6626 (0.6831)\tgrad_norm 1.8776 (2.0134)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][230/625]\teta 0:00:14 lr 0.000571\t wd 0.0100\ttime 0.0398 (0.0358)\tloss 0.5469 (0.6836)\tgrad_norm 1.4654 (2.0217)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][240/625]\teta 0:00:13 lr 0.000571\t wd 0.0100\ttime 0.0323 (0.0358)\tloss 0.7568 (0.6836)\tgrad_norm 2.7135 (2.0251)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][250/625]\teta 0:00:13 lr 0.000571\t wd 0.0100\ttime 0.0384 (0.0358)\tloss 0.5596 (0.6849)\tgrad_norm 1.8710 (2.0245)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][260/625]\teta 0:00:13 lr 0.000570\t wd 0.0100\ttime 0.0325 (0.0358)\tloss 0.5605 (0.6841)\tgrad_norm 1.6511 (2.0239)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][270/625]\teta 0:00:12 lr 0.000570\t wd 0.0100\ttime 0.0324 (0.0358)\tloss 0.4978 (0.6829)\tgrad_norm 1.9237 (2.0260)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][280/625]\teta 0:00:12 lr 0.000570\t wd 0.0100\ttime 0.0323 (0.0358)\tloss 0.7915 (0.6831)\tgrad_norm 1.9749 (2.0296)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][290/625]\teta 0:00:11 lr 0.000570\t wd 0.0100\ttime 0.0387 (0.0358)\tloss 0.7104 (0.6847)\tgrad_norm 1.8776 (2.0280)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][300/625]\teta 0:00:11 lr 0.000569\t wd 0.0100\ttime 0.0352 (0.0357)\tloss 0.6929 (0.6841)\tgrad_norm 2.0534 (2.0318)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][310/625]\teta 0:00:11 lr 0.000569\t wd 0.0100\ttime 0.0389 (0.0358)\tloss 0.5908 (0.6836)\tgrad_norm 1.5254 (2.0294)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][320/625]\teta 0:00:10 lr 0.000569\t wd 0.0100\ttime 0.0362 (0.0358)\tloss 0.7603 (0.6837)\tgrad_norm 1.9262 (2.0232)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][330/625]\teta 0:00:10 lr 0.000569\t wd 0.0100\ttime 0.0352 (0.0357)\tloss 0.7075 (0.6833)\tgrad_norm 1.9918 (2.0201)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][340/625]\teta 0:00:10 lr 0.000568\t wd 0.0100\ttime 0.0357 (0.0357)\tloss 0.6758 (0.6826)\tgrad_norm 2.0468 (2.0200)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][350/625]\teta 0:00:09 lr 0.000568\t wd 0.0100\ttime 0.0323 (0.0357)\tloss 0.6357 (0.6831)\tgrad_norm 1.6972 (2.0189)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][360/625]\teta 0:00:09 lr 0.000568\t wd 0.0100\ttime 0.0327 (0.0357)\tloss 0.9204 (0.6829)\tgrad_norm 2.0360 (2.0179)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][370/625]\teta 0:00:09 lr 0.000567\t wd 0.0100\ttime 0.0346 (0.0357)\tloss 0.7949 (0.6828)\tgrad_norm 3.2365 (2.0208)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][380/625]\teta 0:00:08 lr 0.000567\t wd 0.0100\ttime 0.0330 (0.0356)\tloss 0.5195 (0.6810)\tgrad_norm 1.7574 (2.0202)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][390/625]\teta 0:00:08 lr 0.000567\t wd 0.0100\ttime 0.0355 (0.0356)\tloss 0.7793 (0.6824)\tgrad_norm 2.5444 (2.0258)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][400/625]\teta 0:00:08 lr 0.000567\t wd 0.0100\ttime 0.0386 (0.0356)\tloss 0.9395 (0.6835)\tgrad_norm 2.0191 (2.0249)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][410/625]\teta 0:00:07 lr 0.000566\t wd 0.0100\ttime 0.0327 (0.0356)\tloss 0.5674 (0.6834)\tgrad_norm 2.0368 (2.0227)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][420/625]\teta 0:00:07 lr 0.000566\t wd 0.0100\ttime 0.0394 (0.0357)\tloss 0.6162 (0.6841)\tgrad_norm 1.5062 (2.0200)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][430/625]\teta 0:00:06 lr 0.000566\t wd 0.0100\ttime 0.0330 (0.0357)\tloss 0.4976 (0.6818)\tgrad_norm 1.5336 (2.0137)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][440/625]\teta 0:00:06 lr 0.000566\t wd 0.0100\ttime 0.0352 (0.0357)\tloss 0.8862 (0.6838)\tgrad_norm 2.5261 (2.0178)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][450/625]\teta 0:00:06 lr 0.000565\t wd 0.0100\ttime 0.0353 (0.0357)\tloss 0.4622 (0.6832)\tgrad_norm 2.0026 (2.0137)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][460/625]\teta 0:00:05 lr 0.000565\t wd 0.0100\ttime 0.0354 (0.0356)\tloss 0.9116 (0.6828)\tgrad_norm 2.7390 (2.0144)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][470/625]\teta 0:00:05 lr 0.000565\t wd 0.0100\ttime 0.0362 (0.0357)\tloss 0.5547 (0.6816)\tgrad_norm 2.5921 (2.0144)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][480/625]\teta 0:00:05 lr 0.000565\t wd 0.0100\ttime 0.0322 (0.0356)\tloss 0.7397 (0.6826)\tgrad_norm 1.8831 (2.0179)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][490/625]\teta 0:00:04 lr 0.000564\t wd 0.0100\ttime 0.0353 (0.0357)\tloss 0.7710 (0.6824)\tgrad_norm 2.6110 (2.0205)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][500/625]\teta 0:00:04 lr 0.000564\t wd 0.0100\ttime 0.0388 (0.0357)\tloss 0.5244 (0.6826)\tgrad_norm 1.5253 (2.0195)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][510/625]\teta 0:00:04 lr 0.000564\t wd 0.0100\ttime 0.0324 (0.0357)\tloss 0.7690 (0.6837)\tgrad_norm 1.3582 (2.0197)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][520/625]\teta 0:00:03 lr 0.000564\t wd 0.0100\ttime 0.0395 (0.0357)\tloss 0.6006 (0.6839)\tgrad_norm 1.7851 (2.0199)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][530/625]\teta 0:00:03 lr 0.000563\t wd 0.0100\ttime 0.0325 (0.0357)\tloss 0.8564 (0.6850)\tgrad_norm 2.0425 (2.0180)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][540/625]\teta 0:00:03 lr 0.000563\t wd 0.0100\ttime 0.0324 (0.0356)\tloss 0.4424 (0.6848)\tgrad_norm 1.7628 (2.0149)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][550/625]\teta 0:00:02 lr 0.000563\t wd 0.0100\ttime 0.0326 (0.0356)\tloss 0.7861 (0.6840)\tgrad_norm 2.5826 (2.0128)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][560/625]\teta 0:00:02 lr 0.000563\t wd 0.0100\ttime 0.0322 (0.0356)\tloss 0.6899 (0.6828)\tgrad_norm 2.0955 (2.0098)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][570/625]\teta 0:00:01 lr 0.000562\t wd 0.0100\ttime 0.0326 (0.0355)\tloss 0.8467 (0.6833)\tgrad_norm 2.6295 (2.0100)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][580/625]\teta 0:00:01 lr 0.000562\t wd 0.0100\ttime 0.0322 (0.0355)\tloss 0.8125 (0.6830)\tgrad_norm 1.7654 (2.0075)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][590/625]\teta 0:00:01 lr 0.000562\t wd 0.0100\ttime 0.0362 (0.0355)\tloss 0.5293 (0.6823)\tgrad_norm 1.4678 (2.0054)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][600/625]\teta 0:00:00 lr 0.000562\t wd 0.0100\ttime 0.0354 (0.0355)\tloss 0.6406 (0.6824)\tgrad_norm 2.1132 (2.0085)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][610/625]\teta 0:00:00 lr 0.000561\t wd 0.0100\ttime 0.0325 (0.0354)\tloss 0.4788 (0.6818)\tgrad_norm 1.9141 (2.0106)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [47/100][620/625]\teta 0:00:00 lr 0.000561\t wd 0.0100\ttime 0.0359 (0.0354)\tloss 0.6392 (0.6811)\tgrad_norm 1.7488 (2.0132)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 47 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_47.pth saving......\n",
      "./model_save/ckpt_epoch_47.pth saved !!!\n",
      "Test: [0/157]\tTime 0.018 (0.018)\tLoss 0.6978 (0.6978)\tAcc@1 78.125 (78.125)\tAcc@5 98.438 (98.438)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.8809 (0.6844)\tAcc@1 67.188 (75.994)\tAcc@5 98.438 (99.290)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.7505 (0.6804)\tAcc@1 71.875 (75.595)\tAcc@5 96.875 (98.884)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.5010 (0.6916)\tAcc@1 82.812 (75.655)\tAcc@5 100.000 (98.690)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.7314 (0.6830)\tAcc@1 73.438 (75.724)\tAcc@5 100.000 (98.780)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.6602 (0.6932)\tAcc@1 79.688 (75.368)\tAcc@5 98.438 (98.713)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.7778 (0.6933)\tAcc@1 75.000 (75.666)\tAcc@5 96.875 (98.719)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.5459 (0.6920)\tAcc@1 84.375 (75.616)\tAcc@5 100.000 (98.702)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.5830 (0.6969)\tAcc@1 78.125 (75.444)\tAcc@5 96.875 (98.650)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.7188 (0.6937)\tAcc@1 73.438 (75.412)\tAcc@5 98.438 (98.661)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.7285 (0.6910)\tAcc@1 70.312 (75.480)\tAcc@5 100.000 (98.639)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.7168 (0.6957)\tAcc@1 73.438 (75.296)\tAcc@5 100.000 (98.691)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.6587 (0.6939)\tAcc@1 78.125 (75.362)\tAcc@5 96.875 (98.605)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 1.0127 (0.6998)\tAcc@1 67.188 (75.262)\tAcc@5 100.000 (98.581)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.6914 (0.6975)\tAcc@1 78.125 (75.388)\tAcc@5 95.312 (98.582)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.5493 (0.7034)\tAcc@1 78.125 (75.248)\tAcc@5 100.000 (98.541)\tMem 455MB\n",
      " * Acc@1 75.100 Acc@5 98.540\n",
      "Accuracy of the network on the 10000 test images: 75.1%\n",
      "Max accuracy: 75.10%\n",
      "Train: [48/100][0/625]\teta 0:00:25 lr 0.000561\t wd 0.0100\ttime 0.0405 (0.0405)\tloss 0.4233 (0.4233)\tgrad_norm 1.7641 (1.7641)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][10/625]\teta 0:00:21 lr 0.000561\t wd 0.0100\ttime 0.0324 (0.0351)\tloss 0.5962 (0.5767)\tgrad_norm 1.8850 (1.9978)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][20/625]\teta 0:00:21 lr 0.000560\t wd 0.0100\ttime 0.0352 (0.0349)\tloss 0.7300 (0.6137)\tgrad_norm 2.3003 (2.0378)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][30/625]\teta 0:00:20 lr 0.000560\t wd 0.0100\ttime 0.0379 (0.0351)\tloss 0.6104 (0.6316)\tgrad_norm 2.2610 (2.0616)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][40/625]\teta 0:00:20 lr 0.000560\t wd 0.0100\ttime 0.0380 (0.0353)\tloss 0.6797 (0.6388)\tgrad_norm 1.7229 (2.0756)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][50/625]\teta 0:00:20 lr 0.000560\t wd 0.0100\ttime 0.0323 (0.0355)\tloss 0.6802 (0.6493)\tgrad_norm 2.1194 (2.0676)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][60/625]\teta 0:00:20 lr 0.000559\t wd 0.0100\ttime 0.0362 (0.0357)\tloss 0.6523 (0.6436)\tgrad_norm 2.4256 (2.1064)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][70/625]\teta 0:00:19 lr 0.000559\t wd 0.0100\ttime 0.0389 (0.0357)\tloss 0.5522 (0.6448)\tgrad_norm 1.6119 (2.0806)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][80/625]\teta 0:00:19 lr 0.000559\t wd 0.0100\ttime 0.0332 (0.0356)\tloss 0.6025 (0.6539)\tgrad_norm 2.5569 (2.1108)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][90/625]\teta 0:00:19 lr 0.000559\t wd 0.0100\ttime 0.0362 (0.0356)\tloss 0.6426 (0.6621)\tgrad_norm 2.3186 (2.1289)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][100/625]\teta 0:00:18 lr 0.000558\t wd 0.0100\ttime 0.0372 (0.0356)\tloss 0.6436 (0.6709)\tgrad_norm 1.7351 (2.1187)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][110/625]\teta 0:00:18 lr 0.000558\t wd 0.0100\ttime 0.0365 (0.0357)\tloss 0.5518 (0.6677)\tgrad_norm 1.2832 (2.0825)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][120/625]\teta 0:00:18 lr 0.000558\t wd 0.0100\ttime 0.0331 (0.0357)\tloss 0.7646 (0.6673)\tgrad_norm 1.9875 (2.0932)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][130/625]\teta 0:00:17 lr 0.000558\t wd 0.0100\ttime 0.0363 (0.0358)\tloss 0.6157 (0.6682)\tgrad_norm 1.8336 (2.0810)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][140/625]\teta 0:00:17 lr 0.000557\t wd 0.0100\ttime 0.0417 (0.0357)\tloss 0.6050 (0.6715)\tgrad_norm 1.4903 (2.0727)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][150/625]\teta 0:00:16 lr 0.000557\t wd 0.0100\ttime 0.0324 (0.0358)\tloss 0.5776 (0.6737)\tgrad_norm 1.7057 (2.0506)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][160/625]\teta 0:00:16 lr 0.000557\t wd 0.0100\ttime 0.0356 (0.0358)\tloss 0.6665 (0.6747)\tgrad_norm 2.6594 (2.0360)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][170/625]\teta 0:00:16 lr 0.000557\t wd 0.0100\ttime 0.0357 (0.0358)\tloss 0.6997 (0.6731)\tgrad_norm 2.1107 (2.0436)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][180/625]\teta 0:00:15 lr 0.000556\t wd 0.0100\ttime 0.0329 (0.0358)\tloss 0.5972 (0.6737)\tgrad_norm 1.8691 (2.0487)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][190/625]\teta 0:00:15 lr 0.000556\t wd 0.0100\ttime 0.0344 (0.0358)\tloss 0.5293 (0.6724)\tgrad_norm 1.9748 (2.0383)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][200/625]\teta 0:00:15 lr 0.000556\t wd 0.0100\ttime 0.0359 (0.0358)\tloss 0.5298 (0.6692)\tgrad_norm 1.7031 (2.0386)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][210/625]\teta 0:00:14 lr 0.000556\t wd 0.0100\ttime 0.0360 (0.0358)\tloss 0.5742 (0.6679)\tgrad_norm 2.5806 (2.0398)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][220/625]\teta 0:00:14 lr 0.000555\t wd 0.0100\ttime 0.0358 (0.0358)\tloss 0.8491 (0.6681)\tgrad_norm 1.7216 (2.0374)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][230/625]\teta 0:00:14 lr 0.000555\t wd 0.0100\ttime 0.0325 (0.0358)\tloss 0.5317 (0.6657)\tgrad_norm 1.2901 (2.0318)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][240/625]\teta 0:00:13 lr 0.000555\t wd 0.0100\ttime 0.0326 (0.0357)\tloss 0.9316 (0.6673)\tgrad_norm 1.9459 (2.0293)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][250/625]\teta 0:00:13 lr 0.000555\t wd 0.0100\ttime 0.0327 (0.0357)\tloss 0.6924 (0.6695)\tgrad_norm 2.1251 (2.0380)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][260/625]\teta 0:00:13 lr 0.000554\t wd 0.0100\ttime 0.0358 (0.0357)\tloss 0.7021 (0.6674)\tgrad_norm 2.0898 (2.0337)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][270/625]\teta 0:00:12 lr 0.000554\t wd 0.0100\ttime 0.0356 (0.0357)\tloss 0.6279 (0.6650)\tgrad_norm 1.9235 (2.0267)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][280/625]\teta 0:00:12 lr 0.000554\t wd 0.0100\ttime 0.0363 (0.0357)\tloss 0.9087 (0.6651)\tgrad_norm 2.3938 (2.0263)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][290/625]\teta 0:00:11 lr 0.000554\t wd 0.0100\ttime 0.0385 (0.0358)\tloss 0.7500 (0.6627)\tgrad_norm 2.0601 (2.0276)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][300/625]\teta 0:00:11 lr 0.000553\t wd 0.0100\ttime 0.0356 (0.0358)\tloss 0.7041 (0.6634)\tgrad_norm 1.7158 (2.0293)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][310/625]\teta 0:00:11 lr 0.000553\t wd 0.0100\ttime 0.0358 (0.0358)\tloss 0.7881 (0.6645)\tgrad_norm 1.8706 (2.0309)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][320/625]\teta 0:00:10 lr 0.000553\t wd 0.0100\ttime 0.0327 (0.0358)\tloss 0.4749 (0.6650)\tgrad_norm 1.7891 (2.0404)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][330/625]\teta 0:00:10 lr 0.000553\t wd 0.0100\ttime 0.0328 (0.0358)\tloss 0.6201 (0.6647)\tgrad_norm 1.6203 (2.0386)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][340/625]\teta 0:00:10 lr 0.000552\t wd 0.0100\ttime 0.0393 (0.0358)\tloss 0.7080 (0.6647)\tgrad_norm 1.9236 (2.0466)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][350/625]\teta 0:00:09 lr 0.000552\t wd 0.0100\ttime 0.0377 (0.0358)\tloss 0.7280 (0.6646)\tgrad_norm 1.8470 (2.0466)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][360/625]\teta 0:00:09 lr 0.000552\t wd 0.0100\ttime 0.0329 (0.0358)\tloss 0.5776 (0.6665)\tgrad_norm 2.0402 (2.0524)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][370/625]\teta 0:00:09 lr 0.000552\t wd 0.0100\ttime 0.0328 (0.0358)\tloss 0.5908 (0.6666)\tgrad_norm 1.7210 (2.0512)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][380/625]\teta 0:00:08 lr 0.000551\t wd 0.0100\ttime 0.0324 (0.0358)\tloss 0.6855 (0.6659)\tgrad_norm 2.4302 (2.0534)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][390/625]\teta 0:00:08 lr 0.000551\t wd 0.0100\ttime 0.0351 (0.0358)\tloss 0.7666 (0.6654)\tgrad_norm 1.7556 (2.0520)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][400/625]\teta 0:00:08 lr 0.000551\t wd 0.0100\ttime 0.0361 (0.0358)\tloss 0.5615 (0.6671)\tgrad_norm 2.0239 (2.0516)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][410/625]\teta 0:00:07 lr 0.000551\t wd 0.0100\ttime 0.0385 (0.0358)\tloss 0.9277 (0.6687)\tgrad_norm 1.7747 (2.0573)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][420/625]\teta 0:00:07 lr 0.000550\t wd 0.0100\ttime 0.0363 (0.0357)\tloss 0.5278 (0.6670)\tgrad_norm 1.2923 (2.0496)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][430/625]\teta 0:00:06 lr 0.000550\t wd 0.0100\ttime 0.0392 (0.0358)\tloss 0.5410 (0.6655)\tgrad_norm 1.7278 (2.0448)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][440/625]\teta 0:00:06 lr 0.000550\t wd 0.0100\ttime 0.0329 (0.0358)\tloss 0.7666 (0.6673)\tgrad_norm 2.0352 (2.0463)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][450/625]\teta 0:00:06 lr 0.000550\t wd 0.0100\ttime 0.0351 (0.0358)\tloss 1.0303 (0.6688)\tgrad_norm 2.2703 (2.0492)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][460/625]\teta 0:00:05 lr 0.000549\t wd 0.0100\ttime 0.0397 (0.0358)\tloss 0.6880 (0.6674)\tgrad_norm 2.5663 (2.0487)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][470/625]\teta 0:00:05 lr 0.000549\t wd 0.0100\ttime 0.0351 (0.0358)\tloss 0.5400 (0.6677)\tgrad_norm 1.8357 (2.0480)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][480/625]\teta 0:00:05 lr 0.000549\t wd 0.0100\ttime 0.0351 (0.0358)\tloss 0.5405 (0.6666)\tgrad_norm 1.8857 (2.0477)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][490/625]\teta 0:00:04 lr 0.000548\t wd 0.0100\ttime 0.0357 (0.0358)\tloss 0.6367 (0.6667)\tgrad_norm 1.9048 (2.0453)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][500/625]\teta 0:00:04 lr 0.000548\t wd 0.0100\ttime 0.0354 (0.0358)\tloss 0.6201 (0.6670)\tgrad_norm 2.0739 (2.0479)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][510/625]\teta 0:00:04 lr 0.000548\t wd 0.0100\ttime 0.0326 (0.0358)\tloss 0.7485 (0.6672)\tgrad_norm 1.7695 (2.0486)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][520/625]\teta 0:00:03 lr 0.000548\t wd 0.0100\ttime 0.0325 (0.0357)\tloss 0.4468 (0.6677)\tgrad_norm 1.3837 (2.0498)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][530/625]\teta 0:00:03 lr 0.000547\t wd 0.0100\ttime 0.0375 (0.0357)\tloss 0.5864 (0.6671)\tgrad_norm 1.8122 (2.0448)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][540/625]\teta 0:00:03 lr 0.000547\t wd 0.0100\ttime 0.0323 (0.0357)\tloss 0.5361 (0.6677)\tgrad_norm 1.6140 (2.0458)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][550/625]\teta 0:00:02 lr 0.000547\t wd 0.0100\ttime 0.0329 (0.0357)\tloss 0.5996 (0.6683)\tgrad_norm 1.7815 (2.0440)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][560/625]\teta 0:00:02 lr 0.000547\t wd 0.0100\ttime 0.0386 (0.0357)\tloss 0.7046 (0.6681)\tgrad_norm 1.9742 (2.0404)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][570/625]\teta 0:00:01 lr 0.000546\t wd 0.0100\ttime 0.0391 (0.0357)\tloss 0.6641 (0.6694)\tgrad_norm 1.4892 (2.0402)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][580/625]\teta 0:00:01 lr 0.000546\t wd 0.0100\ttime 0.0396 (0.0357)\tloss 0.5981 (0.6691)\tgrad_norm 1.8254 (2.0389)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][590/625]\teta 0:00:01 lr 0.000546\t wd 0.0100\ttime 0.0365 (0.0357)\tloss 0.8799 (0.6694)\tgrad_norm 2.1888 (2.0364)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][600/625]\teta 0:00:00 lr 0.000546\t wd 0.0100\ttime 0.0409 (0.0358)\tloss 0.6460 (0.6688)\tgrad_norm 1.8844 (2.0350)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][610/625]\teta 0:00:00 lr 0.000545\t wd 0.0100\ttime 0.0331 (0.0358)\tloss 0.6509 (0.6680)\tgrad_norm 2.1887 (2.0342)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [48/100][620/625]\teta 0:00:00 lr 0.000545\t wd 0.0100\ttime 0.0338 (0.0358)\tloss 0.7632 (0.6671)\tgrad_norm 2.0460 (2.0308)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 48 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_48.pth saving......\n",
      "./model_save/ckpt_epoch_48.pth saved !!!\n",
      "Test: [0/157]\tTime 0.021 (0.021)\tLoss 0.9370 (0.9370)\tAcc@1 67.188 (67.188)\tAcc@5 96.875 (96.875)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.8921 (0.7446)\tAcc@1 70.312 (73.722)\tAcc@5 96.875 (98.011)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.016 (0.015)\tLoss 0.5879 (0.7375)\tAcc@1 76.562 (74.554)\tAcc@5 98.438 (98.214)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.5107 (0.7101)\tAcc@1 78.125 (75.605)\tAcc@5 100.000 (98.135)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.5610 (0.7058)\tAcc@1 76.562 (75.762)\tAcc@5 100.000 (98.247)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.6509 (0.6968)\tAcc@1 76.562 (76.103)\tAcc@5 98.438 (98.407)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.016 (0.015)\tLoss 0.7300 (0.7021)\tAcc@1 70.312 (75.615)\tAcc@5 98.438 (98.386)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.016 (0.015)\tLoss 0.7510 (0.7028)\tAcc@1 71.875 (75.484)\tAcc@5 98.438 (98.438)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.016 (0.015)\tLoss 0.5830 (0.6968)\tAcc@1 82.812 (75.559)\tAcc@5 100.000 (98.515)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.7910 (0.6970)\tAcc@1 65.625 (75.635)\tAcc@5 100.000 (98.609)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.4109 (0.6939)\tAcc@1 89.062 (75.634)\tAcc@5 100.000 (98.654)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.6548 (0.6938)\tAcc@1 78.125 (75.662)\tAcc@5 98.438 (98.635)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.7378 (0.6944)\tAcc@1 73.438 (75.646)\tAcc@5 100.000 (98.592)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.5098 (0.6916)\tAcc@1 78.125 (75.668)\tAcc@5 100.000 (98.604)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.7842 (0.6888)\tAcc@1 71.875 (75.765)\tAcc@5 100.000 (98.648)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.6675 (0.6901)\tAcc@1 75.000 (75.662)\tAcc@5 98.438 (98.644)\tMem 455MB\n",
      " * Acc@1 75.690 Acc@5 98.660\n",
      "Accuracy of the network on the 10000 test images: 75.7%\n",
      "Max accuracy: 75.69%\n",
      "Train: [49/100][0/625]\teta 0:00:21 lr 0.000545\t wd 0.0100\ttime 0.0349 (0.0349)\tloss 0.4731 (0.4731)\tgrad_norm 1.0223 (1.0223)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [49/100][10/625]\teta 0:00:21 lr 0.000545\t wd 0.0100\ttime 0.0353 (0.0356)\tloss 0.6548 (0.6510)\tgrad_norm 2.2363 (1.9598)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [49/100][20/625]\teta 0:00:21 lr 0.000545\t wd 0.0100\ttime 0.0336 (0.0362)\tloss 0.5903 (0.6474)\tgrad_norm 2.2300 (1.9608)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [49/100][30/625]\teta 0:00:21 lr 0.000544\t wd 0.0100\ttime 0.0327 (0.0358)\tloss 0.4578 (0.6398)\tgrad_norm 2.0688 (2.0300)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [49/100][40/625]\teta 0:00:21 lr 0.000544\t wd 0.0100\ttime 0.0326 (0.0361)\tloss 0.6670 (0.6501)\tgrad_norm 1.9371 (2.0455)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [49/100][50/625]\teta 0:00:20 lr 0.000544\t wd 0.0100\ttime 0.0326 (0.0360)\tloss 0.4468 (0.6522)\tgrad_norm 1.8614 (2.0857)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [49/100][60/625]\teta 0:00:20 lr 0.000544\t wd 0.0100\ttime 0.0324 (0.0358)\tloss 0.5962 (0.6465)\tgrad_norm 1.9789 (2.0655)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [49/100][70/625]\teta 0:00:19 lr 0.000543\t wd 0.0100\ttime 0.0387 (0.0359)\tloss 0.7935 (0.6585)\tgrad_norm 1.8385 (2.0730)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [49/100][80/625]\teta 0:00:19 lr 0.000543\t wd 0.0100\ttime 0.0344 (0.0360)\tloss 0.6387 (0.6496)\tgrad_norm 1.9922 (2.0371)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [49/100][90/625]\teta 0:00:19 lr 0.000543\t wd 0.0100\ttime 0.0363 (0.0359)\tloss 0.6938 (0.6488)\tgrad_norm 2.1129 (2.0149)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [49/100][100/625]\teta 0:00:18 lr 0.000542\t wd 0.0100\ttime 0.0323 (0.0357)\tloss 0.6362 (0.6531)\tgrad_norm 1.8476 (2.0141)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [49/100][110/625]\teta 0:00:18 lr 0.000542\t wd 0.0100\ttime 0.0357 (0.0357)\tloss 0.6069 (0.6452)\tgrad_norm 1.8351 (2.0029)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [49/100][120/625]\teta 0:00:18 lr 0.000542\t wd 0.0100\ttime 0.0381 (0.0358)\tloss 0.5073 (0.6442)\tgrad_norm 1.4547 (1.9869)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [49/100][130/625]\teta 0:00:17 lr 0.000542\t wd 0.0100\ttime 0.0335 (0.0357)\tloss 0.5610 (0.6452)\tgrad_norm 1.7961 (2.0108)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [49/100][140/625]\teta 0:00:17 lr 0.000541\t wd 0.0100\ttime 0.0394 (0.0359)\tloss 0.6128 (0.6416)\tgrad_norm 1.7699 (nan)\tloss_scale 32768.0000 (33000.3972)\tmem 455MB\n",
      "Train: [49/100][150/625]\teta 0:00:17 lr 0.000541\t wd 0.0100\ttime 0.0375 (0.0358)\tloss 0.8755 (0.6415)\tgrad_norm 2.4435 (nan)\tloss_scale 32768.0000 (32985.0066)\tmem 455MB\n",
      "Train: [49/100][160/625]\teta 0:00:16 lr 0.000541\t wd 0.0100\ttime 0.0325 (0.0359)\tloss 0.6611 (0.6410)\tgrad_norm 2.7832 (nan)\tloss_scale 32768.0000 (32971.5280)\tmem 455MB\n",
      "Train: [49/100][170/625]\teta 0:00:16 lr 0.000541\t wd 0.0100\ttime 0.0355 (0.0360)\tloss 0.8350 (0.6422)\tgrad_norm 1.9863 (nan)\tloss_scale 32768.0000 (32959.6257)\tmem 455MB\n",
      "Train: [49/100][180/625]\teta 0:00:15 lr 0.000540\t wd 0.0100\ttime 0.0360 (0.0359)\tloss 0.5713 (0.6460)\tgrad_norm 1.5249 (nan)\tloss_scale 32768.0000 (32949.0387)\tmem 455MB\n",
      "Train: [49/100][190/625]\teta 0:00:15 lr 0.000540\t wd 0.0100\ttime 0.0334 (0.0358)\tloss 0.7090 (0.6450)\tgrad_norm 1.6296 (nan)\tloss_scale 32768.0000 (32939.5602)\tmem 455MB\n",
      "Train: [49/100][200/625]\teta 0:00:15 lr 0.000540\t wd 0.0100\ttime 0.0327 (0.0357)\tloss 0.6919 (0.6438)\tgrad_norm 1.8247 (nan)\tloss_scale 32768.0000 (32931.0249)\tmem 455MB\n",
      "Train: [49/100][210/625]\teta 0:00:14 lr 0.000540\t wd 0.0100\ttime 0.0323 (0.0356)\tloss 0.7300 (0.6441)\tgrad_norm 1.6907 (nan)\tloss_scale 32768.0000 (32923.2986)\tmem 455MB\n",
      "Train: [49/100][220/625]\teta 0:00:14 lr 0.000539\t wd 0.0100\ttime 0.0326 (0.0355)\tloss 0.6929 (0.6435)\tgrad_norm 2.3125 (nan)\tloss_scale 32768.0000 (32916.2715)\tmem 455MB\n",
      "Train: [49/100][230/625]\teta 0:00:13 lr 0.000539\t wd 0.0100\ttime 0.0322 (0.0354)\tloss 0.7026 (0.6456)\tgrad_norm 2.7276 (nan)\tloss_scale 32768.0000 (32909.8528)\tmem 455MB\n",
      "Train: [49/100][240/625]\teta 0:00:13 lr 0.000539\t wd 0.0100\ttime 0.0341 (0.0354)\tloss 0.6108 (0.6450)\tgrad_norm 1.6170 (nan)\tloss_scale 32768.0000 (32903.9668)\tmem 455MB\n",
      "Train: [49/100][250/625]\teta 0:00:13 lr 0.000539\t wd 0.0100\ttime 0.0328 (0.0353)\tloss 0.6509 (0.6438)\tgrad_norm 1.8105 (nan)\tloss_scale 32768.0000 (32898.5498)\tmem 455MB\n",
      "Train: [49/100][260/625]\teta 0:00:12 lr 0.000538\t wd 0.0100\ttime 0.0330 (0.0353)\tloss 0.5659 (0.6457)\tgrad_norm 1.8336 (nan)\tloss_scale 32768.0000 (32893.5479)\tmem 455MB\n",
      "Train: [49/100][270/625]\teta 0:00:12 lr 0.000538\t wd 0.0100\ttime 0.0331 (0.0352)\tloss 0.4641 (0.6458)\tgrad_norm 1.9266 (nan)\tloss_scale 32768.0000 (32888.9151)\tmem 455MB\n",
      "Train: [49/100][280/625]\teta 0:00:12 lr 0.000538\t wd 0.0100\ttime 0.0419 (0.0352)\tloss 0.7539 (0.6472)\tgrad_norm 1.9488 (nan)\tloss_scale 32768.0000 (32884.6121)\tmem 455MB\n",
      "Train: [49/100][290/625]\teta 0:00:11 lr 0.000538\t wd 0.0100\ttime 0.0357 (0.0352)\tloss 0.9365 (0.6507)\tgrad_norm 2.7407 (nan)\tloss_scale 32768.0000 (32880.6048)\tmem 455MB\n",
      "Train: [49/100][300/625]\teta 0:00:11 lr 0.000537\t wd 0.0100\ttime 0.0356 (0.0352)\tloss 0.4751 (0.6509)\tgrad_norm 1.2039 (nan)\tloss_scale 32768.0000 (32876.8638)\tmem 455MB\n",
      "Train: [49/100][310/625]\teta 0:00:11 lr 0.000537\t wd 0.0100\ttime 0.0352 (0.0353)\tloss 0.4761 (0.6506)\tgrad_norm 1.8225 (nan)\tloss_scale 32768.0000 (32873.3633)\tmem 455MB\n",
      "Train: [49/100][320/625]\teta 0:00:10 lr 0.000537\t wd 0.0100\ttime 0.0347 (0.0353)\tloss 0.7051 (0.6517)\tgrad_norm 2.7413 (nan)\tloss_scale 32768.0000 (32870.0810)\tmem 455MB\n",
      "Train: [49/100][330/625]\teta 0:00:10 lr 0.000537\t wd 0.0100\ttime 0.0328 (0.0354)\tloss 0.4636 (0.6521)\tgrad_norm 1.5630 (nan)\tloss_scale 32768.0000 (32866.9970)\tmem 455MB\n",
      "Train: [49/100][340/625]\teta 0:00:10 lr 0.000536\t wd 0.0100\ttime 0.0400 (0.0355)\tloss 0.6968 (0.6538)\tgrad_norm 2.5707 (nan)\tloss_scale 32768.0000 (32864.0938)\tmem 455MB\n",
      "Train: [49/100][350/625]\teta 0:00:09 lr 0.000536\t wd 0.0100\ttime 0.0328 (0.0355)\tloss 0.5669 (0.6541)\tgrad_norm 2.1042 (nan)\tloss_scale 32768.0000 (32861.3561)\tmem 455MB\n",
      "Train: [49/100][360/625]\teta 0:00:09 lr 0.000536\t wd 0.0100\ttime 0.0387 (0.0355)\tloss 0.8594 (0.6556)\tgrad_norm 2.1991 (nan)\tloss_scale 32768.0000 (32858.7701)\tmem 455MB\n",
      "Train: [49/100][370/625]\teta 0:00:09 lr 0.000536\t wd 0.0100\ttime 0.0358 (0.0355)\tloss 0.7446 (0.6559)\tgrad_norm 1.9692 (nan)\tloss_scale 32768.0000 (32856.3235)\tmem 455MB\n",
      "Train: [49/100][380/625]\teta 0:00:08 lr 0.000535\t wd 0.0100\ttime 0.0325 (0.0355)\tloss 0.4922 (0.6565)\tgrad_norm 1.2715 (nan)\tloss_scale 32768.0000 (32854.0052)\tmem 455MB\n",
      "Train: [49/100][390/625]\teta 0:00:08 lr 0.000535\t wd 0.0100\ttime 0.0356 (0.0355)\tloss 0.6255 (0.6561)\tgrad_norm 1.9195 (nan)\tloss_scale 32768.0000 (32851.8056)\tmem 455MB\n",
      "Train: [49/100][400/625]\teta 0:00:07 lr 0.000535\t wd 0.0100\ttime 0.0389 (0.0355)\tloss 0.7773 (0.6554)\tgrad_norm 2.2441 (nan)\tloss_scale 32768.0000 (32849.7157)\tmem 455MB\n",
      "Train: [49/100][410/625]\teta 0:00:07 lr 0.000535\t wd 0.0100\ttime 0.0326 (0.0355)\tloss 0.3401 (0.6548)\tgrad_norm 1.2917 (nan)\tloss_scale 32768.0000 (32847.7275)\tmem 455MB\n",
      "Train: [49/100][420/625]\teta 0:00:07 lr 0.000534\t wd 0.0100\ttime 0.0366 (0.0355)\tloss 0.5869 (0.6554)\tgrad_norm 1.7318 (nan)\tloss_scale 32768.0000 (32845.8337)\tmem 455MB\n",
      "Train: [49/100][430/625]\teta 0:00:06 lr 0.000534\t wd 0.0100\ttime 0.0328 (0.0354)\tloss 0.7393 (0.6562)\tgrad_norm 2.0081 (nan)\tloss_scale 32768.0000 (32844.0278)\tmem 455MB\n",
      "Train: [49/100][440/625]\teta 0:00:06 lr 0.000534\t wd 0.0100\ttime 0.0324 (0.0354)\tloss 0.4617 (0.6559)\tgrad_norm 2.1407 (nan)\tloss_scale 32768.0000 (32842.3039)\tmem 455MB\n",
      "Train: [49/100][450/625]\teta 0:00:06 lr 0.000534\t wd 0.0100\ttime 0.0360 (0.0354)\tloss 0.8608 (0.6560)\tgrad_norm 2.7599 (nan)\tloss_scale 32768.0000 (32840.6563)\tmem 455MB\n",
      "Train: [49/100][460/625]\teta 0:00:05 lr 0.000533\t wd 0.0100\ttime 0.0391 (0.0354)\tloss 0.8145 (0.6567)\tgrad_norm 2.1921 (nan)\tloss_scale 32768.0000 (32839.0803)\tmem 455MB\n",
      "Train: [49/100][470/625]\teta 0:00:05 lr 0.000533\t wd 0.0100\ttime 0.0339 (0.0354)\tloss 0.5024 (0.6565)\tgrad_norm 2.2865 (nan)\tloss_scale 32768.0000 (32837.5711)\tmem 455MB\n",
      "Train: [49/100][480/625]\teta 0:00:05 lr 0.000533\t wd 0.0100\ttime 0.0346 (0.0354)\tloss 0.6533 (0.6568)\tgrad_norm 2.5433 (nan)\tloss_scale 32768.0000 (32836.1247)\tmem 455MB\n",
      "Train: [49/100][490/625]\teta 0:00:04 lr 0.000532\t wd 0.0100\ttime 0.0325 (0.0355)\tloss 1.0342 (0.6574)\tgrad_norm 2.4927 (nan)\tloss_scale 32768.0000 (32834.7373)\tmem 455MB\n",
      "Train: [49/100][500/625]\teta 0:00:04 lr 0.000532\t wd 0.0100\ttime 0.0327 (0.0355)\tloss 0.6572 (0.6576)\tgrad_norm 1.8284 (nan)\tloss_scale 32768.0000 (32833.4052)\tmem 455MB\n",
      "Train: [49/100][510/625]\teta 0:00:04 lr 0.000532\t wd 0.0100\ttime 0.0385 (0.0355)\tloss 0.8101 (0.6595)\tgrad_norm 2.5612 (nan)\tloss_scale 32768.0000 (32832.1252)\tmem 455MB\n",
      "Train: [49/100][520/625]\teta 0:00:03 lr 0.000532\t wd 0.0100\ttime 0.0357 (0.0355)\tloss 0.6392 (0.6602)\tgrad_norm 1.8546 (nan)\tloss_scale 32768.0000 (32830.8944)\tmem 455MB\n",
      "Train: [49/100][530/625]\teta 0:00:03 lr 0.000531\t wd 0.0100\ttime 0.0332 (0.0355)\tloss 0.5967 (0.6607)\tgrad_norm 2.2936 (nan)\tloss_scale 32768.0000 (32829.7100)\tmem 455MB\n",
      "Train: [49/100][540/625]\teta 0:00:03 lr 0.000531\t wd 0.0100\ttime 0.0389 (0.0355)\tloss 0.8008 (0.6609)\tgrad_norm 2.1000 (nan)\tloss_scale 32768.0000 (32828.5693)\tmem 455MB\n",
      "Train: [49/100][550/625]\teta 0:00:02 lr 0.000531\t wd 0.0100\ttime 0.0329 (0.0355)\tloss 0.4050 (0.6599)\tgrad_norm 1.2388 (nan)\tloss_scale 32768.0000 (32827.4701)\tmem 455MB\n",
      "Train: [49/100][560/625]\teta 0:00:02 lr 0.000531\t wd 0.0100\ttime 0.0328 (0.0355)\tloss 0.8604 (0.6597)\tgrad_norm 2.3427 (nan)\tloss_scale 32768.0000 (32826.4100)\tmem 455MB\n",
      "Train: [49/100][570/625]\teta 0:00:01 lr 0.000530\t wd 0.0100\ttime 0.0328 (0.0355)\tloss 0.6470 (0.6601)\tgrad_norm 2.2707 (nan)\tloss_scale 32768.0000 (32825.3870)\tmem 455MB\n",
      "Train: [49/100][580/625]\teta 0:00:01 lr 0.000530\t wd 0.0100\ttime 0.0383 (0.0355)\tloss 0.5840 (0.6600)\tgrad_norm 1.9552 (nan)\tloss_scale 32768.0000 (32824.3993)\tmem 455MB\n",
      "Train: [49/100][590/625]\teta 0:00:01 lr 0.000530\t wd 0.0100\ttime 0.0327 (0.0355)\tloss 0.4519 (0.6594)\tgrad_norm 1.7710 (nan)\tloss_scale 32768.0000 (32823.4450)\tmem 455MB\n",
      "Train: [49/100][600/625]\teta 0:00:00 lr 0.000530\t wd 0.0100\ttime 0.0352 (0.0355)\tloss 0.5166 (0.6583)\tgrad_norm 2.1732 (nan)\tloss_scale 32768.0000 (32822.5225)\tmem 455MB\n",
      "Train: [49/100][610/625]\teta 0:00:00 lr 0.000529\t wd 0.0100\ttime 0.0361 (0.0355)\tloss 0.7549 (0.6592)\tgrad_norm 1.8328 (nan)\tloss_scale 32768.0000 (32821.6301)\tmem 455MB\n",
      "Train: [49/100][620/625]\teta 0:00:00 lr 0.000529\t wd 0.0100\ttime 0.0383 (0.0356)\tloss 0.7881 (0.6585)\tgrad_norm 1.8515 (nan)\tloss_scale 32768.0000 (32820.7665)\tmem 455MB\n",
      "EPOCH 49 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_49.pth saving......\n",
      "./model_save/ckpt_epoch_49.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.6138 (0.6138)\tAcc@1 79.688 (79.688)\tAcc@5 100.000 (100.000)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.5288 (0.6540)\tAcc@1 76.562 (76.562)\tAcc@5 100.000 (99.148)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.6016 (0.6569)\tAcc@1 76.562 (75.818)\tAcc@5 100.000 (99.107)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.8521 (0.6751)\tAcc@1 75.000 (75.252)\tAcc@5 98.438 (98.790)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.8882 (0.6694)\tAcc@1 73.438 (76.334)\tAcc@5 95.312 (98.780)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.6807 (0.6775)\tAcc@1 75.000 (75.735)\tAcc@5 100.000 (98.866)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.9312 (0.6846)\tAcc@1 71.875 (75.538)\tAcc@5 98.438 (98.770)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.8525 (0.6851)\tAcc@1 75.000 (75.902)\tAcc@5 98.438 (98.724)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.5664 (0.6921)\tAcc@1 84.375 (75.752)\tAcc@5 96.875 (98.746)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.7109 (0.6910)\tAcc@1 78.125 (75.859)\tAcc@5 100.000 (98.729)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.7715 (0.6912)\tAcc@1 76.562 (75.913)\tAcc@5 98.438 (98.762)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.7671 (0.6896)\tAcc@1 71.875 (75.915)\tAcc@5 98.438 (98.747)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.6201 (0.6852)\tAcc@1 81.250 (76.033)\tAcc@5 100.000 (98.747)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.7207 (0.6827)\tAcc@1 76.562 (76.121)\tAcc@5 95.312 (98.700)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.6577 (0.6827)\tAcc@1 76.562 (76.141)\tAcc@5 98.438 (98.670)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.7891 (0.6842)\tAcc@1 71.875 (76.087)\tAcc@5 100.000 (98.686)\tMem 455MB\n",
      " * Acc@1 76.180 Acc@5 98.690\n",
      "Accuracy of the network on the 10000 test images: 76.2%\n",
      "Max accuracy: 76.18%\n",
      "Train: [50/100][0/625]\teta 0:00:23 lr 0.000529\t wd 0.0100\ttime 0.0383 (0.0383)\tloss 0.6143 (0.6143)\tgrad_norm 2.2282 (2.2282)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][10/625]\teta 0:00:22 lr 0.000529\t wd 0.0100\ttime 0.0332 (0.0361)\tloss 0.6147 (0.7104)\tgrad_norm 2.3012 (2.3299)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][20/625]\teta 0:00:21 lr 0.000529\t wd 0.0100\ttime 0.0323 (0.0356)\tloss 0.6318 (0.7039)\tgrad_norm 2.5114 (2.2112)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][30/625]\teta 0:00:20 lr 0.000528\t wd 0.0100\ttime 0.0329 (0.0352)\tloss 0.5830 (0.6893)\tgrad_norm 1.6824 (2.1158)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][40/625]\teta 0:00:20 lr 0.000528\t wd 0.0100\ttime 0.0329 (0.0348)\tloss 0.6138 (0.6630)\tgrad_norm 1.9941 (2.0652)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][50/625]\teta 0:00:19 lr 0.000528\t wd 0.0100\ttime 0.0322 (0.0344)\tloss 0.4731 (0.6529)\tgrad_norm 2.1563 (2.0474)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][60/625]\teta 0:00:19 lr 0.000528\t wd 0.0100\ttime 0.0350 (0.0341)\tloss 0.8701 (0.6558)\tgrad_norm 2.9038 (2.0480)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][70/625]\teta 0:00:18 lr 0.000527\t wd 0.0100\ttime 0.0323 (0.0341)\tloss 0.4182 (0.6523)\tgrad_norm 1.3316 (2.0482)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][80/625]\teta 0:00:18 lr 0.000527\t wd 0.0100\ttime 0.0324 (0.0339)\tloss 0.7051 (0.6531)\tgrad_norm 2.0938 (2.0633)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][90/625]\teta 0:00:18 lr 0.000527\t wd 0.0100\ttime 0.0325 (0.0339)\tloss 0.6533 (0.6503)\tgrad_norm 1.9029 (2.0525)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][100/625]\teta 0:00:17 lr 0.000526\t wd 0.0100\ttime 0.0326 (0.0339)\tloss 0.6118 (0.6498)\tgrad_norm 1.8454 (2.0724)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][110/625]\teta 0:00:17 lr 0.000526\t wd 0.0100\ttime 0.0366 (0.0339)\tloss 0.7300 (0.6460)\tgrad_norm 1.9838 (2.0631)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][120/625]\teta 0:00:17 lr 0.000526\t wd 0.0100\ttime 0.0359 (0.0340)\tloss 0.6235 (0.6478)\tgrad_norm 1.8910 (2.0502)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][130/625]\teta 0:00:16 lr 0.000526\t wd 0.0100\ttime 0.0356 (0.0343)\tloss 0.6123 (0.6478)\tgrad_norm 1.8422 (2.0498)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][140/625]\teta 0:00:16 lr 0.000525\t wd 0.0100\ttime 0.0394 (0.0343)\tloss 0.6743 (0.6451)\tgrad_norm 2.4466 (2.0502)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][150/625]\teta 0:00:16 lr 0.000525\t wd 0.0100\ttime 0.0328 (0.0344)\tloss 0.6509 (0.6503)\tgrad_norm 1.9227 (2.0649)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][160/625]\teta 0:00:16 lr 0.000525\t wd 0.0100\ttime 0.0359 (0.0345)\tloss 0.4841 (0.6438)\tgrad_norm 1.6968 (2.0491)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][170/625]\teta 0:00:15 lr 0.000525\t wd 0.0100\ttime 0.0366 (0.0346)\tloss 0.8169 (0.6458)\tgrad_norm 1.9971 (2.0527)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][180/625]\teta 0:00:15 lr 0.000524\t wd 0.0100\ttime 0.0349 (0.0347)\tloss 0.6553 (0.6461)\tgrad_norm 2.1248 (2.0459)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][190/625]\teta 0:00:15 lr 0.000524\t wd 0.0100\ttime 0.0326 (0.0346)\tloss 0.5659 (0.6439)\tgrad_norm 1.9991 (2.0395)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][200/625]\teta 0:00:14 lr 0.000524\t wd 0.0100\ttime 0.0344 (0.0346)\tloss 0.7075 (0.6460)\tgrad_norm 2.0515 (2.0358)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][210/625]\teta 0:00:14 lr 0.000524\t wd 0.0100\ttime 0.0366 (0.0347)\tloss 0.7949 (0.6461)\tgrad_norm 2.3244 (2.0400)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][220/625]\teta 0:00:14 lr 0.000523\t wd 0.0100\ttime 0.0391 (0.0349)\tloss 0.4985 (0.6476)\tgrad_norm 1.4104 (2.0430)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][230/625]\teta 0:00:13 lr 0.000523\t wd 0.0100\ttime 0.0359 (0.0349)\tloss 0.6182 (0.6483)\tgrad_norm 1.6241 (2.0353)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][240/625]\teta 0:00:13 lr 0.000523\t wd 0.0100\ttime 0.0324 (0.0349)\tloss 0.8354 (0.6496)\tgrad_norm 1.8579 (2.0386)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][250/625]\teta 0:00:13 lr 0.000523\t wd 0.0100\ttime 0.0322 (0.0348)\tloss 0.8623 (0.6520)\tgrad_norm 2.0942 (2.0407)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][260/625]\teta 0:00:12 lr 0.000522\t wd 0.0100\ttime 0.0323 (0.0348)\tloss 0.6143 (0.6518)\tgrad_norm 2.1814 (2.0421)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][270/625]\teta 0:00:12 lr 0.000522\t wd 0.0100\ttime 0.0400 (0.0348)\tloss 0.5010 (0.6516)\tgrad_norm 1.6468 (2.0450)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][280/625]\teta 0:00:12 lr 0.000522\t wd 0.0100\ttime 0.0324 (0.0348)\tloss 0.5107 (0.6497)\tgrad_norm 1.4009 (2.0379)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][290/625]\teta 0:00:11 lr 0.000522\t wd 0.0100\ttime 0.0361 (0.0349)\tloss 0.7109 (0.6519)\tgrad_norm 2.5383 (2.0543)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][300/625]\teta 0:00:11 lr 0.000521\t wd 0.0100\ttime 0.0323 (0.0349)\tloss 0.5903 (0.6509)\tgrad_norm 1.6112 (2.0543)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][310/625]\teta 0:00:10 lr 0.000521\t wd 0.0100\ttime 0.0329 (0.0348)\tloss 0.5210 (0.6503)\tgrad_norm 1.4350 (2.0507)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][320/625]\teta 0:00:10 lr 0.000521\t wd 0.0100\ttime 0.0358 (0.0348)\tloss 0.7817 (0.6503)\tgrad_norm 2.2477 (2.0504)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][330/625]\teta 0:00:10 lr 0.000521\t wd 0.0100\ttime 0.0321 (0.0347)\tloss 0.5845 (0.6494)\tgrad_norm 1.5938 (2.0483)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][340/625]\teta 0:00:09 lr 0.000520\t wd 0.0100\ttime 0.0326 (0.0347)\tloss 0.5532 (0.6485)\tgrad_norm 2.1533 (2.0493)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][350/625]\teta 0:00:09 lr 0.000520\t wd 0.0100\ttime 0.0347 (0.0347)\tloss 0.6392 (0.6476)\tgrad_norm 2.1070 (2.0480)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][360/625]\teta 0:00:09 lr 0.000520\t wd 0.0100\ttime 0.0354 (0.0347)\tloss 0.6240 (0.6474)\tgrad_norm 2.3491 (2.0559)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][370/625]\teta 0:00:08 lr 0.000520\t wd 0.0100\ttime 0.0355 (0.0348)\tloss 0.8169 (0.6466)\tgrad_norm 2.3512 (2.0581)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][380/625]\teta 0:00:08 lr 0.000519\t wd 0.0100\ttime 0.0326 (0.0348)\tloss 0.5986 (0.6441)\tgrad_norm 2.8610 (2.0580)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][390/625]\teta 0:00:08 lr 0.000519\t wd 0.0100\ttime 0.0328 (0.0348)\tloss 0.5122 (0.6444)\tgrad_norm 2.1999 (2.0606)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][400/625]\teta 0:00:07 lr 0.000519\t wd 0.0100\ttime 0.0355 (0.0348)\tloss 0.6567 (0.6442)\tgrad_norm 2.0235 (2.0651)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][410/625]\teta 0:00:07 lr 0.000519\t wd 0.0100\ttime 0.0326 (0.0348)\tloss 0.4775 (0.6449)\tgrad_norm 1.9723 (2.0597)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][420/625]\teta 0:00:07 lr 0.000518\t wd 0.0100\ttime 0.0349 (0.0349)\tloss 0.7109 (0.6455)\tgrad_norm 2.4966 (2.0633)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][430/625]\teta 0:00:06 lr 0.000518\t wd 0.0100\ttime 0.0380 (0.0349)\tloss 0.7642 (0.6437)\tgrad_norm 1.7157 (2.0550)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][440/625]\teta 0:00:06 lr 0.000518\t wd 0.0100\ttime 0.0323 (0.0349)\tloss 0.5190 (0.6439)\tgrad_norm 1.4214 (2.0534)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][450/625]\teta 0:00:06 lr 0.000518\t wd 0.0100\ttime 0.0325 (0.0349)\tloss 0.5679 (0.6443)\tgrad_norm 2.1420 (2.0536)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][460/625]\teta 0:00:05 lr 0.000517\t wd 0.0100\ttime 0.0354 (0.0349)\tloss 0.5039 (0.6429)\tgrad_norm 1.5039 (2.0488)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][470/625]\teta 0:00:05 lr 0.000517\t wd 0.0100\ttime 0.0326 (0.0349)\tloss 0.7212 (0.6434)\tgrad_norm 2.0561 (2.0517)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][480/625]\teta 0:00:05 lr 0.000517\t wd 0.0100\ttime 0.0326 (0.0349)\tloss 0.5366 (0.6429)\tgrad_norm 1.6835 (2.0548)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][490/625]\teta 0:00:04 lr 0.000516\t wd 0.0100\ttime 0.0327 (0.0349)\tloss 0.5952 (0.6445)\tgrad_norm 2.1140 (2.0652)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][500/625]\teta 0:00:04 lr 0.000516\t wd 0.0100\ttime 0.0326 (0.0348)\tloss 0.7251 (0.6449)\tgrad_norm 2.9392 (2.0694)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][510/625]\teta 0:00:04 lr 0.000516\t wd 0.0100\ttime 0.0391 (0.0349)\tloss 0.5879 (0.6450)\tgrad_norm 1.7489 (2.0714)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][520/625]\teta 0:00:03 lr 0.000516\t wd 0.0100\ttime 0.0325 (0.0349)\tloss 0.5615 (0.6449)\tgrad_norm 1.6260 (2.0688)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][530/625]\teta 0:00:03 lr 0.000515\t wd 0.0100\ttime 0.0365 (0.0349)\tloss 0.6060 (0.6446)\tgrad_norm 1.7143 (2.0669)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][540/625]\teta 0:00:02 lr 0.000515\t wd 0.0100\ttime 0.0324 (0.0349)\tloss 0.6284 (0.6443)\tgrad_norm 2.3477 (2.0671)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][550/625]\teta 0:00:02 lr 0.000515\t wd 0.0100\ttime 0.0357 (0.0349)\tloss 0.6147 (0.6439)\tgrad_norm 2.1365 (2.0665)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][560/625]\teta 0:00:02 lr 0.000515\t wd 0.0100\ttime 0.0346 (0.0349)\tloss 0.6279 (0.6438)\tgrad_norm 1.9231 (2.0661)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][570/625]\teta 0:00:01 lr 0.000514\t wd 0.0100\ttime 0.0437 (0.0350)\tloss 0.8247 (0.6437)\tgrad_norm 2.4669 (2.0676)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][580/625]\teta 0:00:01 lr 0.000514\t wd 0.0100\ttime 0.0355 (0.0349)\tloss 0.6089 (0.6440)\tgrad_norm 1.6140 (2.0674)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][590/625]\teta 0:00:01 lr 0.000514\t wd 0.0100\ttime 0.0325 (0.0350)\tloss 0.5449 (0.6430)\tgrad_norm 2.4199 (2.0691)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][600/625]\teta 0:00:00 lr 0.000514\t wd 0.0100\ttime 0.0344 (0.0350)\tloss 0.4121 (0.6433)\tgrad_norm 1.6057 (2.0686)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][610/625]\teta 0:00:00 lr 0.000513\t wd 0.0100\ttime 0.0358 (0.0350)\tloss 0.4438 (0.6439)\tgrad_norm 1.2551 (2.0693)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [50/100][620/625]\teta 0:00:00 lr 0.000513\t wd 0.0100\ttime 0.0395 (0.0350)\tloss 0.6973 (0.6437)\tgrad_norm 2.2172 (2.0726)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 50 training takes 0:00:21\n",
      "./model_save/ckpt_epoch_50.pth saving......\n",
      "./model_save/ckpt_epoch_50.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.7212 (0.7212)\tAcc@1 73.438 (73.438)\tAcc@5 96.875 (96.875)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.8833 (0.7643)\tAcc@1 68.750 (73.722)\tAcc@5 98.438 (97.301)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.7627 (0.7266)\tAcc@1 73.438 (74.479)\tAcc@5 93.750 (97.842)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.5781 (0.7177)\tAcc@1 81.250 (75.504)\tAcc@5 98.438 (97.933)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.6504 (0.6956)\tAcc@1 81.250 (75.877)\tAcc@5 96.875 (98.133)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.6982 (0.7041)\tAcc@1 70.312 (75.276)\tAcc@5 98.438 (98.100)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.9336 (0.7159)\tAcc@1 65.625 (74.898)\tAcc@5 98.438 (98.181)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.6182 (0.7105)\tAcc@1 76.562 (75.000)\tAcc@5 100.000 (98.327)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.6475 (0.7006)\tAcc@1 76.562 (75.367)\tAcc@5 98.438 (98.418)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.7061 (0.6980)\tAcc@1 82.812 (75.532)\tAcc@5 98.438 (98.420)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.5547 (0.6918)\tAcc@1 79.688 (75.712)\tAcc@5 100.000 (98.484)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.6152 (0.6853)\tAcc@1 70.312 (75.901)\tAcc@5 100.000 (98.494)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.4307 (0.6877)\tAcc@1 87.500 (75.930)\tAcc@5 100.000 (98.463)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.8452 (0.6924)\tAcc@1 76.562 (75.930)\tAcc@5 95.312 (98.473)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.4727 (0.6890)\tAcc@1 84.375 (75.942)\tAcc@5 100.000 (98.526)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.7119 (0.6905)\tAcc@1 70.312 (75.942)\tAcc@5 96.875 (98.510)\tMem 455MB\n",
      " * Acc@1 75.810 Acc@5 98.520\n",
      "Accuracy of the network on the 10000 test images: 75.8%\n",
      "Max accuracy: 76.18%\n",
      "Train: [51/100][0/625]\teta 0:00:22 lr 0.000513\t wd 0.0100\ttime 0.0356 (0.0356)\tloss 0.5884 (0.5884)\tgrad_norm 1.8781 (1.8781)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][10/625]\teta 0:00:22 lr 0.000513\t wd 0.0100\ttime 0.0396 (0.0360)\tloss 0.4863 (0.6010)\tgrad_norm 1.7562 (1.8806)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][20/625]\teta 0:00:21 lr 0.000513\t wd 0.0100\ttime 0.0370 (0.0359)\tloss 0.3875 (0.5907)\tgrad_norm 1.1681 (1.8585)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][30/625]\teta 0:00:21 lr 0.000512\t wd 0.0100\ttime 0.0339 (0.0361)\tloss 0.6309 (0.6034)\tgrad_norm 1.8973 (1.9083)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][40/625]\teta 0:00:21 lr 0.000512\t wd 0.0100\ttime 0.0327 (0.0360)\tloss 0.5630 (0.6098)\tgrad_norm 1.9201 (1.9167)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][50/625]\teta 0:00:20 lr 0.000512\t wd 0.0100\ttime 0.0374 (0.0361)\tloss 0.4624 (0.6028)\tgrad_norm 1.9660 (1.9267)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][60/625]\teta 0:00:20 lr 0.000511\t wd 0.0100\ttime 0.0394 (0.0363)\tloss 0.6372 (0.6159)\tgrad_norm 2.6618 (2.0057)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][70/625]\teta 0:00:20 lr 0.000511\t wd 0.0100\ttime 0.0355 (0.0363)\tloss 0.4888 (0.6143)\tgrad_norm 1.9078 (2.0057)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][80/625]\teta 0:00:19 lr 0.000511\t wd 0.0100\ttime 0.0358 (0.0361)\tloss 0.5386 (0.6105)\tgrad_norm 1.4962 (1.9831)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][90/625]\teta 0:00:19 lr 0.000511\t wd 0.0100\ttime 0.0381 (0.0362)\tloss 0.7319 (0.6187)\tgrad_norm 2.0399 (1.9879)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][100/625]\teta 0:00:18 lr 0.000510\t wd 0.0100\ttime 0.0325 (0.0359)\tloss 0.3962 (0.6187)\tgrad_norm 2.2813 (2.0066)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][110/625]\teta 0:00:18 lr 0.000510\t wd 0.0100\ttime 0.0326 (0.0358)\tloss 0.5918 (0.6174)\tgrad_norm 1.7466 (1.9991)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][120/625]\teta 0:00:17 lr 0.000510\t wd 0.0100\ttime 0.0328 (0.0356)\tloss 0.5435 (0.6156)\tgrad_norm 2.2160 (2.0041)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][130/625]\teta 0:00:17 lr 0.000510\t wd 0.0100\ttime 0.0324 (0.0354)\tloss 0.6348 (0.6177)\tgrad_norm 1.8152 (2.0040)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][140/625]\teta 0:00:17 lr 0.000509\t wd 0.0100\ttime 0.0375 (0.0355)\tloss 0.6416 (0.6190)\tgrad_norm 2.9380 (2.0038)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][150/625]\teta 0:00:16 lr 0.000509\t wd 0.0100\ttime 0.0327 (0.0355)\tloss 0.6743 (0.6203)\tgrad_norm 2.6169 (2.0189)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][160/625]\teta 0:00:16 lr 0.000509\t wd 0.0100\ttime 0.0364 (0.0355)\tloss 0.6826 (0.6240)\tgrad_norm 2.5285 (2.0254)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][170/625]\teta 0:00:16 lr 0.000509\t wd 0.0100\ttime 0.0324 (0.0355)\tloss 0.5952 (0.6236)\tgrad_norm 1.4163 (2.0185)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][180/625]\teta 0:00:15 lr 0.000508\t wd 0.0100\ttime 0.0328 (0.0355)\tloss 0.5254 (0.6229)\tgrad_norm 1.7838 (2.0163)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][190/625]\teta 0:00:15 lr 0.000508\t wd 0.0100\ttime 0.0327 (0.0356)\tloss 0.5430 (0.6221)\tgrad_norm 1.9755 (2.0124)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][200/625]\teta 0:00:15 lr 0.000508\t wd 0.0100\ttime 0.0356 (0.0356)\tloss 0.3772 (0.6221)\tgrad_norm 1.4453 (2.0143)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][210/625]\teta 0:00:14 lr 0.000508\t wd 0.0100\ttime 0.0327 (0.0356)\tloss 0.6084 (0.6242)\tgrad_norm 1.8949 (2.0146)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][220/625]\teta 0:00:14 lr 0.000507\t wd 0.0100\ttime 0.0392 (0.0356)\tloss 0.7412 (0.6239)\tgrad_norm 2.8088 (2.0221)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][230/625]\teta 0:00:14 lr 0.000507\t wd 0.0100\ttime 0.0357 (0.0356)\tloss 0.5513 (0.6244)\tgrad_norm 1.7869 (2.0271)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][240/625]\teta 0:00:13 lr 0.000507\t wd 0.0100\ttime 0.0324 (0.0356)\tloss 0.6587 (0.6243)\tgrad_norm 2.0139 (2.0330)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][250/625]\teta 0:00:13 lr 0.000507\t wd 0.0100\ttime 0.0329 (0.0356)\tloss 0.4390 (0.6233)\tgrad_norm 1.4019 (2.0263)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][260/625]\teta 0:00:12 lr 0.000506\t wd 0.0100\ttime 0.0358 (0.0355)\tloss 0.7378 (0.6235)\tgrad_norm 2.2138 (2.0278)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][270/625]\teta 0:00:12 lr 0.000506\t wd 0.0100\ttime 0.0335 (0.0356)\tloss 0.5474 (0.6235)\tgrad_norm 2.1565 (2.0366)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][280/625]\teta 0:00:12 lr 0.000506\t wd 0.0100\ttime 0.0330 (0.0356)\tloss 0.5703 (0.6259)\tgrad_norm 1.7964 (2.0432)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][290/625]\teta 0:00:11 lr 0.000506\t wd 0.0100\ttime 0.0350 (0.0357)\tloss 0.5928 (0.6243)\tgrad_norm 2.0068 (2.0455)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][300/625]\teta 0:00:11 lr 0.000505\t wd 0.0100\ttime 0.0327 (0.0358)\tloss 0.7280 (0.6245)\tgrad_norm 3.5967 (2.0561)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][310/625]\teta 0:00:11 lr 0.000505\t wd 0.0100\ttime 0.0335 (0.0357)\tloss 0.6118 (0.6237)\tgrad_norm 1.9504 (2.0576)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][320/625]\teta 0:00:10 lr 0.000505\t wd 0.0100\ttime 0.0334 (0.0357)\tloss 0.5747 (0.6224)\tgrad_norm 2.4558 (2.0597)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][330/625]\teta 0:00:10 lr 0.000505\t wd 0.0100\ttime 0.0330 (0.0357)\tloss 0.9028 (0.6240)\tgrad_norm 1.6639 (2.0583)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][340/625]\teta 0:00:10 lr 0.000504\t wd 0.0100\ttime 0.0334 (0.0356)\tloss 0.6748 (0.6240)\tgrad_norm 1.9160 (2.0600)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][350/625]\teta 0:00:09 lr 0.000504\t wd 0.0100\ttime 0.0330 (0.0356)\tloss 0.4934 (0.6239)\tgrad_norm 1.8565 (2.0565)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][360/625]\teta 0:00:09 lr 0.000504\t wd 0.0100\ttime 0.0362 (0.0357)\tloss 0.6406 (0.6252)\tgrad_norm 2.1583 (2.0542)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][370/625]\teta 0:00:09 lr 0.000504\t wd 0.0100\ttime 0.0393 (0.0357)\tloss 0.6050 (0.6239)\tgrad_norm 2.2861 (2.0569)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][380/625]\teta 0:00:08 lr 0.000503\t wd 0.0100\ttime 0.0325 (0.0357)\tloss 0.6338 (0.6236)\tgrad_norm 2.3017 (2.0573)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][390/625]\teta 0:00:08 lr 0.000503\t wd 0.0100\ttime 0.0363 (0.0357)\tloss 0.7563 (0.6260)\tgrad_norm 2.2233 (2.0576)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][400/625]\teta 0:00:08 lr 0.000503\t wd 0.0100\ttime 0.0325 (0.0356)\tloss 0.7051 (0.6275)\tgrad_norm 1.7285 (2.0581)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][410/625]\teta 0:00:07 lr 0.000502\t wd 0.0100\ttime 0.0328 (0.0356)\tloss 0.6641 (0.6275)\tgrad_norm 1.8625 (2.0559)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][420/625]\teta 0:00:07 lr 0.000502\t wd 0.0100\ttime 0.0323 (0.0356)\tloss 0.5186 (0.6275)\tgrad_norm 2.0478 (2.0518)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][430/625]\teta 0:00:06 lr 0.000502\t wd 0.0100\ttime 0.0363 (0.0356)\tloss 0.5425 (0.6270)\tgrad_norm 1.4101 (2.0493)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][440/625]\teta 0:00:06 lr 0.000502\t wd 0.0100\ttime 0.0324 (0.0356)\tloss 0.5332 (0.6269)\tgrad_norm 1.8070 (2.0537)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][450/625]\teta 0:00:06 lr 0.000501\t wd 0.0100\ttime 0.0326 (0.0356)\tloss 0.6348 (0.6272)\tgrad_norm 1.8462 (2.0591)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][460/625]\teta 0:00:05 lr 0.000501\t wd 0.0100\ttime 0.0324 (0.0356)\tloss 0.6108 (0.6280)\tgrad_norm 2.1650 (2.0584)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][470/625]\teta 0:00:05 lr 0.000501\t wd 0.0100\ttime 0.0325 (0.0356)\tloss 0.5811 (0.6279)\tgrad_norm 1.5526 (2.0609)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][480/625]\teta 0:00:05 lr 0.000501\t wd 0.0100\ttime 0.0355 (0.0356)\tloss 0.6294 (0.6270)\tgrad_norm 1.5860 (2.0593)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][490/625]\teta 0:00:04 lr 0.000500\t wd 0.0100\ttime 0.0323 (0.0356)\tloss 0.5513 (0.6270)\tgrad_norm 2.4236 (2.0632)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][500/625]\teta 0:00:04 lr 0.000500\t wd 0.0100\ttime 0.0323 (0.0355)\tloss 0.5977 (0.6270)\tgrad_norm 1.9962 (2.0647)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][510/625]\teta 0:00:04 lr 0.000500\t wd 0.0100\ttime 0.0327 (0.0355)\tloss 0.6748 (0.6271)\tgrad_norm 1.8793 (2.0630)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][520/625]\teta 0:00:03 lr 0.000500\t wd 0.0100\ttime 0.0323 (0.0354)\tloss 0.6172 (0.6260)\tgrad_norm 2.3656 (2.0590)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][530/625]\teta 0:00:03 lr 0.000499\t wd 0.0100\ttime 0.0322 (0.0354)\tloss 0.5977 (0.6253)\tgrad_norm 1.7163 (2.0607)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][540/625]\teta 0:00:03 lr 0.000499\t wd 0.0100\ttime 0.0355 (0.0354)\tloss 0.6211 (0.6267)\tgrad_norm 1.5222 (2.0637)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][550/625]\teta 0:00:02 lr 0.000499\t wd 0.0100\ttime 0.0356 (0.0354)\tloss 0.7681 (0.6272)\tgrad_norm 2.4618 (2.0636)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][560/625]\teta 0:00:02 lr 0.000499\t wd 0.0100\ttime 0.0402 (0.0354)\tloss 0.5972 (0.6294)\tgrad_norm 1.5872 (2.0665)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][570/625]\teta 0:00:01 lr 0.000498\t wd 0.0100\ttime 0.0350 (0.0354)\tloss 0.6191 (0.6296)\tgrad_norm 2.6781 (2.0674)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][580/625]\teta 0:00:01 lr 0.000498\t wd 0.0100\ttime 0.0328 (0.0353)\tloss 0.5718 (0.6290)\tgrad_norm 1.9368 (2.0659)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][590/625]\teta 0:00:01 lr 0.000498\t wd 0.0100\ttime 0.0348 (0.0353)\tloss 0.5986 (0.6290)\tgrad_norm 3.1077 (2.0655)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][600/625]\teta 0:00:00 lr 0.000498\t wd 0.0100\ttime 0.0327 (0.0353)\tloss 0.6597 (0.6293)\tgrad_norm 2.2811 (2.0680)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][610/625]\teta 0:00:00 lr 0.000497\t wd 0.0100\ttime 0.0360 (0.0353)\tloss 0.6274 (0.6300)\tgrad_norm 1.9213 (2.0709)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [51/100][620/625]\teta 0:00:00 lr 0.000497\t wd 0.0100\ttime 0.0329 (0.0353)\tloss 0.5103 (0.6310)\tgrad_norm 1.5784 (2.0717)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 51 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_51.pth saving......\n",
      "./model_save/ckpt_epoch_51.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.7422 (0.7422)\tAcc@1 73.438 (73.438)\tAcc@5 100.000 (100.000)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.7192 (0.7206)\tAcc@1 68.750 (73.864)\tAcc@5 100.000 (99.148)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.8203 (0.7318)\tAcc@1 68.750 (73.958)\tAcc@5 96.875 (98.586)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.7070 (0.7191)\tAcc@1 73.438 (74.446)\tAcc@5 100.000 (98.538)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.3943 (0.7050)\tAcc@1 84.375 (75.000)\tAcc@5 100.000 (98.628)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.6929 (0.6876)\tAcc@1 79.688 (75.306)\tAcc@5 100.000 (98.683)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.8096 (0.6771)\tAcc@1 81.250 (75.820)\tAcc@5 96.875 (98.745)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.6792 (0.6666)\tAcc@1 71.875 (76.100)\tAcc@5 98.438 (98.812)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.6284 (0.6641)\tAcc@1 79.688 (76.215)\tAcc@5 98.438 (98.862)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.5737 (0.6655)\tAcc@1 82.812 (76.356)\tAcc@5 100.000 (98.901)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.9507 (0.6693)\tAcc@1 67.188 (76.300)\tAcc@5 96.875 (98.824)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.7310 (0.6697)\tAcc@1 75.000 (76.239)\tAcc@5 100.000 (98.860)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.5864 (0.6695)\tAcc@1 79.688 (76.343)\tAcc@5 100.000 (98.851)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.7261 (0.6702)\tAcc@1 76.562 (76.419)\tAcc@5 100.000 (98.819)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.6401 (0.6689)\tAcc@1 71.875 (76.319)\tAcc@5 98.438 (98.792)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.6904 (0.6723)\tAcc@1 73.438 (76.407)\tAcc@5 98.438 (98.738)\tMem 455MB\n",
      " * Acc@1 76.220 Acc@5 98.740\n",
      "Accuracy of the network on the 10000 test images: 76.2%\n",
      "Max accuracy: 76.22%\n",
      "Train: [52/100][0/625]\teta 0:00:21 lr 0.000497\t wd 0.0100\ttime 0.0337 (0.0337)\tloss 0.4988 (0.4988)\tgrad_norm 2.0158 (2.0158)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [52/100][10/625]\teta 0:00:21 lr 0.000497\t wd 0.0100\ttime 0.0390 (0.0355)\tloss 0.8018 (0.6180)\tgrad_norm 1.8191 (1.9756)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [52/100][20/625]\teta 0:00:21 lr 0.000496\t wd 0.0100\ttime 0.0367 (0.0359)\tloss 0.7021 (0.5939)\tgrad_norm 1.6062 (1.8613)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [52/100][30/625]\teta 0:00:21 lr 0.000496\t wd 0.0100\ttime 0.0372 (0.0360)\tloss 0.7593 (0.6260)\tgrad_norm 2.6871 (1.9720)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [52/100][40/625]\teta 0:00:21 lr 0.000496\t wd 0.0100\ttime 0.0361 (0.0361)\tloss 0.5386 (0.6129)\tgrad_norm 1.9415 (1.9709)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [52/100][50/625]\teta 0:00:20 lr 0.000496\t wd 0.0100\ttime 0.0327 (0.0360)\tloss 0.5063 (0.6222)\tgrad_norm 1.4038 (1.9549)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [52/100][60/625]\teta 0:00:20 lr 0.000495\t wd 0.0100\ttime 0.0391 (0.0360)\tloss 0.6064 (0.6254)\tgrad_norm 1.5597 (1.9416)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [52/100][70/625]\teta 0:00:20 lr 0.000495\t wd 0.0100\ttime 0.0387 (0.0360)\tloss 0.7480 (0.6277)\tgrad_norm 1.8099 (1.9479)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [52/100][80/625]\teta 0:00:19 lr 0.000495\t wd 0.0100\ttime 0.0331 (0.0360)\tloss 0.6396 (0.6297)\tgrad_norm 1.5133 (1.9338)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [52/100][90/625]\teta 0:00:19 lr 0.000495\t wd 0.0100\ttime 0.0337 (0.0360)\tloss 0.6763 (0.6234)\tgrad_norm 2.0574 (1.9316)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [52/100][100/625]\teta 0:00:18 lr 0.000494\t wd 0.0100\ttime 0.0325 (0.0361)\tloss 0.4292 (0.6188)\tgrad_norm 1.9339 (1.9495)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [52/100][110/625]\teta 0:00:18 lr 0.000494\t wd 0.0100\ttime 0.0391 (0.0362)\tloss 0.6011 (0.6132)\tgrad_norm 1.8564 (1.9486)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [52/100][120/625]\teta 0:00:18 lr 0.000494\t wd 0.0100\ttime 0.0363 (0.0363)\tloss 0.5151 (0.6139)\tgrad_norm 1.8150 (1.9395)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [52/100][130/625]\teta 0:00:17 lr 0.000494\t wd 0.0100\ttime 0.0356 (0.0362)\tloss 0.5146 (0.6115)\tgrad_norm 2.5508 (1.9382)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [52/100][140/625]\teta 0:00:17 lr 0.000493\t wd 0.0100\ttime 0.0326 (0.0362)\tloss 0.7505 (0.6114)\tgrad_norm 1.9118 (1.9439)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [52/100][150/625]\teta 0:00:17 lr 0.000493\t wd 0.0100\ttime 0.0330 (0.0360)\tloss 0.6689 (0.6139)\tgrad_norm 2.1733 (1.9551)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [52/100][160/625]\teta 0:00:16 lr 0.000493\t wd 0.0100\ttime 0.0361 (0.0359)\tloss 0.7798 (0.6158)\tgrad_norm 2.5871 (1.9619)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [52/100][170/625]\teta 0:00:16 lr 0.000493\t wd 0.0100\ttime 0.0330 (0.0358)\tloss 0.5430 (0.6150)\tgrad_norm 1.6580 (1.9611)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [52/100][180/625]\teta 0:00:15 lr 0.000492\t wd 0.0100\ttime 0.0329 (0.0359)\tloss 0.6426 (0.6150)\tgrad_norm 1.9348 (1.9671)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [52/100][190/625]\teta 0:00:15 lr 0.000492\t wd 0.0100\ttime 0.0352 (0.0359)\tloss 0.6528 (0.6144)\tgrad_norm 2.0686 (1.9766)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [52/100][200/625]\teta 0:00:15 lr 0.000492\t wd 0.0100\ttime 0.0396 (0.0359)\tloss 0.5552 (0.6102)\tgrad_norm 2.1068 (1.9747)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [52/100][210/625]\teta 0:00:14 lr 0.000492\t wd 0.0100\ttime 0.0357 (0.0358)\tloss 0.6602 (0.6101)\tgrad_norm 1.8518 (1.9666)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [52/100][220/625]\teta 0:00:14 lr 0.000491\t wd 0.0100\ttime 0.0325 (0.0358)\tloss 0.5742 (0.6094)\tgrad_norm 1.9965 (1.9732)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [52/100][230/625]\teta 0:00:14 lr 0.000491\t wd 0.0100\ttime 0.0327 (0.0358)\tloss 0.7686 (0.6098)\tgrad_norm 1.7960 (1.9734)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [52/100][240/625]\teta 0:00:13 lr 0.000491\t wd 0.0100\ttime 0.0354 (0.0358)\tloss 0.6611 (0.6105)\tgrad_norm 2.4851 (1.9811)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [52/100][250/625]\teta 0:00:13 lr 0.000491\t wd 0.0100\ttime 0.0325 (0.0357)\tloss 0.5874 (0.6122)\tgrad_norm 2.1833 (1.9836)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [52/100][260/625]\teta 0:00:13 lr 0.000490\t wd 0.0100\ttime 0.0367 (0.0357)\tloss 0.7734 (0.6144)\tgrad_norm 2.5213 (1.9931)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [52/100][270/625]\teta 0:00:12 lr 0.000490\t wd 0.0100\ttime 0.0324 (0.0357)\tloss 0.5747 (0.6138)\tgrad_norm 2.1976 (nan)\tloss_scale 32768.0000 (32888.9151)\tmem 455MB\n",
      "Train: [52/100][280/625]\teta 0:00:12 lr 0.000490\t wd 0.0100\ttime 0.0366 (0.0357)\tloss 0.7515 (0.6144)\tgrad_norm 1.6860 (nan)\tloss_scale 32768.0000 (32884.6121)\tmem 455MB\n",
      "Train: [52/100][290/625]\teta 0:00:11 lr 0.000490\t wd 0.0100\ttime 0.0377 (0.0357)\tloss 0.6387 (0.6140)\tgrad_norm 2.1255 (nan)\tloss_scale 32768.0000 (32880.6048)\tmem 455MB\n",
      "Train: [52/100][300/625]\teta 0:00:11 lr 0.000489\t wd 0.0100\ttime 0.0358 (0.0357)\tloss 0.5293 (0.6121)\tgrad_norm 1.9269 (nan)\tloss_scale 32768.0000 (32876.8638)\tmem 455MB\n",
      "Train: [52/100][310/625]\teta 0:00:11 lr 0.000489\t wd 0.0100\ttime 0.0333 (0.0357)\tloss 0.8496 (0.6119)\tgrad_norm 1.9336 (nan)\tloss_scale 32768.0000 (32873.3633)\tmem 455MB\n",
      "Train: [52/100][320/625]\teta 0:00:10 lr 0.000489\t wd 0.0100\ttime 0.0369 (0.0357)\tloss 0.6514 (0.6118)\tgrad_norm 1.9616 (nan)\tloss_scale 32768.0000 (32870.0810)\tmem 455MB\n",
      "Train: [52/100][330/625]\teta 0:00:10 lr 0.000489\t wd 0.0100\ttime 0.0326 (0.0357)\tloss 0.7612 (0.6124)\tgrad_norm 2.0609 (nan)\tloss_scale 32768.0000 (32866.9970)\tmem 455MB\n",
      "Train: [52/100][340/625]\teta 0:00:10 lr 0.000488\t wd 0.0100\ttime 0.0328 (0.0357)\tloss 0.7056 (0.6139)\tgrad_norm 2.6158 (nan)\tloss_scale 32768.0000 (32864.0938)\tmem 455MB\n",
      "Train: [52/100][350/625]\teta 0:00:09 lr 0.000488\t wd 0.0100\ttime 0.0354 (0.0358)\tloss 0.6807 (0.6139)\tgrad_norm 2.1275 (nan)\tloss_scale 32768.0000 (32861.3561)\tmem 455MB\n",
      "Train: [52/100][360/625]\teta 0:00:09 lr 0.000488\t wd 0.0100\ttime 0.0327 (0.0357)\tloss 0.6382 (0.6157)\tgrad_norm 2.1428 (nan)\tloss_scale 32768.0000 (32858.7701)\tmem 455MB\n",
      "Train: [52/100][370/625]\teta 0:00:09 lr 0.000487\t wd 0.0100\ttime 0.0355 (0.0357)\tloss 0.6104 (0.6158)\tgrad_norm 1.9717 (nan)\tloss_scale 32768.0000 (32856.3235)\tmem 455MB\n",
      "Train: [52/100][380/625]\teta 0:00:08 lr 0.000487\t wd 0.0100\ttime 0.0363 (0.0357)\tloss 0.7178 (0.6177)\tgrad_norm 2.3657 (nan)\tloss_scale 32768.0000 (32854.0052)\tmem 455MB\n",
      "Train: [52/100][390/625]\teta 0:00:08 lr 0.000487\t wd 0.0100\ttime 0.0359 (0.0357)\tloss 0.4563 (0.6164)\tgrad_norm 1.9359 (nan)\tloss_scale 32768.0000 (32851.8056)\tmem 455MB\n",
      "Train: [52/100][400/625]\teta 0:00:08 lr 0.000487\t wd 0.0100\ttime 0.0364 (0.0357)\tloss 0.5889 (0.6178)\tgrad_norm 1.5478 (nan)\tloss_scale 32768.0000 (32849.7157)\tmem 455MB\n",
      "Train: [52/100][410/625]\teta 0:00:07 lr 0.000486\t wd 0.0100\ttime 0.0368 (0.0356)\tloss 0.4695 (0.6180)\tgrad_norm 1.3258 (nan)\tloss_scale 32768.0000 (32847.7275)\tmem 455MB\n",
      "Train: [52/100][420/625]\teta 0:00:07 lr 0.000486\t wd 0.0100\ttime 0.0325 (0.0356)\tloss 0.5532 (0.6191)\tgrad_norm 1.7175 (nan)\tloss_scale 32768.0000 (32845.8337)\tmem 455MB\n",
      "Train: [52/100][430/625]\teta 0:00:06 lr 0.000486\t wd 0.0100\ttime 0.0328 (0.0356)\tloss 0.6899 (0.6204)\tgrad_norm 2.3502 (nan)\tloss_scale 32768.0000 (32844.0278)\tmem 455MB\n",
      "Train: [52/100][440/625]\teta 0:00:06 lr 0.000486\t wd 0.0100\ttime 0.0326 (0.0355)\tloss 0.7549 (0.6216)\tgrad_norm 2.2169 (nan)\tloss_scale 32768.0000 (32842.3039)\tmem 455MB\n",
      "Train: [52/100][450/625]\teta 0:00:06 lr 0.000485\t wd 0.0100\ttime 0.0325 (0.0355)\tloss 0.5752 (0.6221)\tgrad_norm 1.6828 (nan)\tloss_scale 32768.0000 (32840.6563)\tmem 455MB\n",
      "Train: [52/100][460/625]\teta 0:00:05 lr 0.000485\t wd 0.0100\ttime 0.0328 (0.0355)\tloss 0.8149 (0.6220)\tgrad_norm 1.9653 (nan)\tloss_scale 32768.0000 (32839.0803)\tmem 455MB\n",
      "Train: [52/100][470/625]\teta 0:00:05 lr 0.000485\t wd 0.0100\ttime 0.0351 (0.0355)\tloss 0.5088 (0.6233)\tgrad_norm 1.6467 (nan)\tloss_scale 32768.0000 (32837.5711)\tmem 455MB\n",
      "Train: [52/100][480/625]\teta 0:00:05 lr 0.000485\t wd 0.0100\ttime 0.0323 (0.0355)\tloss 0.8008 (0.6252)\tgrad_norm 2.2911 (nan)\tloss_scale 32768.0000 (32836.1247)\tmem 455MB\n",
      "Train: [52/100][490/625]\teta 0:00:04 lr 0.000484\t wd 0.0100\ttime 0.0361 (0.0355)\tloss 0.7036 (0.6243)\tgrad_norm 2.4415 (nan)\tloss_scale 32768.0000 (32834.7373)\tmem 455MB\n",
      "Train: [52/100][500/625]\teta 0:00:04 lr 0.000484\t wd 0.0100\ttime 0.0327 (0.0355)\tloss 0.7954 (0.6241)\tgrad_norm 2.0272 (nan)\tloss_scale 32768.0000 (32833.4052)\tmem 455MB\n",
      "Train: [52/100][510/625]\teta 0:00:04 lr 0.000484\t wd 0.0100\ttime 0.0326 (0.0355)\tloss 0.6274 (0.6240)\tgrad_norm 2.0029 (nan)\tloss_scale 32768.0000 (32832.1252)\tmem 455MB\n",
      "Train: [52/100][520/625]\teta 0:00:03 lr 0.000484\t wd 0.0100\ttime 0.0325 (0.0355)\tloss 0.6455 (0.6232)\tgrad_norm 1.8150 (nan)\tloss_scale 32768.0000 (32830.8944)\tmem 455MB\n",
      "Train: [52/100][530/625]\teta 0:00:03 lr 0.000483\t wd 0.0100\ttime 0.0324 (0.0355)\tloss 0.5103 (0.6230)\tgrad_norm 1.9775 (nan)\tloss_scale 32768.0000 (32829.7100)\tmem 455MB\n",
      "Train: [52/100][540/625]\teta 0:00:03 lr 0.000483\t wd 0.0100\ttime 0.0322 (0.0354)\tloss 0.6733 (0.6239)\tgrad_norm 1.7564 (nan)\tloss_scale 32768.0000 (32828.5693)\tmem 455MB\n",
      "Train: [52/100][550/625]\teta 0:00:02 lr 0.000483\t wd 0.0100\ttime 0.0327 (0.0354)\tloss 0.4844 (0.6235)\tgrad_norm 1.8246 (nan)\tloss_scale 32768.0000 (32827.4701)\tmem 455MB\n",
      "Train: [52/100][560/625]\teta 0:00:02 lr 0.000483\t wd 0.0100\ttime 0.0325 (0.0354)\tloss 0.8018 (0.6238)\tgrad_norm 2.0698 (nan)\tloss_scale 32768.0000 (32826.4100)\tmem 455MB\n",
      "Train: [52/100][570/625]\teta 0:00:01 lr 0.000482\t wd 0.0100\ttime 0.0392 (0.0354)\tloss 0.7324 (0.6236)\tgrad_norm 2.4836 (nan)\tloss_scale 32768.0000 (32825.3870)\tmem 455MB\n",
      "Train: [52/100][580/625]\teta 0:00:01 lr 0.000482\t wd 0.0100\ttime 0.0386 (0.0354)\tloss 0.5381 (0.6229)\tgrad_norm 1.8423 (nan)\tloss_scale 32768.0000 (32824.3993)\tmem 455MB\n",
      "Train: [52/100][590/625]\teta 0:00:01 lr 0.000482\t wd 0.0100\ttime 0.0326 (0.0354)\tloss 0.7168 (0.6235)\tgrad_norm 2.0604 (nan)\tloss_scale 32768.0000 (32823.4450)\tmem 455MB\n",
      "Train: [52/100][600/625]\teta 0:00:00 lr 0.000482\t wd 0.0100\ttime 0.0349 (0.0354)\tloss 0.5049 (0.6229)\tgrad_norm 2.1390 (nan)\tloss_scale 32768.0000 (32822.5225)\tmem 455MB\n",
      "Train: [52/100][610/625]\teta 0:00:00 lr 0.000481\t wd 0.0100\ttime 0.0354 (0.0354)\tloss 0.5513 (0.6234)\tgrad_norm 1.5049 (nan)\tloss_scale 32768.0000 (32821.6301)\tmem 455MB\n",
      "Train: [52/100][620/625]\teta 0:00:00 lr 0.000481\t wd 0.0100\ttime 0.0366 (0.0354)\tloss 0.6821 (0.6236)\tgrad_norm 2.2253 (nan)\tloss_scale 32768.0000 (32820.7665)\tmem 455MB\n",
      "EPOCH 52 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_52.pth saving......\n",
      "./model_save/ckpt_epoch_52.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.9780 (0.9780)\tAcc@1 65.625 (65.625)\tAcc@5 100.000 (100.000)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.6465 (0.6871)\tAcc@1 76.562 (76.136)\tAcc@5 100.000 (98.864)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.017 (0.016)\tLoss 0.6851 (0.6948)\tAcc@1 76.562 (75.670)\tAcc@5 100.000 (98.586)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.4719 (0.7168)\tAcc@1 79.688 (75.454)\tAcc@5 100.000 (98.488)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.5947 (0.7218)\tAcc@1 79.688 (75.534)\tAcc@5 100.000 (98.399)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.016)\tLoss 0.5542 (0.7254)\tAcc@1 73.438 (75.123)\tAcc@5 100.000 (98.315)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.5288 (0.7246)\tAcc@1 84.375 (75.102)\tAcc@5 98.438 (98.386)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.4983 (0.7258)\tAcc@1 84.375 (75.154)\tAcc@5 100.000 (98.415)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.6357 (0.7136)\tAcc@1 76.562 (75.405)\tAcc@5 100.000 (98.515)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.7207 (0.7069)\tAcc@1 75.000 (75.532)\tAcc@5 100.000 (98.592)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.9829 (0.7036)\tAcc@1 71.875 (75.743)\tAcc@5 98.438 (98.608)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.6958 (0.6993)\tAcc@1 71.875 (75.746)\tAcc@5 100.000 (98.663)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.6973 (0.6969)\tAcc@1 76.562 (75.814)\tAcc@5 100.000 (98.644)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.4124 (0.6905)\tAcc@1 85.938 (75.978)\tAcc@5 100.000 (98.652)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.6421 (0.6889)\tAcc@1 76.562 (76.020)\tAcc@5 98.438 (98.626)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.4385 (0.6900)\tAcc@1 84.375 (75.952)\tAcc@5 100.000 (98.634)\tMem 455MB\n",
      " * Acc@1 75.820 Acc@5 98.660\n",
      "Accuracy of the network on the 10000 test images: 75.8%\n",
      "Max accuracy: 76.22%\n",
      "Train: [53/100][0/625]\teta 0:00:25 lr 0.000481\t wd 0.0100\ttime 0.0407 (0.0407)\tloss 0.5542 (0.5542)\tgrad_norm 1.8539 (1.8539)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][10/625]\teta 0:00:21 lr 0.000481\t wd 0.0100\ttime 0.0393 (0.0353)\tloss 0.7480 (0.6541)\tgrad_norm 2.1248 (2.0292)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][20/625]\teta 0:00:21 lr 0.000480\t wd 0.0100\ttime 0.0332 (0.0358)\tloss 0.6943 (0.6287)\tgrad_norm 2.5378 (2.0380)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][30/625]\teta 0:00:21 lr 0.000480\t wd 0.0100\ttime 0.0326 (0.0356)\tloss 0.5615 (0.6342)\tgrad_norm 1.5351 (2.0277)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][40/625]\teta 0:00:21 lr 0.000480\t wd 0.0100\ttime 0.0365 (0.0360)\tloss 0.6597 (0.6311)\tgrad_norm 1.7489 (2.0362)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][50/625]\teta 0:00:20 lr 0.000480\t wd 0.0100\ttime 0.0391 (0.0359)\tloss 0.4487 (0.6236)\tgrad_norm 1.6699 (2.0412)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][60/625]\teta 0:00:20 lr 0.000479\t wd 0.0100\ttime 0.0400 (0.0361)\tloss 0.5796 (0.6084)\tgrad_norm 2.1345 (2.0090)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][70/625]\teta 0:00:19 lr 0.000479\t wd 0.0100\ttime 0.0329 (0.0359)\tloss 0.6890 (0.6072)\tgrad_norm 2.3261 (2.0193)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][80/625]\teta 0:00:19 lr 0.000479\t wd 0.0100\ttime 0.0327 (0.0358)\tloss 0.7842 (0.6015)\tgrad_norm 2.0112 (2.0129)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][90/625]\teta 0:00:19 lr 0.000479\t wd 0.0100\ttime 0.0399 (0.0358)\tloss 0.7378 (0.5990)\tgrad_norm 2.2953 (2.0116)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][100/625]\teta 0:00:18 lr 0.000478\t wd 0.0100\ttime 0.0368 (0.0358)\tloss 0.5566 (0.5969)\tgrad_norm 1.7178 (2.0154)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][110/625]\teta 0:00:18 lr 0.000478\t wd 0.0100\ttime 0.0333 (0.0358)\tloss 0.6523 (0.5983)\tgrad_norm 1.9441 (2.0086)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][120/625]\teta 0:00:18 lr 0.000478\t wd 0.0100\ttime 0.0331 (0.0357)\tloss 0.5825 (0.5998)\tgrad_norm 2.4996 (2.0349)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][130/625]\teta 0:00:17 lr 0.000478\t wd 0.0100\ttime 0.0330 (0.0355)\tloss 0.5186 (0.5993)\tgrad_norm 1.9040 (2.0369)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][140/625]\teta 0:00:17 lr 0.000477\t wd 0.0100\ttime 0.0344 (0.0354)\tloss 0.5981 (0.5962)\tgrad_norm 1.8028 (2.0273)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][150/625]\teta 0:00:16 lr 0.000477\t wd 0.0100\ttime 0.0326 (0.0353)\tloss 0.7783 (0.5968)\tgrad_norm 3.0911 (2.0393)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][160/625]\teta 0:00:16 lr 0.000477\t wd 0.0100\ttime 0.0368 (0.0353)\tloss 0.6870 (0.5973)\tgrad_norm 1.9730 (2.0355)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][170/625]\teta 0:00:16 lr 0.000477\t wd 0.0100\ttime 0.0360 (0.0352)\tloss 0.5972 (0.5998)\tgrad_norm 2.4260 (2.0544)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][180/625]\teta 0:00:15 lr 0.000476\t wd 0.0100\ttime 0.0357 (0.0354)\tloss 0.5122 (0.6009)\tgrad_norm 1.9984 (2.0556)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][190/625]\teta 0:00:15 lr 0.000476\t wd 0.0100\ttime 0.0338 (0.0354)\tloss 0.5068 (0.5998)\tgrad_norm 2.0564 (2.0555)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][200/625]\teta 0:00:15 lr 0.000476\t wd 0.0100\ttime 0.0343 (0.0355)\tloss 0.6450 (0.6009)\tgrad_norm 2.0149 (2.0631)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][210/625]\teta 0:00:14 lr 0.000476\t wd 0.0100\ttime 0.0354 (0.0354)\tloss 0.7554 (0.6028)\tgrad_norm 2.7838 (2.0749)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][220/625]\teta 0:00:14 lr 0.000475\t wd 0.0100\ttime 0.0354 (0.0354)\tloss 0.6143 (0.6011)\tgrad_norm 1.9595 (2.0743)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][230/625]\teta 0:00:13 lr 0.000475\t wd 0.0100\ttime 0.0356 (0.0354)\tloss 0.4778 (0.6003)\tgrad_norm 2.1633 (2.0809)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][240/625]\teta 0:00:13 lr 0.000475\t wd 0.0100\ttime 0.0360 (0.0354)\tloss 0.6050 (0.6005)\tgrad_norm 2.1015 (2.0956)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][250/625]\teta 0:00:13 lr 0.000475\t wd 0.0100\ttime 0.0324 (0.0355)\tloss 0.3892 (0.5990)\tgrad_norm 1.5467 (2.0963)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][260/625]\teta 0:00:12 lr 0.000474\t wd 0.0100\ttime 0.0324 (0.0354)\tloss 0.7690 (0.6009)\tgrad_norm 2.3797 (2.1037)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][270/625]\teta 0:00:12 lr 0.000474\t wd 0.0100\ttime 0.0327 (0.0354)\tloss 0.6694 (0.6032)\tgrad_norm 1.9069 (2.1052)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][280/625]\teta 0:00:12 lr 0.000474\t wd 0.0100\ttime 0.0366 (0.0354)\tloss 0.6416 (0.6038)\tgrad_norm 2.3182 (2.1027)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][290/625]\teta 0:00:11 lr 0.000474\t wd 0.0100\ttime 0.0337 (0.0355)\tloss 0.6929 (0.6058)\tgrad_norm 2.5400 (2.1123)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][300/625]\teta 0:00:11 lr 0.000473\t wd 0.0100\ttime 0.0328 (0.0355)\tloss 0.6890 (0.6081)\tgrad_norm 1.8816 (2.1093)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][310/625]\teta 0:00:11 lr 0.000473\t wd 0.0100\ttime 0.0380 (0.0356)\tloss 0.6187 (0.6084)\tgrad_norm 2.1654 (2.1035)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][320/625]\teta 0:00:10 lr 0.000473\t wd 0.0100\ttime 0.0324 (0.0355)\tloss 0.5474 (0.6086)\tgrad_norm 1.9450 (2.1004)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][330/625]\teta 0:00:10 lr 0.000473\t wd 0.0100\ttime 0.0390 (0.0355)\tloss 0.5718 (0.6086)\tgrad_norm 1.4121 (2.0965)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][340/625]\teta 0:00:10 lr 0.000472\t wd 0.0100\ttime 0.0357 (0.0355)\tloss 0.7441 (0.6098)\tgrad_norm 2.2500 (2.0969)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][350/625]\teta 0:00:09 lr 0.000472\t wd 0.0100\ttime 0.0327 (0.0355)\tloss 0.6479 (0.6088)\tgrad_norm 2.8355 (2.0984)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][360/625]\teta 0:00:09 lr 0.000472\t wd 0.0100\ttime 0.0333 (0.0355)\tloss 0.3943 (0.6089)\tgrad_norm 1.9179 (2.0990)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][370/625]\teta 0:00:09 lr 0.000471\t wd 0.0100\ttime 0.0328 (0.0355)\tloss 0.6484 (0.6095)\tgrad_norm 2.8635 (2.0996)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][380/625]\teta 0:00:08 lr 0.000471\t wd 0.0100\ttime 0.0326 (0.0355)\tloss 0.6782 (0.6093)\tgrad_norm 2.2517 (2.1025)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][390/625]\teta 0:00:08 lr 0.000471\t wd 0.0100\ttime 0.0394 (0.0355)\tloss 0.4458 (0.6088)\tgrad_norm 1.7808 (2.1062)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][400/625]\teta 0:00:07 lr 0.000471\t wd 0.0100\ttime 0.0328 (0.0355)\tloss 0.6587 (0.6090)\tgrad_norm 2.2975 (2.1044)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][410/625]\teta 0:00:07 lr 0.000470\t wd 0.0100\ttime 0.0326 (0.0355)\tloss 0.6948 (0.6085)\tgrad_norm 2.3890 (2.1024)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][420/625]\teta 0:00:07 lr 0.000470\t wd 0.0100\ttime 0.0374 (0.0355)\tloss 0.4048 (0.6077)\tgrad_norm 1.3003 (2.0992)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][430/625]\teta 0:00:06 lr 0.000470\t wd 0.0100\ttime 0.0358 (0.0355)\tloss 0.7349 (0.6095)\tgrad_norm 2.7026 (2.0992)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][440/625]\teta 0:00:06 lr 0.000470\t wd 0.0100\ttime 0.0323 (0.0355)\tloss 0.6118 (0.6096)\tgrad_norm 1.8787 (2.0952)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][450/625]\teta 0:00:06 lr 0.000469\t wd 0.0100\ttime 0.0351 (0.0355)\tloss 0.7036 (0.6103)\tgrad_norm 2.5963 (2.0914)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][460/625]\teta 0:00:05 lr 0.000469\t wd 0.0100\ttime 0.0388 (0.0355)\tloss 0.5430 (0.6103)\tgrad_norm 1.7500 (2.0932)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][470/625]\teta 0:00:05 lr 0.000469\t wd 0.0100\ttime 0.0351 (0.0355)\tloss 0.7881 (0.6114)\tgrad_norm 2.2990 (2.0940)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][480/625]\teta 0:00:05 lr 0.000469\t wd 0.0100\ttime 0.0387 (0.0356)\tloss 0.5215 (0.6121)\tgrad_norm 1.7585 (2.0920)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][490/625]\teta 0:00:04 lr 0.000468\t wd 0.0100\ttime 0.0325 (0.0356)\tloss 0.5820 (0.6124)\tgrad_norm 1.9358 (2.0923)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][500/625]\teta 0:00:04 lr 0.000468\t wd 0.0100\ttime 0.0355 (0.0356)\tloss 0.4888 (0.6145)\tgrad_norm 1.7334 (2.0938)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][510/625]\teta 0:00:04 lr 0.000468\t wd 0.0100\ttime 0.0325 (0.0356)\tloss 0.7246 (0.6134)\tgrad_norm 2.2257 (2.0931)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][520/625]\teta 0:00:03 lr 0.000468\t wd 0.0100\ttime 0.0366 (0.0355)\tloss 0.7603 (0.6138)\tgrad_norm 2.5793 (2.0934)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][530/625]\teta 0:00:03 lr 0.000467\t wd 0.0100\ttime 0.0324 (0.0355)\tloss 0.6802 (0.6131)\tgrad_norm 2.2444 (2.0937)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][540/625]\teta 0:00:03 lr 0.000467\t wd 0.0100\ttime 0.0362 (0.0355)\tloss 0.4629 (0.6126)\tgrad_norm 2.1027 (2.0896)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][550/625]\teta 0:00:02 lr 0.000467\t wd 0.0100\ttime 0.0322 (0.0355)\tloss 0.7622 (0.6124)\tgrad_norm 3.0780 (2.0887)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][560/625]\teta 0:00:02 lr 0.000467\t wd 0.0100\ttime 0.0391 (0.0354)\tloss 0.4580 (0.6115)\tgrad_norm 1.7642 (2.0844)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][570/625]\teta 0:00:01 lr 0.000466\t wd 0.0100\ttime 0.0326 (0.0354)\tloss 0.4609 (0.6133)\tgrad_norm 1.5706 (2.0875)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][580/625]\teta 0:00:01 lr 0.000466\t wd 0.0100\ttime 0.0364 (0.0354)\tloss 0.4636 (0.6129)\tgrad_norm 2.3039 (2.0867)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][590/625]\teta 0:00:01 lr 0.000466\t wd 0.0100\ttime 0.0356 (0.0354)\tloss 0.5396 (0.6131)\tgrad_norm 1.9006 (2.0874)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][600/625]\teta 0:00:00 lr 0.000466\t wd 0.0100\ttime 0.0328 (0.0355)\tloss 0.8506 (0.6133)\tgrad_norm 1.7955 (2.0844)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][610/625]\teta 0:00:00 lr 0.000465\t wd 0.0100\ttime 0.0398 (0.0355)\tloss 0.6606 (0.6128)\tgrad_norm 2.1875 (2.0845)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [53/100][620/625]\teta 0:00:00 lr 0.000465\t wd 0.0100\ttime 0.0330 (0.0355)\tloss 0.8438 (0.6129)\tgrad_norm 1.7971 (2.0836)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 53 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_53.pth saving......\n",
      "./model_save/ckpt_epoch_53.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.6396 (0.6396)\tAcc@1 81.250 (81.250)\tAcc@5 98.438 (98.438)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.4958 (0.6196)\tAcc@1 75.000 (80.398)\tAcc@5 98.438 (98.295)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.7271 (0.6503)\tAcc@1 68.750 (77.827)\tAcc@5 100.000 (98.363)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.5391 (0.6585)\tAcc@1 82.812 (77.671)\tAcc@5 100.000 (98.185)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.7822 (0.6678)\tAcc@1 75.000 (77.363)\tAcc@5 98.438 (98.285)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 1.1006 (0.6726)\tAcc@1 75.000 (77.512)\tAcc@5 96.875 (98.346)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.5010 (0.6743)\tAcc@1 81.250 (77.203)\tAcc@5 100.000 (98.463)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.7212 (0.6693)\tAcc@1 76.562 (77.113)\tAcc@5 98.438 (98.548)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.5366 (0.6665)\tAcc@1 76.562 (77.045)\tAcc@5 100.000 (98.611)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.6523 (0.6681)\tAcc@1 75.000 (76.923)\tAcc@5 100.000 (98.575)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.6270 (0.6646)\tAcc@1 78.125 (77.166)\tAcc@5 98.438 (98.623)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.4866 (0.6578)\tAcc@1 81.250 (77.238)\tAcc@5 100.000 (98.691)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.5996 (0.6522)\tAcc@1 81.250 (77.363)\tAcc@5 98.438 (98.696)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.6997 (0.6522)\tAcc@1 71.875 (77.219)\tAcc@5 98.438 (98.736)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.5312 (0.6575)\tAcc@1 79.688 (77.028)\tAcc@5 100.000 (98.737)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.8657 (0.6564)\tAcc@1 68.750 (77.038)\tAcc@5 100.000 (98.748)\tMem 455MB\n",
      " * Acc@1 77.000 Acc@5 98.730\n",
      "Accuracy of the network on the 10000 test images: 77.0%\n",
      "Max accuracy: 77.00%\n",
      "Train: [54/100][0/625]\teta 0:00:24 lr 0.000465\t wd 0.0100\ttime 0.0396 (0.0396)\tloss 0.5796 (0.5796)\tgrad_norm 1.7236 (1.7236)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][10/625]\teta 0:00:22 lr 0.000465\t wd 0.0100\ttime 0.0403 (0.0362)\tloss 0.6250 (0.5796)\tgrad_norm 1.9755 (1.9388)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][20/625]\teta 0:00:21 lr 0.000464\t wd 0.0100\ttime 0.0386 (0.0360)\tloss 0.5894 (0.5870)\tgrad_norm 1.6189 (1.8880)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][30/625]\teta 0:00:21 lr 0.000464\t wd 0.0100\ttime 0.0331 (0.0360)\tloss 0.7842 (0.5938)\tgrad_norm 2.5338 (1.9344)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][40/625]\teta 0:00:20 lr 0.000464\t wd 0.0100\ttime 0.0361 (0.0358)\tloss 0.6992 (0.5904)\tgrad_norm 2.0172 (1.9489)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][50/625]\teta 0:00:20 lr 0.000464\t wd 0.0100\ttime 0.0389 (0.0361)\tloss 0.6074 (0.5929)\tgrad_norm 1.9208 (2.0066)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][60/625]\teta 0:00:20 lr 0.000463\t wd 0.0100\ttime 0.0356 (0.0359)\tloss 0.4897 (0.5943)\tgrad_norm 2.2997 (2.0246)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][70/625]\teta 0:00:20 lr 0.000463\t wd 0.0100\ttime 0.0325 (0.0362)\tloss 0.5283 (0.5966)\tgrad_norm 2.0103 (2.0314)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][80/625]\teta 0:00:19 lr 0.000463\t wd 0.0100\ttime 0.0387 (0.0362)\tloss 0.6641 (0.5996)\tgrad_norm 2.0444 (2.0494)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][90/625]\teta 0:00:19 lr 0.000463\t wd 0.0100\ttime 0.0345 (0.0362)\tloss 0.6816 (0.6034)\tgrad_norm 2.5695 (2.0826)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][100/625]\teta 0:00:18 lr 0.000462\t wd 0.0100\ttime 0.0322 (0.0360)\tloss 0.8208 (0.6030)\tgrad_norm 2.8275 (2.1036)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][110/625]\teta 0:00:18 lr 0.000462\t wd 0.0100\ttime 0.0330 (0.0359)\tloss 0.5854 (0.5970)\tgrad_norm 2.1658 (2.0889)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][120/625]\teta 0:00:18 lr 0.000462\t wd 0.0100\ttime 0.0324 (0.0357)\tloss 0.6338 (0.5877)\tgrad_norm 2.1534 (2.0726)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][130/625]\teta 0:00:17 lr 0.000462\t wd 0.0100\ttime 0.0362 (0.0358)\tloss 0.5903 (0.5881)\tgrad_norm 2.0185 (2.0943)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][140/625]\teta 0:00:17 lr 0.000461\t wd 0.0100\ttime 0.0324 (0.0358)\tloss 0.5112 (0.5862)\tgrad_norm 2.1125 (2.0869)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][150/625]\teta 0:00:16 lr 0.000461\t wd 0.0100\ttime 0.0324 (0.0357)\tloss 0.7905 (0.5857)\tgrad_norm 3.1131 (2.0802)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][160/625]\teta 0:00:16 lr 0.000461\t wd 0.0100\ttime 0.0327 (0.0355)\tloss 0.6338 (0.5873)\tgrad_norm 1.9982 (2.0779)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][170/625]\teta 0:00:16 lr 0.000461\t wd 0.0100\ttime 0.0361 (0.0354)\tloss 0.5400 (0.5857)\tgrad_norm 1.6917 (2.0716)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][180/625]\teta 0:00:15 lr 0.000460\t wd 0.0100\ttime 0.0328 (0.0354)\tloss 0.5996 (0.5895)\tgrad_norm 1.7629 (2.0613)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][190/625]\teta 0:00:15 lr 0.000460\t wd 0.0100\ttime 0.0323 (0.0353)\tloss 0.5337 (0.5908)\tgrad_norm 1.7041 (2.0517)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][200/625]\teta 0:00:14 lr 0.000460\t wd 0.0100\ttime 0.0365 (0.0352)\tloss 0.7378 (0.5918)\tgrad_norm 2.5359 (2.0447)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][210/625]\teta 0:00:14 lr 0.000460\t wd 0.0100\ttime 0.0327 (0.0351)\tloss 0.5415 (0.5891)\tgrad_norm 1.6219 (2.0299)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][220/625]\teta 0:00:14 lr 0.000459\t wd 0.0100\ttime 0.0327 (0.0350)\tloss 0.5537 (0.5883)\tgrad_norm 2.0822 (2.0249)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][230/625]\teta 0:00:13 lr 0.000459\t wd 0.0100\ttime 0.0340 (0.0350)\tloss 0.6196 (0.5888)\tgrad_norm 1.5511 (2.0225)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][240/625]\teta 0:00:13 lr 0.000459\t wd 0.0100\ttime 0.0335 (0.0349)\tloss 0.6230 (0.5914)\tgrad_norm 1.7052 (2.0218)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][250/625]\teta 0:00:13 lr 0.000459\t wd 0.0100\ttime 0.0323 (0.0348)\tloss 0.5635 (0.5909)\tgrad_norm 1.6692 (2.0277)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][260/625]\teta 0:00:12 lr 0.000458\t wd 0.0100\ttime 0.0334 (0.0348)\tloss 0.8228 (0.5913)\tgrad_norm 2.2278 (2.0282)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][270/625]\teta 0:00:12 lr 0.000458\t wd 0.0100\ttime 0.0325 (0.0348)\tloss 0.6089 (0.5918)\tgrad_norm 1.8874 (2.0234)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][280/625]\teta 0:00:11 lr 0.000458\t wd 0.0100\ttime 0.0325 (0.0348)\tloss 0.6113 (0.5929)\tgrad_norm 2.2825 (2.0252)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][290/625]\teta 0:00:11 lr 0.000458\t wd 0.0100\ttime 0.0335 (0.0347)\tloss 0.4890 (0.5934)\tgrad_norm 1.4189 (2.0273)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][300/625]\teta 0:00:11 lr 0.000457\t wd 0.0100\ttime 0.0400 (0.0348)\tloss 0.7944 (0.5947)\tgrad_norm 2.7394 (2.0353)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][310/625]\teta 0:00:10 lr 0.000457\t wd 0.0100\ttime 0.0327 (0.0348)\tloss 0.5664 (0.5948)\tgrad_norm 1.4615 (2.0342)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][320/625]\teta 0:00:10 lr 0.000457\t wd 0.0100\ttime 0.0330 (0.0349)\tloss 0.4861 (0.5945)\tgrad_norm 1.5927 (2.0366)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][330/625]\teta 0:00:10 lr 0.000457\t wd 0.0100\ttime 0.0327 (0.0349)\tloss 0.6963 (0.5946)\tgrad_norm 1.8385 (2.0416)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][340/625]\teta 0:00:09 lr 0.000456\t wd 0.0100\ttime 0.0400 (0.0349)\tloss 0.4329 (0.5932)\tgrad_norm 1.6391 (2.0375)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][350/625]\teta 0:00:09 lr 0.000456\t wd 0.0100\ttime 0.0354 (0.0349)\tloss 0.4993 (0.5946)\tgrad_norm 2.0065 (2.0427)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][360/625]\teta 0:00:09 lr 0.000456\t wd 0.0100\ttime 0.0332 (0.0350)\tloss 0.5962 (0.5957)\tgrad_norm 1.8372 (2.0418)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][370/625]\teta 0:00:08 lr 0.000456\t wd 0.0100\ttime 0.0323 (0.0349)\tloss 0.7041 (0.5962)\tgrad_norm 1.9031 (2.0370)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][380/625]\teta 0:00:08 lr 0.000455\t wd 0.0100\ttime 0.0367 (0.0349)\tloss 0.8013 (0.5954)\tgrad_norm 2.4512 (2.0334)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][390/625]\teta 0:00:08 lr 0.000455\t wd 0.0100\ttime 0.0361 (0.0349)\tloss 0.5938 (0.5969)\tgrad_norm 2.1814 (2.0329)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][400/625]\teta 0:00:07 lr 0.000455\t wd 0.0100\ttime 0.0325 (0.0349)\tloss 0.5679 (0.5973)\tgrad_norm 2.0797 (2.0323)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][410/625]\teta 0:00:07 lr 0.000454\t wd 0.0100\ttime 0.0384 (0.0349)\tloss 0.4607 (0.5975)\tgrad_norm 1.7592 (2.0331)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][420/625]\teta 0:00:07 lr 0.000454\t wd 0.0100\ttime 0.0387 (0.0349)\tloss 0.5449 (0.5981)\tgrad_norm 1.6997 (2.0310)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][430/625]\teta 0:00:06 lr 0.000454\t wd 0.0100\ttime 0.0327 (0.0349)\tloss 0.5034 (0.5984)\tgrad_norm 1.8442 (2.0277)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][440/625]\teta 0:00:06 lr 0.000454\t wd 0.0100\ttime 0.0348 (0.0349)\tloss 0.6182 (0.5994)\tgrad_norm 2.0551 (2.0270)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][450/625]\teta 0:00:06 lr 0.000453\t wd 0.0100\ttime 0.0326 (0.0349)\tloss 0.5420 (0.5999)\tgrad_norm 2.2888 (2.0302)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][460/625]\teta 0:00:05 lr 0.000453\t wd 0.0100\ttime 0.0328 (0.0350)\tloss 1.0898 (0.6006)\tgrad_norm 2.6538 (2.0305)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][470/625]\teta 0:00:05 lr 0.000453\t wd 0.0100\ttime 0.0362 (0.0350)\tloss 0.5176 (0.5997)\tgrad_norm 2.0528 (2.0261)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][480/625]\teta 0:00:05 lr 0.000453\t wd 0.0100\ttime 0.0397 (0.0350)\tloss 0.6050 (0.5993)\tgrad_norm 1.5813 (2.0259)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][490/625]\teta 0:00:04 lr 0.000452\t wd 0.0100\ttime 0.0324 (0.0350)\tloss 0.7300 (0.5997)\tgrad_norm 2.4434 (2.0229)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][500/625]\teta 0:00:04 lr 0.000452\t wd 0.0100\ttime 0.0327 (0.0350)\tloss 0.6021 (0.5996)\tgrad_norm 2.1294 (2.0219)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][510/625]\teta 0:00:04 lr 0.000452\t wd 0.0100\ttime 0.0325 (0.0350)\tloss 0.7729 (0.5999)\tgrad_norm 2.5692 (2.0225)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][520/625]\teta 0:00:03 lr 0.000452\t wd 0.0100\ttime 0.0327 (0.0350)\tloss 0.5747 (0.5989)\tgrad_norm 1.8742 (2.0210)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][530/625]\teta 0:00:03 lr 0.000451\t wd 0.0100\ttime 0.0326 (0.0350)\tloss 0.5605 (0.5981)\tgrad_norm 1.8252 (2.0242)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][540/625]\teta 0:00:02 lr 0.000451\t wd 0.0100\ttime 0.0391 (0.0350)\tloss 0.7373 (0.5990)\tgrad_norm 2.2628 (2.0273)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][550/625]\teta 0:00:02 lr 0.000451\t wd 0.0100\ttime 0.0361 (0.0350)\tloss 0.5493 (0.5994)\tgrad_norm 1.5145 (2.0293)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][560/625]\teta 0:00:02 lr 0.000451\t wd 0.0100\ttime 0.0397 (0.0350)\tloss 0.6152 (0.5997)\tgrad_norm 1.8165 (2.0280)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][570/625]\teta 0:00:01 lr 0.000450\t wd 0.0100\ttime 0.0326 (0.0350)\tloss 0.7622 (0.6003)\tgrad_norm 2.5956 (2.0340)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][580/625]\teta 0:00:01 lr 0.000450\t wd 0.0100\ttime 0.0357 (0.0351)\tloss 0.5684 (0.6008)\tgrad_norm 2.6196 (2.0354)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][590/625]\teta 0:00:01 lr 0.000450\t wd 0.0100\ttime 0.0358 (0.0351)\tloss 0.6831 (0.6025)\tgrad_norm 2.3266 (2.0384)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][600/625]\teta 0:00:00 lr 0.000450\t wd 0.0100\ttime 0.0362 (0.0351)\tloss 0.6021 (0.6012)\tgrad_norm 2.0514 (2.0359)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][610/625]\teta 0:00:00 lr 0.000449\t wd 0.0100\ttime 0.0329 (0.0351)\tloss 0.6655 (0.6025)\tgrad_norm 2.2963 (2.0366)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [54/100][620/625]\teta 0:00:00 lr 0.000449\t wd 0.0100\ttime 0.0354 (0.0351)\tloss 0.5337 (0.6024)\tgrad_norm 2.1558 (2.0387)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 54 training takes 0:00:21\n",
      "./model_save/ckpt_epoch_54.pth saving......\n",
      "./model_save/ckpt_epoch_54.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.6011 (0.6011)\tAcc@1 76.562 (76.562)\tAcc@5 98.438 (98.438)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.6987 (0.6407)\tAcc@1 75.000 (78.125)\tAcc@5 98.438 (98.580)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.6406 (0.6367)\tAcc@1 78.125 (77.679)\tAcc@5 98.438 (98.661)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.5020 (0.6409)\tAcc@1 82.812 (77.470)\tAcc@5 100.000 (98.740)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.7061 (0.6496)\tAcc@1 75.000 (76.982)\tAcc@5 96.875 (98.742)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.6084 (0.6567)\tAcc@1 76.562 (76.532)\tAcc@5 100.000 (98.775)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.6543 (0.6523)\tAcc@1 76.562 (76.639)\tAcc@5 98.438 (98.847)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.4822 (0.6466)\tAcc@1 84.375 (76.849)\tAcc@5 100.000 (98.900)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.7129 (0.6356)\tAcc@1 79.688 (77.334)\tAcc@5 95.312 (98.920)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.5068 (0.6381)\tAcc@1 85.938 (77.335)\tAcc@5 100.000 (98.850)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.8369 (0.6472)\tAcc@1 70.312 (77.073)\tAcc@5 100.000 (98.778)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.5176 (0.6464)\tAcc@1 81.250 (77.140)\tAcc@5 100.000 (98.832)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.016 (0.015)\tLoss 0.8491 (0.6443)\tAcc@1 75.000 (77.299)\tAcc@5 100.000 (98.799)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.4287 (0.6409)\tAcc@1 79.688 (77.397)\tAcc@5 100.000 (98.783)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.4565 (0.6381)\tAcc@1 82.812 (77.427)\tAcc@5 100.000 (98.803)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.8477 (0.6425)\tAcc@1 73.438 (77.339)\tAcc@5 93.750 (98.748)\tMem 455MB\n",
      " * Acc@1 77.410 Acc@5 98.770\n",
      "Accuracy of the network on the 10000 test images: 77.4%\n",
      "Max accuracy: 77.41%\n",
      "Train: [55/100][0/625]\teta 0:00:24 lr 0.000449\t wd 0.0100\ttime 0.0391 (0.0391)\tloss 0.5112 (0.5112)\tgrad_norm 1.5868 (1.5868)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [55/100][10/625]\teta 0:00:20 lr 0.000449\t wd 0.0100\ttime 0.0325 (0.0338)\tloss 0.7578 (0.6068)\tgrad_norm 2.7059 (2.1834)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [55/100][20/625]\teta 0:00:21 lr 0.000448\t wd 0.0100\ttime 0.0323 (0.0347)\tloss 0.6860 (0.6003)\tgrad_norm 1.9480 (2.0854)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [55/100][30/625]\teta 0:00:20 lr 0.000448\t wd 0.0100\ttime 0.0327 (0.0348)\tloss 0.3855 (0.5930)\tgrad_norm 1.1934 (2.0193)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [55/100][40/625]\teta 0:00:20 lr 0.000448\t wd 0.0100\ttime 0.0340 (0.0348)\tloss 0.5181 (0.5987)\tgrad_norm 2.3030 (2.0446)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [55/100][50/625]\teta 0:00:20 lr 0.000448\t wd 0.0100\ttime 0.0325 (0.0348)\tloss 0.5293 (0.6016)\tgrad_norm 1.7352 (2.0133)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [55/100][60/625]\teta 0:00:19 lr 0.000447\t wd 0.0100\ttime 0.0348 (0.0351)\tloss 0.5664 (0.5976)\tgrad_norm 2.0494 (1.9913)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [55/100][70/625]\teta 0:00:19 lr 0.000447\t wd 0.0100\ttime 0.0380 (0.0352)\tloss 0.6294 (0.6035)\tgrad_norm 2.1546 (1.9994)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [55/100][80/625]\teta 0:00:19 lr 0.000447\t wd 0.0100\ttime 0.0355 (0.0354)\tloss 0.5742 (0.5986)\tgrad_norm 1.8240 (2.0120)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [55/100][90/625]\teta 0:00:18 lr 0.000447\t wd 0.0100\ttime 0.0330 (0.0354)\tloss 0.7129 (0.6026)\tgrad_norm 2.7219 (2.0223)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [55/100][100/625]\teta 0:00:18 lr 0.000446\t wd 0.0100\ttime 0.0326 (0.0354)\tloss 0.5229 (0.5950)\tgrad_norm 1.9019 (2.0261)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [55/100][110/625]\teta 0:00:18 lr 0.000446\t wd 0.0100\ttime 0.0327 (0.0354)\tloss 0.4211 (0.5938)\tgrad_norm 1.7423 (2.0355)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [55/100][120/625]\teta 0:00:17 lr 0.000446\t wd 0.0100\ttime 0.0390 (0.0355)\tloss 0.5034 (0.5916)\tgrad_norm 2.0267 (2.0412)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [55/100][130/625]\teta 0:00:17 lr 0.000446\t wd 0.0100\ttime 0.0346 (0.0354)\tloss 0.6323 (0.5920)\tgrad_norm 1.7969 (2.0400)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [55/100][140/625]\teta 0:00:17 lr 0.000445\t wd 0.0100\ttime 0.0325 (0.0353)\tloss 0.6924 (0.5914)\tgrad_norm 2.0988 (2.0533)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [55/100][150/625]\teta 0:00:16 lr 0.000445\t wd 0.0100\ttime 0.0325 (0.0353)\tloss 0.8442 (0.5902)\tgrad_norm 2.3776 (2.0479)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [55/100][160/625]\teta 0:00:16 lr 0.000445\t wd 0.0100\ttime 0.0355 (0.0353)\tloss 0.6860 (0.5939)\tgrad_norm 1.7390 (2.0478)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [55/100][170/625]\teta 0:00:16 lr 0.000445\t wd 0.0100\ttime 0.0326 (0.0353)\tloss 0.4775 (0.5954)\tgrad_norm 1.6553 (2.0498)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [55/100][180/625]\teta 0:00:15 lr 0.000444\t wd 0.0100\ttime 0.0326 (0.0353)\tloss 0.5493 (0.5935)\tgrad_norm 1.9224 (2.0411)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [55/100][190/625]\teta 0:00:15 lr 0.000444\t wd 0.0100\ttime 0.0324 (0.0352)\tloss 0.5122 (0.5939)\tgrad_norm 1.5268 (2.0387)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [55/100][200/625]\teta 0:00:14 lr 0.000444\t wd 0.0100\ttime 0.0384 (0.0352)\tloss 0.5688 (0.5922)\tgrad_norm 1.7510 (2.0329)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [55/100][210/625]\teta 0:00:14 lr 0.000444\t wd 0.0100\ttime 0.0391 (0.0353)\tloss 0.6157 (0.5964)\tgrad_norm 2.1898 (2.0473)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [55/100][220/625]\teta 0:00:14 lr 0.000443\t wd 0.0100\ttime 0.0407 (0.0353)\tloss 0.4929 (0.5948)\tgrad_norm 1.7660 (2.0505)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [55/100][230/625]\teta 0:00:13 lr 0.000443\t wd 0.0100\ttime 0.0386 (0.0354)\tloss 0.8730 (0.5956)\tgrad_norm 2.8994 (2.0566)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [55/100][240/625]\teta 0:00:13 lr 0.000443\t wd 0.0100\ttime 0.0394 (0.0355)\tloss 0.6982 (0.5964)\tgrad_norm 2.7154 (2.0636)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [55/100][250/625]\teta 0:00:13 lr 0.000443\t wd 0.0100\ttime 0.0329 (0.0355)\tloss 0.6230 (0.5963)\tgrad_norm 1.4505 (2.0645)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [55/100][260/625]\teta 0:00:12 lr 0.000442\t wd 0.0100\ttime 0.0326 (0.0355)\tloss 0.6299 (0.5945)\tgrad_norm 2.3729 (2.0645)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [55/100][270/625]\teta 0:00:12 lr 0.000442\t wd 0.0100\ttime 0.0393 (0.0355)\tloss 0.6245 (0.5935)\tgrad_norm 1.9519 (2.0715)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [55/100][280/625]\teta 0:00:12 lr 0.000442\t wd 0.0100\ttime 0.0324 (0.0355)\tloss 0.6909 (0.5932)\tgrad_norm 2.3970 (2.0719)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [55/100][290/625]\teta 0:00:11 lr 0.000442\t wd 0.0100\ttime 0.0329 (0.0354)\tloss 0.7266 (0.5933)\tgrad_norm 1.6475 (2.0685)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [55/100][300/625]\teta 0:00:11 lr 0.000441\t wd 0.0100\ttime 0.0375 (0.0354)\tloss 0.5620 (0.5945)\tgrad_norm 1.9472 (2.0747)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [55/100][310/625]\teta 0:00:11 lr 0.000441\t wd 0.0100\ttime 0.0362 (0.0355)\tloss 0.8481 (0.5927)\tgrad_norm 1.8647 (2.0644)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [55/100][320/625]\teta 0:00:10 lr 0.000441\t wd 0.0100\ttime 0.0365 (0.0355)\tloss 0.5835 (0.5937)\tgrad_norm 1.9587 (2.0633)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [55/100][330/625]\teta 0:00:10 lr 0.000441\t wd 0.0100\ttime 0.0395 (0.0355)\tloss 0.6455 (0.5932)\tgrad_norm 1.9767 (2.0618)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [55/100][340/625]\teta 0:00:10 lr 0.000440\t wd 0.0100\ttime 0.0397 (0.0356)\tloss 0.6553 (0.5930)\tgrad_norm 2.1134 (2.0576)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [55/100][350/625]\teta 0:00:09 lr 0.000440\t wd 0.0100\ttime 0.0387 (0.0356)\tloss 0.4880 (0.5934)\tgrad_norm 1.8490 (2.0568)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [55/100][360/625]\teta 0:00:09 lr 0.000440\t wd 0.0100\ttime 0.0392 (0.0356)\tloss 0.6084 (0.5930)\tgrad_norm 1.7615 (2.0562)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [55/100][370/625]\teta 0:00:09 lr 0.000440\t wd 0.0100\ttime 0.0353 (0.0356)\tloss 0.4932 (0.5928)\tgrad_norm 1.6749 (2.0532)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [55/100][380/625]\teta 0:00:08 lr 0.000439\t wd 0.0100\ttime 0.0356 (0.0356)\tloss 0.7358 (0.5940)\tgrad_norm 2.3150 (2.0594)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [55/100][390/625]\teta 0:00:08 lr 0.000439\t wd 0.0100\ttime 0.0281 (0.0356)\tloss 0.6318 (0.5954)\tgrad_norm nan (nan)\tloss_scale 32768.0000 (32851.8056)\tmem 455MB\n",
      "Train: [55/100][400/625]\teta 0:00:08 lr 0.000439\t wd 0.0100\ttime 0.0363 (0.0357)\tloss 0.5137 (0.5959)\tgrad_norm 1.7884 (nan)\tloss_scale 32768.0000 (32849.7157)\tmem 455MB\n",
      "Train: [55/100][410/625]\teta 0:00:07 lr 0.000439\t wd 0.0100\ttime 0.0325 (0.0357)\tloss 0.4988 (0.5948)\tgrad_norm 1.7016 (nan)\tloss_scale 32768.0000 (32847.7275)\tmem 455MB\n",
      "Train: [55/100][420/625]\teta 0:00:07 lr 0.000438\t wd 0.0100\ttime 0.0327 (0.0356)\tloss 0.4856 (0.5937)\tgrad_norm 1.4092 (nan)\tloss_scale 32768.0000 (32845.8337)\tmem 455MB\n",
      "Train: [55/100][430/625]\teta 0:00:06 lr 0.000438\t wd 0.0100\ttime 0.0343 (0.0357)\tloss 0.5850 (0.5947)\tgrad_norm 2.0307 (nan)\tloss_scale 32768.0000 (32844.0278)\tmem 455MB\n",
      "Train: [55/100][440/625]\teta 0:00:06 lr 0.000438\t wd 0.0100\ttime 0.0398 (0.0357)\tloss 0.5137 (0.5963)\tgrad_norm 1.6152 (nan)\tloss_scale 32768.0000 (32842.3039)\tmem 455MB\n",
      "Train: [55/100][450/625]\teta 0:00:06 lr 0.000438\t wd 0.0100\ttime 0.0381 (0.0357)\tloss 0.7520 (0.5964)\tgrad_norm 2.5470 (nan)\tloss_scale 32768.0000 (32840.6563)\tmem 455MB\n",
      "Train: [55/100][460/625]\teta 0:00:05 lr 0.000437\t wd 0.0100\ttime 0.0368 (0.0357)\tloss 0.5957 (0.5958)\tgrad_norm 2.0060 (nan)\tloss_scale 32768.0000 (32839.0803)\tmem 455MB\n",
      "Train: [55/100][470/625]\teta 0:00:05 lr 0.000437\t wd 0.0100\ttime 0.0366 (0.0357)\tloss 0.8599 (0.5961)\tgrad_norm 2.6071 (nan)\tloss_scale 32768.0000 (32837.5711)\tmem 455MB\n",
      "Train: [55/100][480/625]\teta 0:00:05 lr 0.000437\t wd 0.0100\ttime 0.0386 (0.0358)\tloss 0.3223 (0.5954)\tgrad_norm 1.4616 (nan)\tloss_scale 32768.0000 (32836.1247)\tmem 455MB\n",
      "Train: [55/100][490/625]\teta 0:00:04 lr 0.000437\t wd 0.0100\ttime 0.0360 (0.0358)\tloss 0.5981 (0.5948)\tgrad_norm 2.2279 (nan)\tloss_scale 32768.0000 (32834.7373)\tmem 455MB\n",
      "Train: [55/100][500/625]\teta 0:00:04 lr 0.000436\t wd 0.0100\ttime 0.0368 (0.0358)\tloss 0.8511 (0.5955)\tgrad_norm 2.5877 (nan)\tloss_scale 32768.0000 (32833.4052)\tmem 455MB\n",
      "Train: [55/100][510/625]\teta 0:00:04 lr 0.000436\t wd 0.0100\ttime 0.0325 (0.0358)\tloss 0.7539 (0.5957)\tgrad_norm 3.2727 (nan)\tloss_scale 32768.0000 (32832.1252)\tmem 455MB\n",
      "Train: [55/100][520/625]\teta 0:00:03 lr 0.000436\t wd 0.0100\ttime 0.0361 (0.0358)\tloss 0.5884 (0.5952)\tgrad_norm 2.0728 (nan)\tloss_scale 32768.0000 (32830.8944)\tmem 455MB\n",
      "Train: [55/100][530/625]\teta 0:00:03 lr 0.000436\t wd 0.0100\ttime 0.0389 (0.0358)\tloss 0.6167 (0.5955)\tgrad_norm 1.8427 (nan)\tloss_scale 32768.0000 (32829.7100)\tmem 455MB\n",
      "Train: [55/100][540/625]\teta 0:00:03 lr 0.000435\t wd 0.0100\ttime 0.0329 (0.0357)\tloss 0.5488 (0.5951)\tgrad_norm 1.7342 (nan)\tloss_scale 32768.0000 (32828.5693)\tmem 455MB\n",
      "Train: [55/100][550/625]\teta 0:00:02 lr 0.000435\t wd 0.0100\ttime 0.0394 (0.0357)\tloss 0.6274 (0.5952)\tgrad_norm 2.1864 (nan)\tloss_scale 32768.0000 (32827.4701)\tmem 455MB\n",
      "Train: [55/100][560/625]\teta 0:00:02 lr 0.000435\t wd 0.0100\ttime 0.0328 (0.0357)\tloss 0.5786 (0.5957)\tgrad_norm 2.9757 (nan)\tloss_scale 32768.0000 (32826.4100)\tmem 455MB\n",
      "Train: [55/100][570/625]\teta 0:00:01 lr 0.000435\t wd 0.0100\ttime 0.0356 (0.0357)\tloss 0.8574 (0.5960)\tgrad_norm 2.2702 (nan)\tloss_scale 32768.0000 (32825.3870)\tmem 455MB\n",
      "Train: [55/100][580/625]\teta 0:00:01 lr 0.000434\t wd 0.0100\ttime 0.0361 (0.0357)\tloss 0.4407 (0.5969)\tgrad_norm 1.4862 (nan)\tloss_scale 32768.0000 (32824.3993)\tmem 455MB\n",
      "Train: [55/100][590/625]\teta 0:00:01 lr 0.000434\t wd 0.0100\ttime 0.0330 (0.0357)\tloss 0.3572 (0.5962)\tgrad_norm 1.4739 (nan)\tloss_scale 32768.0000 (32823.4450)\tmem 455MB\n",
      "Train: [55/100][600/625]\teta 0:00:00 lr 0.000434\t wd 0.0100\ttime 0.0396 (0.0357)\tloss 0.7080 (0.5962)\tgrad_norm 1.9045 (nan)\tloss_scale 32768.0000 (32822.5225)\tmem 455MB\n",
      "Train: [55/100][610/625]\teta 0:00:00 lr 0.000433\t wd 0.0100\ttime 0.0388 (0.0357)\tloss 0.5352 (0.5953)\tgrad_norm 2.9484 (nan)\tloss_scale 32768.0000 (32821.6301)\tmem 455MB\n",
      "Train: [55/100][620/625]\teta 0:00:00 lr 0.000433\t wd 0.0100\ttime 0.0328 (0.0357)\tloss 0.6406 (0.5961)\tgrad_norm 2.5968 (nan)\tloss_scale 32768.0000 (32820.7665)\tmem 455MB\n",
      "EPOCH 55 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_55.pth saving......\n",
      "./model_save/ckpt_epoch_55.pth saved !!!\n",
      "Test: [0/157]\tTime 0.021 (0.021)\tLoss 0.5098 (0.5098)\tAcc@1 76.562 (76.562)\tAcc@5 98.438 (98.438)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.016)\tLoss 0.4922 (0.7208)\tAcc@1 84.375 (76.136)\tAcc@5 98.438 (98.580)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.016)\tLoss 1.0244 (0.7378)\tAcc@1 67.188 (76.042)\tAcc@5 96.875 (98.214)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.6299 (0.7085)\tAcc@1 78.125 (76.764)\tAcc@5 100.000 (98.639)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.5503 (0.6993)\tAcc@1 78.125 (76.867)\tAcc@5 98.438 (98.590)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.6685 (0.6872)\tAcc@1 73.438 (77.237)\tAcc@5 98.438 (98.744)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.6353 (0.6773)\tAcc@1 76.562 (77.510)\tAcc@5 100.000 (98.873)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.4695 (0.6877)\tAcc@1 81.250 (77.113)\tAcc@5 100.000 (98.790)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.6646 (0.6844)\tAcc@1 71.875 (76.852)\tAcc@5 98.438 (98.765)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.3704 (0.6789)\tAcc@1 84.375 (76.803)\tAcc@5 100.000 (98.850)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.6128 (0.6775)\tAcc@1 82.812 (76.795)\tAcc@5 96.875 (98.747)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.5410 (0.6699)\tAcc@1 78.125 (76.900)\tAcc@5 98.438 (98.747)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.5410 (0.6726)\tAcc@1 79.688 (76.885)\tAcc@5 98.438 (98.735)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.7500 (0.6684)\tAcc@1 76.562 (76.980)\tAcc@5 100.000 (98.783)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.7422 (0.6680)\tAcc@1 76.562 (76.950)\tAcc@5 95.312 (98.781)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.5239 (0.6673)\tAcc@1 82.812 (76.966)\tAcc@5 98.438 (98.758)\tMem 455MB\n",
      " * Acc@1 76.920 Acc@5 98.770\n",
      "Accuracy of the network on the 10000 test images: 76.9%\n",
      "Max accuracy: 77.41%\n",
      "Train: [56/100][0/625]\teta 0:00:22 lr 0.000433\t wd 0.0100\ttime 0.0367 (0.0367)\tloss 0.6714 (0.6714)\tgrad_norm 2.8610 (2.8610)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][10/625]\teta 0:00:21 lr 0.000433\t wd 0.0100\ttime 0.0361 (0.0356)\tloss 0.7178 (0.5834)\tgrad_norm 2.4095 (2.1338)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][20/625]\teta 0:00:21 lr 0.000433\t wd 0.0100\ttime 0.0362 (0.0362)\tloss 0.5332 (0.5740)\tgrad_norm 2.1058 (2.2646)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][30/625]\teta 0:00:21 lr 0.000432\t wd 0.0100\ttime 0.0360 (0.0355)\tloss 0.6714 (0.5813)\tgrad_norm 1.8452 (2.1285)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][40/625]\teta 0:00:20 lr 0.000432\t wd 0.0100\ttime 0.0321 (0.0359)\tloss 0.6831 (0.5859)\tgrad_norm 2.1916 (2.1225)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][50/625]\teta 0:00:20 lr 0.000432\t wd 0.0100\ttime 0.0379 (0.0357)\tloss 0.4573 (0.5906)\tgrad_norm 1.6988 (2.1017)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][60/625]\teta 0:00:20 lr 0.000432\t wd 0.0100\ttime 0.0379 (0.0357)\tloss 0.7578 (0.5821)\tgrad_norm 2.3854 (2.0621)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][70/625]\teta 0:00:19 lr 0.000431\t wd 0.0100\ttime 0.0349 (0.0359)\tloss 0.5737 (0.5800)\tgrad_norm 2.0842 (2.0494)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][80/625]\teta 0:00:19 lr 0.000431\t wd 0.0100\ttime 0.0361 (0.0359)\tloss 0.7329 (0.5778)\tgrad_norm 2.2749 (2.0283)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][90/625]\teta 0:00:19 lr 0.000431\t wd 0.0100\ttime 0.0351 (0.0359)\tloss 0.6865 (0.5855)\tgrad_norm 2.5860 (2.0822)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][100/625]\teta 0:00:18 lr 0.000431\t wd 0.0100\ttime 0.0327 (0.0359)\tloss 0.3579 (0.5798)\tgrad_norm 1.7999 (2.0746)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][110/625]\teta 0:00:18 lr 0.000430\t wd 0.0100\ttime 0.0356 (0.0359)\tloss 0.3972 (0.5717)\tgrad_norm 1.9184 (2.0430)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][120/625]\teta 0:00:18 lr 0.000430\t wd 0.0100\ttime 0.0349 (0.0358)\tloss 0.7207 (0.5710)\tgrad_norm 2.2619 (2.0561)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][130/625]\teta 0:00:17 lr 0.000430\t wd 0.0100\ttime 0.0399 (0.0359)\tloss 0.3809 (0.5757)\tgrad_norm 1.3000 (2.0626)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][140/625]\teta 0:00:17 lr 0.000430\t wd 0.0100\ttime 0.0355 (0.0359)\tloss 0.6382 (0.5764)\tgrad_norm 2.2540 (2.0613)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][150/625]\teta 0:00:17 lr 0.000429\t wd 0.0100\ttime 0.0329 (0.0359)\tloss 0.4646 (0.5745)\tgrad_norm 1.8653 (2.0719)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][160/625]\teta 0:00:16 lr 0.000429\t wd 0.0100\ttime 0.0324 (0.0359)\tloss 0.6196 (0.5748)\tgrad_norm 2.1934 (2.0717)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][170/625]\teta 0:00:16 lr 0.000429\t wd 0.0100\ttime 0.0329 (0.0359)\tloss 0.4963 (0.5772)\tgrad_norm 1.7923 (2.0665)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][180/625]\teta 0:00:15 lr 0.000429\t wd 0.0100\ttime 0.0371 (0.0359)\tloss 0.7363 (0.5817)\tgrad_norm 2.5949 (2.0671)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][190/625]\teta 0:00:15 lr 0.000428\t wd 0.0100\ttime 0.0328 (0.0358)\tloss 0.4937 (0.5803)\tgrad_norm 1.6637 (2.0583)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][200/625]\teta 0:00:15 lr 0.000428\t wd 0.0100\ttime 0.0392 (0.0358)\tloss 0.6001 (0.5782)\tgrad_norm 2.0332 (2.0503)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][210/625]\teta 0:00:14 lr 0.000428\t wd 0.0100\ttime 0.0370 (0.0357)\tloss 0.4600 (0.5805)\tgrad_norm 2.5151 (2.0595)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][220/625]\teta 0:00:14 lr 0.000428\t wd 0.0100\ttime 0.0391 (0.0357)\tloss 0.6353 (0.5841)\tgrad_norm 1.9426 (2.0689)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][230/625]\teta 0:00:14 lr 0.000427\t wd 0.0100\ttime 0.0329 (0.0357)\tloss 0.8228 (0.5877)\tgrad_norm 2.3201 (2.0778)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][240/625]\teta 0:00:13 lr 0.000427\t wd 0.0100\ttime 0.0398 (0.0357)\tloss 0.6479 (0.5884)\tgrad_norm 2.2501 (2.0771)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][250/625]\teta 0:00:13 lr 0.000427\t wd 0.0100\ttime 0.0386 (0.0358)\tloss 0.6206 (0.5903)\tgrad_norm 1.9887 (2.0791)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][260/625]\teta 0:00:13 lr 0.000427\t wd 0.0100\ttime 0.0358 (0.0358)\tloss 0.6587 (0.5876)\tgrad_norm 2.5772 (2.0758)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][270/625]\teta 0:00:12 lr 0.000426\t wd 0.0100\ttime 0.0323 (0.0357)\tloss 0.5713 (0.5898)\tgrad_norm 2.2363 (2.0826)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][280/625]\teta 0:00:12 lr 0.000426\t wd 0.0100\ttime 0.0331 (0.0357)\tloss 0.4558 (0.5886)\tgrad_norm 1.5547 (2.0737)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][290/625]\teta 0:00:11 lr 0.000426\t wd 0.0100\ttime 0.0362 (0.0357)\tloss 0.5039 (0.5874)\tgrad_norm 1.7927 (2.0731)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][300/625]\teta 0:00:11 lr 0.000426\t wd 0.0100\ttime 0.0358 (0.0357)\tloss 0.4124 (0.5890)\tgrad_norm 1.4332 (2.0694)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][310/625]\teta 0:00:11 lr 0.000425\t wd 0.0100\ttime 0.0363 (0.0357)\tloss 0.5605 (0.5895)\tgrad_norm 2.3018 (2.0709)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][320/625]\teta 0:00:10 lr 0.000425\t wd 0.0100\ttime 0.0331 (0.0357)\tloss 0.6724 (0.5917)\tgrad_norm 2.3804 (2.0757)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][330/625]\teta 0:00:10 lr 0.000425\t wd 0.0100\ttime 0.0391 (0.0357)\tloss 0.6196 (0.5915)\tgrad_norm 1.8742 (2.0745)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][340/625]\teta 0:00:10 lr 0.000424\t wd 0.0100\ttime 0.0357 (0.0357)\tloss 0.7266 (0.5904)\tgrad_norm 3.6662 (2.0818)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][350/625]\teta 0:00:09 lr 0.000424\t wd 0.0100\ttime 0.0374 (0.0358)\tloss 0.6558 (0.5897)\tgrad_norm 2.0801 (2.0796)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][360/625]\teta 0:00:09 lr 0.000424\t wd 0.0100\ttime 0.0332 (0.0358)\tloss 0.7588 (0.5902)\tgrad_norm 5.5367 (2.0985)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][370/625]\teta 0:00:09 lr 0.000424\t wd 0.0100\ttime 0.0333 (0.0358)\tloss 0.5962 (0.5905)\tgrad_norm 3.0013 (2.1072)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][380/625]\teta 0:00:08 lr 0.000423\t wd 0.0100\ttime 0.0356 (0.0359)\tloss 0.5620 (0.5911)\tgrad_norm 1.7587 (2.1108)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][390/625]\teta 0:00:08 lr 0.000423\t wd 0.0100\ttime 0.0360 (0.0359)\tloss 0.7378 (0.5909)\tgrad_norm 2.0892 (2.1171)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][400/625]\teta 0:00:08 lr 0.000423\t wd 0.0100\ttime 0.0360 (0.0359)\tloss 0.5020 (0.5915)\tgrad_norm 2.0599 (2.1142)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][410/625]\teta 0:00:07 lr 0.000423\t wd 0.0100\ttime 0.0357 (0.0359)\tloss 0.7412 (0.5911)\tgrad_norm 1.8932 (2.1122)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][420/625]\teta 0:00:07 lr 0.000422\t wd 0.0100\ttime 0.0384 (0.0359)\tloss 0.8677 (0.5904)\tgrad_norm 2.3565 (2.1076)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][430/625]\teta 0:00:07 lr 0.000422\t wd 0.0100\ttime 0.0324 (0.0359)\tloss 0.4360 (0.5899)\tgrad_norm 1.3458 (2.0997)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][440/625]\teta 0:00:06 lr 0.000422\t wd 0.0100\ttime 0.0330 (0.0359)\tloss 0.5601 (0.5902)\tgrad_norm 1.8641 (2.0948)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][450/625]\teta 0:00:06 lr 0.000422\t wd 0.0100\ttime 0.0363 (0.0359)\tloss 0.6455 (0.5903)\tgrad_norm 2.3627 (2.0932)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][460/625]\teta 0:00:05 lr 0.000421\t wd 0.0100\ttime 0.0363 (0.0359)\tloss 0.5508 (0.5913)\tgrad_norm 1.9029 (2.0961)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][470/625]\teta 0:00:05 lr 0.000421\t wd 0.0100\ttime 0.0327 (0.0359)\tloss 0.4709 (0.5895)\tgrad_norm 1.9498 (2.0948)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][480/625]\teta 0:00:05 lr 0.000421\t wd 0.0100\ttime 0.0326 (0.0359)\tloss 0.5942 (0.5899)\tgrad_norm 1.7793 (2.0992)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][490/625]\teta 0:00:04 lr 0.000421\t wd 0.0100\ttime 0.0360 (0.0359)\tloss 0.6509 (0.5894)\tgrad_norm 2.4494 (2.0977)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][500/625]\teta 0:00:04 lr 0.000420\t wd 0.0100\ttime 0.0327 (0.0359)\tloss 0.6523 (0.5900)\tgrad_norm 2.1095 (2.0975)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][510/625]\teta 0:00:04 lr 0.000420\t wd 0.0100\ttime 0.0391 (0.0359)\tloss 0.8398 (0.5905)\tgrad_norm 2.4958 (2.0978)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][520/625]\teta 0:00:03 lr 0.000420\t wd 0.0100\ttime 0.0362 (0.0359)\tloss 0.5879 (0.5902)\tgrad_norm 2.1276 (2.0957)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][530/625]\teta 0:00:03 lr 0.000420\t wd 0.0100\ttime 0.0404 (0.0359)\tloss 0.4841 (0.5897)\tgrad_norm 1.3335 (2.0917)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][540/625]\teta 0:00:03 lr 0.000419\t wd 0.0100\ttime 0.0360 (0.0359)\tloss 0.5684 (0.5883)\tgrad_norm 1.8390 (2.0895)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][550/625]\teta 0:00:02 lr 0.000419\t wd 0.0100\ttime 0.0339 (0.0359)\tloss 0.5522 (0.5879)\tgrad_norm 2.0424 (2.0873)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][560/625]\teta 0:00:02 lr 0.000419\t wd 0.0100\ttime 0.0415 (0.0360)\tloss 0.5146 (0.5880)\tgrad_norm 1.5253 (2.0845)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][570/625]\teta 0:00:01 lr 0.000419\t wd 0.0100\ttime 0.0366 (0.0360)\tloss 0.5464 (0.5877)\tgrad_norm 1.6268 (2.0851)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][580/625]\teta 0:00:01 lr 0.000418\t wd 0.0100\ttime 0.0360 (0.0360)\tloss 0.4001 (0.5872)\tgrad_norm 1.4884 (2.0819)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][590/625]\teta 0:00:01 lr 0.000418\t wd 0.0100\ttime 0.0361 (0.0360)\tloss 0.7402 (0.5880)\tgrad_norm 2.9161 (2.0840)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][600/625]\teta 0:00:00 lr 0.000418\t wd 0.0100\ttime 0.0357 (0.0360)\tloss 0.4473 (0.5875)\tgrad_norm 1.7647 (2.0810)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][610/625]\teta 0:00:00 lr 0.000418\t wd 0.0100\ttime 0.0329 (0.0360)\tloss 0.5635 (0.5874)\tgrad_norm 1.7147 (2.0801)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [56/100][620/625]\teta 0:00:00 lr 0.000417\t wd 0.0100\ttime 0.0330 (0.0360)\tloss 0.6748 (0.5873)\tgrad_norm 1.9541 (2.0779)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 56 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_56.pth saving......\n",
      "./model_save/ckpt_epoch_56.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.6772 (0.6772)\tAcc@1 75.000 (75.000)\tAcc@5 98.438 (98.438)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.016 (0.016)\tLoss 0.6475 (0.6864)\tAcc@1 84.375 (77.983)\tAcc@5 95.312 (98.153)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.016 (0.016)\tLoss 0.4080 (0.6424)\tAcc@1 85.938 (79.241)\tAcc@5 100.000 (98.810)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.016 (0.016)\tLoss 0.9497 (0.6679)\tAcc@1 65.625 (78.327)\tAcc@5 95.312 (98.690)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.016)\tLoss 0.3142 (0.6528)\tAcc@1 87.500 (77.820)\tAcc@5 98.438 (98.780)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.016)\tLoss 0.7397 (0.6474)\tAcc@1 76.562 (77.604)\tAcc@5 98.438 (98.836)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.016)\tLoss 0.5283 (0.6433)\tAcc@1 82.812 (77.766)\tAcc@5 98.438 (98.847)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.016)\tLoss 0.4531 (0.6320)\tAcc@1 82.812 (78.103)\tAcc@5 100.000 (98.922)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.016)\tLoss 0.4890 (0.6302)\tAcc@1 81.250 (78.106)\tAcc@5 98.438 (98.862)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.8955 (0.6300)\tAcc@1 67.188 (78.005)\tAcc@5 96.875 (98.918)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.016 (0.015)\tLoss 0.4819 (0.6378)\tAcc@1 82.812 (77.847)\tAcc@5 100.000 (98.793)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.7441 (0.6402)\tAcc@1 73.438 (77.717)\tAcc@5 100.000 (98.789)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.6255 (0.6401)\tAcc@1 81.250 (77.699)\tAcc@5 96.875 (98.825)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.5864 (0.6392)\tAcc@1 76.562 (77.839)\tAcc@5 98.438 (98.819)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.7319 (0.6399)\tAcc@1 73.438 (77.626)\tAcc@5 98.438 (98.870)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.6738 (0.6377)\tAcc@1 76.562 (77.773)\tAcc@5 100.000 (98.841)\tMem 455MB\n",
      " * Acc@1 77.830 Acc@5 98.850\n",
      "Accuracy of the network on the 10000 test images: 77.8%\n",
      "Max accuracy: 77.83%\n",
      "Train: [57/100][0/625]\teta 0:00:24 lr 0.000417\t wd 0.0100\ttime 0.0387 (0.0387)\tloss 0.4573 (0.4573)\tgrad_norm 2.2198 (2.2198)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][10/625]\teta 0:00:21 lr 0.000417\t wd 0.0100\ttime 0.0393 (0.0357)\tloss 0.7314 (0.5374)\tgrad_norm 2.4781 (1.8248)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][20/625]\teta 0:00:22 lr 0.000417\t wd 0.0100\ttime 0.0356 (0.0364)\tloss 0.5957 (0.5469)\tgrad_norm 2.0433 (1.9305)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][30/625]\teta 0:00:21 lr 0.000417\t wd 0.0100\ttime 0.0352 (0.0361)\tloss 0.6572 (0.5748)\tgrad_norm 2.1774 (2.0084)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][40/625]\teta 0:00:21 lr 0.000416\t wd 0.0100\ttime 0.0359 (0.0360)\tloss 0.5654 (0.5771)\tgrad_norm 2.2226 (2.0274)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][50/625]\teta 0:00:20 lr 0.000416\t wd 0.0100\ttime 0.0326 (0.0354)\tloss 0.5410 (0.5694)\tgrad_norm 2.0463 (2.0588)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][60/625]\teta 0:00:19 lr 0.000416\t wd 0.0100\ttime 0.0327 (0.0351)\tloss 0.6392 (0.5658)\tgrad_norm 1.5942 (2.0079)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][70/625]\teta 0:00:19 lr 0.000416\t wd 0.0100\ttime 0.0332 (0.0349)\tloss 0.6968 (0.5650)\tgrad_norm 2.4182 (2.0146)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][80/625]\teta 0:00:18 lr 0.000415\t wd 0.0100\ttime 0.0340 (0.0348)\tloss 0.5415 (0.5667)\tgrad_norm 2.5804 (2.0306)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][90/625]\teta 0:00:18 lr 0.000415\t wd 0.0100\ttime 0.0398 (0.0350)\tloss 0.4812 (0.5676)\tgrad_norm 1.7577 (2.0242)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][100/625]\teta 0:00:18 lr 0.000415\t wd 0.0100\ttime 0.0335 (0.0351)\tloss 0.3538 (0.5675)\tgrad_norm 1.7731 (2.0445)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][110/625]\teta 0:00:18 lr 0.000415\t wd 0.0100\ttime 0.0327 (0.0351)\tloss 0.5098 (0.5670)\tgrad_norm 1.2704 (2.0296)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][120/625]\teta 0:00:17 lr 0.000414\t wd 0.0100\ttime 0.0327 (0.0352)\tloss 0.4417 (0.5678)\tgrad_norm 2.0913 (2.0324)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][130/625]\teta 0:00:17 lr 0.000414\t wd 0.0100\ttime 0.0399 (0.0353)\tloss 0.5225 (0.5663)\tgrad_norm 1.9870 (2.0168)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][140/625]\teta 0:00:17 lr 0.000414\t wd 0.0100\ttime 0.0359 (0.0353)\tloss 0.4897 (0.5650)\tgrad_norm 1.8612 (2.0151)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][150/625]\teta 0:00:16 lr 0.000414\t wd 0.0100\ttime 0.0395 (0.0355)\tloss 0.5352 (0.5652)\tgrad_norm 1.5578 (2.0207)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][160/625]\teta 0:00:16 lr 0.000413\t wd 0.0100\ttime 0.0402 (0.0357)\tloss 0.4875 (0.5636)\tgrad_norm 2.9263 (2.0220)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][170/625]\teta 0:00:16 lr 0.000413\t wd 0.0100\ttime 0.0360 (0.0358)\tloss 0.4475 (0.5623)\tgrad_norm 2.1329 (2.0195)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][180/625]\teta 0:00:15 lr 0.000413\t wd 0.0100\ttime 0.0328 (0.0358)\tloss 0.7222 (0.5654)\tgrad_norm 2.5329 (2.0208)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][190/625]\teta 0:00:15 lr 0.000412\t wd 0.0100\ttime 0.0326 (0.0358)\tloss 0.6699 (0.5679)\tgrad_norm 2.0435 (2.0273)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][200/625]\teta 0:00:15 lr 0.000412\t wd 0.0100\ttime 0.0330 (0.0357)\tloss 0.4609 (0.5672)\tgrad_norm 1.3130 (2.0187)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][210/625]\teta 0:00:14 lr 0.000412\t wd 0.0100\ttime 0.0357 (0.0356)\tloss 0.6357 (0.5676)\tgrad_norm 1.9178 (2.0136)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][220/625]\teta 0:00:14 lr 0.000412\t wd 0.0100\ttime 0.0329 (0.0356)\tloss 0.5430 (0.5691)\tgrad_norm 1.6237 (2.0161)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][230/625]\teta 0:00:14 lr 0.000411\t wd 0.0100\ttime 0.0394 (0.0356)\tloss 0.7490 (0.5715)\tgrad_norm 2.5271 (2.0245)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][240/625]\teta 0:00:13 lr 0.000411\t wd 0.0100\ttime 0.0328 (0.0355)\tloss 0.5923 (0.5728)\tgrad_norm 1.9873 (2.0239)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][250/625]\teta 0:00:13 lr 0.000411\t wd 0.0100\ttime 0.0395 (0.0356)\tloss 0.7505 (0.5724)\tgrad_norm 1.6305 (2.0177)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][260/625]\teta 0:00:12 lr 0.000411\t wd 0.0100\ttime 0.0330 (0.0356)\tloss 0.5811 (0.5711)\tgrad_norm 1.5369 (2.0112)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][270/625]\teta 0:00:12 lr 0.000410\t wd 0.0100\ttime 0.0350 (0.0356)\tloss 0.3379 (0.5706)\tgrad_norm 2.0087 (2.0136)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][280/625]\teta 0:00:12 lr 0.000410\t wd 0.0100\ttime 0.0346 (0.0356)\tloss 0.6509 (0.5722)\tgrad_norm 2.0970 (2.0179)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][290/625]\teta 0:00:11 lr 0.000410\t wd 0.0100\ttime 0.0348 (0.0355)\tloss 0.6382 (0.5700)\tgrad_norm 1.6674 (2.0168)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][300/625]\teta 0:00:11 lr 0.000410\t wd 0.0100\ttime 0.0330 (0.0355)\tloss 0.7739 (0.5728)\tgrad_norm 1.8084 (2.0217)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][310/625]\teta 0:00:11 lr 0.000409\t wd 0.0100\ttime 0.0356 (0.0354)\tloss 0.7959 (0.5729)\tgrad_norm 2.3688 (2.0244)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][320/625]\teta 0:00:10 lr 0.000409\t wd 0.0100\ttime 0.0325 (0.0354)\tloss 0.5068 (0.5736)\tgrad_norm 1.7425 (2.0250)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][330/625]\teta 0:00:10 lr 0.000409\t wd 0.0100\ttime 0.0325 (0.0354)\tloss 0.5059 (0.5752)\tgrad_norm 2.1991 (2.0284)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][340/625]\teta 0:00:10 lr 0.000409\t wd 0.0100\ttime 0.0354 (0.0354)\tloss 0.6802 (0.5743)\tgrad_norm 2.0144 (2.0245)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][350/625]\teta 0:00:09 lr 0.000408\t wd 0.0100\ttime 0.0355 (0.0354)\tloss 0.7822 (0.5746)\tgrad_norm 1.7117 (2.0184)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][360/625]\teta 0:00:09 lr 0.000408\t wd 0.0100\ttime 0.0389 (0.0354)\tloss 0.3528 (0.5735)\tgrad_norm 1.5909 (2.0157)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][370/625]\teta 0:00:09 lr 0.000408\t wd 0.0100\ttime 0.0359 (0.0354)\tloss 0.3950 (0.5746)\tgrad_norm 1.2532 (2.0135)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][380/625]\teta 0:00:08 lr 0.000408\t wd 0.0100\ttime 0.0356 (0.0354)\tloss 0.5142 (0.5741)\tgrad_norm 1.6850 (2.0156)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][390/625]\teta 0:00:08 lr 0.000407\t wd 0.0100\ttime 0.0358 (0.0354)\tloss 0.5659 (0.5744)\tgrad_norm 1.6784 (2.0154)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][400/625]\teta 0:00:07 lr 0.000407\t wd 0.0100\ttime 0.0394 (0.0354)\tloss 0.5288 (0.5750)\tgrad_norm 1.5157 (2.0161)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][410/625]\teta 0:00:07 lr 0.000407\t wd 0.0100\ttime 0.0327 (0.0354)\tloss 0.8931 (0.5760)\tgrad_norm 3.7731 (2.0214)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][420/625]\teta 0:00:07 lr 0.000407\t wd 0.0100\ttime 0.0394 (0.0354)\tloss 0.4844 (0.5750)\tgrad_norm 2.4607 (2.0213)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][430/625]\teta 0:00:06 lr 0.000406\t wd 0.0100\ttime 0.0326 (0.0354)\tloss 0.5303 (0.5736)\tgrad_norm 2.3814 (2.0188)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][440/625]\teta 0:00:06 lr 0.000406\t wd 0.0100\ttime 0.0329 (0.0354)\tloss 0.6182 (0.5724)\tgrad_norm 2.5663 (2.0229)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][450/625]\teta 0:00:06 lr 0.000406\t wd 0.0100\ttime 0.0325 (0.0354)\tloss 0.4517 (0.5729)\tgrad_norm 2.6035 (2.0297)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][460/625]\teta 0:00:05 lr 0.000406\t wd 0.0100\ttime 0.0325 (0.0354)\tloss 0.4224 (0.5729)\tgrad_norm 2.2048 (2.0294)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][470/625]\teta 0:00:05 lr 0.000405\t wd 0.0100\ttime 0.0354 (0.0354)\tloss 0.6323 (0.5728)\tgrad_norm 2.7378 (2.0304)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][480/625]\teta 0:00:05 lr 0.000405\t wd 0.0100\ttime 0.0329 (0.0354)\tloss 0.5171 (0.5728)\tgrad_norm 1.6819 (2.0325)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][490/625]\teta 0:00:04 lr 0.000405\t wd 0.0100\ttime 0.0368 (0.0354)\tloss 0.6836 (0.5736)\tgrad_norm 1.9785 (2.0342)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][500/625]\teta 0:00:04 lr 0.000405\t wd 0.0100\ttime 0.0326 (0.0354)\tloss 0.4292 (0.5745)\tgrad_norm 1.8409 (2.0353)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][510/625]\teta 0:00:04 lr 0.000404\t wd 0.0100\ttime 0.0383 (0.0354)\tloss 0.5957 (0.5751)\tgrad_norm 1.7875 (2.0381)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][520/625]\teta 0:00:03 lr 0.000404\t wd 0.0100\ttime 0.0356 (0.0354)\tloss 0.5132 (0.5749)\tgrad_norm 2.7155 (2.0422)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][530/625]\teta 0:00:03 lr 0.000404\t wd 0.0100\ttime 0.0396 (0.0354)\tloss 0.4924 (0.5750)\tgrad_norm 2.2585 (2.0419)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][540/625]\teta 0:00:03 lr 0.000404\t wd 0.0100\ttime 0.0324 (0.0354)\tloss 0.4473 (0.5737)\tgrad_norm 1.5009 (2.0403)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][550/625]\teta 0:00:02 lr 0.000403\t wd 0.0100\ttime 0.0358 (0.0354)\tloss 0.7578 (0.5742)\tgrad_norm 2.9722 (2.0423)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][560/625]\teta 0:00:02 lr 0.000403\t wd 0.0100\ttime 0.0359 (0.0354)\tloss 0.4436 (0.5737)\tgrad_norm 1.4196 (2.0374)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][570/625]\teta 0:00:01 lr 0.000403\t wd 0.0100\ttime 0.0366 (0.0354)\tloss 0.3582 (0.5733)\tgrad_norm 1.5861 (2.0357)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][580/625]\teta 0:00:01 lr 0.000403\t wd 0.0100\ttime 0.0357 (0.0354)\tloss 0.4221 (0.5741)\tgrad_norm 1.1415 (2.0326)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][590/625]\teta 0:00:01 lr 0.000402\t wd 0.0100\ttime 0.0325 (0.0354)\tloss 0.7017 (0.5746)\tgrad_norm 2.4769 (2.0314)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][600/625]\teta 0:00:00 lr 0.000402\t wd 0.0100\ttime 0.0325 (0.0354)\tloss 0.6704 (0.5762)\tgrad_norm 1.7609 (2.0304)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][610/625]\teta 0:00:00 lr 0.000402\t wd 0.0100\ttime 0.0403 (0.0354)\tloss 0.4019 (0.5759)\tgrad_norm 1.5548 (2.0281)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [57/100][620/625]\teta 0:00:00 lr 0.000402\t wd 0.0100\ttime 0.0330 (0.0354)\tloss 0.5693 (0.5756)\tgrad_norm 2.0374 (2.0305)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 57 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_57.pth saving......\n",
      "./model_save/ckpt_epoch_57.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.5322 (0.5322)\tAcc@1 78.125 (78.125)\tAcc@5 98.438 (98.438)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.016)\tLoss 0.7231 (0.5915)\tAcc@1 73.438 (77.983)\tAcc@5 100.000 (99.290)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.6504 (0.6324)\tAcc@1 68.750 (77.307)\tAcc@5 100.000 (99.033)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.6865 (0.6102)\tAcc@1 75.000 (78.075)\tAcc@5 100.000 (99.042)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.4890 (0.6244)\tAcc@1 84.375 (77.591)\tAcc@5 98.438 (99.047)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.5894 (0.6229)\tAcc@1 81.250 (77.727)\tAcc@5 100.000 (99.112)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.5381 (0.6393)\tAcc@1 79.688 (77.254)\tAcc@5 100.000 (99.001)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.5996 (0.6452)\tAcc@1 82.812 (77.091)\tAcc@5 100.000 (98.988)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.4792 (0.6483)\tAcc@1 79.688 (77.064)\tAcc@5 100.000 (98.958)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.8198 (0.6567)\tAcc@1 75.000 (76.940)\tAcc@5 98.438 (98.918)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.6411 (0.6623)\tAcc@1 78.125 (76.841)\tAcc@5 96.875 (98.824)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.7729 (0.6623)\tAcc@1 73.438 (76.816)\tAcc@5 95.312 (98.775)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.5322 (0.6673)\tAcc@1 76.562 (76.717)\tAcc@5 100.000 (98.760)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.8608 (0.6675)\tAcc@1 70.312 (76.658)\tAcc@5 96.875 (98.807)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.6050 (0.6646)\tAcc@1 81.250 (76.806)\tAcc@5 98.438 (98.814)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.7246 (0.6599)\tAcc@1 76.562 (77.059)\tAcc@5 98.438 (98.820)\tMem 455MB\n",
      " * Acc@1 77.100 Acc@5 98.820\n",
      "Accuracy of the network on the 10000 test images: 77.1%\n",
      "Max accuracy: 77.83%\n",
      "Train: [58/100][0/625]\teta 0:00:23 lr 0.000402\t wd 0.0100\ttime 0.0375 (0.0375)\tloss 0.7021 (0.7021)\tgrad_norm 2.2163 (2.2163)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][10/625]\teta 0:00:21 lr 0.000401\t wd 0.0100\ttime 0.0327 (0.0353)\tloss 0.4548 (0.5816)\tgrad_norm 1.8877 (2.0771)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][20/625]\teta 0:00:21 lr 0.000401\t wd 0.0100\ttime 0.0325 (0.0355)\tloss 0.6123 (0.5702)\tgrad_norm 1.9122 (2.0544)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][30/625]\teta 0:00:21 lr 0.000401\t wd 0.0100\ttime 0.0330 (0.0358)\tloss 0.6768 (0.5729)\tgrad_norm 2.0727 (2.0886)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][40/625]\teta 0:00:21 lr 0.000401\t wd 0.0100\ttime 0.0388 (0.0360)\tloss 0.5171 (0.5627)\tgrad_norm 2.5030 (2.0430)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][50/625]\teta 0:00:20 lr 0.000400\t wd 0.0100\ttime 0.0377 (0.0360)\tloss 0.4192 (0.5646)\tgrad_norm 1.8083 (2.0623)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][60/625]\teta 0:00:20 lr 0.000400\t wd 0.0100\ttime 0.0324 (0.0360)\tloss 0.5254 (0.5606)\tgrad_norm 2.3256 (2.0750)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][70/625]\teta 0:00:19 lr 0.000400\t wd 0.0100\ttime 0.0325 (0.0360)\tloss 0.3774 (0.5659)\tgrad_norm 1.7252 (2.0692)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][80/625]\teta 0:00:19 lr 0.000400\t wd 0.0100\ttime 0.0323 (0.0357)\tloss 0.5425 (0.5712)\tgrad_norm 2.0910 (2.0889)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][90/625]\teta 0:00:18 lr 0.000399\t wd 0.0100\ttime 0.0325 (0.0355)\tloss 0.6162 (0.5755)\tgrad_norm 2.4379 (2.1196)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][100/625]\teta 0:00:18 lr 0.000399\t wd 0.0100\ttime 0.0325 (0.0352)\tloss 0.5571 (0.5742)\tgrad_norm 2.9423 (2.1004)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][110/625]\teta 0:00:18 lr 0.000399\t wd 0.0100\ttime 0.0352 (0.0351)\tloss 0.6196 (0.5711)\tgrad_norm 2.4302 (2.1124)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][120/625]\teta 0:00:17 lr 0.000399\t wd 0.0100\ttime 0.0325 (0.0352)\tloss 0.6245 (0.5755)\tgrad_norm 1.6979 (2.1103)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][130/625]\teta 0:00:17 lr 0.000398\t wd 0.0100\ttime 0.0322 (0.0350)\tloss 0.4275 (0.5738)\tgrad_norm 1.7621 (2.1060)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][140/625]\teta 0:00:16 lr 0.000398\t wd 0.0100\ttime 0.0324 (0.0349)\tloss 0.4727 (0.5758)\tgrad_norm 2.8567 (2.1126)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][150/625]\teta 0:00:16 lr 0.000398\t wd 0.0100\ttime 0.0360 (0.0349)\tloss 0.7241 (0.5751)\tgrad_norm 2.1016 (2.0982)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][160/625]\teta 0:00:16 lr 0.000398\t wd 0.0100\ttime 0.0344 (0.0348)\tloss 0.5107 (0.5759)\tgrad_norm 2.1696 (2.0852)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][170/625]\teta 0:00:15 lr 0.000397\t wd 0.0100\ttime 0.0327 (0.0349)\tloss 0.4375 (0.5754)\tgrad_norm 1.6611 (2.0706)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][180/625]\teta 0:00:15 lr 0.000397\t wd 0.0100\ttime 0.0331 (0.0350)\tloss 0.6851 (0.5763)\tgrad_norm 2.0553 (2.0622)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][190/625]\teta 0:00:15 lr 0.000397\t wd 0.0100\ttime 0.0324 (0.0350)\tloss 0.5669 (0.5745)\tgrad_norm 1.6363 (2.0484)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][200/625]\teta 0:00:14 lr 0.000397\t wd 0.0100\ttime 0.0365 (0.0350)\tloss 0.3003 (0.5711)\tgrad_norm 1.3131 (2.0438)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][210/625]\teta 0:00:14 lr 0.000396\t wd 0.0100\ttime 0.0326 (0.0349)\tloss 0.4827 (0.5666)\tgrad_norm 1.6636 (2.0351)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][220/625]\teta 0:00:14 lr 0.000396\t wd 0.0100\ttime 0.0359 (0.0349)\tloss 0.3904 (0.5650)\tgrad_norm 1.5242 (2.0416)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][230/625]\teta 0:00:13 lr 0.000396\t wd 0.0100\ttime 0.0346 (0.0348)\tloss 0.5415 (0.5651)\tgrad_norm 1.8908 (2.0342)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][240/625]\teta 0:00:13 lr 0.000396\t wd 0.0100\ttime 0.0325 (0.0348)\tloss 0.6899 (0.5667)\tgrad_norm 1.7531 (2.0367)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][250/625]\teta 0:00:13 lr 0.000395\t wd 0.0100\ttime 0.0329 (0.0348)\tloss 0.5220 (0.5672)\tgrad_norm 2.1035 (2.0347)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][260/625]\teta 0:00:12 lr 0.000395\t wd 0.0100\ttime 0.0323 (0.0348)\tloss 0.6074 (0.5672)\tgrad_norm 2.0106 (2.0276)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][270/625]\teta 0:00:12 lr 0.000395\t wd 0.0100\ttime 0.0353 (0.0348)\tloss 0.4321 (0.5682)\tgrad_norm 1.4405 (2.0289)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][280/625]\teta 0:00:12 lr 0.000395\t wd 0.0100\ttime 0.0328 (0.0348)\tloss 0.6387 (0.5679)\tgrad_norm 2.3211 (2.0252)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][290/625]\teta 0:00:11 lr 0.000394\t wd 0.0100\ttime 0.0327 (0.0348)\tloss 0.5508 (0.5678)\tgrad_norm 1.9168 (2.0200)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][300/625]\teta 0:00:11 lr 0.000394\t wd 0.0100\ttime 0.0386 (0.0348)\tloss 0.4836 (0.5661)\tgrad_norm 1.8644 (2.0156)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][310/625]\teta 0:00:10 lr 0.000394\t wd 0.0100\ttime 0.0369 (0.0349)\tloss 0.4167 (0.5670)\tgrad_norm 1.5206 (2.0136)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][320/625]\teta 0:00:10 lr 0.000394\t wd 0.0100\ttime 0.0328 (0.0349)\tloss 0.5708 (0.5655)\tgrad_norm 2.3883 (2.0183)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][330/625]\teta 0:00:10 lr 0.000393\t wd 0.0100\ttime 0.0355 (0.0350)\tloss 0.4900 (0.5675)\tgrad_norm 1.9555 (2.0276)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][340/625]\teta 0:00:09 lr 0.000393\t wd 0.0100\ttime 0.0370 (0.0350)\tloss 0.5078 (0.5673)\tgrad_norm 2.2232 (2.0272)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][350/625]\teta 0:00:09 lr 0.000393\t wd 0.0100\ttime 0.0326 (0.0350)\tloss 0.6143 (0.5678)\tgrad_norm 2.0892 (2.0222)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][360/625]\teta 0:00:09 lr 0.000393\t wd 0.0100\ttime 0.0401 (0.0351)\tloss 0.5591 (0.5662)\tgrad_norm 1.7985 (2.0170)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][370/625]\teta 0:00:08 lr 0.000392\t wd 0.0100\ttime 0.0353 (0.0351)\tloss 0.6279 (0.5673)\tgrad_norm 2.0865 (2.0115)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][380/625]\teta 0:00:08 lr 0.000392\t wd 0.0100\ttime 0.0330 (0.0351)\tloss 0.5767 (0.5690)\tgrad_norm 2.0498 (2.0144)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][390/625]\teta 0:00:08 lr 0.000392\t wd 0.0100\ttime 0.0392 (0.0352)\tloss 0.7051 (0.5694)\tgrad_norm 1.9239 (2.0167)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][400/625]\teta 0:00:07 lr 0.000392\t wd 0.0100\ttime 0.0392 (0.0352)\tloss 0.4680 (0.5698)\tgrad_norm 1.6041 (2.0225)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][410/625]\teta 0:00:07 lr 0.000391\t wd 0.0100\ttime 0.0432 (0.0353)\tloss 0.7686 (0.5709)\tgrad_norm 2.4585 (2.0244)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][420/625]\teta 0:00:07 lr 0.000391\t wd 0.0100\ttime 0.0340 (0.0353)\tloss 0.5273 (0.5716)\tgrad_norm 1.4239 (2.0207)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][430/625]\teta 0:00:06 lr 0.000391\t wd 0.0100\ttime 0.0391 (0.0353)\tloss 0.6328 (0.5711)\tgrad_norm 2.4145 (2.0180)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][440/625]\teta 0:00:06 lr 0.000391\t wd 0.0100\ttime 0.0356 (0.0353)\tloss 0.4194 (0.5707)\tgrad_norm 1.9030 (2.0177)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][450/625]\teta 0:00:06 lr 0.000390\t wd 0.0100\ttime 0.0374 (0.0353)\tloss 0.7061 (0.5707)\tgrad_norm 2.0069 (2.0208)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][460/625]\teta 0:00:05 lr 0.000390\t wd 0.0100\ttime 0.0359 (0.0354)\tloss 0.7002 (0.5705)\tgrad_norm 2.2806 (2.0169)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][470/625]\teta 0:00:05 lr 0.000390\t wd 0.0100\ttime 0.0329 (0.0354)\tloss 0.6323 (0.5716)\tgrad_norm 1.5667 (2.0200)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][480/625]\teta 0:00:05 lr 0.000390\t wd 0.0100\ttime 0.0325 (0.0354)\tloss 0.4292 (0.5717)\tgrad_norm 1.7855 (2.0224)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][490/625]\teta 0:00:04 lr 0.000389\t wd 0.0100\ttime 0.0396 (0.0354)\tloss 0.6636 (0.5720)\tgrad_norm 2.0154 (2.0199)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][500/625]\teta 0:00:04 lr 0.000389\t wd 0.0100\ttime 0.0325 (0.0354)\tloss 0.8110 (0.5721)\tgrad_norm 2.1512 (2.0201)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][510/625]\teta 0:00:04 lr 0.000389\t wd 0.0100\ttime 0.0326 (0.0354)\tloss 0.5312 (0.5708)\tgrad_norm 2.4009 (2.0180)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [58/100][520/625]\teta 0:00:03 lr 0.000389\t wd 0.0100\ttime 0.0322 (0.0353)\tloss 0.5020 (0.5703)\tgrad_norm 1.8537 (nan)\tloss_scale 32768.0000 (32830.8944)\tmem 455MB\n",
      "Train: [58/100][530/625]\teta 0:00:03 lr 0.000388\t wd 0.0100\ttime 0.0350 (0.0353)\tloss 0.8960 (0.5702)\tgrad_norm 2.9046 (nan)\tloss_scale 32768.0000 (32829.7100)\tmem 455MB\n",
      "Train: [58/100][540/625]\teta 0:00:03 lr 0.000388\t wd 0.0100\ttime 0.0324 (0.0353)\tloss 0.5107 (0.5707)\tgrad_norm 1.6444 (nan)\tloss_scale 32768.0000 (32828.5693)\tmem 455MB\n",
      "Train: [58/100][550/625]\teta 0:00:02 lr 0.000388\t wd 0.0100\ttime 0.0343 (0.0353)\tloss 0.4524 (0.5695)\tgrad_norm 1.7631 (nan)\tloss_scale 32768.0000 (32827.4701)\tmem 455MB\n",
      "Train: [58/100][560/625]\teta 0:00:02 lr 0.000388\t wd 0.0100\ttime 0.0326 (0.0353)\tloss 0.6484 (0.5700)\tgrad_norm 2.1035 (nan)\tloss_scale 32768.0000 (32826.4100)\tmem 455MB\n",
      "Train: [58/100][570/625]\teta 0:00:01 lr 0.000387\t wd 0.0100\ttime 0.0381 (0.0353)\tloss 0.5146 (0.5694)\tgrad_norm 1.5954 (nan)\tloss_scale 32768.0000 (32825.3870)\tmem 455MB\n",
      "Train: [58/100][580/625]\teta 0:00:01 lr 0.000387\t wd 0.0100\ttime 0.0326 (0.0353)\tloss 0.6226 (0.5696)\tgrad_norm 2.0216 (nan)\tloss_scale 32768.0000 (32824.3993)\tmem 455MB\n",
      "Train: [58/100][590/625]\teta 0:00:01 lr 0.000387\t wd 0.0100\ttime 0.0374 (0.0354)\tloss 0.6128 (0.5693)\tgrad_norm 2.0853 (nan)\tloss_scale 32768.0000 (32823.4450)\tmem 455MB\n",
      "Train: [58/100][600/625]\teta 0:00:00 lr 0.000387\t wd 0.0100\ttime 0.0359 (0.0354)\tloss 0.6045 (0.5693)\tgrad_norm 2.1913 (nan)\tloss_scale 32768.0000 (32822.5225)\tmem 455MB\n",
      "Train: [58/100][610/625]\teta 0:00:00 lr 0.000386\t wd 0.0100\ttime 0.0357 (0.0354)\tloss 0.6079 (0.5693)\tgrad_norm 2.3629 (nan)\tloss_scale 32768.0000 (32821.6301)\tmem 455MB\n",
      "Train: [58/100][620/625]\teta 0:00:00 lr 0.000386\t wd 0.0100\ttime 0.0368 (0.0354)\tloss 0.5317 (0.5699)\tgrad_norm 2.9195 (nan)\tloss_scale 32768.0000 (32820.7665)\tmem 455MB\n",
      "EPOCH 58 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_58.pth saving......\n",
      "./model_save/ckpt_epoch_58.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.7666 (0.7666)\tAcc@1 76.562 (76.562)\tAcc@5 98.438 (98.438)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.016 (0.016)\tLoss 0.6733 (0.6262)\tAcc@1 75.000 (77.699)\tAcc@5 100.000 (98.864)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.016 (0.016)\tLoss 0.8545 (0.6553)\tAcc@1 76.562 (77.307)\tAcc@5 98.438 (98.958)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.016 (0.016)\tLoss 0.4971 (0.6386)\tAcc@1 85.938 (77.823)\tAcc@5 100.000 (98.992)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.016)\tLoss 0.6201 (0.6386)\tAcc@1 78.125 (77.553)\tAcc@5 96.875 (98.857)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.016 (0.016)\tLoss 0.5391 (0.6342)\tAcc@1 73.438 (77.574)\tAcc@5 100.000 (98.897)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.016 (0.016)\tLoss 0.8228 (0.6372)\tAcc@1 79.688 (77.766)\tAcc@5 96.875 (98.950)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.016)\tLoss 0.7427 (0.6401)\tAcc@1 70.312 (77.157)\tAcc@5 100.000 (99.032)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.016 (0.016)\tLoss 0.6675 (0.6357)\tAcc@1 75.000 (77.353)\tAcc@5 100.000 (99.016)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.016)\tLoss 0.7915 (0.6311)\tAcc@1 78.125 (77.576)\tAcc@5 95.312 (99.056)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.016)\tLoss 0.4971 (0.6290)\tAcc@1 87.500 (77.707)\tAcc@5 98.438 (99.041)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.7061 (0.6336)\tAcc@1 76.562 (77.717)\tAcc@5 96.875 (98.986)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.4880 (0.6308)\tAcc@1 78.125 (77.841)\tAcc@5 100.000 (98.915)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.7031 (0.6268)\tAcc@1 71.875 (77.958)\tAcc@5 100.000 (98.915)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.5771 (0.6249)\tAcc@1 79.688 (78.003)\tAcc@5 98.438 (98.925)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.5776 (0.6264)\tAcc@1 81.250 (78.063)\tAcc@5 98.438 (98.934)\tMem 455MB\n",
      " * Acc@1 78.110 Acc@5 98.930\n",
      "Accuracy of the network on the 10000 test images: 78.1%\n",
      "Max accuracy: 78.11%\n",
      "Train: [59/100][0/625]\teta 0:00:23 lr 0.000386\t wd 0.0100\ttime 0.0372 (0.0372)\tloss 0.5361 (0.5361)\tgrad_norm 1.7302 (1.7302)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][10/625]\teta 0:00:22 lr 0.000386\t wd 0.0100\ttime 0.0397 (0.0359)\tloss 0.5151 (0.6042)\tgrad_norm 1.5983 (1.9243)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][20/625]\teta 0:00:21 lr 0.000385\t wd 0.0100\ttime 0.0394 (0.0363)\tloss 0.5664 (0.5650)\tgrad_norm 1.9116 (1.9891)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][30/625]\teta 0:00:21 lr 0.000385\t wd 0.0100\ttime 0.0360 (0.0361)\tloss 0.5381 (0.5668)\tgrad_norm 2.1190 (2.1020)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][40/625]\teta 0:00:21 lr 0.000385\t wd 0.0100\ttime 0.0397 (0.0361)\tloss 0.5386 (0.5627)\tgrad_norm 3.0762 (2.1670)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][50/625]\teta 0:00:20 lr 0.000385\t wd 0.0100\ttime 0.0344 (0.0363)\tloss 0.2615 (0.5594)\tgrad_norm 1.1241 (2.1593)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][60/625]\teta 0:00:20 lr 0.000384\t wd 0.0100\ttime 0.0362 (0.0364)\tloss 0.5464 (0.5647)\tgrad_norm 1.5678 (2.1113)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][70/625]\teta 0:00:20 lr 0.000384\t wd 0.0100\ttime 0.0328 (0.0364)\tloss 0.6201 (0.5646)\tgrad_norm 2.0778 (2.1010)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][80/625]\teta 0:00:19 lr 0.000384\t wd 0.0100\ttime 0.0359 (0.0364)\tloss 0.5176 (0.5636)\tgrad_norm 1.7774 (2.1060)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][90/625]\teta 0:00:19 lr 0.000384\t wd 0.0100\ttime 0.0352 (0.0363)\tloss 0.5049 (0.5609)\tgrad_norm 1.7757 (2.0700)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][100/625]\teta 0:00:19 lr 0.000383\t wd 0.0100\ttime 0.0327 (0.0363)\tloss 0.7144 (0.5614)\tgrad_norm 1.8283 (2.0649)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][110/625]\teta 0:00:18 lr 0.000383\t wd 0.0100\ttime 0.0361 (0.0362)\tloss 0.4099 (0.5653)\tgrad_norm 1.3326 (2.0719)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][120/625]\teta 0:00:18 lr 0.000383\t wd 0.0100\ttime 0.0392 (0.0362)\tloss 0.3938 (0.5641)\tgrad_norm 1.7649 (2.0598)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][130/625]\teta 0:00:17 lr 0.000383\t wd 0.0100\ttime 0.0386 (0.0361)\tloss 0.5078 (0.5683)\tgrad_norm 1.7583 (2.0705)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][140/625]\teta 0:00:17 lr 0.000382\t wd 0.0100\ttime 0.0355 (0.0361)\tloss 0.5620 (0.5677)\tgrad_norm 1.9213 (2.0670)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][150/625]\teta 0:00:17 lr 0.000382\t wd 0.0100\ttime 0.0361 (0.0362)\tloss 0.5806 (0.5692)\tgrad_norm 2.3877 (2.0760)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][160/625]\teta 0:00:16 lr 0.000382\t wd 0.0100\ttime 0.0324 (0.0361)\tloss 0.4304 (0.5666)\tgrad_norm 1.4826 (2.0622)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][170/625]\teta 0:00:16 lr 0.000382\t wd 0.0100\ttime 0.0328 (0.0361)\tloss 0.4856 (0.5622)\tgrad_norm 1.7691 (2.0484)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][180/625]\teta 0:00:16 lr 0.000381\t wd 0.0100\ttime 0.0350 (0.0360)\tloss 0.3945 (0.5564)\tgrad_norm 1.6476 (2.0358)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][190/625]\teta 0:00:15 lr 0.000381\t wd 0.0100\ttime 0.0401 (0.0360)\tloss 0.4768 (0.5557)\tgrad_norm 1.5273 (2.0483)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][200/625]\teta 0:00:15 lr 0.000381\t wd 0.0100\ttime 0.0324 (0.0360)\tloss 0.4402 (0.5562)\tgrad_norm 2.0771 (2.0573)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][210/625]\teta 0:00:14 lr 0.000381\t wd 0.0100\ttime 0.0361 (0.0360)\tloss 0.4658 (0.5563)\tgrad_norm 1.9985 (2.0698)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][220/625]\teta 0:00:14 lr 0.000380\t wd 0.0100\ttime 0.0361 (0.0360)\tloss 0.5840 (0.5586)\tgrad_norm 2.0792 (2.0746)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][230/625]\teta 0:00:14 lr 0.000380\t wd 0.0100\ttime 0.0341 (0.0359)\tloss 0.4617 (0.5588)\tgrad_norm 1.8538 (2.0748)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][240/625]\teta 0:00:13 lr 0.000380\t wd 0.0100\ttime 0.0368 (0.0360)\tloss 0.4836 (0.5570)\tgrad_norm 1.9437 (2.0608)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][250/625]\teta 0:00:13 lr 0.000380\t wd 0.0100\ttime 0.0398 (0.0359)\tloss 0.7114 (0.5576)\tgrad_norm 2.3954 (2.0614)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][260/625]\teta 0:00:13 lr 0.000379\t wd 0.0100\ttime 0.0356 (0.0359)\tloss 0.8887 (0.5607)\tgrad_norm 2.6598 (2.0614)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][270/625]\teta 0:00:12 lr 0.000379\t wd 0.0100\ttime 0.0392 (0.0359)\tloss 0.6519 (0.5602)\tgrad_norm 1.9686 (2.0622)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][280/625]\teta 0:00:12 lr 0.000379\t wd 0.0100\ttime 0.0377 (0.0359)\tloss 0.7168 (0.5593)\tgrad_norm 3.0163 (2.0619)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][290/625]\teta 0:00:12 lr 0.000379\t wd 0.0100\ttime 0.0396 (0.0359)\tloss 0.7139 (0.5592)\tgrad_norm 3.0530 (2.0609)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][300/625]\teta 0:00:11 lr 0.000378\t wd 0.0100\ttime 0.0324 (0.0359)\tloss 0.4419 (0.5567)\tgrad_norm 2.4344 (2.0527)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][310/625]\teta 0:00:11 lr 0.000378\t wd 0.0100\ttime 0.0326 (0.0358)\tloss 0.5850 (0.5573)\tgrad_norm 3.2752 (2.0601)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][320/625]\teta 0:00:10 lr 0.000378\t wd 0.0100\ttime 0.0359 (0.0358)\tloss 0.6099 (0.5561)\tgrad_norm 2.2851 (2.0590)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][330/625]\teta 0:00:10 lr 0.000378\t wd 0.0100\ttime 0.0349 (0.0358)\tloss 0.6147 (0.5565)\tgrad_norm 1.6607 (2.0579)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][340/625]\teta 0:00:10 lr 0.000377\t wd 0.0100\ttime 0.0332 (0.0357)\tloss 0.6025 (0.5568)\tgrad_norm 1.7517 (2.0593)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][350/625]\teta 0:00:09 lr 0.000377\t wd 0.0100\ttime 0.0375 (0.0358)\tloss 0.5303 (0.5572)\tgrad_norm 1.7284 (2.0608)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][360/625]\teta 0:00:09 lr 0.000377\t wd 0.0100\ttime 0.0349 (0.0358)\tloss 0.5640 (0.5581)\tgrad_norm 2.3308 (2.0694)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][370/625]\teta 0:00:09 lr 0.000377\t wd 0.0100\ttime 0.0332 (0.0358)\tloss 0.4785 (0.5569)\tgrad_norm 1.9453 (2.0701)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][380/625]\teta 0:00:08 lr 0.000377\t wd 0.0100\ttime 0.0391 (0.0358)\tloss 0.8442 (0.5565)\tgrad_norm 2.7575 (2.0706)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][390/625]\teta 0:00:08 lr 0.000376\t wd 0.0100\ttime 0.0330 (0.0358)\tloss 0.3779 (0.5572)\tgrad_norm 1.3758 (2.0751)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][400/625]\teta 0:00:08 lr 0.000376\t wd 0.0100\ttime 0.0328 (0.0358)\tloss 0.6729 (0.5577)\tgrad_norm 2.2922 (2.0741)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][410/625]\teta 0:00:07 lr 0.000376\t wd 0.0100\ttime 0.0392 (0.0359)\tloss 0.3306 (0.5580)\tgrad_norm 1.9980 (2.0733)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][420/625]\teta 0:00:07 lr 0.000376\t wd 0.0100\ttime 0.0332 (0.0359)\tloss 0.5898 (0.5584)\tgrad_norm 1.7346 (2.0742)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][430/625]\teta 0:00:06 lr 0.000375\t wd 0.0100\ttime 0.0323 (0.0358)\tloss 0.5122 (0.5576)\tgrad_norm 2.3701 (2.0730)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][440/625]\teta 0:00:06 lr 0.000375\t wd 0.0100\ttime 0.0380 (0.0358)\tloss 0.4771 (0.5583)\tgrad_norm 2.7054 (2.0767)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][450/625]\teta 0:00:06 lr 0.000375\t wd 0.0100\ttime 0.0354 (0.0359)\tloss 0.8457 (0.5587)\tgrad_norm 2.3559 (2.0790)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][460/625]\teta 0:00:05 lr 0.000375\t wd 0.0100\ttime 0.0342 (0.0359)\tloss 0.5684 (0.5591)\tgrad_norm 1.7906 (2.0784)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][470/625]\teta 0:00:05 lr 0.000374\t wd 0.0100\ttime 0.0325 (0.0359)\tloss 0.3499 (0.5592)\tgrad_norm 1.8907 (2.0769)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][480/625]\teta 0:00:05 lr 0.000374\t wd 0.0100\ttime 0.0324 (0.0358)\tloss 0.7432 (0.5595)\tgrad_norm 3.9173 (2.0787)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][490/625]\teta 0:00:04 lr 0.000374\t wd 0.0100\ttime 0.0324 (0.0358)\tloss 0.4556 (0.5593)\tgrad_norm 1.5742 (2.0819)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][500/625]\teta 0:00:04 lr 0.000374\t wd 0.0100\ttime 0.0328 (0.0358)\tloss 0.5718 (0.5591)\tgrad_norm 2.2752 (2.0836)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][510/625]\teta 0:00:04 lr 0.000373\t wd 0.0100\ttime 0.0327 (0.0357)\tloss 0.7349 (0.5595)\tgrad_norm 2.1519 (2.0824)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][520/625]\teta 0:00:03 lr 0.000373\t wd 0.0100\ttime 0.0362 (0.0357)\tloss 0.4602 (0.5590)\tgrad_norm 1.6168 (2.0764)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][530/625]\teta 0:00:03 lr 0.000373\t wd 0.0100\ttime 0.0374 (0.0357)\tloss 0.5503 (0.5583)\tgrad_norm 2.1608 (2.0723)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][540/625]\teta 0:00:03 lr 0.000373\t wd 0.0100\ttime 0.0367 (0.0357)\tloss 0.4714 (0.5566)\tgrad_norm 1.6769 (2.0673)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][550/625]\teta 0:00:02 lr 0.000372\t wd 0.0100\ttime 0.0323 (0.0356)\tloss 0.8198 (0.5572)\tgrad_norm 1.9280 (2.0670)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][560/625]\teta 0:00:02 lr 0.000372\t wd 0.0100\ttime 0.0322 (0.0356)\tloss 0.5444 (0.5574)\tgrad_norm 2.2153 (2.0692)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][570/625]\teta 0:00:01 lr 0.000372\t wd 0.0100\ttime 0.0328 (0.0355)\tloss 0.5161 (0.5567)\tgrad_norm 1.6595 (2.0701)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][580/625]\teta 0:00:01 lr 0.000372\t wd 0.0100\ttime 0.0325 (0.0355)\tloss 0.4939 (0.5568)\tgrad_norm 1.3942 (2.0684)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][590/625]\teta 0:00:01 lr 0.000371\t wd 0.0100\ttime 0.0322 (0.0355)\tloss 0.5020 (0.5564)\tgrad_norm 1.4862 (2.0677)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][600/625]\teta 0:00:00 lr 0.000371\t wd 0.0100\ttime 0.0357 (0.0355)\tloss 0.4895 (0.5569)\tgrad_norm 2.2002 (2.0696)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][610/625]\teta 0:00:00 lr 0.000371\t wd 0.0100\ttime 0.0327 (0.0355)\tloss 0.6748 (0.5577)\tgrad_norm 2.0716 (2.0714)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [59/100][620/625]\teta 0:00:00 lr 0.000371\t wd 0.0100\ttime 0.0329 (0.0355)\tloss 0.6167 (0.5577)\tgrad_norm 2.8619 (2.0721)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 59 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_59.pth saving......\n",
      "./model_save/ckpt_epoch_59.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.5830 (0.5830)\tAcc@1 76.562 (76.562)\tAcc@5 100.000 (100.000)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.5342 (0.5966)\tAcc@1 78.125 (78.977)\tAcc@5 100.000 (99.574)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.5454 (0.6178)\tAcc@1 75.000 (77.604)\tAcc@5 100.000 (99.107)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.017 (0.015)\tLoss 0.6167 (0.6327)\tAcc@1 78.125 (77.167)\tAcc@5 98.438 (98.841)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.5518 (0.6363)\tAcc@1 82.812 (77.477)\tAcc@5 100.000 (98.857)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.4653 (0.6306)\tAcc@1 84.375 (77.604)\tAcc@5 100.000 (98.775)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.4722 (0.6339)\tAcc@1 82.812 (77.766)\tAcc@5 100.000 (98.796)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.4458 (0.6269)\tAcc@1 87.500 (78.367)\tAcc@5 98.438 (98.790)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.6836 (0.6233)\tAcc@1 76.562 (78.299)\tAcc@5 98.438 (98.881)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.5938 (0.6253)\tAcc@1 79.688 (78.280)\tAcc@5 98.438 (98.901)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.5728 (0.6246)\tAcc@1 81.250 (78.373)\tAcc@5 100.000 (98.871)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.6860 (0.6167)\tAcc@1 75.000 (78.632)\tAcc@5 100.000 (98.944)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.7754 (0.6187)\tAcc@1 71.875 (78.629)\tAcc@5 95.312 (98.889)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.7476 (0.6168)\tAcc@1 71.875 (78.674)\tAcc@5 96.875 (98.855)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.7134 (0.6196)\tAcc@1 76.562 (78.579)\tAcc@5 98.438 (98.870)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.7651 (0.6191)\tAcc@1 71.875 (78.663)\tAcc@5 98.438 (98.893)\tMem 455MB\n",
      " * Acc@1 78.660 Acc@5 98.900\n",
      "Accuracy of the network on the 10000 test images: 78.7%\n",
      "Max accuracy: 78.66%\n",
      "Train: [60/100][0/625]\teta 0:00:24 lr 0.000370\t wd 0.0100\ttime 0.0398 (0.0398)\tloss 0.4414 (0.4414)\tgrad_norm 1.7389 (1.7389)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][10/625]\teta 0:00:22 lr 0.000370\t wd 0.0100\ttime 0.0355 (0.0360)\tloss 0.8843 (0.5886)\tgrad_norm 2.5464 (2.0991)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][20/625]\teta 0:00:21 lr 0.000370\t wd 0.0100\ttime 0.0355 (0.0364)\tloss 0.5591 (0.5540)\tgrad_norm 1.8768 (2.0426)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][30/625]\teta 0:00:21 lr 0.000370\t wd 0.0100\ttime 0.0398 (0.0361)\tloss 0.6621 (0.5366)\tgrad_norm 2.0262 (1.9713)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][40/625]\teta 0:00:20 lr 0.000369\t wd 0.0100\ttime 0.0327 (0.0357)\tloss 0.6558 (0.5475)\tgrad_norm 2.1929 (2.0256)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][50/625]\teta 0:00:20 lr 0.000369\t wd 0.0100\ttime 0.0355 (0.0357)\tloss 0.3696 (0.5393)\tgrad_norm 1.5379 (2.0085)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][60/625]\teta 0:00:20 lr 0.000369\t wd 0.0100\ttime 0.0325 (0.0356)\tloss 0.4702 (0.5402)\tgrad_norm 1.5329 (2.0500)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][70/625]\teta 0:00:19 lr 0.000369\t wd 0.0100\ttime 0.0393 (0.0357)\tloss 0.6885 (0.5444)\tgrad_norm 2.1115 (2.0654)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][80/625]\teta 0:00:19 lr 0.000368\t wd 0.0100\ttime 0.0360 (0.0357)\tloss 0.4758 (0.5398)\tgrad_norm 2.0305 (2.0583)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][90/625]\teta 0:00:18 lr 0.000368\t wd 0.0100\ttime 0.0329 (0.0355)\tloss 0.3584 (0.5374)\tgrad_norm 2.2013 (2.0484)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][100/625]\teta 0:00:18 lr 0.000368\t wd 0.0100\ttime 0.0322 (0.0353)\tloss 0.5991 (0.5457)\tgrad_norm 2.2211 (2.0840)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][110/625]\teta 0:00:18 lr 0.000368\t wd 0.0100\ttime 0.0359 (0.0352)\tloss 0.4121 (0.5442)\tgrad_norm 2.2289 (2.0981)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][120/625]\teta 0:00:17 lr 0.000367\t wd 0.0100\ttime 0.0326 (0.0353)\tloss 0.5483 (0.5414)\tgrad_norm 1.8581 (2.1002)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][130/625]\teta 0:00:17 lr 0.000367\t wd 0.0100\ttime 0.0331 (0.0353)\tloss 0.3865 (0.5412)\tgrad_norm 2.5198 (2.0868)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][140/625]\teta 0:00:17 lr 0.000367\t wd 0.0100\ttime 0.0326 (0.0354)\tloss 0.6030 (0.5413)\tgrad_norm 2.5063 (2.0803)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][150/625]\teta 0:00:16 lr 0.000367\t wd 0.0100\ttime 0.0330 (0.0353)\tloss 0.4993 (0.5401)\tgrad_norm 1.9427 (2.0744)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][160/625]\teta 0:00:16 lr 0.000366\t wd 0.0100\ttime 0.0328 (0.0353)\tloss 0.5254 (0.5347)\tgrad_norm 2.3096 (2.0558)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][170/625]\teta 0:00:16 lr 0.000366\t wd 0.0100\ttime 0.0364 (0.0353)\tloss 0.4473 (0.5351)\tgrad_norm 2.2920 (2.0538)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][180/625]\teta 0:00:15 lr 0.000366\t wd 0.0100\ttime 0.0385 (0.0353)\tloss 0.3530 (0.5355)\tgrad_norm 1.5709 (2.0606)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][190/625]\teta 0:00:15 lr 0.000366\t wd 0.0100\ttime 0.0325 (0.0353)\tloss 0.6670 (0.5375)\tgrad_norm 2.0938 (2.0808)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][200/625]\teta 0:00:14 lr 0.000366\t wd 0.0100\ttime 0.0323 (0.0352)\tloss 0.7349 (0.5404)\tgrad_norm 1.8903 (2.0921)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][210/625]\teta 0:00:14 lr 0.000365\t wd 0.0100\ttime 0.0336 (0.0352)\tloss 0.5825 (0.5404)\tgrad_norm 2.6070 (2.0986)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][220/625]\teta 0:00:14 lr 0.000365\t wd 0.0100\ttime 0.0361 (0.0353)\tloss 0.5400 (0.5391)\tgrad_norm 1.8138 (2.0909)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][230/625]\teta 0:00:13 lr 0.000365\t wd 0.0100\ttime 0.0372 (0.0353)\tloss 0.3535 (0.5398)\tgrad_norm 1.4318 (2.0823)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][240/625]\teta 0:00:13 lr 0.000365\t wd 0.0100\ttime 0.0400 (0.0354)\tloss 0.7993 (0.5445)\tgrad_norm 2.4222 (2.0860)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][250/625]\teta 0:00:13 lr 0.000364\t wd 0.0100\ttime 0.0330 (0.0354)\tloss 0.6294 (0.5467)\tgrad_norm 2.4731 (2.0879)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][260/625]\teta 0:00:12 lr 0.000364\t wd 0.0100\ttime 0.0386 (0.0355)\tloss 0.6792 (0.5478)\tgrad_norm 2.3117 (2.0866)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][270/625]\teta 0:00:12 lr 0.000364\t wd 0.0100\ttime 0.0326 (0.0355)\tloss 0.5845 (0.5454)\tgrad_norm 2.2674 (2.0815)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][280/625]\teta 0:00:12 lr 0.000364\t wd 0.0100\ttime 0.0324 (0.0355)\tloss 0.4045 (0.5432)\tgrad_norm 1.6725 (2.0727)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][290/625]\teta 0:00:11 lr 0.000363\t wd 0.0100\ttime 0.0401 (0.0356)\tloss 0.5615 (0.5437)\tgrad_norm 2.2181 (2.0782)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][300/625]\teta 0:00:11 lr 0.000363\t wd 0.0100\ttime 0.0385 (0.0356)\tloss 0.5010 (0.5455)\tgrad_norm 1.6601 (2.0793)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][310/625]\teta 0:00:11 lr 0.000363\t wd 0.0100\ttime 0.0393 (0.0356)\tloss 0.8213 (0.5479)\tgrad_norm 2.0368 (2.0775)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][320/625]\teta 0:00:10 lr 0.000363\t wd 0.0100\ttime 0.0370 (0.0357)\tloss 0.6191 (0.5476)\tgrad_norm 1.8739 (2.0679)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][330/625]\teta 0:00:10 lr 0.000362\t wd 0.0100\ttime 0.0325 (0.0357)\tloss 0.4373 (0.5482)\tgrad_norm 1.4286 (2.0691)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][340/625]\teta 0:00:10 lr 0.000362\t wd 0.0100\ttime 0.0359 (0.0357)\tloss 0.5410 (0.5484)\tgrad_norm 2.1779 (2.0695)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][350/625]\teta 0:00:09 lr 0.000362\t wd 0.0100\ttime 0.0323 (0.0357)\tloss 0.3572 (0.5478)\tgrad_norm 1.7486 (2.0651)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][360/625]\teta 0:00:09 lr 0.000362\t wd 0.0100\ttime 0.0364 (0.0357)\tloss 0.5273 (0.5465)\tgrad_norm 2.0764 (2.0605)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][370/625]\teta 0:00:09 lr 0.000361\t wd 0.0100\ttime 0.0350 (0.0356)\tloss 0.6562 (0.5459)\tgrad_norm 2.6078 (2.0544)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][380/625]\teta 0:00:08 lr 0.000361\t wd 0.0100\ttime 0.0327 (0.0356)\tloss 0.6748 (0.5454)\tgrad_norm 2.2583 (2.0489)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][390/625]\teta 0:00:08 lr 0.000361\t wd 0.0100\ttime 0.0387 (0.0356)\tloss 0.5176 (0.5471)\tgrad_norm 1.3642 (2.0512)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][400/625]\teta 0:00:08 lr 0.000361\t wd 0.0100\ttime 0.0395 (0.0356)\tloss 0.4888 (0.5479)\tgrad_norm 2.5021 (2.0538)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][410/625]\teta 0:00:07 lr 0.000360\t wd 0.0100\ttime 0.0359 (0.0356)\tloss 0.4309 (0.5480)\tgrad_norm 1.6244 (2.0505)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][420/625]\teta 0:00:07 lr 0.000360\t wd 0.0100\ttime 0.0355 (0.0356)\tloss 0.5522 (0.5467)\tgrad_norm 1.9327 (2.0489)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][430/625]\teta 0:00:06 lr 0.000360\t wd 0.0100\ttime 0.0331 (0.0356)\tloss 0.5234 (0.5464)\tgrad_norm 2.3436 (2.0485)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][440/625]\teta 0:00:06 lr 0.000360\t wd 0.0100\ttime 0.0325 (0.0356)\tloss 0.5742 (0.5473)\tgrad_norm 1.5022 (2.0441)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][450/625]\teta 0:00:06 lr 0.000359\t wd 0.0100\ttime 0.0395 (0.0356)\tloss 0.3892 (0.5469)\tgrad_norm 1.4891 (2.0452)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][460/625]\teta 0:00:05 lr 0.000359\t wd 0.0100\ttime 0.0326 (0.0356)\tloss 0.6714 (0.5476)\tgrad_norm 2.0908 (2.0475)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][470/625]\teta 0:00:05 lr 0.000359\t wd 0.0100\ttime 0.0329 (0.0356)\tloss 0.5078 (0.5482)\tgrad_norm 1.7415 (2.0498)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][480/625]\teta 0:00:05 lr 0.000359\t wd 0.0100\ttime 0.0355 (0.0357)\tloss 0.5181 (0.5480)\tgrad_norm 1.4733 (2.0485)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][490/625]\teta 0:00:04 lr 0.000358\t wd 0.0100\ttime 0.0390 (0.0357)\tloss 0.6475 (0.5496)\tgrad_norm 1.8141 (2.0479)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][500/625]\teta 0:00:04 lr 0.000358\t wd 0.0100\ttime 0.0331 (0.0357)\tloss 0.5068 (0.5501)\tgrad_norm 2.2273 (2.0510)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][510/625]\teta 0:00:04 lr 0.000358\t wd 0.0100\ttime 0.0385 (0.0357)\tloss 0.4829 (0.5494)\tgrad_norm 1.5698 (2.0510)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][520/625]\teta 0:00:03 lr 0.000358\t wd 0.0100\ttime 0.0390 (0.0357)\tloss 0.5669 (0.5490)\tgrad_norm 2.2051 (2.0508)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][530/625]\teta 0:00:03 lr 0.000357\t wd 0.0100\ttime 0.0402 (0.0357)\tloss 0.3354 (0.5486)\tgrad_norm 1.2864 (2.0511)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][540/625]\teta 0:00:03 lr 0.000357\t wd 0.0100\ttime 0.0392 (0.0357)\tloss 0.6406 (0.5473)\tgrad_norm 2.5698 (2.0524)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][550/625]\teta 0:00:02 lr 0.000357\t wd 0.0100\ttime 0.0361 (0.0357)\tloss 0.5493 (0.5479)\tgrad_norm 1.5964 (2.0533)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][560/625]\teta 0:00:02 lr 0.000357\t wd 0.0100\ttime 0.0357 (0.0358)\tloss 0.4905 (0.5480)\tgrad_norm 2.5480 (2.0539)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][570/625]\teta 0:00:01 lr 0.000356\t wd 0.0100\ttime 0.0324 (0.0357)\tloss 0.6636 (0.5487)\tgrad_norm 2.1703 (2.0540)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][580/625]\teta 0:00:01 lr 0.000356\t wd 0.0100\ttime 0.0364 (0.0357)\tloss 0.6738 (0.5479)\tgrad_norm 2.0152 (2.0537)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][590/625]\teta 0:00:01 lr 0.000356\t wd 0.0100\ttime 0.0326 (0.0357)\tloss 0.6792 (0.5490)\tgrad_norm 2.0333 (2.0514)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][600/625]\teta 0:00:00 lr 0.000356\t wd 0.0100\ttime 0.0330 (0.0357)\tloss 0.4331 (0.5484)\tgrad_norm 1.8587 (2.0526)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][610/625]\teta 0:00:00 lr 0.000355\t wd 0.0100\ttime 0.0358 (0.0357)\tloss 0.5386 (0.5480)\tgrad_norm 2.0167 (2.0521)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [60/100][620/625]\teta 0:00:00 lr 0.000355\t wd 0.0100\ttime 0.0325 (0.0356)\tloss 0.4863 (0.5476)\tgrad_norm 1.8358 (2.0530)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 60 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_60.pth saving......\n",
      "./model_save/ckpt_epoch_60.pth saved !!!\n",
      "Test: [0/157]\tTime 0.021 (0.021)\tLoss 0.5269 (0.5269)\tAcc@1 76.562 (76.562)\tAcc@5 100.000 (100.000)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.016)\tLoss 0.5630 (0.5973)\tAcc@1 76.562 (77.415)\tAcc@5 96.875 (99.148)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.016)\tLoss 0.5444 (0.6145)\tAcc@1 84.375 (77.679)\tAcc@5 98.438 (98.810)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.3972 (0.5903)\tAcc@1 89.062 (78.730)\tAcc@5 100.000 (99.042)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.6987 (0.6206)\tAcc@1 75.000 (77.744)\tAcc@5 98.438 (98.780)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.6118 (0.6225)\tAcc@1 79.688 (78.064)\tAcc@5 100.000 (98.897)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.6826 (0.6263)\tAcc@1 76.562 (78.202)\tAcc@5 96.875 (98.899)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.5083 (0.6160)\tAcc@1 79.688 (78.367)\tAcc@5 100.000 (98.922)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.5747 (0.6098)\tAcc@1 78.125 (78.665)\tAcc@5 98.438 (98.900)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.5239 (0.6186)\tAcc@1 81.250 (78.571)\tAcc@5 100.000 (98.850)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.7886 (0.6204)\tAcc@1 70.312 (78.465)\tAcc@5 100.000 (98.855)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.6562 (0.6241)\tAcc@1 78.125 (78.421)\tAcc@5 100.000 (98.930)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.5078 (0.6218)\tAcc@1 84.375 (78.590)\tAcc@5 100.000 (98.967)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.4856 (0.6181)\tAcc@1 81.250 (78.650)\tAcc@5 100.000 (98.974)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.5479 (0.6156)\tAcc@1 75.000 (78.635)\tAcc@5 100.000 (99.014)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.4089 (0.6168)\tAcc@1 82.812 (78.601)\tAcc@5 100.000 (99.048)\tMem 455MB\n",
      " * Acc@1 78.710 Acc@5 99.060\n",
      "Accuracy of the network on the 10000 test images: 78.7%\n",
      "Max accuracy: 78.71%\n",
      "Train: [61/100][0/625]\teta 0:00:25 lr 0.000355\t wd 0.0100\ttime 0.0413 (0.0413)\tloss 0.4697 (0.4697)\tgrad_norm 1.9733 (1.9733)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][10/625]\teta 0:00:21 lr 0.000355\t wd 0.0100\ttime 0.0354 (0.0351)\tloss 0.6123 (0.5508)\tgrad_norm 3.0052 (2.0936)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][20/625]\teta 0:00:21 lr 0.000355\t wd 0.0100\ttime 0.0340 (0.0353)\tloss 0.2769 (0.5540)\tgrad_norm 1.5969 (2.0406)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][30/625]\teta 0:00:21 lr 0.000354\t wd 0.0100\ttime 0.0383 (0.0354)\tloss 0.5259 (0.5458)\tgrad_norm 2.0454 (2.0555)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][40/625]\teta 0:00:20 lr 0.000354\t wd 0.0100\ttime 0.0390 (0.0354)\tloss 0.4744 (0.5539)\tgrad_norm 2.4364 (2.0700)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][50/625]\teta 0:00:20 lr 0.000354\t wd 0.0100\ttime 0.0358 (0.0353)\tloss 0.6143 (0.5460)\tgrad_norm 2.2183 (2.0308)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][60/625]\teta 0:00:20 lr 0.000354\t wd 0.0100\ttime 0.0392 (0.0355)\tloss 0.6084 (0.5434)\tgrad_norm 1.8771 (2.0305)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][70/625]\teta 0:00:19 lr 0.000353\t wd 0.0100\ttime 0.0358 (0.0356)\tloss 0.5161 (0.5420)\tgrad_norm 1.9757 (2.0249)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][80/625]\teta 0:00:19 lr 0.000353\t wd 0.0100\ttime 0.0324 (0.0355)\tloss 0.7280 (0.5375)\tgrad_norm 2.5066 (2.0148)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][90/625]\teta 0:00:18 lr 0.000353\t wd 0.0100\ttime 0.0326 (0.0353)\tloss 0.7300 (0.5402)\tgrad_norm 2.3014 (2.0160)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][100/625]\teta 0:00:18 lr 0.000353\t wd 0.0100\ttime 0.0360 (0.0353)\tloss 0.6338 (0.5438)\tgrad_norm 2.3435 (2.0219)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][110/625]\teta 0:00:18 lr 0.000352\t wd 0.0100\ttime 0.0354 (0.0353)\tloss 0.4004 (0.5454)\tgrad_norm 1.7424 (2.0294)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][120/625]\teta 0:00:17 lr 0.000352\t wd 0.0100\ttime 0.0326 (0.0354)\tloss 0.5977 (0.5431)\tgrad_norm 1.7859 (2.0299)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][130/625]\teta 0:00:17 lr 0.000352\t wd 0.0100\ttime 0.0326 (0.0354)\tloss 0.4587 (0.5408)\tgrad_norm 1.7524 (2.0401)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][140/625]\teta 0:00:17 lr 0.000352\t wd 0.0100\ttime 0.0357 (0.0354)\tloss 0.4688 (0.5410)\tgrad_norm 2.2142 (2.0494)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][150/625]\teta 0:00:16 lr 0.000351\t wd 0.0100\ttime 0.0377 (0.0354)\tloss 0.7080 (0.5453)\tgrad_norm 2.3555 (2.0571)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][160/625]\teta 0:00:16 lr 0.000351\t wd 0.0100\ttime 0.0378 (0.0355)\tloss 0.5386 (0.5446)\tgrad_norm 2.5663 (2.0676)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][170/625]\teta 0:00:16 lr 0.000351\t wd 0.0100\ttime 0.0327 (0.0355)\tloss 0.8257 (0.5479)\tgrad_norm 2.8513 (2.0708)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][180/625]\teta 0:00:15 lr 0.000351\t wd 0.0100\ttime 0.0326 (0.0355)\tloss 0.4922 (0.5463)\tgrad_norm 1.8233 (2.0701)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][190/625]\teta 0:00:15 lr 0.000350\t wd 0.0100\ttime 0.0327 (0.0355)\tloss 0.4033 (0.5436)\tgrad_norm 1.6921 (2.0681)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][200/625]\teta 0:00:15 lr 0.000350\t wd 0.0100\ttime 0.0379 (0.0355)\tloss 0.5425 (0.5422)\tgrad_norm 2.6376 (2.0618)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][210/625]\teta 0:00:14 lr 0.000350\t wd 0.0100\ttime 0.0391 (0.0356)\tloss 0.4553 (0.5419)\tgrad_norm 2.3396 (2.0629)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][220/625]\teta 0:00:14 lr 0.000350\t wd 0.0100\ttime 0.0330 (0.0355)\tloss 0.5190 (0.5439)\tgrad_norm 2.0002 (2.0590)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][230/625]\teta 0:00:14 lr 0.000349\t wd 0.0100\ttime 0.0353 (0.0355)\tloss 0.5171 (0.5420)\tgrad_norm 1.4912 (2.0651)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][240/625]\teta 0:00:13 lr 0.000349\t wd 0.0100\ttime 0.0389 (0.0355)\tloss 0.4956 (0.5405)\tgrad_norm 1.8186 (2.0635)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][250/625]\teta 0:00:13 lr 0.000349\t wd 0.0100\ttime 0.0351 (0.0356)\tloss 0.5933 (0.5396)\tgrad_norm 1.9246 (2.0609)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][260/625]\teta 0:00:13 lr 0.000349\t wd 0.0100\ttime 0.0392 (0.0356)\tloss 0.5649 (0.5401)\tgrad_norm 1.9778 (2.0678)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][270/625]\teta 0:00:12 lr 0.000349\t wd 0.0100\ttime 0.0351 (0.0356)\tloss 0.5864 (0.5409)\tgrad_norm 2.0014 (2.0696)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][280/625]\teta 0:00:12 lr 0.000348\t wd 0.0100\ttime 0.0322 (0.0356)\tloss 0.5459 (0.5415)\tgrad_norm 1.7742 (2.0672)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][290/625]\teta 0:00:11 lr 0.000348\t wd 0.0100\ttime 0.0420 (0.0357)\tloss 0.4004 (0.5411)\tgrad_norm 1.6688 (2.0679)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][300/625]\teta 0:00:11 lr 0.000348\t wd 0.0100\ttime 0.0326 (0.0356)\tloss 0.4487 (0.5412)\tgrad_norm 1.5136 (2.0643)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][310/625]\teta 0:00:11 lr 0.000348\t wd 0.0100\ttime 0.0381 (0.0356)\tloss 0.5200 (0.5403)\tgrad_norm 1.7562 (2.0669)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][320/625]\teta 0:00:10 lr 0.000347\t wd 0.0100\ttime 0.0368 (0.0356)\tloss 0.5283 (0.5417)\tgrad_norm 1.3799 (2.0667)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][330/625]\teta 0:00:10 lr 0.000347\t wd 0.0100\ttime 0.0325 (0.0355)\tloss 0.6919 (0.5423)\tgrad_norm 2.0071 (2.0669)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][340/625]\teta 0:00:10 lr 0.000347\t wd 0.0100\ttime 0.0325 (0.0355)\tloss 0.5142 (0.5430)\tgrad_norm 2.2557 (2.0687)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][350/625]\teta 0:00:09 lr 0.000347\t wd 0.0100\ttime 0.0322 (0.0354)\tloss 0.5298 (0.5446)\tgrad_norm 1.8812 (2.0697)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][360/625]\teta 0:00:09 lr 0.000346\t wd 0.0100\ttime 0.0329 (0.0354)\tloss 0.4756 (0.5454)\tgrad_norm 2.5128 (2.0717)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][370/625]\teta 0:00:09 lr 0.000346\t wd 0.0100\ttime 0.0329 (0.0354)\tloss 0.5181 (0.5443)\tgrad_norm 2.3262 (2.0741)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][380/625]\teta 0:00:08 lr 0.000346\t wd 0.0100\ttime 0.0328 (0.0354)\tloss 0.5879 (0.5449)\tgrad_norm 1.9790 (2.0718)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][390/625]\teta 0:00:08 lr 0.000346\t wd 0.0100\ttime 0.0324 (0.0354)\tloss 0.4917 (0.5444)\tgrad_norm 1.8403 (2.0658)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][400/625]\teta 0:00:07 lr 0.000345\t wd 0.0100\ttime 0.0331 (0.0354)\tloss 0.7100 (0.5442)\tgrad_norm 2.1830 (2.0635)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][410/625]\teta 0:00:07 lr 0.000345\t wd 0.0100\ttime 0.0324 (0.0354)\tloss 0.6558 (0.5443)\tgrad_norm 3.0781 (2.0611)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][420/625]\teta 0:00:07 lr 0.000345\t wd 0.0100\ttime 0.0400 (0.0355)\tloss 0.5322 (0.5454)\tgrad_norm 2.0995 (2.0627)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][430/625]\teta 0:00:06 lr 0.000345\t wd 0.0100\ttime 0.0328 (0.0354)\tloss 0.6006 (0.5454)\tgrad_norm 2.0153 (2.0587)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][440/625]\teta 0:00:06 lr 0.000344\t wd 0.0100\ttime 0.0356 (0.0354)\tloss 0.5381 (0.5477)\tgrad_norm 1.5223 (2.0600)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][450/625]\teta 0:00:06 lr 0.000344\t wd 0.0100\ttime 0.0361 (0.0355)\tloss 0.5269 (0.5476)\tgrad_norm 2.0551 (2.0614)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][460/625]\teta 0:00:05 lr 0.000344\t wd 0.0100\ttime 0.0406 (0.0355)\tloss 0.4277 (0.5482)\tgrad_norm 1.6744 (2.0603)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][470/625]\teta 0:00:05 lr 0.000344\t wd 0.0100\ttime 0.0328 (0.0355)\tloss 0.3848 (0.5473)\tgrad_norm 2.0341 (2.0594)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][480/625]\teta 0:00:05 lr 0.000343\t wd 0.0100\ttime 0.0389 (0.0355)\tloss 0.6089 (0.5485)\tgrad_norm 2.1674 (2.0581)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][490/625]\teta 0:00:04 lr 0.000343\t wd 0.0100\ttime 0.0391 (0.0355)\tloss 0.6128 (0.5484)\tgrad_norm 2.8086 (2.0558)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][500/625]\teta 0:00:04 lr 0.000343\t wd 0.0100\ttime 0.0326 (0.0356)\tloss 0.4973 (0.5472)\tgrad_norm 1.7396 (2.0521)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][510/625]\teta 0:00:04 lr 0.000343\t wd 0.0100\ttime 0.0357 (0.0355)\tloss 0.5933 (0.5465)\tgrad_norm 1.6623 (2.0483)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][520/625]\teta 0:00:03 lr 0.000342\t wd 0.0100\ttime 0.0352 (0.0356)\tloss 0.3286 (0.5461)\tgrad_norm 1.6673 (2.0476)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][530/625]\teta 0:00:03 lr 0.000342\t wd 0.0100\ttime 0.0328 (0.0356)\tloss 0.6304 (0.5459)\tgrad_norm 2.5678 (2.0460)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][540/625]\teta 0:00:03 lr 0.000342\t wd 0.0100\ttime 0.0325 (0.0356)\tloss 0.3647 (0.5445)\tgrad_norm 2.0866 (2.0440)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][550/625]\teta 0:00:02 lr 0.000342\t wd 0.0100\ttime 0.0368 (0.0355)\tloss 0.4778 (0.5441)\tgrad_norm 1.8005 (2.0456)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][560/625]\teta 0:00:02 lr 0.000341\t wd 0.0100\ttime 0.0325 (0.0355)\tloss 0.5146 (0.5436)\tgrad_norm 1.9706 (2.0431)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][570/625]\teta 0:00:01 lr 0.000341\t wd 0.0100\ttime 0.0329 (0.0355)\tloss 0.5229 (0.5448)\tgrad_norm 2.3015 (2.0444)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][580/625]\teta 0:00:01 lr 0.000341\t wd 0.0100\ttime 0.0327 (0.0355)\tloss 0.5464 (0.5461)\tgrad_norm 2.0475 (2.0449)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][590/625]\teta 0:00:01 lr 0.000341\t wd 0.0100\ttime 0.0399 (0.0355)\tloss 0.4761 (0.5458)\tgrad_norm 1.7282 (2.0420)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][600/625]\teta 0:00:00 lr 0.000340\t wd 0.0100\ttime 0.0344 (0.0356)\tloss 0.5488 (0.5458)\tgrad_norm 1.7991 (2.0435)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][610/625]\teta 0:00:00 lr 0.000340\t wd 0.0100\ttime 0.0390 (0.0356)\tloss 0.6802 (0.5462)\tgrad_norm 2.6219 (2.0468)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [61/100][620/625]\teta 0:00:00 lr 0.000340\t wd 0.0100\ttime 0.0353 (0.0356)\tloss 0.6768 (0.5457)\tgrad_norm 2.7386 (2.0454)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 61 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_61.pth saving......\n",
      "./model_save/ckpt_epoch_61.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.7002 (0.7002)\tAcc@1 73.438 (73.438)\tAcc@5 100.000 (100.000)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.016 (0.016)\tLoss 0.6836 (0.6656)\tAcc@1 76.562 (76.562)\tAcc@5 98.438 (98.864)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.016)\tLoss 0.6489 (0.6319)\tAcc@1 75.000 (77.158)\tAcc@5 100.000 (98.884)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.016)\tLoss 0.4255 (0.6449)\tAcc@1 87.500 (77.722)\tAcc@5 98.438 (98.690)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.016)\tLoss 0.6323 (0.6555)\tAcc@1 78.125 (77.477)\tAcc@5 96.875 (98.628)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.016)\tLoss 0.5107 (0.6565)\tAcc@1 82.812 (77.727)\tAcc@5 100.000 (98.683)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.016)\tLoss 0.4851 (0.6436)\tAcc@1 79.688 (77.971)\tAcc@5 100.000 (98.822)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.016)\tLoss 0.7080 (0.6400)\tAcc@1 75.000 (78.037)\tAcc@5 98.438 (98.834)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.7808 (0.6320)\tAcc@1 75.000 (78.144)\tAcc@5 96.875 (98.823)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.7549 (0.6285)\tAcc@1 81.250 (78.280)\tAcc@5 100.000 (98.918)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.7729 (0.6263)\tAcc@1 75.000 (78.280)\tAcc@5 95.312 (98.855)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.6841 (0.6259)\tAcc@1 78.125 (78.252)\tAcc@5 98.438 (98.860)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.3918 (0.6245)\tAcc@1 84.375 (78.383)\tAcc@5 100.000 (98.902)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.7749 (0.6277)\tAcc@1 76.562 (78.328)\tAcc@5 100.000 (98.891)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.5356 (0.6251)\tAcc@1 79.688 (78.391)\tAcc@5 100.000 (98.903)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.5156 (0.6213)\tAcc@1 81.250 (78.539)\tAcc@5 100.000 (98.934)\tMem 455MB\n",
      " * Acc@1 78.580 Acc@5 98.940\n",
      "Accuracy of the network on the 10000 test images: 78.6%\n",
      "Max accuracy: 78.71%\n",
      "Train: [62/100][0/625]\teta 0:00:24 lr 0.000340\t wd 0.0100\ttime 0.0389 (0.0389)\tloss 0.4336 (0.4336)\tgrad_norm 2.6360 (2.6360)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [62/100][10/625]\teta 0:00:21 lr 0.000340\t wd 0.0100\ttime 0.0363 (0.0352)\tloss 0.6011 (0.5619)\tgrad_norm 2.2147 (2.1918)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [62/100][20/625]\teta 0:00:21 lr 0.000339\t wd 0.0100\ttime 0.0363 (0.0354)\tloss 0.5439 (0.5121)\tgrad_norm 2.1305 (nan)\tloss_scale 32768.0000 (34328.3810)\tmem 455MB\n",
      "Train: [62/100][30/625]\teta 0:00:21 lr 0.000339\t wd 0.0100\ttime 0.0333 (0.0360)\tloss 0.3831 (0.5054)\tgrad_norm 1.4988 (nan)\tloss_scale 32768.0000 (33825.0323)\tmem 455MB\n",
      "Train: [62/100][40/625]\teta 0:00:21 lr 0.000339\t wd 0.0100\ttime 0.0323 (0.0363)\tloss 0.7173 (0.5144)\tgrad_norm 2.0198 (nan)\tloss_scale 32768.0000 (33567.2195)\tmem 455MB\n",
      "Train: [62/100][50/625]\teta 0:00:20 lr 0.000339\t wd 0.0100\ttime 0.0401 (0.0360)\tloss 0.4946 (0.5159)\tgrad_norm 1.6749 (nan)\tloss_scale 32768.0000 (33410.5098)\tmem 455MB\n",
      "Train: [62/100][60/625]\teta 0:00:20 lr 0.000338\t wd 0.0100\ttime 0.0392 (0.0363)\tloss 0.5239 (0.5143)\tgrad_norm 2.4549 (nan)\tloss_scale 32768.0000 (33305.1803)\tmem 455MB\n",
      "Train: [62/100][70/625]\teta 0:00:20 lr 0.000338\t wd 0.0100\ttime 0.0361 (0.0361)\tloss 0.4954 (0.5210)\tgrad_norm 1.8873 (nan)\tloss_scale 32768.0000 (33229.5211)\tmem 455MB\n",
      "Train: [62/100][80/625]\teta 0:00:19 lr 0.000338\t wd 0.0100\ttime 0.0395 (0.0360)\tloss 0.4485 (0.5158)\tgrad_norm 1.7724 (nan)\tloss_scale 32768.0000 (33172.5432)\tmem 455MB\n",
      "Train: [62/100][90/625]\teta 0:00:19 lr 0.000338\t wd 0.0100\ttime 0.0359 (0.0360)\tloss 0.3618 (0.5129)\tgrad_norm 1.7186 (nan)\tloss_scale 32768.0000 (33128.0879)\tmem 455MB\n",
      "Train: [62/100][100/625]\teta 0:00:18 lr 0.000337\t wd 0.0100\ttime 0.0328 (0.0359)\tloss 0.5171 (0.5127)\tgrad_norm 1.5738 (nan)\tloss_scale 32768.0000 (33092.4356)\tmem 455MB\n",
      "Train: [62/100][110/625]\teta 0:00:18 lr 0.000337\t wd 0.0100\ttime 0.0355 (0.0358)\tloss 0.4761 (0.5092)\tgrad_norm 2.0317 (nan)\tloss_scale 32768.0000 (33063.2072)\tmem 455MB\n",
      "Train: [62/100][120/625]\teta 0:00:18 lr 0.000337\t wd 0.0100\ttime 0.0367 (0.0358)\tloss 0.9048 (0.5152)\tgrad_norm 3.7528 (nan)\tloss_scale 32768.0000 (33038.8099)\tmem 455MB\n",
      "Train: [62/100][130/625]\teta 0:00:17 lr 0.000337\t wd 0.0100\ttime 0.0328 (0.0358)\tloss 0.4407 (0.5144)\tgrad_norm 2.1861 (nan)\tloss_scale 32768.0000 (33018.1374)\tmem 455MB\n",
      "Train: [62/100][140/625]\teta 0:00:17 lr 0.000337\t wd 0.0100\ttime 0.0358 (0.0358)\tloss 0.5903 (0.5173)\tgrad_norm 2.2967 (nan)\tloss_scale 32768.0000 (33000.3972)\tmem 455MB\n",
      "Train: [62/100][150/625]\teta 0:00:16 lr 0.000336\t wd 0.0100\ttime 0.0358 (0.0358)\tloss 0.5400 (0.5133)\tgrad_norm 1.9650 (nan)\tloss_scale 32768.0000 (32985.0066)\tmem 455MB\n",
      "Train: [62/100][160/625]\teta 0:00:16 lr 0.000336\t wd 0.0100\ttime 0.0354 (0.0357)\tloss 0.4844 (0.5140)\tgrad_norm 2.6286 (nan)\tloss_scale 32768.0000 (32971.5280)\tmem 455MB\n",
      "Train: [62/100][170/625]\teta 0:00:16 lr 0.000336\t wd 0.0100\ttime 0.0355 (0.0357)\tloss 0.4302 (0.5137)\tgrad_norm 2.2547 (nan)\tloss_scale 32768.0000 (32959.6257)\tmem 455MB\n",
      "Train: [62/100][180/625]\teta 0:00:15 lr 0.000336\t wd 0.0100\ttime 0.0337 (0.0357)\tloss 0.6128 (0.5150)\tgrad_norm 1.8971 (nan)\tloss_scale 32768.0000 (32949.0387)\tmem 455MB\n",
      "Train: [62/100][190/625]\teta 0:00:15 lr 0.000335\t wd 0.0100\ttime 0.0359 (0.0357)\tloss 0.4194 (0.5145)\tgrad_norm 1.5958 (nan)\tloss_scale 32768.0000 (32939.5602)\tmem 455MB\n",
      "Train: [62/100][200/625]\teta 0:00:15 lr 0.000335\t wd 0.0100\ttime 0.0353 (0.0357)\tloss 0.4919 (0.5158)\tgrad_norm 1.6386 (nan)\tloss_scale 32768.0000 (32931.0249)\tmem 455MB\n",
      "Train: [62/100][210/625]\teta 0:00:14 lr 0.000335\t wd 0.0100\ttime 0.0345 (0.0357)\tloss 0.6133 (0.5151)\tgrad_norm 2.2441 (nan)\tloss_scale 32768.0000 (32923.2986)\tmem 455MB\n",
      "Train: [62/100][220/625]\teta 0:00:14 lr 0.000335\t wd 0.0100\ttime 0.0384 (0.0357)\tloss 0.5361 (0.5157)\tgrad_norm 2.5755 (nan)\tloss_scale 32768.0000 (32916.2715)\tmem 455MB\n",
      "Train: [62/100][230/625]\teta 0:00:14 lr 0.000334\t wd 0.0100\ttime 0.0324 (0.0357)\tloss 0.5757 (0.5170)\tgrad_norm 2.1027 (nan)\tloss_scale 32768.0000 (32909.8528)\tmem 455MB\n",
      "Train: [62/100][240/625]\teta 0:00:13 lr 0.000334\t wd 0.0100\ttime 0.0323 (0.0357)\tloss 0.4431 (0.5171)\tgrad_norm 1.7205 (nan)\tloss_scale 32768.0000 (32903.9668)\tmem 455MB\n",
      "Train: [62/100][250/625]\teta 0:00:13 lr 0.000334\t wd 0.0100\ttime 0.0326 (0.0357)\tloss 0.4038 (0.5165)\tgrad_norm 1.7281 (nan)\tloss_scale 32768.0000 (32898.5498)\tmem 455MB\n",
      "Train: [62/100][260/625]\teta 0:00:13 lr 0.000334\t wd 0.0100\ttime 0.0394 (0.0357)\tloss 0.5781 (0.5168)\tgrad_norm 2.7805 (nan)\tloss_scale 32768.0000 (32893.5479)\tmem 455MB\n",
      "Train: [62/100][270/625]\teta 0:00:12 lr 0.000333\t wd 0.0100\ttime 0.0326 (0.0357)\tloss 0.5254 (0.5209)\tgrad_norm 2.0524 (nan)\tloss_scale 32768.0000 (32888.9151)\tmem 455MB\n",
      "Train: [62/100][280/625]\teta 0:00:12 lr 0.000333\t wd 0.0100\ttime 0.0327 (0.0357)\tloss 0.6021 (0.5210)\tgrad_norm 1.9723 (nan)\tloss_scale 32768.0000 (32884.6121)\tmem 455MB\n",
      "Train: [62/100][290/625]\teta 0:00:11 lr 0.000333\t wd 0.0100\ttime 0.0353 (0.0357)\tloss 0.6099 (0.5211)\tgrad_norm 2.6357 (nan)\tloss_scale 32768.0000 (32880.6048)\tmem 455MB\n",
      "Train: [62/100][300/625]\teta 0:00:11 lr 0.000333\t wd 0.0100\ttime 0.0350 (0.0356)\tloss 0.7368 (0.5225)\tgrad_norm 2.4350 (nan)\tloss_scale 32768.0000 (32876.8638)\tmem 455MB\n",
      "Train: [62/100][310/625]\teta 0:00:11 lr 0.000332\t wd 0.0100\ttime 0.0334 (0.0356)\tloss 0.4722 (0.5214)\tgrad_norm 1.8015 (nan)\tloss_scale 32768.0000 (32873.3633)\tmem 455MB\n",
      "Train: [62/100][320/625]\teta 0:00:10 lr 0.000332\t wd 0.0100\ttime 0.0343 (0.0356)\tloss 0.4028 (0.5211)\tgrad_norm 1.8449 (nan)\tloss_scale 32768.0000 (32870.0810)\tmem 455MB\n",
      "Train: [62/100][330/625]\teta 0:00:10 lr 0.000332\t wd 0.0100\ttime 0.0359 (0.0356)\tloss 0.5342 (0.5220)\tgrad_norm 2.0008 (nan)\tloss_scale 32768.0000 (32866.9970)\tmem 455MB\n",
      "Train: [62/100][340/625]\teta 0:00:10 lr 0.000332\t wd 0.0100\ttime 0.0334 (0.0355)\tloss 0.7109 (0.5235)\tgrad_norm 3.3167 (nan)\tloss_scale 32768.0000 (32864.0938)\tmem 455MB\n",
      "Train: [62/100][350/625]\teta 0:00:09 lr 0.000331\t wd 0.0100\ttime 0.0325 (0.0355)\tloss 0.4480 (0.5237)\tgrad_norm 1.6184 (nan)\tloss_scale 32768.0000 (32861.3561)\tmem 455MB\n",
      "Train: [62/100][360/625]\teta 0:00:09 lr 0.000331\t wd 0.0100\ttime 0.0367 (0.0355)\tloss 0.6357 (0.5225)\tgrad_norm 1.8933 (nan)\tloss_scale 32768.0000 (32858.7701)\tmem 455MB\n",
      "Train: [62/100][370/625]\teta 0:00:09 lr 0.000331\t wd 0.0100\ttime 0.0371 (0.0356)\tloss 0.4668 (0.5220)\tgrad_norm 1.6987 (nan)\tloss_scale 32768.0000 (32856.3235)\tmem 455MB\n",
      "Train: [62/100][380/625]\teta 0:00:08 lr 0.000331\t wd 0.0100\ttime 0.0365 (0.0356)\tloss 0.5684 (0.5219)\tgrad_norm 2.5064 (nan)\tloss_scale 32768.0000 (32854.0052)\tmem 455MB\n",
      "Train: [62/100][390/625]\teta 0:00:08 lr 0.000330\t wd 0.0100\ttime 0.0354 (0.0356)\tloss 0.5156 (0.5237)\tgrad_norm 2.5516 (nan)\tloss_scale 32768.0000 (32851.8056)\tmem 455MB\n",
      "Train: [62/100][400/625]\teta 0:00:07 lr 0.000330\t wd 0.0100\ttime 0.0355 (0.0355)\tloss 0.5322 (0.5270)\tgrad_norm 2.2892 (nan)\tloss_scale 32768.0000 (32849.7157)\tmem 455MB\n",
      "Train: [62/100][410/625]\teta 0:00:07 lr 0.000330\t wd 0.0100\ttime 0.0342 (0.0355)\tloss 0.7305 (0.5276)\tgrad_norm 2.4658 (nan)\tloss_scale 32768.0000 (32847.7275)\tmem 455MB\n",
      "Train: [62/100][420/625]\teta 0:00:07 lr 0.000330\t wd 0.0100\ttime 0.0351 (0.0356)\tloss 0.5376 (0.5273)\tgrad_norm 2.0419 (nan)\tloss_scale 32768.0000 (32845.8337)\tmem 455MB\n",
      "Train: [62/100][430/625]\teta 0:00:06 lr 0.000330\t wd 0.0100\ttime 0.0407 (0.0356)\tloss 0.7725 (0.5282)\tgrad_norm 2.2808 (nan)\tloss_scale 32768.0000 (32844.0278)\tmem 455MB\n",
      "Train: [62/100][440/625]\teta 0:00:06 lr 0.000329\t wd 0.0100\ttime 0.0324 (0.0356)\tloss 0.3784 (0.5266)\tgrad_norm 1.3587 (nan)\tloss_scale 32768.0000 (32842.3039)\tmem 455MB\n",
      "Train: [62/100][450/625]\teta 0:00:06 lr 0.000329\t wd 0.0100\ttime 0.0329 (0.0356)\tloss 0.4355 (0.5264)\tgrad_norm 1.6612 (nan)\tloss_scale 32768.0000 (32840.6563)\tmem 455MB\n",
      "Train: [62/100][460/625]\teta 0:00:05 lr 0.000329\t wd 0.0100\ttime 0.0323 (0.0356)\tloss 0.6025 (0.5266)\tgrad_norm 1.7558 (nan)\tloss_scale 32768.0000 (32839.0803)\tmem 455MB\n",
      "Train: [62/100][470/625]\teta 0:00:05 lr 0.000329\t wd 0.0100\ttime 0.0361 (0.0355)\tloss 0.5112 (0.5263)\tgrad_norm 2.2151 (nan)\tloss_scale 32768.0000 (32837.5711)\tmem 455MB\n",
      "Train: [62/100][480/625]\teta 0:00:05 lr 0.000328\t wd 0.0100\ttime 0.0401 (0.0355)\tloss 0.6338 (0.5267)\tgrad_norm 2.3581 (nan)\tloss_scale 32768.0000 (32836.1247)\tmem 455MB\n",
      "Train: [62/100][490/625]\teta 0:00:04 lr 0.000328\t wd 0.0100\ttime 0.0360 (0.0355)\tloss 0.6123 (0.5261)\tgrad_norm 2.0338 (nan)\tloss_scale 32768.0000 (32834.7373)\tmem 455MB\n",
      "Train: [62/100][500/625]\teta 0:00:04 lr 0.000328\t wd 0.0100\ttime 0.0324 (0.0355)\tloss 0.4968 (0.5265)\tgrad_norm 1.7576 (nan)\tloss_scale 32768.0000 (32833.4052)\tmem 455MB\n",
      "Train: [62/100][510/625]\teta 0:00:04 lr 0.000328\t wd 0.0100\ttime 0.0356 (0.0355)\tloss 0.4319 (0.5274)\tgrad_norm 1.6555 (nan)\tloss_scale 32768.0000 (32832.1252)\tmem 455MB\n",
      "Train: [62/100][520/625]\teta 0:00:03 lr 0.000327\t wd 0.0100\ttime 0.0392 (0.0355)\tloss 0.4841 (0.5283)\tgrad_norm 1.6878 (nan)\tloss_scale 32768.0000 (32830.8944)\tmem 455MB\n",
      "Train: [62/100][530/625]\teta 0:00:03 lr 0.000327\t wd 0.0100\ttime 0.0356 (0.0356)\tloss 0.4888 (0.5293)\tgrad_norm 1.8891 (nan)\tloss_scale 32768.0000 (32829.7100)\tmem 455MB\n",
      "Train: [62/100][540/625]\teta 0:00:03 lr 0.000327\t wd 0.0100\ttime 0.0459 (0.0356)\tloss 0.5981 (0.5295)\tgrad_norm 2.5509 (nan)\tloss_scale 32768.0000 (32828.5693)\tmem 455MB\n",
      "Train: [62/100][550/625]\teta 0:00:02 lr 0.000327\t wd 0.0100\ttime 0.0399 (0.0356)\tloss 0.4346 (0.5290)\tgrad_norm 1.4377 (nan)\tloss_scale 32768.0000 (32827.4701)\tmem 455MB\n",
      "Train: [62/100][560/625]\teta 0:00:02 lr 0.000326\t wd 0.0100\ttime 0.0377 (0.0357)\tloss 0.6646 (0.5297)\tgrad_norm 2.2508 (nan)\tloss_scale 32768.0000 (32826.4100)\tmem 455MB\n",
      "Train: [62/100][570/625]\teta 0:00:01 lr 0.000326\t wd 0.0100\ttime 0.0328 (0.0357)\tloss 0.5576 (0.5291)\tgrad_norm 2.0487 (nan)\tloss_scale 32768.0000 (32825.3870)\tmem 455MB\n",
      "Train: [62/100][580/625]\teta 0:00:01 lr 0.000326\t wd 0.0100\ttime 0.0349 (0.0357)\tloss 0.5220 (0.5291)\tgrad_norm 1.5278 (nan)\tloss_scale 32768.0000 (32824.3993)\tmem 455MB\n",
      "Train: [62/100][590/625]\teta 0:00:01 lr 0.000326\t wd 0.0100\ttime 0.0346 (0.0357)\tloss 0.5532 (0.5296)\tgrad_norm 2.1357 (nan)\tloss_scale 32768.0000 (32823.4450)\tmem 455MB\n",
      "Train: [62/100][600/625]\teta 0:00:00 lr 0.000325\t wd 0.0100\ttime 0.0379 (0.0357)\tloss 0.4092 (0.5289)\tgrad_norm 1.4216 (nan)\tloss_scale 32768.0000 (32822.5225)\tmem 455MB\n",
      "Train: [62/100][610/625]\teta 0:00:00 lr 0.000325\t wd 0.0100\ttime 0.0324 (0.0357)\tloss 0.4814 (0.5281)\tgrad_norm 1.6216 (nan)\tloss_scale 32768.0000 (32821.6301)\tmem 455MB\n",
      "Train: [62/100][620/625]\teta 0:00:00 lr 0.000325\t wd 0.0100\ttime 0.0325 (0.0357)\tloss 0.4841 (0.5282)\tgrad_norm 1.5784 (nan)\tloss_scale 32768.0000 (32820.7665)\tmem 455MB\n",
      "EPOCH 62 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_62.pth saving......\n",
      "./model_save/ckpt_epoch_62.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.6211 (0.6211)\tAcc@1 81.250 (81.250)\tAcc@5 100.000 (100.000)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.016)\tLoss 0.6616 (0.6267)\tAcc@1 76.562 (78.125)\tAcc@5 100.000 (99.006)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.016)\tLoss 0.7129 (0.6178)\tAcc@1 76.562 (78.423)\tAcc@5 98.438 (99.107)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.016)\tLoss 0.9663 (0.6288)\tAcc@1 68.750 (77.772)\tAcc@5 95.312 (98.942)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.016)\tLoss 0.5532 (0.5906)\tAcc@1 79.688 (79.040)\tAcc@5 100.000 (99.123)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.6479 (0.6021)\tAcc@1 70.312 (78.493)\tAcc@5 100.000 (99.203)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.016 (0.015)\tLoss 0.5933 (0.6006)\tAcc@1 79.688 (78.560)\tAcc@5 100.000 (99.206)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.7510 (0.6140)\tAcc@1 73.438 (78.389)\tAcc@5 100.000 (99.186)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.6216 (0.6251)\tAcc@1 79.688 (78.241)\tAcc@5 100.000 (99.113)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.016 (0.015)\tLoss 0.5669 (0.6248)\tAcc@1 75.000 (78.314)\tAcc@5 100.000 (99.073)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.016 (0.015)\tLoss 0.8315 (0.6298)\tAcc@1 70.312 (78.032)\tAcc@5 98.438 (99.072)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.8501 (0.6248)\tAcc@1 71.875 (78.153)\tAcc@5 98.438 (99.085)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.5264 (0.6216)\tAcc@1 78.125 (78.125)\tAcc@5 100.000 (99.109)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.9873 (0.6282)\tAcc@1 73.438 (77.886)\tAcc@5 95.312 (98.998)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.3618 (0.6260)\tAcc@1 87.500 (77.981)\tAcc@5 100.000 (98.992)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.5464 (0.6261)\tAcc@1 75.000 (77.897)\tAcc@5 100.000 (99.007)\tMem 455MB\n",
      " * Acc@1 77.980 Acc@5 98.990\n",
      "Accuracy of the network on the 10000 test images: 78.0%\n",
      "Max accuracy: 78.71%\n",
      "Train: [63/100][0/625]\teta 0:00:23 lr 0.000325\t wd 0.0100\ttime 0.0371 (0.0371)\tloss 0.4492 (0.4492)\tgrad_norm 2.1170 (2.1170)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][10/625]\teta 0:00:21 lr 0.000325\t wd 0.0100\ttime 0.0355 (0.0348)\tloss 0.7549 (0.4921)\tgrad_norm 2.2840 (1.9617)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][20/625]\teta 0:00:21 lr 0.000324\t wd 0.0100\ttime 0.0348 (0.0357)\tloss 0.4851 (0.5054)\tgrad_norm 2.1405 (2.0699)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][30/625]\teta 0:00:21 lr 0.000324\t wd 0.0100\ttime 0.0327 (0.0355)\tloss 0.5283 (0.5187)\tgrad_norm 2.4722 (2.1580)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][40/625]\teta 0:00:20 lr 0.000324\t wd 0.0100\ttime 0.0390 (0.0356)\tloss 0.8442 (0.5320)\tgrad_norm 2.6013 (2.1096)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][50/625]\teta 0:00:20 lr 0.000324\t wd 0.0100\ttime 0.0325 (0.0357)\tloss 0.4451 (0.5341)\tgrad_norm 2.4924 (2.1313)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][60/625]\teta 0:00:20 lr 0.000323\t wd 0.0100\ttime 0.0350 (0.0357)\tloss 0.6860 (0.5379)\tgrad_norm 1.9106 (2.1504)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][70/625]\teta 0:00:19 lr 0.000323\t wd 0.0100\ttime 0.0353 (0.0358)\tloss 0.5337 (0.5414)\tgrad_norm 1.9183 (2.1723)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][80/625]\teta 0:00:19 lr 0.000323\t wd 0.0100\ttime 0.0330 (0.0357)\tloss 0.6763 (0.5445)\tgrad_norm 2.9866 (2.1920)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][90/625]\teta 0:00:19 lr 0.000323\t wd 0.0100\ttime 0.0323 (0.0357)\tloss 0.4238 (0.5428)\tgrad_norm 1.8575 (2.1720)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][100/625]\teta 0:00:18 lr 0.000322\t wd 0.0100\ttime 0.0369 (0.0356)\tloss 0.4858 (0.5336)\tgrad_norm 1.5748 (2.1458)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][110/625]\teta 0:00:18 lr 0.000322\t wd 0.0100\ttime 0.0360 (0.0357)\tloss 0.5625 (0.5340)\tgrad_norm 2.1336 (2.1312)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][120/625]\teta 0:00:18 lr 0.000322\t wd 0.0100\ttime 0.0364 (0.0357)\tloss 0.4941 (0.5324)\tgrad_norm 1.7820 (2.1186)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][130/625]\teta 0:00:17 lr 0.000322\t wd 0.0100\ttime 0.0326 (0.0357)\tloss 0.6855 (0.5315)\tgrad_norm 2.4214 (2.1165)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][140/625]\teta 0:00:17 lr 0.000322\t wd 0.0100\ttime 0.0386 (0.0357)\tloss 0.3044 (0.5255)\tgrad_norm 1.9373 (2.0997)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][150/625]\teta 0:00:16 lr 0.000321\t wd 0.0100\ttime 0.0331 (0.0356)\tloss 0.4231 (0.5272)\tgrad_norm 1.5046 (2.0918)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][160/625]\teta 0:00:16 lr 0.000321\t wd 0.0100\ttime 0.0359 (0.0356)\tloss 0.4937 (0.5251)\tgrad_norm 1.7060 (2.0854)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][170/625]\teta 0:00:16 lr 0.000321\t wd 0.0100\ttime 0.0333 (0.0355)\tloss 0.3533 (0.5236)\tgrad_norm 2.6834 (2.0957)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][180/625]\teta 0:00:15 lr 0.000321\t wd 0.0100\ttime 0.0347 (0.0355)\tloss 0.5356 (0.5255)\tgrad_norm 2.0383 (2.0945)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][190/625]\teta 0:00:15 lr 0.000320\t wd 0.0100\ttime 0.0323 (0.0355)\tloss 0.4851 (0.5221)\tgrad_norm 1.9078 (2.0858)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][200/625]\teta 0:00:15 lr 0.000320\t wd 0.0100\ttime 0.0327 (0.0354)\tloss 0.4458 (0.5252)\tgrad_norm 1.8613 (2.0912)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][210/625]\teta 0:00:14 lr 0.000320\t wd 0.0100\ttime 0.0323 (0.0353)\tloss 0.3972 (0.5239)\tgrad_norm 2.1253 (2.0829)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][220/625]\teta 0:00:14 lr 0.000320\t wd 0.0100\ttime 0.0327 (0.0352)\tloss 0.6162 (0.5253)\tgrad_norm 2.1144 (2.0939)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][230/625]\teta 0:00:13 lr 0.000319\t wd 0.0100\ttime 0.0327 (0.0351)\tloss 0.4062 (0.5236)\tgrad_norm 1.5895 (2.0913)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][240/625]\teta 0:00:13 lr 0.000319\t wd 0.0100\ttime 0.0345 (0.0351)\tloss 0.3914 (0.5210)\tgrad_norm 1.4795 (2.0834)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][250/625]\teta 0:00:13 lr 0.000319\t wd 0.0100\ttime 0.0327 (0.0350)\tloss 0.6221 (0.5199)\tgrad_norm 2.8745 (2.0890)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][260/625]\teta 0:00:12 lr 0.000319\t wd 0.0100\ttime 0.0329 (0.0350)\tloss 0.5664 (0.5210)\tgrad_norm 2.7673 (2.0991)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][270/625]\teta 0:00:12 lr 0.000318\t wd 0.0100\ttime 0.0352 (0.0349)\tloss 0.4832 (0.5232)\tgrad_norm 1.6235 (2.1007)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][280/625]\teta 0:00:12 lr 0.000318\t wd 0.0100\ttime 0.0355 (0.0349)\tloss 0.6177 (0.5225)\tgrad_norm 2.5891 (2.1045)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][290/625]\teta 0:00:11 lr 0.000318\t wd 0.0100\ttime 0.0325 (0.0349)\tloss 0.6035 (0.5225)\tgrad_norm 2.5773 (2.1084)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][300/625]\teta 0:00:11 lr 0.000318\t wd 0.0100\ttime 0.0356 (0.0349)\tloss 0.4143 (0.5224)\tgrad_norm 2.1008 (2.1060)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][310/625]\teta 0:00:11 lr 0.000317\t wd 0.0100\ttime 0.0353 (0.0349)\tloss 0.3103 (0.5237)\tgrad_norm 1.1807 (2.1096)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][320/625]\teta 0:00:10 lr 0.000317\t wd 0.0100\ttime 0.0359 (0.0349)\tloss 0.4810 (0.5240)\tgrad_norm 2.6108 (2.1130)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][330/625]\teta 0:00:10 lr 0.000317\t wd 0.0100\ttime 0.0325 (0.0350)\tloss 0.5454 (0.5247)\tgrad_norm 1.9489 (2.1223)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][340/625]\teta 0:00:09 lr 0.000317\t wd 0.0100\ttime 0.0362 (0.0350)\tloss 0.4268 (0.5257)\tgrad_norm 1.9547 (2.1212)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][350/625]\teta 0:00:09 lr 0.000317\t wd 0.0100\ttime 0.0326 (0.0350)\tloss 0.5923 (0.5243)\tgrad_norm 2.3635 (2.1189)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][360/625]\teta 0:00:09 lr 0.000316\t wd 0.0100\ttime 0.0329 (0.0350)\tloss 0.5420 (0.5253)\tgrad_norm 1.7588 (2.1219)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][370/625]\teta 0:00:08 lr 0.000316\t wd 0.0100\ttime 0.0413 (0.0351)\tloss 0.7939 (0.5263)\tgrad_norm 2.6077 (2.1215)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][380/625]\teta 0:00:08 lr 0.000316\t wd 0.0100\ttime 0.0390 (0.0351)\tloss 0.4126 (0.5255)\tgrad_norm 1.7746 (2.1148)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][390/625]\teta 0:00:08 lr 0.000316\t wd 0.0100\ttime 0.0396 (0.0351)\tloss 0.3965 (0.5257)\tgrad_norm 2.2012 (2.1173)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][400/625]\teta 0:00:07 lr 0.000315\t wd 0.0100\ttime 0.0324 (0.0351)\tloss 0.3850 (0.5256)\tgrad_norm 1.4984 (2.1155)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][410/625]\teta 0:00:07 lr 0.000315\t wd 0.0100\ttime 0.0325 (0.0351)\tloss 0.5303 (0.5256)\tgrad_norm 2.0509 (2.1122)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][420/625]\teta 0:00:07 lr 0.000315\t wd 0.0100\ttime 0.0359 (0.0351)\tloss 0.3374 (0.5258)\tgrad_norm 1.9807 (2.1149)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][430/625]\teta 0:00:06 lr 0.000315\t wd 0.0100\ttime 0.0327 (0.0350)\tloss 0.4534 (0.5262)\tgrad_norm 2.1431 (2.1160)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][440/625]\teta 0:00:06 lr 0.000314\t wd 0.0100\ttime 0.0357 (0.0351)\tloss 0.5918 (0.5252)\tgrad_norm 2.1988 (2.1159)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][450/625]\teta 0:00:06 lr 0.000314\t wd 0.0100\ttime 0.0356 (0.0350)\tloss 0.4707 (0.5250)\tgrad_norm 2.3862 (2.1173)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][460/625]\teta 0:00:05 lr 0.000314\t wd 0.0100\ttime 0.0396 (0.0351)\tloss 0.5513 (0.5260)\tgrad_norm 2.6036 (2.1179)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][470/625]\teta 0:00:05 lr 0.000314\t wd 0.0100\ttime 0.0388 (0.0351)\tloss 0.5801 (0.5259)\tgrad_norm 2.7097 (2.1201)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][480/625]\teta 0:00:05 lr 0.000313\t wd 0.0100\ttime 0.0387 (0.0351)\tloss 0.4255 (0.5256)\tgrad_norm 1.8171 (2.1188)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][490/625]\teta 0:00:04 lr 0.000313\t wd 0.0100\ttime 0.0380 (0.0351)\tloss 0.8169 (0.5253)\tgrad_norm 2.3681 (2.1204)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][500/625]\teta 0:00:04 lr 0.000313\t wd 0.0100\ttime 0.0378 (0.0351)\tloss 0.3765 (0.5250)\tgrad_norm 1.5239 (2.1205)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][510/625]\teta 0:00:04 lr 0.000313\t wd 0.0100\ttime 0.0326 (0.0352)\tloss 0.3970 (0.5262)\tgrad_norm 1.3898 (2.1212)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][520/625]\teta 0:00:03 lr 0.000313\t wd 0.0100\ttime 0.0333 (0.0352)\tloss 0.5020 (0.5265)\tgrad_norm 2.0717 (2.1222)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][530/625]\teta 0:00:03 lr 0.000312\t wd 0.0100\ttime 0.0329 (0.0352)\tloss 0.4558 (0.5256)\tgrad_norm 2.1794 (2.1205)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][540/625]\teta 0:00:02 lr 0.000312\t wd 0.0100\ttime 0.0394 (0.0352)\tloss 0.4231 (0.5263)\tgrad_norm 2.0771 (2.1226)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][550/625]\teta 0:00:02 lr 0.000312\t wd 0.0100\ttime 0.0386 (0.0352)\tloss 0.4724 (0.5257)\tgrad_norm 2.1821 (2.1216)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][560/625]\teta 0:00:02 lr 0.000312\t wd 0.0100\ttime 0.0357 (0.0352)\tloss 0.5586 (0.5257)\tgrad_norm 2.1756 (2.1230)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][570/625]\teta 0:00:01 lr 0.000311\t wd 0.0100\ttime 0.0326 (0.0352)\tloss 0.7007 (0.5261)\tgrad_norm 2.3088 (2.1194)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][580/625]\teta 0:00:01 lr 0.000311\t wd 0.0100\ttime 0.0367 (0.0352)\tloss 0.4438 (0.5256)\tgrad_norm 1.7115 (2.1192)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][590/625]\teta 0:00:01 lr 0.000311\t wd 0.0100\ttime 0.0327 (0.0351)\tloss 0.4084 (0.5250)\tgrad_norm 2.1103 (2.1160)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][600/625]\teta 0:00:00 lr 0.000311\t wd 0.0100\ttime 0.0359 (0.0351)\tloss 0.4617 (0.5241)\tgrad_norm 1.7247 (2.1139)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][610/625]\teta 0:00:00 lr 0.000310\t wd 0.0100\ttime 0.0325 (0.0351)\tloss 0.6968 (0.5233)\tgrad_norm 2.0068 (2.1138)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [63/100][620/625]\teta 0:00:00 lr 0.000310\t wd 0.0100\ttime 0.0329 (0.0351)\tloss 0.3848 (0.5229)\tgrad_norm 2.0019 (2.1121)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 63 training takes 0:00:21\n",
      "./model_save/ckpt_epoch_63.pth saving......\n",
      "./model_save/ckpt_epoch_63.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.7539 (0.7539)\tAcc@1 76.562 (76.562)\tAcc@5 100.000 (100.000)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.4956 (0.5754)\tAcc@1 79.688 (79.830)\tAcc@5 98.438 (98.864)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.6455 (0.5935)\tAcc@1 76.562 (79.315)\tAcc@5 100.000 (98.810)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.016)\tLoss 0.6885 (0.5884)\tAcc@1 78.125 (79.688)\tAcc@5 98.438 (98.891)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.5752 (0.5939)\tAcc@1 78.125 (79.688)\tAcc@5 100.000 (98.704)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.7051 (0.5818)\tAcc@1 71.875 (79.933)\tAcc@5 98.438 (98.775)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.016 (0.015)\tLoss 0.4944 (0.5828)\tAcc@1 81.250 (79.995)\tAcc@5 100.000 (98.822)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.6978 (0.5986)\tAcc@1 76.562 (79.335)\tAcc@5 100.000 (98.878)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.6230 (0.6076)\tAcc@1 81.250 (79.321)\tAcc@5 100.000 (98.843)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.5684 (0.6059)\tAcc@1 81.250 (79.378)\tAcc@5 100.000 (98.867)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.4766 (0.6058)\tAcc@1 78.125 (79.208)\tAcc@5 100.000 (98.809)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.8062 (0.6087)\tAcc@1 71.875 (79.153)\tAcc@5 95.312 (98.775)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 1.0742 (0.6108)\tAcc@1 70.312 (79.016)\tAcc@5 96.875 (98.773)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.6367 (0.6209)\tAcc@1 78.125 (78.626)\tAcc@5 100.000 (98.748)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.6167 (0.6192)\tAcc@1 78.125 (78.624)\tAcc@5 100.000 (98.781)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.9971 (0.6226)\tAcc@1 60.938 (78.591)\tAcc@5 98.438 (98.769)\tMem 455MB\n",
      " * Acc@1 78.600 Acc@5 98.780\n",
      "Accuracy of the network on the 10000 test images: 78.6%\n",
      "Max accuracy: 78.71%\n",
      "Train: [64/100][0/625]\teta 0:00:23 lr 0.000310\t wd 0.0100\ttime 0.0372 (0.0372)\tloss 0.4075 (0.4075)\tgrad_norm 1.6100 (1.6100)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][10/625]\teta 0:00:22 lr 0.000310\t wd 0.0100\ttime 0.0384 (0.0363)\tloss 0.4565 (0.4598)\tgrad_norm 1.4131 (2.0698)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][20/625]\teta 0:00:21 lr 0.000310\t wd 0.0100\ttime 0.0354 (0.0363)\tloss 0.7461 (0.4820)\tgrad_norm 2.4683 (2.1061)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][30/625]\teta 0:00:21 lr 0.000309\t wd 0.0100\ttime 0.0358 (0.0360)\tloss 0.2484 (0.4734)\tgrad_norm 1.7612 (2.0591)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][40/625]\teta 0:00:20 lr 0.000309\t wd 0.0100\ttime 0.0324 (0.0359)\tloss 0.5796 (0.4866)\tgrad_norm 2.2627 (2.0919)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][50/625]\teta 0:00:20 lr 0.000309\t wd 0.0100\ttime 0.0361 (0.0358)\tloss 0.4529 (0.4881)\tgrad_norm 1.4517 (2.0869)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][60/625]\teta 0:00:20 lr 0.000309\t wd 0.0100\ttime 0.0355 (0.0360)\tloss 0.7041 (0.4858)\tgrad_norm 2.0688 (2.1031)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][70/625]\teta 0:00:19 lr 0.000308\t wd 0.0100\ttime 0.0364 (0.0359)\tloss 0.6108 (0.4927)\tgrad_norm 3.0480 (2.1269)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][80/625]\teta 0:00:19 lr 0.000308\t wd 0.0100\ttime 0.0328 (0.0358)\tloss 0.5249 (0.4967)\tgrad_norm 2.0999 (2.1220)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][90/625]\teta 0:00:19 lr 0.000308\t wd 0.0100\ttime 0.0369 (0.0358)\tloss 0.5566 (0.5096)\tgrad_norm 1.9323 (2.1486)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][100/625]\teta 0:00:18 lr 0.000308\t wd 0.0100\ttime 0.0329 (0.0356)\tloss 0.4866 (0.5080)\tgrad_norm 2.3057 (2.1294)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][110/625]\teta 0:00:18 lr 0.000307\t wd 0.0100\ttime 0.0331 (0.0354)\tloss 0.5547 (0.5112)\tgrad_norm 2.0747 (2.1227)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][120/625]\teta 0:00:17 lr 0.000307\t wd 0.0100\ttime 0.0357 (0.0354)\tloss 0.6484 (0.5067)\tgrad_norm 1.9996 (2.0945)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][130/625]\teta 0:00:17 lr 0.000307\t wd 0.0100\ttime 0.0357 (0.0354)\tloss 0.6147 (0.5066)\tgrad_norm 2.0335 (2.0879)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][140/625]\teta 0:00:17 lr 0.000307\t wd 0.0100\ttime 0.0330 (0.0354)\tloss 0.4368 (0.5054)\tgrad_norm 1.9302 (2.0927)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][150/625]\teta 0:00:16 lr 0.000307\t wd 0.0100\ttime 0.0354 (0.0355)\tloss 0.5054 (0.5048)\tgrad_norm 2.0492 (2.1293)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][160/625]\teta 0:00:16 lr 0.000306\t wd 0.0100\ttime 0.0372 (0.0355)\tloss 0.5591 (0.5039)\tgrad_norm 2.6142 (2.1310)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][170/625]\teta 0:00:16 lr 0.000306\t wd 0.0100\ttime 0.0356 (0.0356)\tloss 0.4172 (0.5030)\tgrad_norm 1.7916 (2.1198)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][180/625]\teta 0:00:15 lr 0.000306\t wd 0.0100\ttime 0.0341 (0.0356)\tloss 0.4260 (0.5077)\tgrad_norm 1.5418 (2.1323)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][190/625]\teta 0:00:15 lr 0.000306\t wd 0.0100\ttime 0.0386 (0.0356)\tloss 0.5962 (0.5099)\tgrad_norm 2.2572 (2.1381)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][200/625]\teta 0:00:15 lr 0.000305\t wd 0.0100\ttime 0.0328 (0.0355)\tloss 0.5371 (0.5077)\tgrad_norm 1.7083 (2.1282)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][210/625]\teta 0:00:14 lr 0.000305\t wd 0.0100\ttime 0.0324 (0.0356)\tloss 0.4924 (0.5090)\tgrad_norm 2.2959 (2.1226)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][220/625]\teta 0:00:14 lr 0.000305\t wd 0.0100\ttime 0.0361 (0.0356)\tloss 0.4048 (0.5078)\tgrad_norm 1.8078 (2.1207)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][230/625]\teta 0:00:14 lr 0.000305\t wd 0.0100\ttime 0.0363 (0.0356)\tloss 0.6084 (0.5114)\tgrad_norm 2.9156 (2.1216)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][240/625]\teta 0:00:13 lr 0.000304\t wd 0.0100\ttime 0.0348 (0.0356)\tloss 0.5122 (0.5134)\tgrad_norm 2.0706 (2.1187)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][250/625]\teta 0:00:13 lr 0.000304\t wd 0.0100\ttime 0.0332 (0.0357)\tloss 0.5859 (0.5122)\tgrad_norm 1.7669 (2.1114)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][260/625]\teta 0:00:13 lr 0.000304\t wd 0.0100\ttime 0.0323 (0.0357)\tloss 0.5151 (0.5133)\tgrad_norm 2.2250 (2.1140)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][270/625]\teta 0:00:12 lr 0.000304\t wd 0.0100\ttime 0.0332 (0.0357)\tloss 0.5376 (0.5144)\tgrad_norm 2.1791 (2.1132)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][280/625]\teta 0:00:12 lr 0.000303\t wd 0.0100\ttime 0.0323 (0.0357)\tloss 0.5610 (0.5126)\tgrad_norm 2.0975 (2.1087)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][290/625]\teta 0:00:11 lr 0.000303\t wd 0.0100\ttime 0.0365 (0.0356)\tloss 0.5122 (0.5158)\tgrad_norm 1.7099 (2.1097)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][300/625]\teta 0:00:11 lr 0.000303\t wd 0.0100\ttime 0.0360 (0.0357)\tloss 0.3198 (0.5168)\tgrad_norm 1.4374 (2.1087)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][310/625]\teta 0:00:11 lr 0.000303\t wd 0.0100\ttime 0.0323 (0.0357)\tloss 0.6436 (0.5171)\tgrad_norm 2.3943 (2.1108)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][320/625]\teta 0:00:10 lr 0.000303\t wd 0.0100\ttime 0.0323 (0.0356)\tloss 0.4993 (0.5172)\tgrad_norm 2.9747 (2.1107)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][330/625]\teta 0:00:10 lr 0.000302\t wd 0.0100\ttime 0.0324 (0.0356)\tloss 0.4021 (0.5174)\tgrad_norm 1.6709 (2.1092)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][340/625]\teta 0:00:10 lr 0.000302\t wd 0.0100\ttime 0.0397 (0.0356)\tloss 0.5063 (0.5165)\tgrad_norm 2.4919 (2.1092)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][350/625]\teta 0:00:09 lr 0.000302\t wd 0.0100\ttime 0.0323 (0.0356)\tloss 0.5156 (0.5148)\tgrad_norm 1.8601 (2.1045)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][360/625]\teta 0:00:09 lr 0.000302\t wd 0.0100\ttime 0.0393 (0.0356)\tloss 0.5811 (0.5140)\tgrad_norm 2.9323 (2.1047)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][370/625]\teta 0:00:09 lr 0.000301\t wd 0.0100\ttime 0.0355 (0.0356)\tloss 0.6060 (0.5143)\tgrad_norm 2.0709 (2.1053)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][380/625]\teta 0:00:08 lr 0.000301\t wd 0.0100\ttime 0.0326 (0.0355)\tloss 0.7393 (0.5158)\tgrad_norm 1.8972 (2.1045)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][390/625]\teta 0:00:08 lr 0.000301\t wd 0.0100\ttime 0.0399 (0.0356)\tloss 0.4009 (0.5160)\tgrad_norm 1.6872 (2.1026)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][400/625]\teta 0:00:08 lr 0.000301\t wd 0.0100\ttime 0.0361 (0.0356)\tloss 0.5317 (0.5167)\tgrad_norm 2.5131 (2.1071)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][410/625]\teta 0:00:07 lr 0.000300\t wd 0.0100\ttime 0.0326 (0.0356)\tloss 0.3975 (0.5160)\tgrad_norm 1.7715 (2.1026)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][420/625]\teta 0:00:07 lr 0.000300\t wd 0.0100\ttime 0.0328 (0.0356)\tloss 0.5020 (0.5160)\tgrad_norm 2.0910 (2.1024)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][430/625]\teta 0:00:06 lr 0.000300\t wd 0.0100\ttime 0.0324 (0.0356)\tloss 0.6069 (0.5162)\tgrad_norm 2.6145 (2.1029)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][440/625]\teta 0:00:06 lr 0.000300\t wd 0.0100\ttime 0.0329 (0.0356)\tloss 0.3696 (0.5165)\tgrad_norm 1.9837 (2.1029)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][450/625]\teta 0:00:06 lr 0.000299\t wd 0.0100\ttime 0.0352 (0.0356)\tloss 0.6055 (0.5171)\tgrad_norm 2.1136 (2.1025)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][460/625]\teta 0:00:05 lr 0.000299\t wd 0.0100\ttime 0.0329 (0.0356)\tloss 0.5625 (0.5191)\tgrad_norm 1.9305 (2.1066)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][470/625]\teta 0:00:05 lr 0.000299\t wd 0.0100\ttime 0.0357 (0.0355)\tloss 0.3508 (0.5198)\tgrad_norm 1.5452 (2.1071)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][480/625]\teta 0:00:05 lr 0.000299\t wd 0.0100\ttime 0.0393 (0.0356)\tloss 0.4763 (0.5209)\tgrad_norm 1.9824 (2.1074)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][490/625]\teta 0:00:04 lr 0.000299\t wd 0.0100\ttime 0.0327 (0.0356)\tloss 0.5693 (0.5224)\tgrad_norm 2.9637 (2.1109)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][500/625]\teta 0:00:04 lr 0.000298\t wd 0.0100\ttime 0.0324 (0.0356)\tloss 0.3953 (0.5224)\tgrad_norm 1.4120 (2.1092)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][510/625]\teta 0:00:04 lr 0.000298\t wd 0.0100\ttime 0.0330 (0.0355)\tloss 0.4048 (0.5221)\tgrad_norm 2.0783 (2.1077)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][520/625]\teta 0:00:03 lr 0.000298\t wd 0.0100\ttime 0.0362 (0.0356)\tloss 0.5308 (0.5220)\tgrad_norm 2.4893 (2.1054)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][530/625]\teta 0:00:03 lr 0.000298\t wd 0.0100\ttime 0.0398 (0.0356)\tloss 0.4692 (0.5223)\tgrad_norm 1.8933 (2.1038)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][540/625]\teta 0:00:03 lr 0.000297\t wd 0.0100\ttime 0.0350 (0.0356)\tloss 0.7466 (0.5236)\tgrad_norm 2.3160 (2.1075)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][550/625]\teta 0:00:02 lr 0.000297\t wd 0.0100\ttime 0.0326 (0.0356)\tloss 0.6216 (0.5228)\tgrad_norm 2.0103 (2.1036)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][560/625]\teta 0:00:02 lr 0.000297\t wd 0.0100\ttime 0.0394 (0.0356)\tloss 0.5239 (0.5221)\tgrad_norm 2.1450 (2.1004)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][570/625]\teta 0:00:01 lr 0.000297\t wd 0.0100\ttime 0.0329 (0.0356)\tloss 0.6084 (0.5224)\tgrad_norm 1.8609 (2.1017)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][580/625]\teta 0:00:01 lr 0.000296\t wd 0.0100\ttime 0.0365 (0.0356)\tloss 0.5771 (0.5221)\tgrad_norm 2.1011 (2.1022)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][590/625]\teta 0:00:01 lr 0.000296\t wd 0.0100\ttime 0.0326 (0.0356)\tloss 0.6328 (0.5215)\tgrad_norm 2.5657 (2.0987)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][600/625]\teta 0:00:00 lr 0.000296\t wd 0.0100\ttime 0.0340 (0.0355)\tloss 0.7070 (0.5218)\tgrad_norm 2.1044 (2.0961)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][610/625]\teta 0:00:00 lr 0.000296\t wd 0.0100\ttime 0.0366 (0.0355)\tloss 0.5249 (0.5217)\tgrad_norm 2.2099 (2.0976)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [64/100][620/625]\teta 0:00:00 lr 0.000296\t wd 0.0100\ttime 0.0330 (0.0356)\tloss 0.4060 (0.5222)\tgrad_norm 2.0622 (2.1002)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 64 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_64.pth saving......\n",
      "./model_save/ckpt_epoch_64.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.6870 (0.6870)\tAcc@1 79.688 (79.688)\tAcc@5 92.188 (92.188)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.016)\tLoss 0.6958 (0.6114)\tAcc@1 76.562 (77.983)\tAcc@5 98.438 (98.153)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.016 (0.016)\tLoss 0.6226 (0.5984)\tAcc@1 76.562 (77.976)\tAcc@5 100.000 (98.438)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.016 (0.016)\tLoss 0.4324 (0.5738)\tAcc@1 87.500 (79.637)\tAcc@5 98.438 (98.438)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.016)\tLoss 0.6772 (0.5923)\tAcc@1 79.688 (79.268)\tAcc@5 98.438 (98.590)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.016)\tLoss 0.6792 (0.5913)\tAcc@1 75.000 (79.228)\tAcc@5 100.000 (98.805)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.016 (0.016)\tLoss 0.6152 (0.6102)\tAcc@1 81.250 (78.637)\tAcc@5 98.438 (98.847)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.016 (0.016)\tLoss 0.5376 (0.6230)\tAcc@1 81.250 (78.103)\tAcc@5 98.438 (98.922)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.016 (0.016)\tLoss 0.5674 (0.6080)\tAcc@1 78.125 (78.646)\tAcc@5 100.000 (98.939)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.016)\tLoss 0.8101 (0.6111)\tAcc@1 73.438 (78.674)\tAcc@5 96.875 (98.987)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.016)\tLoss 0.5522 (0.6141)\tAcc@1 79.688 (78.527)\tAcc@5 100.000 (98.963)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.016)\tLoss 0.5752 (0.6135)\tAcc@1 79.688 (78.547)\tAcc@5 100.000 (98.986)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.016)\tLoss 0.3994 (0.6148)\tAcc@1 85.938 (78.474)\tAcc@5 100.000 (99.006)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.4634 (0.6154)\tAcc@1 79.688 (78.471)\tAcc@5 98.438 (99.034)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.5796 (0.6122)\tAcc@1 82.812 (78.613)\tAcc@5 98.438 (98.992)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.5210 (0.6073)\tAcc@1 84.375 (78.798)\tAcc@5 98.438 (98.976)\tMem 455MB\n",
      " * Acc@1 78.760 Acc@5 98.970\n",
      "Accuracy of the network on the 10000 test images: 78.8%\n",
      "Max accuracy: 78.76%\n",
      "Train: [65/100][0/625]\teta 0:00:24 lr 0.000295\t wd 0.0100\ttime 0.0395 (0.0395)\tloss 0.5391 (0.5391)\tgrad_norm 2.1913 (2.1913)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [65/100][10/625]\teta 0:00:22 lr 0.000295\t wd 0.0100\ttime 0.0359 (0.0367)\tloss 0.5962 (0.5401)\tgrad_norm 2.5997 (2.1988)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [65/100][20/625]\teta 0:00:21 lr 0.000295\t wd 0.0100\ttime 0.0392 (0.0361)\tloss 0.4673 (0.5243)\tgrad_norm 2.0430 (2.1266)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [65/100][30/625]\teta 0:00:21 lr 0.000295\t wd 0.0100\ttime 0.0324 (0.0358)\tloss 0.4741 (0.5242)\tgrad_norm 1.8081 (2.1026)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [65/100][40/625]\teta 0:00:21 lr 0.000294\t wd 0.0100\ttime 0.0358 (0.0362)\tloss 0.5781 (0.5234)\tgrad_norm 2.3920 (2.0846)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [65/100][50/625]\teta 0:00:20 lr 0.000294\t wd 0.0100\ttime 0.0395 (0.0363)\tloss 0.7485 (0.5285)\tgrad_norm 2.3025 (2.0952)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [65/100][60/625]\teta 0:00:20 lr 0.000294\t wd 0.0100\ttime 0.0355 (0.0361)\tloss 0.3364 (0.5208)\tgrad_norm 1.2856 (2.0875)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [65/100][70/625]\teta 0:00:19 lr 0.000294\t wd 0.0100\ttime 0.0329 (0.0360)\tloss 0.4080 (0.5121)\tgrad_norm 2.1079 (2.0799)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [65/100][80/625]\teta 0:00:19 lr 0.000294\t wd 0.0100\ttime 0.0334 (0.0357)\tloss 0.4001 (0.5100)\tgrad_norm 2.0505 (2.1086)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [65/100][90/625]\teta 0:00:19 lr 0.000293\t wd 0.0100\ttime 0.0368 (0.0358)\tloss 0.6187 (0.5144)\tgrad_norm 2.3185 (2.1235)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [65/100][100/625]\teta 0:00:18 lr 0.000293\t wd 0.0100\ttime 0.0367 (0.0361)\tloss 0.5840 (0.5182)\tgrad_norm 2.4682 (2.1374)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [65/100][110/625]\teta 0:00:18 lr 0.000293\t wd 0.0100\ttime 0.0357 (0.0361)\tloss 0.4812 (0.5169)\tgrad_norm 2.1622 (2.1433)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [65/100][120/625]\teta 0:00:18 lr 0.000293\t wd 0.0100\ttime 0.0403 (0.0362)\tloss 0.4136 (0.5174)\tgrad_norm 1.5476 (2.1360)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [65/100][130/625]\teta 0:00:17 lr 0.000292\t wd 0.0100\ttime 0.0389 (0.0363)\tloss 0.4856 (0.5123)\tgrad_norm 2.1912 (2.1194)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [65/100][140/625]\teta 0:00:17 lr 0.000292\t wd 0.0100\ttime 0.0399 (0.0363)\tloss 0.7158 (0.5117)\tgrad_norm 2.5120 (2.1222)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [65/100][150/625]\teta 0:00:17 lr 0.000292\t wd 0.0100\ttime 0.0332 (0.0363)\tloss 0.6880 (0.5115)\tgrad_norm 2.1848 (nan)\tloss_scale 32768.0000 (32985.0066)\tmem 455MB\n",
      "Train: [65/100][160/625]\teta 0:00:16 lr 0.000292\t wd 0.0100\ttime 0.0371 (0.0363)\tloss 0.6562 (0.5092)\tgrad_norm 2.2497 (nan)\tloss_scale 32768.0000 (32971.5280)\tmem 455MB\n",
      "Train: [65/100][170/625]\teta 0:00:16 lr 0.000291\t wd 0.0100\ttime 0.0329 (0.0364)\tloss 0.3855 (0.5062)\tgrad_norm 2.0457 (nan)\tloss_scale 32768.0000 (32959.6257)\tmem 455MB\n",
      "Train: [65/100][180/625]\teta 0:00:16 lr 0.000291\t wd 0.0100\ttime 0.0329 (0.0362)\tloss 0.4746 (0.5063)\tgrad_norm 2.1924 (nan)\tloss_scale 32768.0000 (32949.0387)\tmem 455MB\n",
      "Train: [65/100][190/625]\teta 0:00:15 lr 0.000291\t wd 0.0100\ttime 0.0366 (0.0361)\tloss 0.4309 (0.5035)\tgrad_norm 2.9356 (nan)\tloss_scale 32768.0000 (32939.5602)\tmem 455MB\n",
      "Train: [65/100][200/625]\teta 0:00:15 lr 0.000291\t wd 0.0100\ttime 0.0333 (0.0360)\tloss 0.3669 (0.5011)\tgrad_norm 1.7023 (nan)\tloss_scale 32768.0000 (32931.0249)\tmem 455MB\n",
      "Train: [65/100][210/625]\teta 0:00:14 lr 0.000291\t wd 0.0100\ttime 0.0398 (0.0360)\tloss 0.3174 (0.5018)\tgrad_norm 1.5461 (nan)\tloss_scale 32768.0000 (32923.2986)\tmem 455MB\n",
      "Train: [65/100][220/625]\teta 0:00:14 lr 0.000290\t wd 0.0100\ttime 0.0358 (0.0360)\tloss 0.5933 (0.5052)\tgrad_norm 2.7169 (nan)\tloss_scale 32768.0000 (32916.2715)\tmem 455MB\n",
      "Train: [65/100][230/625]\teta 0:00:14 lr 0.000290\t wd 0.0100\ttime 0.0386 (0.0360)\tloss 0.4326 (0.5055)\tgrad_norm 1.8687 (nan)\tloss_scale 32768.0000 (32909.8528)\tmem 455MB\n",
      "Train: [65/100][240/625]\teta 0:00:13 lr 0.000290\t wd 0.0100\ttime 0.0359 (0.0361)\tloss 0.4836 (0.5042)\tgrad_norm 1.7078 (nan)\tloss_scale 32768.0000 (32903.9668)\tmem 455MB\n",
      "Train: [65/100][250/625]\teta 0:00:13 lr 0.000290\t wd 0.0100\ttime 0.0358 (0.0361)\tloss 0.5391 (0.5032)\tgrad_norm 2.1923 (nan)\tloss_scale 32768.0000 (32898.5498)\tmem 455MB\n",
      "Train: [65/100][260/625]\teta 0:00:13 lr 0.000289\t wd 0.0100\ttime 0.0323 (0.0361)\tloss 0.3547 (0.5038)\tgrad_norm 1.3705 (nan)\tloss_scale 32768.0000 (32893.5479)\tmem 455MB\n",
      "Train: [65/100][270/625]\teta 0:00:12 lr 0.000289\t wd 0.0100\ttime 0.0330 (0.0361)\tloss 0.3284 (0.5041)\tgrad_norm 1.4911 (nan)\tloss_scale 32768.0000 (32888.9151)\tmem 455MB\n",
      "Train: [65/100][280/625]\teta 0:00:12 lr 0.000289\t wd 0.0100\ttime 0.0385 (0.0361)\tloss 0.4180 (0.5033)\tgrad_norm 2.1603 (nan)\tloss_scale 32768.0000 (32884.6121)\tmem 455MB\n",
      "Train: [65/100][290/625]\teta 0:00:12 lr 0.000289\t wd 0.0100\ttime 0.0394 (0.0360)\tloss 0.5430 (0.5033)\tgrad_norm 1.9905 (nan)\tloss_scale 32768.0000 (32880.6048)\tmem 455MB\n",
      "Train: [65/100][300/625]\teta 0:00:11 lr 0.000288\t wd 0.0100\ttime 0.0324 (0.0360)\tloss 0.4497 (0.5033)\tgrad_norm 1.7647 (nan)\tloss_scale 32768.0000 (32876.8638)\tmem 455MB\n",
      "Train: [65/100][310/625]\teta 0:00:11 lr 0.000288\t wd 0.0100\ttime 0.0378 (0.0360)\tloss 0.4597 (0.5028)\tgrad_norm 2.2881 (nan)\tloss_scale 32768.0000 (32873.3633)\tmem 455MB\n",
      "Train: [65/100][320/625]\teta 0:00:10 lr 0.000288\t wd 0.0100\ttime 0.0377 (0.0360)\tloss 0.4712 (0.5038)\tgrad_norm 2.0383 (nan)\tloss_scale 32768.0000 (32870.0810)\tmem 455MB\n",
      "Train: [65/100][330/625]\teta 0:00:10 lr 0.000288\t wd 0.0100\ttime 0.0355 (0.0360)\tloss 0.6094 (0.5058)\tgrad_norm 2.5844 (nan)\tloss_scale 32768.0000 (32866.9970)\tmem 455MB\n",
      "Train: [65/100][340/625]\teta 0:00:10 lr 0.000288\t wd 0.0100\ttime 0.0352 (0.0360)\tloss 0.6123 (0.5060)\tgrad_norm 1.9133 (nan)\tloss_scale 32768.0000 (32864.0938)\tmem 455MB\n",
      "Train: [65/100][350/625]\teta 0:00:09 lr 0.000287\t wd 0.0100\ttime 0.0329 (0.0359)\tloss 0.4470 (0.5062)\tgrad_norm 1.6457 (nan)\tloss_scale 32768.0000 (32861.3561)\tmem 455MB\n",
      "Train: [65/100][360/625]\teta 0:00:09 lr 0.000287\t wd 0.0100\ttime 0.0333 (0.0360)\tloss 0.5376 (0.5063)\tgrad_norm 2.4503 (nan)\tloss_scale 32768.0000 (32858.7701)\tmem 455MB\n",
      "Train: [65/100][370/625]\teta 0:00:09 lr 0.000287\t wd 0.0100\ttime 0.0387 (0.0360)\tloss 0.4751 (0.5078)\tgrad_norm 2.2138 (nan)\tloss_scale 32768.0000 (32856.3235)\tmem 455MB\n",
      "Train: [65/100][380/625]\teta 0:00:08 lr 0.000287\t wd 0.0100\ttime 0.0368 (0.0360)\tloss 0.6133 (0.5098)\tgrad_norm 2.4334 (nan)\tloss_scale 32768.0000 (32854.0052)\tmem 455MB\n",
      "Train: [65/100][390/625]\teta 0:00:08 lr 0.000286\t wd 0.0100\ttime 0.0352 (0.0360)\tloss 0.5005 (0.5098)\tgrad_norm 1.8528 (nan)\tloss_scale 32768.0000 (32851.8056)\tmem 455MB\n",
      "Train: [65/100][400/625]\teta 0:00:08 lr 0.000286\t wd 0.0100\ttime 0.0328 (0.0360)\tloss 0.5127 (0.5097)\tgrad_norm 2.1960 (nan)\tloss_scale 32768.0000 (32849.7157)\tmem 455MB\n",
      "Train: [65/100][410/625]\teta 0:00:07 lr 0.000286\t wd 0.0100\ttime 0.0355 (0.0360)\tloss 0.6836 (0.5094)\tgrad_norm 2.5397 (nan)\tloss_scale 32768.0000 (32847.7275)\tmem 455MB\n",
      "Train: [65/100][420/625]\teta 0:00:07 lr 0.000286\t wd 0.0100\ttime 0.0326 (0.0359)\tloss 0.4724 (0.5101)\tgrad_norm 2.5062 (nan)\tloss_scale 32768.0000 (32845.8337)\tmem 455MB\n",
      "Train: [65/100][430/625]\teta 0:00:07 lr 0.000285\t wd 0.0100\ttime 0.0340 (0.0359)\tloss 0.5693 (0.5106)\tgrad_norm 2.0092 (nan)\tloss_scale 32768.0000 (32844.0278)\tmem 455MB\n",
      "Train: [65/100][440/625]\teta 0:00:06 lr 0.000285\t wd 0.0100\ttime 0.0356 (0.0359)\tloss 0.3022 (0.5094)\tgrad_norm 1.7740 (nan)\tloss_scale 32768.0000 (32842.3039)\tmem 455MB\n",
      "Train: [65/100][450/625]\teta 0:00:06 lr 0.000285\t wd 0.0100\ttime 0.0370 (0.0359)\tloss 0.4705 (0.5083)\tgrad_norm 1.8728 (nan)\tloss_scale 32768.0000 (32840.6563)\tmem 455MB\n",
      "Train: [65/100][460/625]\teta 0:00:05 lr 0.000285\t wd 0.0100\ttime 0.0359 (0.0360)\tloss 0.6284 (0.5078)\tgrad_norm 2.8214 (nan)\tloss_scale 32768.0000 (32839.0803)\tmem 455MB\n",
      "Train: [65/100][470/625]\teta 0:00:05 lr 0.000285\t wd 0.0100\ttime 0.0352 (0.0360)\tloss 0.5039 (0.5086)\tgrad_norm 2.3888 (nan)\tloss_scale 32768.0000 (32837.5711)\tmem 455MB\n",
      "Train: [65/100][480/625]\teta 0:00:05 lr 0.000284\t wd 0.0100\ttime 0.0351 (0.0360)\tloss 0.5977 (0.5106)\tgrad_norm 2.4146 (nan)\tloss_scale 32768.0000 (32836.1247)\tmem 455MB\n",
      "Train: [65/100][490/625]\teta 0:00:04 lr 0.000284\t wd 0.0100\ttime 0.0328 (0.0360)\tloss 0.6475 (0.5104)\tgrad_norm 2.5116 (nan)\tloss_scale 32768.0000 (32834.7373)\tmem 455MB\n",
      "Train: [65/100][500/625]\teta 0:00:04 lr 0.000284\t wd 0.0100\ttime 0.0357 (0.0360)\tloss 0.6343 (0.5117)\tgrad_norm 2.4555 (nan)\tloss_scale 32768.0000 (32833.4052)\tmem 455MB\n",
      "Train: [65/100][510/625]\teta 0:00:04 lr 0.000284\t wd 0.0100\ttime 0.0329 (0.0360)\tloss 0.4209 (0.5107)\tgrad_norm 1.6299 (nan)\tloss_scale 32768.0000 (32832.1252)\tmem 455MB\n",
      "Train: [65/100][520/625]\teta 0:00:03 lr 0.000283\t wd 0.0100\ttime 0.0332 (0.0359)\tloss 0.4263 (0.5099)\tgrad_norm 2.4732 (nan)\tloss_scale 32768.0000 (32830.8944)\tmem 455MB\n",
      "Train: [65/100][530/625]\teta 0:00:03 lr 0.000283\t wd 0.0100\ttime 0.0364 (0.0359)\tloss 0.4663 (0.5099)\tgrad_norm 2.2661 (nan)\tloss_scale 32768.0000 (32829.7100)\tmem 455MB\n",
      "Train: [65/100][540/625]\teta 0:00:03 lr 0.000283\t wd 0.0100\ttime 0.0334 (0.0359)\tloss 0.4316 (0.5099)\tgrad_norm 2.1531 (nan)\tloss_scale 32768.0000 (32828.5693)\tmem 455MB\n",
      "Train: [65/100][550/625]\teta 0:00:02 lr 0.000283\t wd 0.0100\ttime 0.0336 (0.0359)\tloss 0.3716 (0.5092)\tgrad_norm 2.0498 (nan)\tloss_scale 32768.0000 (32827.4701)\tmem 455MB\n",
      "Train: [65/100][560/625]\teta 0:00:02 lr 0.000282\t wd 0.0100\ttime 0.0377 (0.0359)\tloss 0.6816 (0.5102)\tgrad_norm 2.3325 (nan)\tloss_scale 32768.0000 (32826.4100)\tmem 455MB\n",
      "Train: [65/100][570/625]\teta 0:00:01 lr 0.000282\t wd 0.0100\ttime 0.0324 (0.0359)\tloss 0.5728 (0.5099)\tgrad_norm 2.5479 (nan)\tloss_scale 32768.0000 (32825.3870)\tmem 455MB\n",
      "Train: [65/100][580/625]\teta 0:00:01 lr 0.000282\t wd 0.0100\ttime 0.0330 (0.0358)\tloss 0.3972 (0.5089)\tgrad_norm 1.4527 (nan)\tloss_scale 32768.0000 (32824.3993)\tmem 455MB\n",
      "Train: [65/100][590/625]\teta 0:00:01 lr 0.000282\t wd 0.0100\ttime 0.0328 (0.0358)\tloss 0.4373 (0.5082)\tgrad_norm 1.6578 (nan)\tloss_scale 32768.0000 (32823.4450)\tmem 455MB\n",
      "Train: [65/100][600/625]\teta 0:00:00 lr 0.000282\t wd 0.0100\ttime 0.0343 (0.0358)\tloss 0.4714 (0.5084)\tgrad_norm 2.0355 (nan)\tloss_scale 32768.0000 (32822.5225)\tmem 455MB\n",
      "Train: [65/100][610/625]\teta 0:00:00 lr 0.000281\t wd 0.0100\ttime 0.0327 (0.0358)\tloss 0.5830 (0.5085)\tgrad_norm 3.1603 (nan)\tloss_scale 32768.0000 (32821.6301)\tmem 455MB\n",
      "Train: [65/100][620/625]\teta 0:00:00 lr 0.000281\t wd 0.0100\ttime 0.0346 (0.0357)\tloss 0.5791 (0.5086)\tgrad_norm 2.6920 (nan)\tloss_scale 32768.0000 (32820.7665)\tmem 455MB\n",
      "EPOCH 65 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_65.pth saving......\n",
      "./model_save/ckpt_epoch_65.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.5171 (0.5171)\tAcc@1 78.125 (78.125)\tAcc@5 98.438 (98.438)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.7344 (0.6727)\tAcc@1 75.000 (76.705)\tAcc@5 96.875 (98.722)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.5020 (0.6406)\tAcc@1 81.250 (77.009)\tAcc@5 98.438 (98.810)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.7178 (0.6318)\tAcc@1 68.750 (77.218)\tAcc@5 93.750 (98.639)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.5146 (0.6235)\tAcc@1 76.562 (77.439)\tAcc@5 100.000 (98.780)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.4441 (0.6264)\tAcc@1 84.375 (77.574)\tAcc@5 100.000 (98.713)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.4558 (0.6273)\tAcc@1 81.250 (77.715)\tAcc@5 100.000 (98.745)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.8296 (0.6271)\tAcc@1 76.562 (77.773)\tAcc@5 98.438 (98.834)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.016 (0.015)\tLoss 0.6987 (0.6232)\tAcc@1 73.438 (77.855)\tAcc@5 98.438 (98.881)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.4365 (0.6143)\tAcc@1 87.500 (78.314)\tAcc@5 98.438 (98.815)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.8569 (0.6240)\tAcc@1 71.875 (78.048)\tAcc@5 98.438 (98.809)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.5171 (0.6169)\tAcc@1 82.812 (78.392)\tAcc@5 100.000 (98.789)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.6250 (0.6169)\tAcc@1 82.812 (78.538)\tAcc@5 100.000 (98.760)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.4836 (0.6188)\tAcc@1 81.250 (78.471)\tAcc@5 100.000 (98.819)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.4119 (0.6182)\tAcc@1 87.500 (78.579)\tAcc@5 100.000 (98.836)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.7939 (0.6189)\tAcc@1 75.000 (78.632)\tAcc@5 98.438 (98.800)\tMem 455MB\n",
      " * Acc@1 78.740 Acc@5 98.810\n",
      "Accuracy of the network on the 10000 test images: 78.7%\n",
      "Max accuracy: 78.76%\n",
      "Train: [66/100][0/625]\teta 0:00:23 lr 0.000281\t wd 0.0100\ttime 0.0384 (0.0384)\tloss 0.7480 (0.7480)\tgrad_norm 2.5930 (2.5930)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][10/625]\teta 0:00:22 lr 0.000281\t wd 0.0100\ttime 0.0324 (0.0362)\tloss 0.5278 (0.5086)\tgrad_norm 2.5910 (2.3313)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][20/625]\teta 0:00:21 lr 0.000281\t wd 0.0100\ttime 0.0362 (0.0360)\tloss 0.5303 (0.5017)\tgrad_norm 2.0356 (2.2473)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][30/625]\teta 0:00:21 lr 0.000280\t wd 0.0100\ttime 0.0357 (0.0360)\tloss 0.6836 (0.5215)\tgrad_norm 2.8884 (2.2614)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][40/625]\teta 0:00:21 lr 0.000280\t wd 0.0100\ttime 0.0324 (0.0361)\tloss 0.3340 (0.5067)\tgrad_norm 1.8991 (2.1862)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][50/625]\teta 0:00:20 lr 0.000280\t wd 0.0100\ttime 0.0368 (0.0358)\tloss 0.4956 (0.4970)\tgrad_norm 2.2850 (2.1625)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][60/625]\teta 0:00:20 lr 0.000280\t wd 0.0100\ttime 0.0355 (0.0356)\tloss 0.6104 (0.5077)\tgrad_norm 2.4328 (2.1978)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][70/625]\teta 0:00:19 lr 0.000279\t wd 0.0100\ttime 0.0338 (0.0358)\tloss 0.4990 (0.5216)\tgrad_norm 1.7001 (2.2167)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][80/625]\teta 0:00:19 lr 0.000279\t wd 0.0100\ttime 0.0351 (0.0358)\tloss 0.4224 (0.5173)\tgrad_norm 2.0723 (2.1994)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][90/625]\teta 0:00:19 lr 0.000279\t wd 0.0100\ttime 0.0362 (0.0358)\tloss 0.7734 (0.5169)\tgrad_norm 3.4657 (2.2084)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][100/625]\teta 0:00:18 lr 0.000279\t wd 0.0100\ttime 0.0353 (0.0358)\tloss 0.5386 (0.5108)\tgrad_norm 2.2925 (2.1813)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][110/625]\teta 0:00:18 lr 0.000278\t wd 0.0100\ttime 0.0358 (0.0358)\tloss 0.5269 (0.5090)\tgrad_norm 2.1910 (2.1695)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][120/625]\teta 0:00:18 lr 0.000278\t wd 0.0100\ttime 0.0326 (0.0358)\tloss 0.4546 (0.5083)\tgrad_norm 1.3924 (2.1481)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][130/625]\teta 0:00:17 lr 0.000278\t wd 0.0100\ttime 0.0327 (0.0357)\tloss 0.5498 (0.5093)\tgrad_norm 2.9638 (2.1545)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][140/625]\teta 0:00:17 lr 0.000278\t wd 0.0100\ttime 0.0385 (0.0358)\tloss 0.5938 (0.5107)\tgrad_norm 1.9497 (2.1614)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][150/625]\teta 0:00:17 lr 0.000278\t wd 0.0100\ttime 0.0359 (0.0358)\tloss 0.5024 (0.5117)\tgrad_norm 1.8285 (2.1590)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][160/625]\teta 0:00:16 lr 0.000277\t wd 0.0100\ttime 0.0356 (0.0357)\tloss 0.5176 (0.5134)\tgrad_norm 2.9181 (2.1663)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][170/625]\teta 0:00:16 lr 0.000277\t wd 0.0100\ttime 0.0397 (0.0357)\tloss 0.4727 (0.5141)\tgrad_norm 1.9494 (2.1594)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][180/625]\teta 0:00:15 lr 0.000277\t wd 0.0100\ttime 0.0354 (0.0358)\tloss 0.4180 (0.5141)\tgrad_norm 2.1106 (2.1564)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][190/625]\teta 0:00:15 lr 0.000277\t wd 0.0100\ttime 0.0326 (0.0358)\tloss 0.5405 (0.5129)\tgrad_norm 1.8099 (2.1510)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][200/625]\teta 0:00:15 lr 0.000276\t wd 0.0100\ttime 0.0398 (0.0357)\tloss 0.4773 (0.5143)\tgrad_norm 1.9328 (2.1461)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][210/625]\teta 0:00:14 lr 0.000276\t wd 0.0100\ttime 0.0328 (0.0357)\tloss 0.6118 (0.5117)\tgrad_norm 3.6667 (2.1426)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][220/625]\teta 0:00:14 lr 0.000276\t wd 0.0100\ttime 0.0392 (0.0357)\tloss 0.4937 (0.5097)\tgrad_norm 2.0763 (2.1350)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][230/625]\teta 0:00:14 lr 0.000276\t wd 0.0100\ttime 0.0328 (0.0357)\tloss 0.7305 (0.5124)\tgrad_norm 2.8315 (2.1436)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][240/625]\teta 0:00:13 lr 0.000276\t wd 0.0100\ttime 0.0327 (0.0358)\tloss 0.5889 (0.5129)\tgrad_norm 2.4265 (2.1360)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][250/625]\teta 0:00:13 lr 0.000275\t wd 0.0100\ttime 0.0357 (0.0357)\tloss 0.5669 (0.5143)\tgrad_norm 2.2154 (2.1408)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][260/625]\teta 0:00:13 lr 0.000275\t wd 0.0100\ttime 0.0337 (0.0358)\tloss 0.5444 (0.5130)\tgrad_norm 1.7670 (2.1271)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][270/625]\teta 0:00:12 lr 0.000275\t wd 0.0100\ttime 0.0324 (0.0357)\tloss 0.5854 (0.5111)\tgrad_norm 1.6893 (2.1204)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][280/625]\teta 0:00:12 lr 0.000275\t wd 0.0100\ttime 0.0360 (0.0357)\tloss 0.4763 (0.5108)\tgrad_norm 2.4235 (2.1252)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][290/625]\teta 0:00:11 lr 0.000274\t wd 0.0100\ttime 0.0393 (0.0358)\tloss 0.5107 (0.5133)\tgrad_norm 1.8394 (2.1278)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][300/625]\teta 0:00:11 lr 0.000274\t wd 0.0100\ttime 0.0328 (0.0358)\tloss 0.4839 (0.5119)\tgrad_norm 2.1568 (2.1212)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][310/625]\teta 0:00:11 lr 0.000274\t wd 0.0100\ttime 0.0327 (0.0358)\tloss 0.4551 (0.5102)\tgrad_norm 2.0552 (2.1167)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][320/625]\teta 0:00:10 lr 0.000274\t wd 0.0100\ttime 0.0347 (0.0358)\tloss 0.4380 (0.5103)\tgrad_norm 2.2960 (2.1186)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][330/625]\teta 0:00:10 lr 0.000273\t wd 0.0100\ttime 0.0329 (0.0358)\tloss 0.6626 (0.5104)\tgrad_norm 2.3996 (2.1193)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][340/625]\teta 0:00:10 lr 0.000273\t wd 0.0100\ttime 0.0323 (0.0358)\tloss 0.3340 (0.5092)\tgrad_norm 1.7467 (2.1146)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][350/625]\teta 0:00:09 lr 0.000273\t wd 0.0100\ttime 0.0394 (0.0358)\tloss 0.5479 (0.5069)\tgrad_norm 1.9108 (2.1084)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][360/625]\teta 0:00:09 lr 0.000273\t wd 0.0100\ttime 0.0356 (0.0358)\tloss 0.5010 (0.5056)\tgrad_norm 2.1506 (2.1031)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][370/625]\teta 0:00:09 lr 0.000273\t wd 0.0100\ttime 0.0341 (0.0358)\tloss 0.5786 (0.5063)\tgrad_norm 2.7078 (2.1011)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][380/625]\teta 0:00:08 lr 0.000272\t wd 0.0100\ttime 0.0360 (0.0358)\tloss 0.5596 (0.5060)\tgrad_norm 2.3253 (2.1042)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][390/625]\teta 0:00:08 lr 0.000272\t wd 0.0100\ttime 0.0334 (0.0357)\tloss 0.5688 (0.5065)\tgrad_norm 2.1199 (2.1074)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][400/625]\teta 0:00:08 lr 0.000272\t wd 0.0100\ttime 0.0326 (0.0357)\tloss 0.5806 (0.5075)\tgrad_norm 2.4148 (2.1121)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][410/625]\teta 0:00:07 lr 0.000272\t wd 0.0100\ttime 0.0357 (0.0357)\tloss 0.5381 (0.5071)\tgrad_norm 2.4387 (2.1147)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][420/625]\teta 0:00:07 lr 0.000271\t wd 0.0100\ttime 0.0329 (0.0356)\tloss 0.5190 (0.5078)\tgrad_norm 2.5307 (2.1203)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][430/625]\teta 0:00:06 lr 0.000271\t wd 0.0100\ttime 0.0366 (0.0356)\tloss 0.4285 (0.5078)\tgrad_norm 2.2427 (2.1254)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][440/625]\teta 0:00:06 lr 0.000271\t wd 0.0100\ttime 0.0366 (0.0356)\tloss 0.4678 (0.5078)\tgrad_norm 2.5471 (2.1255)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][450/625]\teta 0:00:06 lr 0.000271\t wd 0.0100\ttime 0.0342 (0.0356)\tloss 0.4902 (0.5069)\tgrad_norm 2.2004 (2.1220)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][460/625]\teta 0:00:05 lr 0.000271\t wd 0.0100\ttime 0.0325 (0.0356)\tloss 0.4551 (0.5066)\tgrad_norm 2.0027 (2.1251)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][470/625]\teta 0:00:05 lr 0.000270\t wd 0.0100\ttime 0.0390 (0.0356)\tloss 0.3391 (0.5071)\tgrad_norm 2.1111 (2.1263)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][480/625]\teta 0:00:05 lr 0.000270\t wd 0.0100\ttime 0.0326 (0.0356)\tloss 0.4045 (0.5074)\tgrad_norm 1.9489 (2.1257)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][490/625]\teta 0:00:04 lr 0.000270\t wd 0.0100\ttime 0.0355 (0.0357)\tloss 0.2228 (0.5071)\tgrad_norm 1.4861 (2.1241)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][500/625]\teta 0:00:04 lr 0.000270\t wd 0.0100\ttime 0.0367 (0.0357)\tloss 0.4819 (0.5064)\tgrad_norm 1.9598 (2.1229)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][510/625]\teta 0:00:04 lr 0.000269\t wd 0.0100\ttime 0.0324 (0.0357)\tloss 0.4661 (0.5066)\tgrad_norm 2.2740 (2.1239)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][520/625]\teta 0:00:03 lr 0.000269\t wd 0.0100\ttime 0.0327 (0.0356)\tloss 0.5415 (0.5063)\tgrad_norm 1.8939 (2.1206)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][530/625]\teta 0:00:03 lr 0.000269\t wd 0.0100\ttime 0.0324 (0.0357)\tloss 0.5347 (0.5070)\tgrad_norm 1.6898 (2.1176)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][540/625]\teta 0:00:03 lr 0.000269\t wd 0.0100\ttime 0.0396 (0.0357)\tloss 0.4033 (0.5064)\tgrad_norm 1.5846 (2.1154)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][550/625]\teta 0:00:02 lr 0.000269\t wd 0.0100\ttime 0.0394 (0.0357)\tloss 0.4897 (0.5058)\tgrad_norm 2.0800 (2.1152)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][560/625]\teta 0:00:02 lr 0.000268\t wd 0.0100\ttime 0.0341 (0.0357)\tloss 0.4958 (0.5065)\tgrad_norm 1.9247 (2.1191)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][570/625]\teta 0:00:01 lr 0.000268\t wd 0.0100\ttime 0.0352 (0.0357)\tloss 0.4609 (0.5067)\tgrad_norm 1.9305 (2.1193)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][580/625]\teta 0:00:01 lr 0.000268\t wd 0.0100\ttime 0.0391 (0.0357)\tloss 0.4773 (0.5063)\tgrad_norm 1.9830 (2.1193)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][590/625]\teta 0:00:01 lr 0.000268\t wd 0.0100\ttime 0.0358 (0.0357)\tloss 0.5771 (0.5071)\tgrad_norm 2.6918 (2.1248)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][600/625]\teta 0:00:00 lr 0.000267\t wd 0.0100\ttime 0.0360 (0.0357)\tloss 0.3599 (0.5065)\tgrad_norm 1.5129 (2.1244)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][610/625]\teta 0:00:00 lr 0.000267\t wd 0.0100\ttime 0.0330 (0.0357)\tloss 0.3906 (0.5061)\tgrad_norm 2.3831 (2.1248)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [66/100][620/625]\teta 0:00:00 lr 0.000267\t wd 0.0100\ttime 0.0339 (0.0357)\tloss 0.3796 (0.5057)\tgrad_norm 2.0793 (2.1221)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 66 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_66.pth saving......\n",
      "./model_save/ckpt_epoch_66.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.7017 (0.7017)\tAcc@1 76.562 (76.562)\tAcc@5 100.000 (100.000)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.6572 (0.6436)\tAcc@1 78.125 (77.131)\tAcc@5 96.875 (98.864)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.6006 (0.6535)\tAcc@1 81.250 (77.009)\tAcc@5 98.438 (99.107)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.6934 (0.6281)\tAcc@1 78.125 (77.823)\tAcc@5 96.875 (98.942)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.7412 (0.6160)\tAcc@1 75.000 (78.201)\tAcc@5 98.438 (98.971)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.5137 (0.6092)\tAcc@1 84.375 (78.646)\tAcc@5 98.438 (98.928)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.7090 (0.6095)\tAcc@1 78.125 (78.612)\tAcc@5 100.000 (98.950)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.016 (0.015)\tLoss 0.7861 (0.6097)\tAcc@1 71.875 (78.675)\tAcc@5 100.000 (99.010)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.4958 (0.6074)\tAcc@1 87.500 (78.916)\tAcc@5 96.875 (98.958)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.8740 (0.6121)\tAcc@1 65.625 (78.640)\tAcc@5 100.000 (98.901)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.3916 (0.6111)\tAcc@1 85.938 (78.744)\tAcc@5 98.438 (98.902)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.2715 (0.6028)\tAcc@1 90.625 (78.998)\tAcc@5 100.000 (98.944)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.5449 (0.5991)\tAcc@1 79.688 (78.977)\tAcc@5 100.000 (99.019)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.7207 (0.6028)\tAcc@1 76.562 (78.853)\tAcc@5 98.438 (98.962)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.5732 (0.6060)\tAcc@1 81.250 (78.856)\tAcc@5 100.000 (98.936)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.5146 (0.6093)\tAcc@1 82.812 (78.746)\tAcc@5 100.000 (98.955)\tMem 455MB\n",
      " * Acc@1 78.710 Acc@5 98.910\n",
      "Accuracy of the network on the 10000 test images: 78.7%\n",
      "Max accuracy: 78.76%\n",
      "Train: [67/100][0/625]\teta 0:00:23 lr 0.000267\t wd 0.0100\ttime 0.0372 (0.0372)\tloss 0.4958 (0.4958)\tgrad_norm 2.1579 (2.1579)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][10/625]\teta 0:00:22 lr 0.000267\t wd 0.0100\ttime 0.0329 (0.0363)\tloss 0.3752 (0.5442)\tgrad_norm 2.1691 (2.0694)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][20/625]\teta 0:00:22 lr 0.000266\t wd 0.0100\ttime 0.0394 (0.0366)\tloss 0.4771 (0.5293)\tgrad_norm 2.2922 (2.0904)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][30/625]\teta 0:00:21 lr 0.000266\t wd 0.0100\ttime 0.0331 (0.0363)\tloss 0.5078 (0.5083)\tgrad_norm 2.5902 (2.0919)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][40/625]\teta 0:00:21 lr 0.000266\t wd 0.0100\ttime 0.0323 (0.0363)\tloss 0.3535 (0.4866)\tgrad_norm 1.7112 (2.0469)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][50/625]\teta 0:00:20 lr 0.000266\t wd 0.0100\ttime 0.0364 (0.0362)\tloss 0.6621 (0.4980)\tgrad_norm 2.3150 (2.0686)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][60/625]\teta 0:00:20 lr 0.000265\t wd 0.0100\ttime 0.0363 (0.0364)\tloss 0.4917 (0.4948)\tgrad_norm 2.2487 (2.0663)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][70/625]\teta 0:00:20 lr 0.000265\t wd 0.0100\ttime 0.0354 (0.0363)\tloss 0.4490 (0.4913)\tgrad_norm 1.5317 (2.0718)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][80/625]\teta 0:00:19 lr 0.000265\t wd 0.0100\ttime 0.0344 (0.0362)\tloss 0.2362 (0.4907)\tgrad_norm 1.6079 (2.0805)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][90/625]\teta 0:00:19 lr 0.000265\t wd 0.0100\ttime 0.0391 (0.0361)\tloss 0.4351 (0.4890)\tgrad_norm 1.8972 (2.0964)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][100/625]\teta 0:00:18 lr 0.000265\t wd 0.0100\ttime 0.0328 (0.0360)\tloss 0.3679 (0.4843)\tgrad_norm 2.2141 (2.1027)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][110/625]\teta 0:00:18 lr 0.000264\t wd 0.0100\ttime 0.0325 (0.0359)\tloss 0.5288 (0.4809)\tgrad_norm 2.7373 (2.1170)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][120/625]\teta 0:00:18 lr 0.000264\t wd 0.0100\ttime 0.0363 (0.0358)\tloss 0.5908 (0.4847)\tgrad_norm 1.9473 (2.1188)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][130/625]\teta 0:00:17 lr 0.000264\t wd 0.0100\ttime 0.0326 (0.0357)\tloss 0.3450 (0.4839)\tgrad_norm 1.9333 (2.1068)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][140/625]\teta 0:00:17 lr 0.000264\t wd 0.0100\ttime 0.0394 (0.0357)\tloss 0.3281 (0.4837)\tgrad_norm 2.0189 (2.1079)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][150/625]\teta 0:00:16 lr 0.000263\t wd 0.0100\ttime 0.0323 (0.0355)\tloss 0.4910 (0.4820)\tgrad_norm 2.2581 (2.1076)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][160/625]\teta 0:00:16 lr 0.000263\t wd 0.0100\ttime 0.0333 (0.0354)\tloss 0.5586 (0.4823)\tgrad_norm 2.6974 (2.1232)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][170/625]\teta 0:00:16 lr 0.000263\t wd 0.0100\ttime 0.0325 (0.0354)\tloss 0.3381 (0.4786)\tgrad_norm 1.6843 (2.1225)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][180/625]\teta 0:00:15 lr 0.000263\t wd 0.0100\ttime 0.0365 (0.0353)\tloss 0.4810 (0.4766)\tgrad_norm 2.0757 (2.1122)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][190/625]\teta 0:00:15 lr 0.000263\t wd 0.0100\ttime 0.0328 (0.0352)\tloss 0.5063 (0.4782)\tgrad_norm 1.8408 (2.1211)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][200/625]\teta 0:00:14 lr 0.000262\t wd 0.0100\ttime 0.0364 (0.0351)\tloss 0.6729 (0.4803)\tgrad_norm 2.3218 (2.1230)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][210/625]\teta 0:00:14 lr 0.000262\t wd 0.0100\ttime 0.0325 (0.0351)\tloss 0.5161 (0.4809)\tgrad_norm 1.8975 (2.1251)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][220/625]\teta 0:00:14 lr 0.000262\t wd 0.0100\ttime 0.0327 (0.0351)\tloss 0.4609 (0.4814)\tgrad_norm 1.9308 (2.1212)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][230/625]\teta 0:00:13 lr 0.000262\t wd 0.0100\ttime 0.0361 (0.0351)\tloss 0.5112 (0.4795)\tgrad_norm 2.2116 (2.1254)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][240/625]\teta 0:00:13 lr 0.000261\t wd 0.0100\ttime 0.0327 (0.0350)\tloss 0.4280 (0.4788)\tgrad_norm 1.7302 (2.1263)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][250/625]\teta 0:00:13 lr 0.000261\t wd 0.0100\ttime 0.0325 (0.0349)\tloss 0.4570 (0.4804)\tgrad_norm 3.0860 (2.1319)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][260/625]\teta 0:00:12 lr 0.000261\t wd 0.0100\ttime 0.0325 (0.0349)\tloss 0.6455 (0.4809)\tgrad_norm 2.3537 (2.1384)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][270/625]\teta 0:00:12 lr 0.000261\t wd 0.0100\ttime 0.0327 (0.0349)\tloss 0.5806 (0.4828)\tgrad_norm 2.1350 (2.1354)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][280/625]\teta 0:00:12 lr 0.000261\t wd 0.0100\ttime 0.0365 (0.0350)\tloss 0.5156 (0.4843)\tgrad_norm 2.3404 (2.1438)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][290/625]\teta 0:00:11 lr 0.000260\t wd 0.0100\ttime 0.0322 (0.0349)\tloss 0.7017 (0.4866)\tgrad_norm 2.2009 (2.1505)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][300/625]\teta 0:00:11 lr 0.000260\t wd 0.0100\ttime 0.0326 (0.0350)\tloss 0.4895 (0.4881)\tgrad_norm 2.4174 (2.1486)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][310/625]\teta 0:00:11 lr 0.000260\t wd 0.0100\ttime 0.0379 (0.0351)\tloss 0.4771 (0.4881)\tgrad_norm 1.8125 (2.1448)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][320/625]\teta 0:00:10 lr 0.000260\t wd 0.0100\ttime 0.0324 (0.0351)\tloss 0.5186 (0.4904)\tgrad_norm 2.4770 (2.1468)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][330/625]\teta 0:00:10 lr 0.000259\t wd 0.0100\ttime 0.0323 (0.0351)\tloss 0.3860 (0.4880)\tgrad_norm 1.4844 (2.1466)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][340/625]\teta 0:00:09 lr 0.000259\t wd 0.0100\ttime 0.0352 (0.0351)\tloss 0.3684 (0.4885)\tgrad_norm 1.5775 (2.1448)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][350/625]\teta 0:00:09 lr 0.000259\t wd 0.0100\ttime 0.0360 (0.0351)\tloss 0.4170 (0.4890)\tgrad_norm 2.2582 (2.1448)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][360/625]\teta 0:00:09 lr 0.000259\t wd 0.0100\ttime 0.0361 (0.0351)\tloss 0.4165 (0.4894)\tgrad_norm 1.6160 (2.1464)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][370/625]\teta 0:00:08 lr 0.000259\t wd 0.0100\ttime 0.0326 (0.0351)\tloss 0.3833 (0.4884)\tgrad_norm 1.9142 (2.1453)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][380/625]\teta 0:00:08 lr 0.000258\t wd 0.0100\ttime 0.0358 (0.0351)\tloss 0.5830 (0.4879)\tgrad_norm 1.7786 (2.1423)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][390/625]\teta 0:00:08 lr 0.000258\t wd 0.0100\ttime 0.0332 (0.0352)\tloss 0.7041 (0.4893)\tgrad_norm 2.1878 (2.1504)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][400/625]\teta 0:00:07 lr 0.000258\t wd 0.0100\ttime 0.0328 (0.0352)\tloss 0.4734 (0.4914)\tgrad_norm 2.2828 (2.1517)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][410/625]\teta 0:00:07 lr 0.000258\t wd 0.0100\ttime 0.0329 (0.0352)\tloss 0.3271 (0.4915)\tgrad_norm 1.8772 (2.1547)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][420/625]\teta 0:00:07 lr 0.000257\t wd 0.0100\ttime 0.0326 (0.0352)\tloss 0.3171 (0.4910)\tgrad_norm 2.0798 (2.1533)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][430/625]\teta 0:00:06 lr 0.000257\t wd 0.0100\ttime 0.0350 (0.0352)\tloss 0.5122 (0.4909)\tgrad_norm 2.1769 (2.1498)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][440/625]\teta 0:00:06 lr 0.000257\t wd 0.0100\ttime 0.0365 (0.0353)\tloss 0.5781 (0.4928)\tgrad_norm 2.0726 (2.1504)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][450/625]\teta 0:00:06 lr 0.000257\t wd 0.0100\ttime 0.0361 (0.0353)\tloss 0.4248 (0.4927)\tgrad_norm 2.1326 (2.1527)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][460/625]\teta 0:00:05 lr 0.000257\t wd 0.0100\ttime 0.0361 (0.0353)\tloss 0.4858 (0.4927)\tgrad_norm 2.1595 (2.1508)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][470/625]\teta 0:00:05 lr 0.000256\t wd 0.0100\ttime 0.0356 (0.0353)\tloss 0.5811 (0.4930)\tgrad_norm 2.0372 (2.1540)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][480/625]\teta 0:00:05 lr 0.000256\t wd 0.0100\ttime 0.0357 (0.0353)\tloss 0.4241 (0.4930)\tgrad_norm 1.9711 (2.1509)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][490/625]\teta 0:00:04 lr 0.000256\t wd 0.0100\ttime 0.0361 (0.0353)\tloss 0.2773 (0.4925)\tgrad_norm 1.4481 (2.1467)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][500/625]\teta 0:00:04 lr 0.000256\t wd 0.0100\ttime 0.0335 (0.0353)\tloss 0.6348 (0.4929)\tgrad_norm 3.1402 (2.1527)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][510/625]\teta 0:00:04 lr 0.000255\t wd 0.0100\ttime 0.0381 (0.0353)\tloss 0.4109 (0.4928)\tgrad_norm 1.7013 (2.1543)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][520/625]\teta 0:00:03 lr 0.000255\t wd 0.0100\ttime 0.0342 (0.0353)\tloss 0.4673 (0.4930)\tgrad_norm 1.7963 (2.1508)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][530/625]\teta 0:00:03 lr 0.000255\t wd 0.0100\ttime 0.0321 (0.0352)\tloss 0.3296 (0.4928)\tgrad_norm 1.3825 (2.1505)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][540/625]\teta 0:00:02 lr 0.000255\t wd 0.0100\ttime 0.0357 (0.0352)\tloss 0.3540 (0.4929)\tgrad_norm 1.8556 (2.1480)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][550/625]\teta 0:00:02 lr 0.000255\t wd 0.0100\ttime 0.0326 (0.0352)\tloss 0.7529 (0.4940)\tgrad_norm 2.6994 (2.1501)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][560/625]\teta 0:00:02 lr 0.000254\t wd 0.0100\ttime 0.0355 (0.0351)\tloss 0.7524 (0.4943)\tgrad_norm 2.5717 (2.1477)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][570/625]\teta 0:00:01 lr 0.000254\t wd 0.0100\ttime 0.0362 (0.0351)\tloss 0.3757 (0.4946)\tgrad_norm 1.6602 (2.1463)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][580/625]\teta 0:00:01 lr 0.000254\t wd 0.0100\ttime 0.0358 (0.0351)\tloss 0.3804 (0.4939)\tgrad_norm 1.5322 (2.1423)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][590/625]\teta 0:00:01 lr 0.000254\t wd 0.0100\ttime 0.0325 (0.0351)\tloss 0.6548 (0.4942)\tgrad_norm 2.0358 (2.1384)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][600/625]\teta 0:00:00 lr 0.000253\t wd 0.0100\ttime 0.0329 (0.0351)\tloss 0.3596 (0.4937)\tgrad_norm 2.2666 (2.1360)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][610/625]\teta 0:00:00 lr 0.000253\t wd 0.0100\ttime 0.0392 (0.0351)\tloss 0.2678 (0.4932)\tgrad_norm 1.4907 (2.1341)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [67/100][620/625]\teta 0:00:00 lr 0.000253\t wd 0.0100\ttime 0.0359 (0.0351)\tloss 0.3972 (0.4925)\tgrad_norm 1.6498 (2.1319)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 67 training takes 0:00:21\n",
      "./model_save/ckpt_epoch_67.pth saving......\n",
      "./model_save/ckpt_epoch_67.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.7393 (0.7393)\tAcc@1 79.688 (79.688)\tAcc@5 95.312 (95.312)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.6333 (0.6478)\tAcc@1 71.875 (77.841)\tAcc@5 100.000 (98.864)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.4634 (0.6376)\tAcc@1 79.688 (77.902)\tAcc@5 100.000 (98.884)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.6938 (0.6225)\tAcc@1 68.750 (78.528)\tAcc@5 100.000 (98.891)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.016 (0.015)\tLoss 0.7236 (0.6145)\tAcc@1 75.000 (78.925)\tAcc@5 95.312 (98.628)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.016 (0.015)\tLoss 0.6743 (0.6131)\tAcc@1 81.250 (79.013)\tAcc@5 98.438 (98.652)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.7368 (0.6141)\tAcc@1 78.125 (79.150)\tAcc@5 100.000 (98.719)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.5884 (0.6176)\tAcc@1 78.125 (78.939)\tAcc@5 100.000 (98.658)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.016 (0.015)\tLoss 0.3699 (0.6138)\tAcc@1 89.062 (78.954)\tAcc@5 98.438 (98.746)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.016 (0.015)\tLoss 0.7188 (0.6179)\tAcc@1 79.688 (78.880)\tAcc@5 98.438 (98.729)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.020 (0.015)\tLoss 0.5991 (0.6149)\tAcc@1 75.000 (78.852)\tAcc@5 100.000 (98.747)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.7095 (0.6109)\tAcc@1 75.000 (79.012)\tAcc@5 93.750 (98.705)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.6016 (0.6076)\tAcc@1 75.000 (79.093)\tAcc@5 96.875 (98.709)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.4910 (0.6126)\tAcc@1 85.938 (79.043)\tAcc@5 98.438 (98.700)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.8320 (0.6120)\tAcc@1 68.750 (79.023)\tAcc@5 95.312 (98.681)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.4712 (0.6078)\tAcc@1 85.938 (79.191)\tAcc@5 100.000 (98.769)\tMem 455MB\n",
      " * Acc@1 79.240 Acc@5 98.760\n",
      "Accuracy of the network on the 10000 test images: 79.2%\n",
      "Max accuracy: 79.24%\n",
      "Train: [68/100][0/625]\teta 0:00:23 lr 0.000253\t wd 0.0100\ttime 0.0370 (0.0370)\tloss 0.4683 (0.4683)\tgrad_norm 1.9616 (1.9616)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [68/100][10/625]\teta 0:00:22 lr 0.000253\t wd 0.0100\ttime 0.0386 (0.0363)\tloss 0.3552 (0.4684)\tgrad_norm 2.0281 (2.2621)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [68/100][20/625]\teta 0:00:21 lr 0.000252\t wd 0.0100\ttime 0.0362 (0.0362)\tloss 0.6001 (0.4890)\tgrad_norm 2.5192 (2.2286)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [68/100][30/625]\teta 0:00:21 lr 0.000252\t wd 0.0100\ttime 0.0323 (0.0354)\tloss 0.6113 (0.4862)\tgrad_norm 2.4926 (2.1853)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [68/100][40/625]\teta 0:00:20 lr 0.000252\t wd 0.0100\ttime 0.0380 (0.0353)\tloss 0.4290 (0.4849)\tgrad_norm 1.7791 (2.1843)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [68/100][50/625]\teta 0:00:20 lr 0.000252\t wd 0.0100\ttime 0.0384 (0.0356)\tloss 0.4121 (0.4751)\tgrad_norm 2.8224 (2.1478)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [68/100][60/625]\teta 0:00:20 lr 0.000252\t wd 0.0100\ttime 0.0325 (0.0359)\tloss 0.4019 (0.4715)\tgrad_norm 1.7037 (2.1124)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [68/100][70/625]\teta 0:00:19 lr 0.000251\t wd 0.0100\ttime 0.0327 (0.0359)\tloss 0.5054 (0.4737)\tgrad_norm 2.0533 (2.1187)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [68/100][80/625]\teta 0:00:19 lr 0.000251\t wd 0.0100\ttime 0.0327 (0.0358)\tloss 0.3125 (0.4657)\tgrad_norm 1.8508 (2.0971)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [68/100][90/625]\teta 0:00:19 lr 0.000251\t wd 0.0100\ttime 0.0332 (0.0358)\tloss 0.7349 (0.4662)\tgrad_norm 2.3557 (2.0995)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [68/100][100/625]\teta 0:00:18 lr 0.000251\t wd 0.0100\ttime 0.0328 (0.0358)\tloss 0.5571 (0.4710)\tgrad_norm 2.1843 (2.1051)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [68/100][110/625]\teta 0:00:18 lr 0.000250\t wd 0.0100\ttime 0.0324 (0.0358)\tloss 0.4297 (0.4722)\tgrad_norm 2.4466 (2.1129)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [68/100][120/625]\teta 0:00:18 lr 0.000250\t wd 0.0100\ttime 0.0365 (0.0358)\tloss 0.5854 (0.4758)\tgrad_norm 2.6030 (2.1208)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [68/100][130/625]\teta 0:00:17 lr 0.000250\t wd 0.0100\ttime 0.0391 (0.0360)\tloss 0.5098 (0.4735)\tgrad_norm 2.4361 (2.1111)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [68/100][140/625]\teta 0:00:17 lr 0.000250\t wd 0.0100\ttime 0.0393 (0.0360)\tloss 0.5210 (0.4725)\tgrad_norm 2.4447 (2.1231)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [68/100][150/625]\teta 0:00:17 lr 0.000250\t wd 0.0100\ttime 0.0344 (0.0361)\tloss 0.5659 (0.4744)\tgrad_norm 2.9907 (2.1315)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [68/100][160/625]\teta 0:00:16 lr 0.000249\t wd 0.0100\ttime 0.0323 (0.0361)\tloss 0.5474 (0.4764)\tgrad_norm 1.9574 (2.1284)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [68/100][170/625]\teta 0:00:16 lr 0.000249\t wd 0.0100\ttime 0.0353 (0.0361)\tloss 0.3340 (0.4736)\tgrad_norm 1.8402 (2.1231)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [68/100][180/625]\teta 0:00:16 lr 0.000249\t wd 0.0100\ttime 0.0384 (0.0361)\tloss 0.4453 (0.4702)\tgrad_norm 1.9218 (2.1094)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [68/100][190/625]\teta 0:00:15 lr 0.000249\t wd 0.0100\ttime 0.0353 (0.0361)\tloss 0.4561 (0.4700)\tgrad_norm 1.7505 (2.1043)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [68/100][200/625]\teta 0:00:15 lr 0.000248\t wd 0.0100\ttime 0.0361 (0.0361)\tloss 0.5596 (0.4728)\tgrad_norm 2.5286 (2.1165)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [68/100][210/625]\teta 0:00:14 lr 0.000248\t wd 0.0100\ttime 0.0332 (0.0361)\tloss 0.5234 (0.4758)\tgrad_norm 3.0832 (2.1308)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [68/100][220/625]\teta 0:00:14 lr 0.000248\t wd 0.0100\ttime 0.0323 (0.0361)\tloss 0.4329 (0.4753)\tgrad_norm 1.8098 (2.1251)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [68/100][230/625]\teta 0:00:14 lr 0.000248\t wd 0.0100\ttime 0.0396 (0.0361)\tloss 0.5850 (0.4770)\tgrad_norm 2.3194 (2.1283)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [68/100][240/625]\teta 0:00:13 lr 0.000248\t wd 0.0100\ttime 0.0364 (0.0361)\tloss 0.6914 (0.4779)\tgrad_norm 2.1561 (2.1278)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [68/100][250/625]\teta 0:00:13 lr 0.000247\t wd 0.0100\ttime 0.0328 (0.0361)\tloss 0.4851 (0.4794)\tgrad_norm 1.4593 (2.1301)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [68/100][260/625]\teta 0:00:13 lr 0.000247\t wd 0.0100\ttime 0.0358 (0.0361)\tloss 0.4907 (0.4782)\tgrad_norm 2.1495 (2.1274)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [68/100][270/625]\teta 0:00:12 lr 0.000247\t wd 0.0100\ttime 0.0387 (0.0360)\tloss 0.3293 (0.4769)\tgrad_norm 2.0290 (nan)\tloss_scale 32768.0000 (32888.9151)\tmem 455MB\n",
      "Train: [68/100][280/625]\teta 0:00:12 lr 0.000247\t wd 0.0100\ttime 0.0372 (0.0360)\tloss 0.4307 (0.4777)\tgrad_norm 2.3386 (nan)\tloss_scale 32768.0000 (32884.6121)\tmem 455MB\n",
      "Train: [68/100][290/625]\teta 0:00:12 lr 0.000247\t wd 0.0100\ttime 0.0373 (0.0361)\tloss 0.4082 (0.4755)\tgrad_norm 2.0133 (nan)\tloss_scale 32768.0000 (32880.6048)\tmem 455MB\n",
      "Train: [68/100][300/625]\teta 0:00:11 lr 0.000246\t wd 0.0100\ttime 0.0329 (0.0361)\tloss 0.4084 (0.4757)\tgrad_norm 2.0923 (nan)\tloss_scale 32768.0000 (32876.8638)\tmem 455MB\n",
      "Train: [68/100][310/625]\teta 0:00:11 lr 0.000246\t wd 0.0100\ttime 0.0331 (0.0360)\tloss 0.4929 (0.4746)\tgrad_norm 2.2935 (nan)\tloss_scale 32768.0000 (32873.3633)\tmem 455MB\n",
      "Train: [68/100][320/625]\teta 0:00:10 lr 0.000246\t wd 0.0100\ttime 0.0326 (0.0360)\tloss 0.3987 (0.4756)\tgrad_norm 1.9657 (nan)\tloss_scale 32768.0000 (32870.0810)\tmem 455MB\n",
      "Train: [68/100][330/625]\teta 0:00:10 lr 0.000246\t wd 0.0100\ttime 0.0367 (0.0361)\tloss 0.5747 (0.4759)\tgrad_norm 2.2763 (nan)\tloss_scale 32768.0000 (32866.9970)\tmem 455MB\n",
      "Train: [68/100][340/625]\teta 0:00:10 lr 0.000245\t wd 0.0100\ttime 0.0331 (0.0361)\tloss 0.7075 (0.4769)\tgrad_norm 2.5671 (nan)\tloss_scale 32768.0000 (32864.0938)\tmem 455MB\n",
      "Train: [68/100][350/625]\teta 0:00:09 lr 0.000245\t wd 0.0100\ttime 0.0390 (0.0361)\tloss 0.4275 (0.4773)\tgrad_norm 2.1315 (nan)\tloss_scale 32768.0000 (32861.3561)\tmem 455MB\n",
      "Train: [68/100][360/625]\teta 0:00:09 lr 0.000245\t wd 0.0100\ttime 0.0386 (0.0361)\tloss 0.4924 (0.4768)\tgrad_norm 1.9051 (nan)\tloss_scale 32768.0000 (32858.7701)\tmem 455MB\n",
      "Train: [68/100][370/625]\teta 0:00:09 lr 0.000245\t wd 0.0100\ttime 0.0326 (0.0361)\tloss 0.6475 (0.4782)\tgrad_norm 2.2897 (nan)\tloss_scale 32768.0000 (32856.3235)\tmem 455MB\n",
      "Train: [68/100][380/625]\teta 0:00:08 lr 0.000245\t wd 0.0100\ttime 0.0359 (0.0361)\tloss 0.6392 (0.4786)\tgrad_norm 3.0790 (nan)\tloss_scale 32768.0000 (32854.0052)\tmem 455MB\n",
      "Train: [68/100][390/625]\teta 0:00:08 lr 0.000244\t wd 0.0100\ttime 0.0386 (0.0361)\tloss 0.4004 (0.4796)\tgrad_norm 2.5421 (nan)\tloss_scale 32768.0000 (32851.8056)\tmem 455MB\n",
      "Train: [68/100][400/625]\teta 0:00:08 lr 0.000244\t wd 0.0100\ttime 0.0366 (0.0361)\tloss 0.6509 (0.4789)\tgrad_norm 3.0499 (nan)\tloss_scale 32768.0000 (32849.7157)\tmem 455MB\n",
      "Train: [68/100][410/625]\teta 0:00:07 lr 0.000244\t wd 0.0100\ttime 0.0355 (0.0361)\tloss 0.3232 (0.4790)\tgrad_norm 2.8299 (nan)\tloss_scale 32768.0000 (32847.7275)\tmem 455MB\n",
      "Train: [68/100][420/625]\teta 0:00:07 lr 0.000244\t wd 0.0100\ttime 0.0326 (0.0361)\tloss 0.6548 (0.4816)\tgrad_norm 1.9392 (nan)\tloss_scale 32768.0000 (32845.8337)\tmem 455MB\n",
      "Train: [68/100][430/625]\teta 0:00:07 lr 0.000243\t wd 0.0100\ttime 0.0358 (0.0361)\tloss 0.6577 (0.4821)\tgrad_norm 2.6844 (nan)\tloss_scale 32768.0000 (32844.0278)\tmem 455MB\n",
      "Train: [68/100][440/625]\teta 0:00:06 lr 0.000243\t wd 0.0100\ttime 0.0352 (0.0361)\tloss 0.6396 (0.4822)\tgrad_norm 2.2313 (nan)\tloss_scale 32768.0000 (32842.3039)\tmem 455MB\n",
      "Train: [68/100][450/625]\teta 0:00:06 lr 0.000243\t wd 0.0100\ttime 0.0327 (0.0361)\tloss 0.5288 (0.4828)\tgrad_norm 2.1500 (nan)\tloss_scale 32768.0000 (32840.6563)\tmem 455MB\n",
      "Train: [68/100][460/625]\teta 0:00:05 lr 0.000243\t wd 0.0100\ttime 0.0332 (0.0361)\tloss 0.5532 (0.4826)\tgrad_norm 2.7750 (nan)\tloss_scale 32768.0000 (32839.0803)\tmem 455MB\n",
      "Train: [68/100][470/625]\teta 0:00:05 lr 0.000243\t wd 0.0100\ttime 0.0389 (0.0361)\tloss 0.6934 (0.4844)\tgrad_norm 2.8460 (nan)\tloss_scale 32768.0000 (32837.5711)\tmem 455MB\n",
      "Train: [68/100][480/625]\teta 0:00:05 lr 0.000242\t wd 0.0100\ttime 0.0339 (0.0361)\tloss 0.4749 (0.4849)\tgrad_norm 1.9991 (nan)\tloss_scale 32768.0000 (32836.1247)\tmem 455MB\n",
      "Train: [68/100][490/625]\teta 0:00:04 lr 0.000242\t wd 0.0100\ttime 0.0326 (0.0361)\tloss 0.4978 (0.4848)\tgrad_norm 2.2513 (nan)\tloss_scale 32768.0000 (32834.7373)\tmem 455MB\n",
      "Train: [68/100][500/625]\teta 0:00:04 lr 0.000242\t wd 0.0100\ttime 0.0416 (0.0361)\tloss 0.4124 (0.4843)\tgrad_norm 2.0192 (nan)\tloss_scale 32768.0000 (32833.4052)\tmem 455MB\n",
      "Train: [68/100][510/625]\teta 0:00:04 lr 0.000242\t wd 0.0100\ttime 0.0326 (0.0361)\tloss 0.3638 (0.4839)\tgrad_norm 1.2781 (nan)\tloss_scale 32768.0000 (32832.1252)\tmem 455MB\n",
      "Train: [68/100][520/625]\teta 0:00:03 lr 0.000242\t wd 0.0100\ttime 0.0335 (0.0360)\tloss 0.3528 (0.4828)\tgrad_norm 1.6636 (nan)\tloss_scale 32768.0000 (32830.8944)\tmem 455MB\n",
      "Train: [68/100][530/625]\teta 0:00:03 lr 0.000241\t wd 0.0100\ttime 0.0361 (0.0360)\tloss 0.6973 (0.4825)\tgrad_norm 1.9785 (nan)\tloss_scale 32768.0000 (32829.7100)\tmem 455MB\n",
      "Train: [68/100][540/625]\teta 0:00:03 lr 0.000241\t wd 0.0100\ttime 0.0376 (0.0360)\tloss 0.5605 (0.4829)\tgrad_norm 2.1267 (nan)\tloss_scale 32768.0000 (32828.5693)\tmem 455MB\n",
      "Train: [68/100][550/625]\teta 0:00:02 lr 0.000241\t wd 0.0100\ttime 0.0335 (0.0360)\tloss 0.3381 (0.4828)\tgrad_norm 1.3044 (nan)\tloss_scale 32768.0000 (32827.4701)\tmem 455MB\n",
      "Train: [68/100][560/625]\teta 0:00:02 lr 0.000241\t wd 0.0100\ttime 0.0345 (0.0359)\tloss 0.5010 (0.4821)\tgrad_norm 1.9795 (nan)\tloss_scale 32768.0000 (32826.4100)\tmem 455MB\n",
      "Train: [68/100][570/625]\teta 0:00:01 lr 0.000240\t wd 0.0100\ttime 0.0345 (0.0359)\tloss 0.1956 (0.4820)\tgrad_norm 1.2649 (nan)\tloss_scale 32768.0000 (32825.3870)\tmem 455MB\n",
      "Train: [68/100][580/625]\teta 0:00:01 lr 0.000240\t wd 0.0100\ttime 0.0343 (0.0359)\tloss 0.3545 (0.4819)\tgrad_norm 1.9946 (nan)\tloss_scale 32768.0000 (32824.3993)\tmem 455MB\n",
      "Train: [68/100][590/625]\teta 0:00:01 lr 0.000240\t wd 0.0100\ttime 0.0364 (0.0359)\tloss 0.5938 (0.4819)\tgrad_norm 2.8604 (nan)\tloss_scale 32768.0000 (32823.4450)\tmem 455MB\n",
      "Train: [68/100][600/625]\teta 0:00:00 lr 0.000240\t wd 0.0100\ttime 0.0365 (0.0359)\tloss 0.4370 (0.4828)\tgrad_norm 1.5622 (nan)\tloss_scale 32768.0000 (32822.5225)\tmem 455MB\n",
      "Train: [68/100][610/625]\teta 0:00:00 lr 0.000240\t wd 0.0100\ttime 0.0379 (0.0359)\tloss 0.7729 (0.4843)\tgrad_norm 2.3085 (nan)\tloss_scale 32768.0000 (32821.6301)\tmem 455MB\n",
      "Train: [68/100][620/625]\teta 0:00:00 lr 0.000239\t wd 0.0100\ttime 0.0367 (0.0359)\tloss 0.6626 (0.4843)\tgrad_norm 2.7121 (nan)\tloss_scale 32768.0000 (32820.7665)\tmem 455MB\n",
      "EPOCH 68 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_68.pth saving......\n",
      "./model_save/ckpt_epoch_68.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.3718 (0.3718)\tAcc@1 87.500 (87.500)\tAcc@5 100.000 (100.000)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.016)\tLoss 0.6655 (0.6689)\tAcc@1 84.375 (78.409)\tAcc@5 98.438 (98.864)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.016)\tLoss 0.6479 (0.6726)\tAcc@1 76.562 (78.051)\tAcc@5 95.312 (98.586)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.016)\tLoss 0.7334 (0.6680)\tAcc@1 79.688 (77.873)\tAcc@5 98.438 (98.538)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.3325 (0.6452)\tAcc@1 90.625 (78.811)\tAcc@5 98.438 (98.666)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.8130 (0.6331)\tAcc@1 70.312 (78.830)\tAcc@5 100.000 (98.744)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.7847 (0.6304)\tAcc@1 75.000 (79.073)\tAcc@5 100.000 (98.873)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.6562 (0.6192)\tAcc@1 81.250 (79.291)\tAcc@5 96.875 (98.900)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.7183 (0.6151)\tAcc@1 73.438 (79.321)\tAcc@5 100.000 (98.958)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.9429 (0.6141)\tAcc@1 71.875 (79.172)\tAcc@5 100.000 (99.004)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.4497 (0.6105)\tAcc@1 82.812 (79.285)\tAcc@5 100.000 (99.041)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.5215 (0.6066)\tAcc@1 82.812 (79.307)\tAcc@5 98.438 (99.015)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.4224 (0.6104)\tAcc@1 89.062 (79.145)\tAcc@5 100.000 (98.993)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.5332 (0.6046)\tAcc@1 82.812 (79.270)\tAcc@5 100.000 (99.022)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.7944 (0.6021)\tAcc@1 73.438 (79.300)\tAcc@5 98.438 (99.058)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.7251 (0.6043)\tAcc@1 78.125 (79.232)\tAcc@5 98.438 (99.058)\tMem 455MB\n",
      " * Acc@1 79.240 Acc@5 99.070\n",
      "Accuracy of the network on the 10000 test images: 79.2%\n",
      "Max accuracy: 79.24%\n",
      "Train: [69/100][0/625]\teta 0:00:24 lr 0.000239\t wd 0.0100\ttime 0.0395 (0.0395)\tloss 0.4219 (0.4219)\tgrad_norm 2.3773 (2.3773)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][10/625]\teta 0:00:21 lr 0.000239\t wd 0.0100\ttime 0.0330 (0.0357)\tloss 0.4443 (0.4753)\tgrad_norm 1.7219 (2.1339)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][20/625]\teta 0:00:21 lr 0.000239\t wd 0.0100\ttime 0.0326 (0.0360)\tloss 0.5229 (0.4886)\tgrad_norm 1.7215 (2.1064)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][30/625]\teta 0:00:21 lr 0.000239\t wd 0.0100\ttime 0.0359 (0.0357)\tloss 0.5728 (0.4781)\tgrad_norm 2.3326 (2.0191)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][40/625]\teta 0:00:20 lr 0.000238\t wd 0.0100\ttime 0.0323 (0.0357)\tloss 0.3188 (0.4779)\tgrad_norm 1.5321 (2.0151)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][50/625]\teta 0:00:20 lr 0.000238\t wd 0.0100\ttime 0.0394 (0.0362)\tloss 0.6392 (0.4783)\tgrad_norm 2.2210 (2.0283)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][60/625]\teta 0:00:20 lr 0.000238\t wd 0.0100\ttime 0.0354 (0.0361)\tloss 0.6709 (0.4754)\tgrad_norm 2.8407 (2.0284)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][70/625]\teta 0:00:20 lr 0.000238\t wd 0.0100\ttime 0.0359 (0.0361)\tloss 0.5869 (0.4780)\tgrad_norm 2.3136 (2.0396)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][80/625]\teta 0:00:19 lr 0.000237\t wd 0.0100\ttime 0.0327 (0.0362)\tloss 0.6221 (0.4819)\tgrad_norm 2.1528 (2.0349)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][90/625]\teta 0:00:19 lr 0.000237\t wd 0.0100\ttime 0.0393 (0.0361)\tloss 0.4802 (0.4829)\tgrad_norm 2.6252 (2.0540)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][100/625]\teta 0:00:18 lr 0.000237\t wd 0.0100\ttime 0.0322 (0.0361)\tloss 0.4600 (0.4796)\tgrad_norm 2.0791 (2.0689)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][110/625]\teta 0:00:18 lr 0.000237\t wd 0.0100\ttime 0.0324 (0.0359)\tloss 0.4766 (0.4806)\tgrad_norm 1.7867 (2.0766)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][120/625]\teta 0:00:18 lr 0.000237\t wd 0.0100\ttime 0.0327 (0.0359)\tloss 0.5410 (0.4813)\tgrad_norm 1.7988 (2.0633)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][130/625]\teta 0:00:17 lr 0.000236\t wd 0.0100\ttime 0.0352 (0.0359)\tloss 0.4226 (0.4792)\tgrad_norm 1.8081 (2.0654)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][140/625]\teta 0:00:17 lr 0.000236\t wd 0.0100\ttime 0.0357 (0.0358)\tloss 0.5415 (0.4788)\tgrad_norm 2.0874 (2.0792)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][150/625]\teta 0:00:17 lr 0.000236\t wd 0.0100\ttime 0.0399 (0.0358)\tloss 0.4866 (0.4789)\tgrad_norm 2.4995 (2.0918)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][160/625]\teta 0:00:16 lr 0.000236\t wd 0.0100\ttime 0.0325 (0.0359)\tloss 0.5049 (0.4789)\tgrad_norm 2.0146 (2.0900)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][170/625]\teta 0:00:16 lr 0.000236\t wd 0.0100\ttime 0.0328 (0.0359)\tloss 0.4141 (0.4783)\tgrad_norm 1.9140 (2.0989)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][180/625]\teta 0:00:16 lr 0.000235\t wd 0.0100\ttime 0.0397 (0.0360)\tloss 0.3447 (0.4767)\tgrad_norm 1.2997 (2.0935)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][190/625]\teta 0:00:15 lr 0.000235\t wd 0.0100\ttime 0.0388 (0.0360)\tloss 0.4683 (0.4752)\tgrad_norm 1.8368 (2.0965)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][200/625]\teta 0:00:15 lr 0.000235\t wd 0.0100\ttime 0.0352 (0.0361)\tloss 0.3550 (0.4774)\tgrad_norm 1.7022 (2.0981)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][210/625]\teta 0:00:14 lr 0.000235\t wd 0.0100\ttime 0.0357 (0.0361)\tloss 0.5649 (0.4811)\tgrad_norm 2.1568 (2.1150)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][220/625]\teta 0:00:14 lr 0.000234\t wd 0.0100\ttime 0.0353 (0.0360)\tloss 0.2515 (0.4799)\tgrad_norm 1.5565 (2.1056)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][230/625]\teta 0:00:14 lr 0.000234\t wd 0.0100\ttime 0.0325 (0.0360)\tloss 0.5347 (0.4807)\tgrad_norm 1.7333 (2.1039)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][240/625]\teta 0:00:13 lr 0.000234\t wd 0.0100\ttime 0.0324 (0.0359)\tloss 0.3997 (0.4813)\tgrad_norm 1.9641 (2.1040)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][250/625]\teta 0:00:13 lr 0.000234\t wd 0.0100\ttime 0.0326 (0.0358)\tloss 0.3687 (0.4792)\tgrad_norm 2.1206 (2.0992)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][260/625]\teta 0:00:13 lr 0.000234\t wd 0.0100\ttime 0.0327 (0.0358)\tloss 0.4756 (0.4787)\tgrad_norm 2.1585 (2.0979)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][270/625]\teta 0:00:12 lr 0.000233\t wd 0.0100\ttime 0.0362 (0.0358)\tloss 0.7676 (0.4794)\tgrad_norm 2.7108 (2.1002)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][280/625]\teta 0:00:12 lr 0.000233\t wd 0.0100\ttime 0.0328 (0.0357)\tloss 0.6533 (0.4821)\tgrad_norm 2.2255 (2.1013)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][290/625]\teta 0:00:11 lr 0.000233\t wd 0.0100\ttime 0.0326 (0.0357)\tloss 0.6245 (0.4824)\tgrad_norm 2.2238 (2.0997)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][300/625]\teta 0:00:11 lr 0.000233\t wd 0.0100\ttime 0.0328 (0.0357)\tloss 0.4949 (0.4813)\tgrad_norm 1.9246 (2.0979)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][310/625]\teta 0:00:11 lr 0.000233\t wd 0.0100\ttime 0.0329 (0.0356)\tloss 0.4077 (0.4805)\tgrad_norm 2.3618 (2.0982)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][320/625]\teta 0:00:10 lr 0.000232\t wd 0.0100\ttime 0.0324 (0.0355)\tloss 0.5283 (0.4806)\tgrad_norm 2.5960 (2.1025)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][330/625]\teta 0:00:10 lr 0.000232\t wd 0.0100\ttime 0.0325 (0.0355)\tloss 0.3901 (0.4815)\tgrad_norm 1.8183 (2.1082)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][340/625]\teta 0:00:10 lr 0.000232\t wd 0.0100\ttime 0.0362 (0.0354)\tloss 0.4119 (0.4817)\tgrad_norm 2.1024 (2.1113)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][350/625]\teta 0:00:09 lr 0.000232\t wd 0.0100\ttime 0.0333 (0.0354)\tloss 0.4644 (0.4822)\tgrad_norm 2.3191 (2.1165)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][360/625]\teta 0:00:09 lr 0.000231\t wd 0.0100\ttime 0.0328 (0.0353)\tloss 0.4697 (0.4803)\tgrad_norm 1.9847 (2.1185)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][370/625]\teta 0:00:08 lr 0.000231\t wd 0.0100\ttime 0.0327 (0.0353)\tloss 0.5459 (0.4801)\tgrad_norm 3.0025 (2.1232)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][380/625]\teta 0:00:08 lr 0.000231\t wd 0.0100\ttime 0.0328 (0.0353)\tloss 0.4324 (0.4791)\tgrad_norm 1.6569 (2.1221)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][390/625]\teta 0:00:08 lr 0.000231\t wd 0.0100\ttime 0.0327 (0.0352)\tloss 0.5703 (0.4789)\tgrad_norm 2.5463 (2.1244)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][400/625]\teta 0:00:07 lr 0.000231\t wd 0.0100\ttime 0.0326 (0.0352)\tloss 0.4351 (0.4787)\tgrad_norm 1.8674 (2.1249)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][410/625]\teta 0:00:07 lr 0.000230\t wd 0.0100\ttime 0.0329 (0.0352)\tloss 0.9019 (0.4787)\tgrad_norm 2.5025 (2.1232)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][420/625]\teta 0:00:07 lr 0.000230\t wd 0.0100\ttime 0.0328 (0.0351)\tloss 0.5776 (0.4782)\tgrad_norm 1.7931 (2.1226)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][430/625]\teta 0:00:06 lr 0.000230\t wd 0.0100\ttime 0.0329 (0.0352)\tloss 0.5972 (0.4788)\tgrad_norm 2.0253 (2.1247)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][440/625]\teta 0:00:06 lr 0.000230\t wd 0.0100\ttime 0.0359 (0.0352)\tloss 0.4885 (0.4791)\tgrad_norm 2.4037 (2.1241)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][450/625]\teta 0:00:06 lr 0.000230\t wd 0.0100\ttime 0.0395 (0.0352)\tloss 0.4348 (0.4792)\tgrad_norm 2.0107 (2.1229)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][460/625]\teta 0:00:05 lr 0.000229\t wd 0.0100\ttime 0.0329 (0.0352)\tloss 0.7075 (0.4792)\tgrad_norm 2.3400 (2.1185)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][470/625]\teta 0:00:05 lr 0.000229\t wd 0.0100\ttime 0.0324 (0.0352)\tloss 0.3669 (0.4790)\tgrad_norm 2.1436 (2.1200)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][480/625]\teta 0:00:05 lr 0.000229\t wd 0.0100\ttime 0.0360 (0.0352)\tloss 0.4702 (0.4787)\tgrad_norm 1.8650 (2.1194)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][490/625]\teta 0:00:04 lr 0.000229\t wd 0.0100\ttime 0.0436 (0.0353)\tloss 0.5835 (0.4788)\tgrad_norm 2.6985 (2.1185)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][500/625]\teta 0:00:04 lr 0.000228\t wd 0.0100\ttime 0.0341 (0.0353)\tloss 0.5322 (0.4798)\tgrad_norm 2.0915 (2.1196)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][510/625]\teta 0:00:04 lr 0.000228\t wd 0.0100\ttime 0.0356 (0.0354)\tloss 0.4568 (0.4806)\tgrad_norm 2.0352 (2.1187)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][520/625]\teta 0:00:03 lr 0.000228\t wd 0.0100\ttime 0.0341 (0.0354)\tloss 0.6465 (0.4818)\tgrad_norm 3.0791 (2.1223)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][530/625]\teta 0:00:03 lr 0.000228\t wd 0.0100\ttime 0.0361 (0.0354)\tloss 0.6929 (0.4815)\tgrad_norm 2.0573 (2.1172)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][540/625]\teta 0:00:03 lr 0.000228\t wd 0.0100\ttime 0.0329 (0.0354)\tloss 0.4202 (0.4810)\tgrad_norm 2.1348 (2.1164)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][550/625]\teta 0:00:02 lr 0.000227\t wd 0.0100\ttime 0.0325 (0.0353)\tloss 0.4541 (0.4809)\tgrad_norm 2.6270 (2.1197)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][560/625]\teta 0:00:02 lr 0.000227\t wd 0.0100\ttime 0.0357 (0.0353)\tloss 0.5171 (0.4816)\tgrad_norm 1.9870 (2.1210)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][570/625]\teta 0:00:01 lr 0.000227\t wd 0.0100\ttime 0.0361 (0.0353)\tloss 0.3862 (0.4815)\tgrad_norm 1.5306 (2.1196)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][580/625]\teta 0:00:01 lr 0.000227\t wd 0.0100\ttime 0.0324 (0.0353)\tloss 0.4863 (0.4811)\tgrad_norm 2.7563 (2.1235)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][590/625]\teta 0:00:01 lr 0.000227\t wd 0.0100\ttime 0.0396 (0.0352)\tloss 0.3638 (0.4813)\tgrad_norm 1.6951 (2.1278)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][600/625]\teta 0:00:00 lr 0.000226\t wd 0.0100\ttime 0.0326 (0.0353)\tloss 0.4246 (0.4819)\tgrad_norm 1.8582 (2.1294)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][610/625]\teta 0:00:00 lr 0.000226\t wd 0.0100\ttime 0.0356 (0.0353)\tloss 0.4238 (0.4815)\tgrad_norm 2.1510 (2.1280)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [69/100][620/625]\teta 0:00:00 lr 0.000226\t wd 0.0100\ttime 0.0325 (0.0352)\tloss 0.3633 (0.4817)\tgrad_norm 2.2612 (2.1287)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 69 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_69.pth saving......\n",
      "./model_save/ckpt_epoch_69.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.6304 (0.6304)\tAcc@1 79.688 (79.688)\tAcc@5 98.438 (98.438)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.6821 (0.6153)\tAcc@1 82.812 (80.966)\tAcc@5 95.312 (98.722)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.5591 (0.6047)\tAcc@1 78.125 (80.283)\tAcc@5 100.000 (98.958)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.5566 (0.6041)\tAcc@1 81.250 (80.040)\tAcc@5 98.438 (98.891)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.5645 (0.5905)\tAcc@1 79.688 (80.373)\tAcc@5 100.000 (98.933)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.6455 (0.5867)\tAcc@1 75.000 (80.239)\tAcc@5 100.000 (99.081)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.4590 (0.5833)\tAcc@1 81.250 (80.251)\tAcc@5 100.000 (99.078)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.5229 (0.5815)\tAcc@1 81.250 (80.502)\tAcc@5 100.000 (99.054)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.8413 (0.5879)\tAcc@1 65.625 (80.093)\tAcc@5 100.000 (99.074)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.7896 (0.5871)\tAcc@1 73.438 (80.185)\tAcc@5 100.000 (99.073)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.016 (0.015)\tLoss 0.5825 (0.5948)\tAcc@1 79.688 (80.012)\tAcc@5 98.438 (99.025)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.016 (0.015)\tLoss 0.5820 (0.5940)\tAcc@1 81.250 (80.082)\tAcc@5 98.438 (99.029)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.016 (0.015)\tLoss 0.4902 (0.6006)\tAcc@1 81.250 (79.830)\tAcc@5 100.000 (98.954)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.7202 (0.5986)\tAcc@1 81.250 (79.735)\tAcc@5 96.875 (98.962)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.5449 (0.6023)\tAcc@1 81.250 (79.621)\tAcc@5 96.875 (98.881)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.6826 (0.6045)\tAcc@1 78.125 (79.584)\tAcc@5 98.438 (98.851)\tMem 455MB\n",
      " * Acc@1 79.620 Acc@5 98.860\n",
      "Accuracy of the network on the 10000 test images: 79.6%\n",
      "Max accuracy: 79.62%\n",
      "Train: [70/100][0/625]\teta 0:00:23 lr 0.000226\t wd 0.0100\ttime 0.0384 (0.0384)\tloss 0.3677 (0.3677)\tgrad_norm 1.8620 (1.8620)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][10/625]\teta 0:00:22 lr 0.000226\t wd 0.0100\ttime 0.0362 (0.0364)\tloss 0.4126 (0.3704)\tgrad_norm 1.8346 (1.9334)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][20/625]\teta 0:00:22 lr 0.000225\t wd 0.0100\ttime 0.0409 (0.0371)\tloss 0.5342 (0.4369)\tgrad_norm 2.2820 (2.1936)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][30/625]\teta 0:00:21 lr 0.000225\t wd 0.0100\ttime 0.0391 (0.0367)\tloss 0.4307 (0.4403)\tgrad_norm 2.9724 (2.1778)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][40/625]\teta 0:00:21 lr 0.000225\t wd 0.0100\ttime 0.0394 (0.0371)\tloss 0.3293 (0.4449)\tgrad_norm 2.3514 (2.1532)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][50/625]\teta 0:00:21 lr 0.000225\t wd 0.0100\ttime 0.0376 (0.0372)\tloss 0.3762 (0.4463)\tgrad_norm 1.8769 (2.1116)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][60/625]\teta 0:00:20 lr 0.000225\t wd 0.0100\ttime 0.0389 (0.0371)\tloss 0.4155 (0.4506)\tgrad_norm 2.0916 (2.1124)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][70/625]\teta 0:00:20 lr 0.000224\t wd 0.0100\ttime 0.0357 (0.0371)\tloss 0.5513 (0.4594)\tgrad_norm 2.9168 (2.1413)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][80/625]\teta 0:00:20 lr 0.000224\t wd 0.0100\ttime 0.0362 (0.0370)\tloss 0.5068 (0.4562)\tgrad_norm 2.1039 (2.1507)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][90/625]\teta 0:00:19 lr 0.000224\t wd 0.0100\ttime 0.0397 (0.0369)\tloss 0.5098 (0.4518)\tgrad_norm 2.4863 (2.1329)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][100/625]\teta 0:00:19 lr 0.000224\t wd 0.0100\ttime 0.0394 (0.0370)\tloss 0.4368 (0.4513)\tgrad_norm 2.1140 (2.1469)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][110/625]\teta 0:00:19 lr 0.000224\t wd 0.0100\ttime 0.0403 (0.0369)\tloss 0.4570 (0.4496)\tgrad_norm 1.9902 (2.1490)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][120/625]\teta 0:00:18 lr 0.000223\t wd 0.0100\ttime 0.0401 (0.0371)\tloss 0.5376 (0.4529)\tgrad_norm 2.6715 (2.1564)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][130/625]\teta 0:00:18 lr 0.000223\t wd 0.0100\ttime 0.0325 (0.0370)\tloss 0.4419 (0.4529)\tgrad_norm 2.6545 (2.1349)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][140/625]\teta 0:00:17 lr 0.000223\t wd 0.0100\ttime 0.0326 (0.0368)\tloss 0.4958 (0.4567)\tgrad_norm 3.0457 (2.1397)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][150/625]\teta 0:00:17 lr 0.000223\t wd 0.0100\ttime 0.0361 (0.0365)\tloss 0.4038 (0.4562)\tgrad_norm 1.5620 (2.1396)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][160/625]\teta 0:00:16 lr 0.000222\t wd 0.0100\ttime 0.0323 (0.0363)\tloss 0.4912 (0.4573)\tgrad_norm 2.3560 (2.1373)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][170/625]\teta 0:00:16 lr 0.000222\t wd 0.0100\ttime 0.0359 (0.0362)\tloss 0.6797 (0.4610)\tgrad_norm 2.1131 (2.1385)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][180/625]\teta 0:00:16 lr 0.000222\t wd 0.0100\ttime 0.0360 (0.0362)\tloss 0.5771 (0.4635)\tgrad_norm 2.2176 (2.1412)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][190/625]\teta 0:00:15 lr 0.000222\t wd 0.0100\ttime 0.0368 (0.0362)\tloss 0.4531 (0.4614)\tgrad_norm 2.1414 (2.1247)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][200/625]\teta 0:00:15 lr 0.000222\t wd 0.0100\ttime 0.0329 (0.0362)\tloss 0.3440 (0.4607)\tgrad_norm 1.6793 (2.1253)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][210/625]\teta 0:00:15 lr 0.000221\t wd 0.0100\ttime 0.0396 (0.0363)\tloss 0.4517 (0.4606)\tgrad_norm 1.7236 (2.1332)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][220/625]\teta 0:00:14 lr 0.000221\t wd 0.0100\ttime 0.0329 (0.0362)\tloss 0.5410 (0.4619)\tgrad_norm 1.6158 (2.1381)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][230/625]\teta 0:00:14 lr 0.000221\t wd 0.0100\ttime 0.0327 (0.0361)\tloss 0.3735 (0.4640)\tgrad_norm 1.9291 (2.1407)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][240/625]\teta 0:00:13 lr 0.000221\t wd 0.0100\ttime 0.0358 (0.0361)\tloss 0.4109 (0.4633)\tgrad_norm 1.7586 (2.1469)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][250/625]\teta 0:00:13 lr 0.000221\t wd 0.0100\ttime 0.0361 (0.0361)\tloss 0.4856 (0.4659)\tgrad_norm 2.5544 (2.1499)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][260/625]\teta 0:00:13 lr 0.000220\t wd 0.0100\ttime 0.0342 (0.0360)\tloss 0.4990 (0.4673)\tgrad_norm 2.5562 (2.1571)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][270/625]\teta 0:00:12 lr 0.000220\t wd 0.0100\ttime 0.0356 (0.0359)\tloss 0.3652 (0.4676)\tgrad_norm 1.6269 (2.1550)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][280/625]\teta 0:00:12 lr 0.000220\t wd 0.0100\ttime 0.0361 (0.0359)\tloss 0.5186 (0.4698)\tgrad_norm 2.2336 (2.1564)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][290/625]\teta 0:00:12 lr 0.000220\t wd 0.0100\ttime 0.0324 (0.0359)\tloss 0.4446 (0.4696)\tgrad_norm 1.6835 (2.1565)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][300/625]\teta 0:00:11 lr 0.000220\t wd 0.0100\ttime 0.0341 (0.0358)\tloss 0.6899 (0.4704)\tgrad_norm 2.4056 (2.1514)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][310/625]\teta 0:00:11 lr 0.000219\t wd 0.0100\ttime 0.0327 (0.0358)\tloss 0.3333 (0.4727)\tgrad_norm 1.3853 (2.1555)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][320/625]\teta 0:00:10 lr 0.000219\t wd 0.0100\ttime 0.0351 (0.0358)\tloss 0.4009 (0.4732)\tgrad_norm 1.5642 (2.1540)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][330/625]\teta 0:00:10 lr 0.000219\t wd 0.0100\ttime 0.0359 (0.0358)\tloss 0.4729 (0.4724)\tgrad_norm 2.2383 (2.1496)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][340/625]\teta 0:00:10 lr 0.000219\t wd 0.0100\ttime 0.0358 (0.0358)\tloss 0.4182 (0.4737)\tgrad_norm 2.3140 (2.1545)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][350/625]\teta 0:00:09 lr 0.000218\t wd 0.0100\ttime 0.0324 (0.0358)\tloss 0.5645 (0.4723)\tgrad_norm 2.0564 (2.1520)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][360/625]\teta 0:00:09 lr 0.000218\t wd 0.0100\ttime 0.0393 (0.0358)\tloss 0.4468 (0.4723)\tgrad_norm 1.9634 (2.1514)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][370/625]\teta 0:00:09 lr 0.000218\t wd 0.0100\ttime 0.0328 (0.0358)\tloss 0.6899 (0.4733)\tgrad_norm 2.0913 (2.1491)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][380/625]\teta 0:00:08 lr 0.000218\t wd 0.0100\ttime 0.0360 (0.0358)\tloss 0.6147 (0.4740)\tgrad_norm 2.4563 (2.1524)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][390/625]\teta 0:00:08 lr 0.000218\t wd 0.0100\ttime 0.0331 (0.0358)\tloss 0.5122 (0.4763)\tgrad_norm 2.3722 (2.1561)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][400/625]\teta 0:00:08 lr 0.000217\t wd 0.0100\ttime 0.0324 (0.0358)\tloss 0.4058 (0.4750)\tgrad_norm 1.6992 (2.1577)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][410/625]\teta 0:00:07 lr 0.000217\t wd 0.0100\ttime 0.0328 (0.0357)\tloss 0.4651 (0.4745)\tgrad_norm 2.4055 (2.1552)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][420/625]\teta 0:00:07 lr 0.000217\t wd 0.0100\ttime 0.0394 (0.0357)\tloss 0.2637 (0.4746)\tgrad_norm 1.3668 (2.1592)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][430/625]\teta 0:00:06 lr 0.000217\t wd 0.0100\ttime 0.0329 (0.0357)\tloss 0.4529 (0.4745)\tgrad_norm 2.7860 (2.1623)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][440/625]\teta 0:00:06 lr 0.000217\t wd 0.0100\ttime 0.0321 (0.0357)\tloss 0.7056 (0.4750)\tgrad_norm 2.3211 (2.1600)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][450/625]\teta 0:00:06 lr 0.000216\t wd 0.0100\ttime 0.0331 (0.0357)\tloss 0.4490 (0.4744)\tgrad_norm 2.4036 (2.1547)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][460/625]\teta 0:00:05 lr 0.000216\t wd 0.0100\ttime 0.0328 (0.0357)\tloss 0.5098 (0.4732)\tgrad_norm 3.1548 (2.1547)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][470/625]\teta 0:00:05 lr 0.000216\t wd 0.0100\ttime 0.0329 (0.0357)\tloss 0.5088 (0.4732)\tgrad_norm 2.1420 (2.1560)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][480/625]\teta 0:00:05 lr 0.000216\t wd 0.0100\ttime 0.0369 (0.0356)\tloss 0.3772 (0.4724)\tgrad_norm 1.5342 (2.1543)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][490/625]\teta 0:00:04 lr 0.000216\t wd 0.0100\ttime 0.0322 (0.0356)\tloss 0.3171 (0.4716)\tgrad_norm 1.7510 (2.1529)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][500/625]\teta 0:00:04 lr 0.000215\t wd 0.0100\ttime 0.0359 (0.0356)\tloss 0.4971 (0.4717)\tgrad_norm 2.2236 (2.1521)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][510/625]\teta 0:00:04 lr 0.000215\t wd 0.0100\ttime 0.0389 (0.0356)\tloss 0.3730 (0.4715)\tgrad_norm 1.2891 (2.1515)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][520/625]\teta 0:00:03 lr 0.000215\t wd 0.0100\ttime 0.0415 (0.0356)\tloss 0.3855 (0.4717)\tgrad_norm 1.9630 (2.1532)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][530/625]\teta 0:00:03 lr 0.000215\t wd 0.0100\ttime 0.0371 (0.0356)\tloss 0.4595 (0.4714)\tgrad_norm 2.6344 (2.1562)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][540/625]\teta 0:00:03 lr 0.000215\t wd 0.0100\ttime 0.0324 (0.0356)\tloss 0.6685 (0.4745)\tgrad_norm 3.1958 (2.1627)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][550/625]\teta 0:00:02 lr 0.000214\t wd 0.0100\ttime 0.0326 (0.0356)\tloss 0.4458 (0.4732)\tgrad_norm 1.9016 (2.1614)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][560/625]\teta 0:00:02 lr 0.000214\t wd 0.0100\ttime 0.0328 (0.0355)\tloss 0.4431 (0.4729)\tgrad_norm 1.6602 (2.1587)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][570/625]\teta 0:00:01 lr 0.000214\t wd 0.0100\ttime 0.0363 (0.0355)\tloss 0.3188 (0.4727)\tgrad_norm 1.0903 (2.1546)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][580/625]\teta 0:00:01 lr 0.000214\t wd 0.0100\ttime 0.0327 (0.0355)\tloss 0.4954 (0.4736)\tgrad_norm 1.8791 (2.1543)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][590/625]\teta 0:00:01 lr 0.000213\t wd 0.0100\ttime 0.0356 (0.0355)\tloss 0.5244 (0.4744)\tgrad_norm 1.7690 (2.1518)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][600/625]\teta 0:00:00 lr 0.000213\t wd 0.0100\ttime 0.0327 (0.0355)\tloss 0.6128 (0.4749)\tgrad_norm 2.8660 (2.1539)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][610/625]\teta 0:00:00 lr 0.000213\t wd 0.0100\ttime 0.0352 (0.0355)\tloss 0.4246 (0.4740)\tgrad_norm 2.4137 (2.1508)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [70/100][620/625]\teta 0:00:00 lr 0.000213\t wd 0.0100\ttime 0.0327 (0.0355)\tloss 0.4795 (0.4738)\tgrad_norm 1.7985 (2.1488)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 70 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_70.pth saving......\n",
      "./model_save/ckpt_epoch_70.pth saved !!!\n",
      "Test: [0/157]\tTime 0.021 (0.021)\tLoss 0.4805 (0.4805)\tAcc@1 82.812 (82.812)\tAcc@5 100.000 (100.000)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.016 (0.016)\tLoss 0.5566 (0.6751)\tAcc@1 81.250 (77.557)\tAcc@5 100.000 (99.290)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.016)\tLoss 0.5669 (0.6231)\tAcc@1 82.812 (79.167)\tAcc@5 100.000 (99.033)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.8931 (0.6124)\tAcc@1 70.312 (79.637)\tAcc@5 98.438 (99.093)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.6382 (0.6132)\tAcc@1 76.562 (79.002)\tAcc@5 100.000 (99.047)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.017 (0.015)\tLoss 0.6343 (0.6127)\tAcc@1 75.000 (79.013)\tAcc@5 98.438 (98.989)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.4116 (0.6101)\tAcc@1 84.375 (79.406)\tAcc@5 100.000 (99.001)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.6719 (0.6167)\tAcc@1 73.438 (79.247)\tAcc@5 100.000 (98.988)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.5034 (0.6200)\tAcc@1 81.250 (79.205)\tAcc@5 96.875 (98.900)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.5200 (0.6115)\tAcc@1 82.812 (79.516)\tAcc@5 100.000 (98.901)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.8281 (0.6143)\tAcc@1 67.188 (79.316)\tAcc@5 95.312 (98.917)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.5503 (0.6174)\tAcc@1 82.812 (79.336)\tAcc@5 98.438 (98.874)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.7202 (0.6136)\tAcc@1 78.125 (79.545)\tAcc@5 98.438 (98.902)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.016 (0.015)\tLoss 0.5894 (0.6121)\tAcc@1 79.688 (79.532)\tAcc@5 100.000 (98.927)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.5669 (0.6085)\tAcc@1 78.125 (79.643)\tAcc@5 98.438 (98.925)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.016 (0.015)\tLoss 1.0527 (0.6113)\tAcc@1 67.188 (79.501)\tAcc@5 98.438 (98.913)\tMem 455MB\n",
      " * Acc@1 79.490 Acc@5 98.930\n",
      "Accuracy of the network on the 10000 test images: 79.5%\n",
      "Max accuracy: 79.62%\n",
      "Train: [71/100][0/625]\teta 0:00:23 lr 0.000213\t wd 0.0100\ttime 0.0377 (0.0377)\tloss 0.5327 (0.5327)\tgrad_norm 2.3238 (2.3238)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [71/100][10/625]\teta 0:00:22 lr 0.000213\t wd 0.0100\ttime 0.0358 (0.0367)\tloss 0.4905 (0.4768)\tgrad_norm 2.0756 (2.1151)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [71/100][20/625]\teta 0:00:22 lr 0.000212\t wd 0.0100\ttime 0.0391 (0.0365)\tloss 0.5791 (0.4812)\tgrad_norm 1.6575 (2.1042)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [71/100][30/625]\teta 0:00:21 lr 0.000212\t wd 0.0100\ttime 0.0357 (0.0363)\tloss 0.2722 (0.4623)\tgrad_norm 1.5356 (2.0560)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [71/100][40/625]\teta 0:00:21 lr 0.000212\t wd 0.0100\ttime 0.0342 (0.0363)\tloss 0.4304 (0.4483)\tgrad_norm 2.1626 (2.0362)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [71/100][50/625]\teta 0:00:20 lr 0.000212\t wd 0.0100\ttime 0.0324 (0.0362)\tloss 0.4661 (0.4544)\tgrad_norm 2.1542 (2.0477)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [71/100][60/625]\teta 0:00:20 lr 0.000212\t wd 0.0100\ttime 0.0324 (0.0361)\tloss 0.6802 (0.4564)\tgrad_norm 2.1270 (2.0614)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [71/100][70/625]\teta 0:00:19 lr 0.000211\t wd 0.0100\ttime 0.0325 (0.0360)\tloss 0.4360 (0.4516)\tgrad_norm 2.3707 (2.0464)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [71/100][80/625]\teta 0:00:19 lr 0.000211\t wd 0.0100\ttime 0.0397 (0.0360)\tloss 0.4473 (0.4592)\tgrad_norm 2.2833 (2.0941)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [71/100][90/625]\teta 0:00:19 lr 0.000211\t wd 0.0100\ttime 0.0328 (0.0360)\tloss 0.4810 (0.4625)\tgrad_norm 1.9238 (2.0950)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [71/100][100/625]\teta 0:00:18 lr 0.000211\t wd 0.0100\ttime 0.0329 (0.0360)\tloss 0.3489 (0.4584)\tgrad_norm 2.3966 (2.0871)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [71/100][110/625]\teta 0:00:18 lr 0.000210\t wd 0.0100\ttime 0.0343 (0.0360)\tloss 0.2717 (0.4593)\tgrad_norm 1.5763 (2.0911)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [71/100][120/625]\teta 0:00:18 lr 0.000210\t wd 0.0100\ttime 0.0358 (0.0361)\tloss 0.4487 (0.4590)\tgrad_norm 2.5839 (2.0933)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [71/100][130/625]\teta 0:00:17 lr 0.000210\t wd 0.0100\ttime 0.0354 (0.0362)\tloss 0.5454 (0.4615)\tgrad_norm 2.0941 (2.0933)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [71/100][140/625]\teta 0:00:17 lr 0.000210\t wd 0.0100\ttime 0.0340 (0.0361)\tloss 0.3513 (0.4657)\tgrad_norm 2.2252 (2.1080)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [71/100][150/625]\teta 0:00:17 lr 0.000210\t wd 0.0100\ttime 0.0390 (0.0361)\tloss 0.4539 (0.4653)\tgrad_norm 2.3258 (2.1003)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [71/100][160/625]\teta 0:00:16 lr 0.000209\t wd 0.0100\ttime 0.0326 (0.0361)\tloss 0.6313 (0.4654)\tgrad_norm 3.1814 (2.1042)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [71/100][170/625]\teta 0:00:16 lr 0.000209\t wd 0.0100\ttime 0.0327 (0.0359)\tloss 0.5542 (0.4650)\tgrad_norm 2.3258 (2.1122)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [71/100][180/625]\teta 0:00:15 lr 0.000209\t wd 0.0100\ttime 0.0361 (0.0358)\tloss 0.4358 (0.4653)\tgrad_norm 1.9147 (2.1294)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [71/100][190/625]\teta 0:00:15 lr 0.000209\t wd 0.0100\ttime 0.0346 (0.0358)\tloss 0.2681 (0.4658)\tgrad_norm 1.1511 (2.1278)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [71/100][200/625]\teta 0:00:15 lr 0.000209\t wd 0.0100\ttime 0.0377 (0.0359)\tloss 0.4805 (0.4652)\tgrad_norm 2.6570 (2.1244)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [71/100][210/625]\teta 0:00:14 lr 0.000208\t wd 0.0100\ttime 0.0392 (0.0359)\tloss 0.3691 (0.4630)\tgrad_norm 1.8629 (2.1267)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [71/100][220/625]\teta 0:00:14 lr 0.000208\t wd 0.0100\ttime 0.0361 (0.0360)\tloss 0.5146 (0.4641)\tgrad_norm 3.0373 (2.1346)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [71/100][230/625]\teta 0:00:14 lr 0.000208\t wd 0.0100\ttime 0.0324 (0.0360)\tloss 0.2876 (0.4634)\tgrad_norm 2.5991 (2.1402)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [71/100][240/625]\teta 0:00:13 lr 0.000208\t wd 0.0100\ttime 0.0395 (0.0360)\tloss 0.4065 (0.4646)\tgrad_norm 2.0864 (2.1424)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [71/100][250/625]\teta 0:00:13 lr 0.000208\t wd 0.0100\ttime 0.0383 (0.0360)\tloss 0.2822 (0.4624)\tgrad_norm 1.9700 (2.1374)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [71/100][260/625]\teta 0:00:13 lr 0.000207\t wd 0.0100\ttime 0.0393 (0.0360)\tloss 0.5205 (0.4640)\tgrad_norm 2.8738 (2.1449)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [71/100][270/625]\teta 0:00:12 lr 0.000207\t wd 0.0100\ttime 0.0396 (0.0360)\tloss 0.5640 (0.4644)\tgrad_norm 2.4393 (2.1541)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [71/100][280/625]\teta 0:00:12 lr 0.000207\t wd 0.0100\ttime 0.0335 (0.0360)\tloss 0.5537 (0.4630)\tgrad_norm 2.1930 (2.1502)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [71/100][290/625]\teta 0:00:12 lr 0.000207\t wd 0.0100\ttime 0.0344 (0.0360)\tloss 0.3782 (0.4628)\tgrad_norm 1.8306 (2.1493)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [71/100][300/625]\teta 0:00:11 lr 0.000207\t wd 0.0100\ttime 0.0340 (0.0360)\tloss 0.4282 (0.4621)\tgrad_norm 1.9954 (2.1464)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [71/100][310/625]\teta 0:00:11 lr 0.000206\t wd 0.0100\ttime 0.0326 (0.0360)\tloss 0.3445 (0.4624)\tgrad_norm 2.2284 (2.1467)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [71/100][320/625]\teta 0:00:10 lr 0.000206\t wd 0.0100\ttime 0.0328 (0.0360)\tloss 0.5508 (0.4618)\tgrad_norm 2.3021 (2.1502)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [71/100][330/625]\teta 0:00:10 lr 0.000206\t wd 0.0100\ttime 0.0326 (0.0359)\tloss 0.4861 (0.4613)\tgrad_norm 2.1107 (2.1523)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [71/100][340/625]\teta 0:00:10 lr 0.000206\t wd 0.0100\ttime 0.0372 (0.0360)\tloss 0.3633 (0.4610)\tgrad_norm 1.9694 (2.1583)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [71/100][350/625]\teta 0:00:09 lr 0.000206\t wd 0.0100\ttime 0.0326 (0.0360)\tloss 0.4910 (0.4611)\tgrad_norm 2.4448 (2.1592)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [71/100][360/625]\teta 0:00:09 lr 0.000205\t wd 0.0100\ttime 0.0356 (0.0360)\tloss 0.4324 (0.4609)\tgrad_norm 2.4168 (2.1575)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [71/100][370/625]\teta 0:00:09 lr 0.000205\t wd 0.0100\ttime 0.0362 (0.0360)\tloss 0.3577 (0.4605)\tgrad_norm 1.8344 (2.1565)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [71/100][380/625]\teta 0:00:08 lr 0.000205\t wd 0.0100\ttime 0.0389 (0.0360)\tloss 0.4768 (0.4620)\tgrad_norm 1.8053 (2.1588)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [71/100][390/625]\teta 0:00:08 lr 0.000205\t wd 0.0100\ttime 0.0391 (0.0360)\tloss 0.3335 (0.4616)\tgrad_norm 1.8890 (2.1614)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [71/100][400/625]\teta 0:00:08 lr 0.000205\t wd 0.0100\ttime 0.0386 (0.0359)\tloss 0.6089 (0.4620)\tgrad_norm 2.5506 (nan)\tloss_scale 32768.0000 (32849.7157)\tmem 455MB\n",
      "Train: [71/100][410/625]\teta 0:00:07 lr 0.000204\t wd 0.0100\ttime 0.0331 (0.0359)\tloss 0.3235 (0.4626)\tgrad_norm 1.5299 (nan)\tloss_scale 32768.0000 (32847.7275)\tmem 455MB\n",
      "Train: [71/100][420/625]\teta 0:00:07 lr 0.000204\t wd 0.0100\ttime 0.0327 (0.0359)\tloss 0.6479 (0.4631)\tgrad_norm 3.6855 (nan)\tloss_scale 32768.0000 (32845.8337)\tmem 455MB\n",
      "Train: [71/100][430/625]\teta 0:00:07 lr 0.000204\t wd 0.0100\ttime 0.0332 (0.0359)\tloss 0.4866 (0.4640)\tgrad_norm 2.2338 (nan)\tloss_scale 32768.0000 (32844.0278)\tmem 455MB\n",
      "Train: [71/100][440/625]\teta 0:00:06 lr 0.000204\t wd 0.0100\ttime 0.0367 (0.0360)\tloss 0.5195 (0.4659)\tgrad_norm 2.6038 (nan)\tloss_scale 32768.0000 (32842.3039)\tmem 455MB\n",
      "Train: [71/100][450/625]\teta 0:00:06 lr 0.000204\t wd 0.0100\ttime 0.0389 (0.0360)\tloss 0.4980 (0.4652)\tgrad_norm 1.7787 (nan)\tloss_scale 32768.0000 (32840.6563)\tmem 455MB\n",
      "Train: [71/100][460/625]\teta 0:00:05 lr 0.000203\t wd 0.0100\ttime 0.0384 (0.0360)\tloss 0.2786 (0.4646)\tgrad_norm 1.5511 (nan)\tloss_scale 32768.0000 (32839.0803)\tmem 455MB\n",
      "Train: [71/100][470/625]\teta 0:00:05 lr 0.000203\t wd 0.0100\ttime 0.0349 (0.0360)\tloss 0.4004 (0.4636)\tgrad_norm 1.6128 (nan)\tloss_scale 32768.0000 (32837.5711)\tmem 455MB\n",
      "Train: [71/100][480/625]\teta 0:00:05 lr 0.000203\t wd 0.0100\ttime 0.0336 (0.0360)\tloss 0.3892 (0.4639)\tgrad_norm 1.6086 (nan)\tloss_scale 32768.0000 (32836.1247)\tmem 455MB\n",
      "Train: [71/100][490/625]\teta 0:00:04 lr 0.000203\t wd 0.0100\ttime 0.0362 (0.0359)\tloss 0.4734 (0.4645)\tgrad_norm 2.5506 (nan)\tloss_scale 32768.0000 (32834.7373)\tmem 455MB\n",
      "Train: [71/100][500/625]\teta 0:00:04 lr 0.000202\t wd 0.0100\ttime 0.0394 (0.0359)\tloss 0.2900 (0.4636)\tgrad_norm 1.6175 (nan)\tloss_scale 32768.0000 (32833.4052)\tmem 455MB\n",
      "Train: [71/100][510/625]\teta 0:00:04 lr 0.000202\t wd 0.0100\ttime 0.0326 (0.0359)\tloss 0.4587 (0.4631)\tgrad_norm 1.8732 (nan)\tloss_scale 32768.0000 (32832.1252)\tmem 455MB\n",
      "Train: [71/100][520/625]\teta 0:00:03 lr 0.000202\t wd 0.0100\ttime 0.0395 (0.0359)\tloss 0.5059 (0.4646)\tgrad_norm 1.7616 (nan)\tloss_scale 32768.0000 (32830.8944)\tmem 455MB\n",
      "Train: [71/100][530/625]\teta 0:00:03 lr 0.000202\t wd 0.0100\ttime 0.0396 (0.0360)\tloss 0.5830 (0.4647)\tgrad_norm 2.8569 (nan)\tloss_scale 32768.0000 (32829.7100)\tmem 455MB\n",
      "Train: [71/100][540/625]\teta 0:00:03 lr 0.000202\t wd 0.0100\ttime 0.0330 (0.0359)\tloss 0.4812 (0.4653)\tgrad_norm 3.3781 (nan)\tloss_scale 32768.0000 (32828.5693)\tmem 455MB\n",
      "Train: [71/100][550/625]\teta 0:00:02 lr 0.000201\t wd 0.0100\ttime 0.0360 (0.0360)\tloss 0.4780 (0.4654)\tgrad_norm 2.3573 (nan)\tloss_scale 32768.0000 (32827.4701)\tmem 455MB\n",
      "Train: [71/100][560/625]\teta 0:00:02 lr 0.000201\t wd 0.0100\ttime 0.0356 (0.0360)\tloss 0.5200 (0.4655)\tgrad_norm 3.2332 (nan)\tloss_scale 32768.0000 (32826.4100)\tmem 455MB\n",
      "Train: [71/100][570/625]\teta 0:00:01 lr 0.000201\t wd 0.0100\ttime 0.0336 (0.0360)\tloss 0.5947 (0.4655)\tgrad_norm 2.6320 (nan)\tloss_scale 32768.0000 (32825.3870)\tmem 455MB\n",
      "Train: [71/100][580/625]\teta 0:00:01 lr 0.000201\t wd 0.0100\ttime 0.0361 (0.0359)\tloss 0.4258 (0.4645)\tgrad_norm 2.1537 (nan)\tloss_scale 32768.0000 (32824.3993)\tmem 455MB\n",
      "Train: [71/100][590/625]\teta 0:00:01 lr 0.000201\t wd 0.0100\ttime 0.0361 (0.0359)\tloss 0.4399 (0.4650)\tgrad_norm 2.3631 (nan)\tloss_scale 32768.0000 (32823.4450)\tmem 455MB\n",
      "Train: [71/100][600/625]\teta 0:00:00 lr 0.000200\t wd 0.0100\ttime 0.0355 (0.0359)\tloss 0.5269 (0.4643)\tgrad_norm 2.1318 (nan)\tloss_scale 32768.0000 (32822.5225)\tmem 455MB\n",
      "Train: [71/100][610/625]\teta 0:00:00 lr 0.000200\t wd 0.0100\ttime 0.0390 (0.0359)\tloss 0.4365 (0.4646)\tgrad_norm 2.1219 (nan)\tloss_scale 32768.0000 (32821.6301)\tmem 455MB\n",
      "Train: [71/100][620/625]\teta 0:00:00 lr 0.000200\t wd 0.0100\ttime 0.0409 (0.0359)\tloss 0.6650 (0.4648)\tgrad_norm 2.3754 (nan)\tloss_scale 32768.0000 (32820.7665)\tmem 455MB\n",
      "EPOCH 71 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_71.pth saving......\n",
      "./model_save/ckpt_epoch_71.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.2617 (0.2617)\tAcc@1 87.500 (87.500)\tAcc@5 100.000 (100.000)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.6743 (0.5406)\tAcc@1 73.438 (79.972)\tAcc@5 100.000 (99.148)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.5366 (0.5644)\tAcc@1 84.375 (80.208)\tAcc@5 100.000 (99.107)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.7251 (0.5658)\tAcc@1 76.562 (80.343)\tAcc@5 100.000 (99.244)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.4202 (0.5711)\tAcc@1 90.625 (80.907)\tAcc@5 98.438 (99.085)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.6177 (0.5773)\tAcc@1 76.562 (80.331)\tAcc@5 100.000 (99.050)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.7896 (0.5809)\tAcc@1 78.125 (80.533)\tAcc@5 100.000 (99.001)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.4958 (0.5784)\tAcc@1 82.812 (80.414)\tAcc@5 100.000 (99.032)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.5088 (0.5922)\tAcc@1 81.250 (79.996)\tAcc@5 100.000 (98.920)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.7119 (0.5925)\tAcc@1 78.125 (79.825)\tAcc@5 98.438 (98.953)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.6802 (0.5951)\tAcc@1 81.250 (79.935)\tAcc@5 95.312 (98.917)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.6396 (0.5951)\tAcc@1 78.125 (79.969)\tAcc@5 98.438 (98.944)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.3804 (0.5924)\tAcc@1 87.500 (80.127)\tAcc@5 100.000 (98.980)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.5352 (0.5891)\tAcc@1 79.688 (80.236)\tAcc@5 100.000 (99.022)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.7007 (0.5907)\tAcc@1 68.750 (79.998)\tAcc@5 98.438 (99.025)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.6060 (0.5923)\tAcc@1 78.125 (80.029)\tAcc@5 100.000 (99.027)\tMem 455MB\n",
      " * Acc@1 80.000 Acc@5 99.030\n",
      "Accuracy of the network on the 10000 test images: 80.0%\n",
      "Max accuracy: 80.00%\n",
      "Train: [72/100][0/625]\teta 0:00:24 lr 0.000200\t wd 0.0100\ttime 0.0399 (0.0399)\tloss 0.6123 (0.6123)\tgrad_norm 2.4539 (2.4539)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][10/625]\teta 0:00:22 lr 0.000200\t wd 0.0100\ttime 0.0339 (0.0359)\tloss 0.5737 (0.5007)\tgrad_norm 2.7844 (2.1975)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][20/625]\teta 0:00:21 lr 0.000200\t wd 0.0100\ttime 0.0378 (0.0359)\tloss 0.5425 (0.4567)\tgrad_norm 3.0040 (2.1842)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][30/625]\teta 0:00:21 lr 0.000199\t wd 0.0100\ttime 0.0328 (0.0358)\tloss 0.7139 (0.4740)\tgrad_norm 3.2833 (2.1850)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][40/625]\teta 0:00:21 lr 0.000199\t wd 0.0100\ttime 0.0357 (0.0359)\tloss 0.3284 (0.4681)\tgrad_norm 2.0024 (2.1863)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][50/625]\teta 0:00:20 lr 0.000199\t wd 0.0100\ttime 0.0368 (0.0358)\tloss 0.4697 (0.4536)\tgrad_norm 1.8931 (2.1116)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][60/625]\teta 0:00:20 lr 0.000199\t wd 0.0100\ttime 0.0357 (0.0358)\tloss 0.5713 (0.4600)\tgrad_norm 2.4198 (2.1345)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][70/625]\teta 0:00:19 lr 0.000199\t wd 0.0100\ttime 0.0325 (0.0356)\tloss 0.5527 (0.4637)\tgrad_norm 2.4541 (2.1627)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][80/625]\teta 0:00:19 lr 0.000198\t wd 0.0100\ttime 0.0328 (0.0355)\tloss 0.5020 (0.4667)\tgrad_norm 1.8832 (2.1760)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][90/625]\teta 0:00:18 lr 0.000198\t wd 0.0100\ttime 0.0350 (0.0353)\tloss 0.4568 (0.4706)\tgrad_norm 2.3842 (2.1868)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][100/625]\teta 0:00:18 lr 0.000198\t wd 0.0100\ttime 0.0337 (0.0352)\tloss 0.4917 (0.4656)\tgrad_norm 2.1088 (2.1752)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][110/625]\teta 0:00:18 lr 0.000198\t wd 0.0100\ttime 0.0330 (0.0351)\tloss 0.4910 (0.4664)\tgrad_norm 1.9271 (2.1638)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][120/625]\teta 0:00:17 lr 0.000198\t wd 0.0100\ttime 0.0323 (0.0350)\tloss 0.5103 (0.4645)\tgrad_norm 2.5589 (2.1530)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][130/625]\teta 0:00:17 lr 0.000197\t wd 0.0100\ttime 0.0326 (0.0349)\tloss 0.4314 (0.4635)\tgrad_norm 1.9363 (2.1494)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][140/625]\teta 0:00:16 lr 0.000197\t wd 0.0100\ttime 0.0327 (0.0348)\tloss 0.4897 (0.4600)\tgrad_norm 2.3171 (2.1491)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][150/625]\teta 0:00:16 lr 0.000197\t wd 0.0100\ttime 0.0359 (0.0348)\tloss 0.5112 (0.4604)\tgrad_norm 2.1240 (2.1489)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][160/625]\teta 0:00:16 lr 0.000197\t wd 0.0100\ttime 0.0329 (0.0348)\tloss 0.5112 (0.4606)\tgrad_norm 2.5698 (2.1595)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][170/625]\teta 0:00:15 lr 0.000197\t wd 0.0100\ttime 0.0335 (0.0348)\tloss 0.5029 (0.4624)\tgrad_norm 2.3640 (2.1696)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][180/625]\teta 0:00:15 lr 0.000196\t wd 0.0100\ttime 0.0393 (0.0350)\tloss 0.3418 (0.4653)\tgrad_norm 1.7006 (2.1886)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][190/625]\teta 0:00:15 lr 0.000196\t wd 0.0100\ttime 0.0387 (0.0350)\tloss 0.4314 (0.4681)\tgrad_norm 2.8224 (2.2077)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][200/625]\teta 0:00:14 lr 0.000196\t wd 0.0100\ttime 0.0324 (0.0350)\tloss 0.3826 (0.4666)\tgrad_norm 2.1403 (2.2069)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][210/625]\teta 0:00:14 lr 0.000196\t wd 0.0100\ttime 0.0362 (0.0350)\tloss 0.5903 (0.4663)\tgrad_norm 3.1356 (2.2191)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][220/625]\teta 0:00:14 lr 0.000196\t wd 0.0100\ttime 0.0353 (0.0350)\tloss 0.4065 (0.4651)\tgrad_norm 2.2701 (2.2088)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][230/625]\teta 0:00:13 lr 0.000195\t wd 0.0100\ttime 0.0358 (0.0351)\tloss 0.4736 (0.4653)\tgrad_norm 1.8897 (2.2002)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][240/625]\teta 0:00:13 lr 0.000195\t wd 0.0100\ttime 0.0356 (0.0351)\tloss 0.5264 (0.4665)\tgrad_norm 2.7530 (2.2142)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][250/625]\teta 0:00:13 lr 0.000195\t wd 0.0100\ttime 0.0391 (0.0352)\tloss 0.5107 (0.4664)\tgrad_norm 1.8046 (2.2188)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][260/625]\teta 0:00:12 lr 0.000195\t wd 0.0100\ttime 0.0401 (0.0353)\tloss 0.4211 (0.4652)\tgrad_norm 1.6248 (2.2131)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][270/625]\teta 0:00:12 lr 0.000195\t wd 0.0100\ttime 0.0329 (0.0354)\tloss 0.3430 (0.4623)\tgrad_norm 1.7560 (2.2014)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][280/625]\teta 0:00:12 lr 0.000194\t wd 0.0100\ttime 0.0354 (0.0354)\tloss 0.1980 (0.4606)\tgrad_norm 1.2125 (2.1948)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][290/625]\teta 0:00:11 lr 0.000194\t wd 0.0100\ttime 0.0350 (0.0354)\tloss 0.4722 (0.4614)\tgrad_norm 2.7090 (2.1963)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][300/625]\teta 0:00:11 lr 0.000194\t wd 0.0100\ttime 0.0322 (0.0354)\tloss 0.5649 (0.4605)\tgrad_norm 2.4242 (2.1929)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][310/625]\teta 0:00:11 lr 0.000194\t wd 0.0100\ttime 0.0360 (0.0354)\tloss 0.3635 (0.4594)\tgrad_norm 2.2610 (2.1827)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][320/625]\teta 0:00:10 lr 0.000194\t wd 0.0100\ttime 0.0386 (0.0354)\tloss 0.3911 (0.4590)\tgrad_norm 2.0290 (2.1812)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][330/625]\teta 0:00:10 lr 0.000193\t wd 0.0100\ttime 0.0328 (0.0354)\tloss 0.6255 (0.4583)\tgrad_norm 2.2339 (2.1751)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][340/625]\teta 0:00:10 lr 0.000193\t wd 0.0100\ttime 0.0349 (0.0354)\tloss 0.4827 (0.4578)\tgrad_norm 2.1692 (2.1766)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][350/625]\teta 0:00:09 lr 0.000193\t wd 0.0100\ttime 0.0377 (0.0354)\tloss 0.3477 (0.4562)\tgrad_norm 1.8902 (2.1745)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][360/625]\teta 0:00:09 lr 0.000193\t wd 0.0100\ttime 0.0328 (0.0354)\tloss 0.7456 (0.4564)\tgrad_norm 2.7408 (2.1731)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][370/625]\teta 0:00:09 lr 0.000193\t wd 0.0100\ttime 0.0386 (0.0354)\tloss 0.4924 (0.4574)\tgrad_norm 1.9777 (2.1732)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][380/625]\teta 0:00:08 lr 0.000192\t wd 0.0100\ttime 0.0328 (0.0355)\tloss 0.5259 (0.4576)\tgrad_norm 2.3282 (2.1763)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][390/625]\teta 0:00:08 lr 0.000192\t wd 0.0100\ttime 0.0357 (0.0355)\tloss 0.3767 (0.4565)\tgrad_norm 2.2670 (2.1736)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][400/625]\teta 0:00:07 lr 0.000192\t wd 0.0100\ttime 0.0324 (0.0355)\tloss 0.4983 (0.4562)\tgrad_norm 2.8426 (2.1786)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][410/625]\teta 0:00:07 lr 0.000192\t wd 0.0100\ttime 0.0327 (0.0354)\tloss 0.4702 (0.4561)\tgrad_norm 2.3577 (2.1781)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][420/625]\teta 0:00:07 lr 0.000192\t wd 0.0100\ttime 0.0325 (0.0354)\tloss 0.5337 (0.4561)\tgrad_norm 2.0309 (2.1740)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][430/625]\teta 0:00:06 lr 0.000191\t wd 0.0100\ttime 0.0327 (0.0354)\tloss 0.5059 (0.4566)\tgrad_norm 2.6715 (2.1715)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][440/625]\teta 0:00:06 lr 0.000191\t wd 0.0100\ttime 0.0325 (0.0353)\tloss 0.3928 (0.4573)\tgrad_norm 1.5862 (2.1697)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][450/625]\teta 0:00:06 lr 0.000191\t wd 0.0100\ttime 0.0327 (0.0353)\tloss 0.5356 (0.4567)\tgrad_norm 2.6544 (2.1724)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][460/625]\teta 0:00:05 lr 0.000191\t wd 0.0100\ttime 0.0325 (0.0353)\tloss 0.5693 (0.4574)\tgrad_norm 2.5287 (2.1751)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][470/625]\teta 0:00:05 lr 0.000191\t wd 0.0100\ttime 0.0402 (0.0353)\tloss 0.4741 (0.4574)\tgrad_norm 1.7404 (2.1748)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][480/625]\teta 0:00:05 lr 0.000190\t wd 0.0100\ttime 0.0380 (0.0353)\tloss 0.4634 (0.4569)\tgrad_norm 1.7108 (2.1744)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][490/625]\teta 0:00:04 lr 0.000190\t wd 0.0100\ttime 0.0392 (0.0354)\tloss 0.5708 (0.4578)\tgrad_norm 1.9230 (2.1798)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][500/625]\teta 0:00:04 lr 0.000190\t wd 0.0100\ttime 0.0391 (0.0354)\tloss 0.3367 (0.4570)\tgrad_norm 2.2704 (2.1791)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][510/625]\teta 0:00:04 lr 0.000190\t wd 0.0100\ttime 0.0355 (0.0354)\tloss 0.4871 (0.4569)\tgrad_norm 2.3272 (2.1837)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][520/625]\teta 0:00:03 lr 0.000190\t wd 0.0100\ttime 0.0396 (0.0354)\tloss 0.4958 (0.4565)\tgrad_norm 1.7118 (2.1836)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][530/625]\teta 0:00:03 lr 0.000189\t wd 0.0100\ttime 0.0356 (0.0354)\tloss 0.4917 (0.4570)\tgrad_norm 1.6751 (2.1821)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][540/625]\teta 0:00:03 lr 0.000189\t wd 0.0100\ttime 0.0325 (0.0354)\tloss 0.3794 (0.4571)\tgrad_norm 1.7357 (2.1810)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][550/625]\teta 0:00:02 lr 0.000189\t wd 0.0100\ttime 0.0332 (0.0354)\tloss 0.4265 (0.4584)\tgrad_norm 1.8178 (2.1811)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][560/625]\teta 0:00:02 lr 0.000189\t wd 0.0100\ttime 0.0326 (0.0354)\tloss 0.3337 (0.4587)\tgrad_norm 1.6939 (2.1808)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][570/625]\teta 0:00:01 lr 0.000189\t wd 0.0100\ttime 0.0366 (0.0354)\tloss 0.4324 (0.4592)\tgrad_norm 2.0039 (2.1777)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][580/625]\teta 0:00:01 lr 0.000188\t wd 0.0100\ttime 0.0420 (0.0354)\tloss 0.4333 (0.4600)\tgrad_norm 2.2574 (2.1777)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][590/625]\teta 0:00:01 lr 0.000188\t wd 0.0100\ttime 0.0324 (0.0355)\tloss 0.4177 (0.4593)\tgrad_norm 1.9894 (2.1778)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][600/625]\teta 0:00:00 lr 0.000188\t wd 0.0100\ttime 0.0358 (0.0354)\tloss 0.4878 (0.4596)\tgrad_norm 1.9771 (2.1777)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][610/625]\teta 0:00:00 lr 0.000188\t wd 0.0100\ttime 0.0357 (0.0355)\tloss 0.3540 (0.4583)\tgrad_norm 2.1249 (2.1805)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [72/100][620/625]\teta 0:00:00 lr 0.000188\t wd 0.0100\ttime 0.0353 (0.0355)\tloss 0.3340 (0.4577)\tgrad_norm 1.6325 (2.1783)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 72 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_72.pth saving......\n",
      "./model_save/ckpt_epoch_72.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.5820 (0.5820)\tAcc@1 79.688 (79.688)\tAcc@5 96.875 (96.875)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.6431 (0.6198)\tAcc@1 81.250 (78.835)\tAcc@5 98.438 (98.864)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.3984 (0.6352)\tAcc@1 84.375 (78.943)\tAcc@5 100.000 (98.810)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.8394 (0.6281)\tAcc@1 79.688 (79.688)\tAcc@5 100.000 (98.942)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.6406 (0.6215)\tAcc@1 78.125 (79.802)\tAcc@5 96.875 (98.780)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.5073 (0.6089)\tAcc@1 78.125 (80.055)\tAcc@5 100.000 (98.897)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.016 (0.015)\tLoss 0.8184 (0.6100)\tAcc@1 73.438 (79.918)\tAcc@5 100.000 (98.899)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.4441 (0.6046)\tAcc@1 84.375 (79.908)\tAcc@5 100.000 (98.922)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.5811 (0.6030)\tAcc@1 79.688 (79.726)\tAcc@5 98.438 (98.920)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.4036 (0.5949)\tAcc@1 85.938 (79.945)\tAcc@5 100.000 (98.918)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.4907 (0.6062)\tAcc@1 81.250 (79.688)\tAcc@5 100.000 (98.886)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.2357 (0.5990)\tAcc@1 90.625 (79.969)\tAcc@5 100.000 (98.930)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.3801 (0.5986)\tAcc@1 89.062 (79.920)\tAcc@5 100.000 (98.889)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.5806 (0.5940)\tAcc@1 79.688 (80.069)\tAcc@5 100.000 (98.938)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.7539 (0.5972)\tAcc@1 75.000 (79.942)\tAcc@5 96.875 (98.892)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.4902 (0.5967)\tAcc@1 81.250 (79.905)\tAcc@5 98.438 (98.903)\tMem 455MB\n",
      " * Acc@1 79.780 Acc@5 98.930\n",
      "Accuracy of the network on the 10000 test images: 79.8%\n",
      "Max accuracy: 80.00%\n",
      "Train: [73/100][0/625]\teta 0:00:23 lr 0.000188\t wd 0.0100\ttime 0.0373 (0.0373)\tloss 0.2939 (0.2939)\tgrad_norm 1.4159 (1.4159)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][10/625]\teta 0:00:22 lr 0.000187\t wd 0.0100\ttime 0.0323 (0.0369)\tloss 0.5688 (0.4210)\tgrad_norm 2.7130 (2.1713)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][20/625]\teta 0:00:21 lr 0.000187\t wd 0.0100\ttime 0.0328 (0.0363)\tloss 0.2727 (0.4225)\tgrad_norm 1.6816 (2.0724)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][30/625]\teta 0:00:21 lr 0.000187\t wd 0.0100\ttime 0.0325 (0.0361)\tloss 0.4551 (0.4296)\tgrad_norm 1.9791 (2.0332)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][40/625]\teta 0:00:21 lr 0.000187\t wd 0.0100\ttime 0.0327 (0.0361)\tloss 0.5137 (0.4436)\tgrad_norm 1.9663 (2.0416)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][50/625]\teta 0:00:20 lr 0.000187\t wd 0.0100\ttime 0.0327 (0.0360)\tloss 0.2264 (0.4353)\tgrad_norm 1.8362 (2.0586)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][60/625]\teta 0:00:20 lr 0.000186\t wd 0.0100\ttime 0.0358 (0.0360)\tloss 0.4412 (0.4436)\tgrad_norm 2.5115 (2.1103)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][70/625]\teta 0:00:20 lr 0.000186\t wd 0.0100\ttime 0.0327 (0.0362)\tloss 0.4543 (0.4481)\tgrad_norm 2.5830 (2.1524)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][80/625]\teta 0:00:19 lr 0.000186\t wd 0.0100\ttime 0.0328 (0.0361)\tloss 0.4253 (0.4494)\tgrad_norm 2.1991 (2.1579)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][90/625]\teta 0:00:19 lr 0.000186\t wd 0.0100\ttime 0.0329 (0.0361)\tloss 0.4570 (0.4563)\tgrad_norm 1.7736 (2.1638)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][100/625]\teta 0:00:18 lr 0.000186\t wd 0.0100\ttime 0.0362 (0.0360)\tloss 0.2786 (0.4519)\tgrad_norm 2.1990 (2.1450)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][110/625]\teta 0:00:18 lr 0.000185\t wd 0.0100\ttime 0.0328 (0.0361)\tloss 0.5200 (0.4519)\tgrad_norm 2.0128 (2.1299)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][120/625]\teta 0:00:18 lr 0.000185\t wd 0.0100\ttime 0.0329 (0.0361)\tloss 0.5137 (0.4516)\tgrad_norm 2.1852 (2.1253)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][130/625]\teta 0:00:17 lr 0.000185\t wd 0.0100\ttime 0.0363 (0.0361)\tloss 0.3701 (0.4504)\tgrad_norm 1.3915 (2.1159)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][140/625]\teta 0:00:17 lr 0.000185\t wd 0.0100\ttime 0.0363 (0.0362)\tloss 0.3467 (0.4477)\tgrad_norm 2.2399 (2.1197)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][150/625]\teta 0:00:17 lr 0.000185\t wd 0.0100\ttime 0.0356 (0.0362)\tloss 0.6147 (0.4489)\tgrad_norm 1.9860 (2.1252)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][160/625]\teta 0:00:16 lr 0.000184\t wd 0.0100\ttime 0.0389 (0.0363)\tloss 0.5913 (0.4513)\tgrad_norm 2.2829 (2.1335)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][170/625]\teta 0:00:16 lr 0.000184\t wd 0.0100\ttime 0.0364 (0.0364)\tloss 0.3760 (0.4500)\tgrad_norm 1.7838 (2.1226)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][180/625]\teta 0:00:16 lr 0.000184\t wd 0.0100\ttime 0.0357 (0.0363)\tloss 0.3811 (0.4501)\tgrad_norm 1.7007 (2.1225)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][190/625]\teta 0:00:15 lr 0.000184\t wd 0.0100\ttime 0.0359 (0.0363)\tloss 0.4404 (0.4507)\tgrad_norm 1.8660 (2.1223)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][200/625]\teta 0:00:15 lr 0.000184\t wd 0.0100\ttime 0.0325 (0.0364)\tloss 0.4744 (0.4498)\tgrad_norm 2.1269 (2.1240)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][210/625]\teta 0:00:15 lr 0.000183\t wd 0.0100\ttime 0.0362 (0.0364)\tloss 0.9663 (0.4540)\tgrad_norm 3.0326 (2.1269)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][220/625]\teta 0:00:14 lr 0.000183\t wd 0.0100\ttime 0.0360 (0.0364)\tloss 0.4524 (0.4529)\tgrad_norm 2.1448 (2.1241)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][230/625]\teta 0:00:14 lr 0.000183\t wd 0.0100\ttime 0.0356 (0.0363)\tloss 0.3254 (0.4541)\tgrad_norm 1.7312 (2.1275)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][240/625]\teta 0:00:13 lr 0.000183\t wd 0.0100\ttime 0.0387 (0.0363)\tloss 0.4036 (0.4532)\tgrad_norm 1.8933 (2.1281)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][250/625]\teta 0:00:13 lr 0.000183\t wd 0.0100\ttime 0.0385 (0.0363)\tloss 0.4607 (0.4542)\tgrad_norm 1.4918 (2.1257)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][260/625]\teta 0:00:13 lr 0.000182\t wd 0.0100\ttime 0.0383 (0.0363)\tloss 0.3831 (0.4536)\tgrad_norm 1.9614 (2.1320)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][270/625]\teta 0:00:12 lr 0.000182\t wd 0.0100\ttime 0.0393 (0.0363)\tloss 0.3394 (0.4523)\tgrad_norm 1.9719 (2.1335)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][280/625]\teta 0:00:12 lr 0.000182\t wd 0.0100\ttime 0.0396 (0.0363)\tloss 0.5010 (0.4525)\tgrad_norm 2.9367 (2.1390)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][290/625]\teta 0:00:12 lr 0.000182\t wd 0.0100\ttime 0.0354 (0.0362)\tloss 0.4458 (0.4527)\tgrad_norm 2.4984 (2.1434)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][300/625]\teta 0:00:11 lr 0.000182\t wd 0.0100\ttime 0.0395 (0.0362)\tloss 0.4417 (0.4528)\tgrad_norm 2.0680 (2.1406)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][310/625]\teta 0:00:11 lr 0.000181\t wd 0.0100\ttime 0.0378 (0.0362)\tloss 0.3018 (0.4515)\tgrad_norm 1.4357 (2.1402)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][320/625]\teta 0:00:11 lr 0.000181\t wd 0.0100\ttime 0.0327 (0.0362)\tloss 0.2637 (0.4498)\tgrad_norm 1.8213 (2.1380)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][330/625]\teta 0:00:10 lr 0.000181\t wd 0.0100\ttime 0.0334 (0.0362)\tloss 0.3677 (0.4512)\tgrad_norm 1.4788 (2.1455)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][340/625]\teta 0:00:10 lr 0.000181\t wd 0.0100\ttime 0.0352 (0.0362)\tloss 0.4419 (0.4523)\tgrad_norm 1.6674 (2.1493)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][350/625]\teta 0:00:09 lr 0.000181\t wd 0.0100\ttime 0.0359 (0.0362)\tloss 0.5190 (0.4510)\tgrad_norm 2.0047 (2.1429)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][360/625]\teta 0:00:09 lr 0.000180\t wd 0.0100\ttime 0.0361 (0.0362)\tloss 0.3906 (0.4523)\tgrad_norm 1.9965 (2.1470)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][370/625]\teta 0:00:09 lr 0.000180\t wd 0.0100\ttime 0.0326 (0.0362)\tloss 0.4910 (0.4531)\tgrad_norm 2.2613 (2.1467)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][380/625]\teta 0:00:08 lr 0.000180\t wd 0.0100\ttime 0.0384 (0.0362)\tloss 0.6348 (0.4534)\tgrad_norm 2.6864 (2.1491)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][390/625]\teta 0:00:08 lr 0.000180\t wd 0.0100\ttime 0.0326 (0.0362)\tloss 0.4473 (0.4518)\tgrad_norm 2.1465 (2.1407)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][400/625]\teta 0:00:08 lr 0.000180\t wd 0.0100\ttime 0.0327 (0.0361)\tloss 0.5547 (0.4512)\tgrad_norm 2.2071 (2.1373)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][410/625]\teta 0:00:07 lr 0.000180\t wd 0.0100\ttime 0.0333 (0.0361)\tloss 0.4666 (0.4508)\tgrad_norm 1.8736 (2.1366)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][420/625]\teta 0:00:07 lr 0.000179\t wd 0.0100\ttime 0.0329 (0.0361)\tloss 0.2717 (0.4509)\tgrad_norm 1.7780 (2.1392)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][430/625]\teta 0:00:07 lr 0.000179\t wd 0.0100\ttime 0.0390 (0.0361)\tloss 0.6274 (0.4526)\tgrad_norm 2.2998 (2.1418)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][440/625]\teta 0:00:06 lr 0.000179\t wd 0.0100\ttime 0.0354 (0.0361)\tloss 0.4827 (0.4516)\tgrad_norm 2.0519 (2.1432)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][450/625]\teta 0:00:06 lr 0.000179\t wd 0.0100\ttime 0.0390 (0.0361)\tloss 0.3481 (0.4512)\tgrad_norm 1.6272 (2.1405)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][460/625]\teta 0:00:05 lr 0.000179\t wd 0.0100\ttime 0.0360 (0.0361)\tloss 0.5806 (0.4516)\tgrad_norm 2.3901 (2.1450)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][470/625]\teta 0:00:05 lr 0.000178\t wd 0.0100\ttime 0.0362 (0.0361)\tloss 0.3630 (0.4507)\tgrad_norm 2.0784 (2.1415)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][480/625]\teta 0:00:05 lr 0.000178\t wd 0.0100\ttime 0.0398 (0.0361)\tloss 0.4536 (0.4505)\tgrad_norm 2.8201 (2.1398)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][490/625]\teta 0:00:04 lr 0.000178\t wd 0.0100\ttime 0.0344 (0.0361)\tloss 0.3728 (0.4508)\tgrad_norm 2.0176 (2.1385)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][500/625]\teta 0:00:04 lr 0.000178\t wd 0.0100\ttime 0.0328 (0.0361)\tloss 0.4373 (0.4512)\tgrad_norm 3.0746 (2.1411)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][510/625]\teta 0:00:04 lr 0.000178\t wd 0.0100\ttime 0.0322 (0.0361)\tloss 0.5396 (0.4510)\tgrad_norm 3.1786 (2.1387)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][520/625]\teta 0:00:03 lr 0.000177\t wd 0.0100\ttime 0.0378 (0.0361)\tloss 0.4177 (0.4509)\tgrad_norm 2.2749 (2.1366)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][530/625]\teta 0:00:03 lr 0.000177\t wd 0.0100\ttime 0.0356 (0.0360)\tloss 0.4500 (0.4520)\tgrad_norm 1.9754 (2.1372)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][540/625]\teta 0:00:03 lr 0.000177\t wd 0.0100\ttime 0.0324 (0.0360)\tloss 0.5625 (0.4520)\tgrad_norm 2.3997 (2.1393)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][550/625]\teta 0:00:02 lr 0.000177\t wd 0.0100\ttime 0.0359 (0.0360)\tloss 0.4045 (0.4519)\tgrad_norm 2.2349 (2.1393)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][560/625]\teta 0:00:02 lr 0.000177\t wd 0.0100\ttime 0.0351 (0.0359)\tloss 0.3367 (0.4517)\tgrad_norm 1.5479 (2.1381)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][570/625]\teta 0:00:01 lr 0.000176\t wd 0.0100\ttime 0.0356 (0.0359)\tloss 0.6631 (0.4521)\tgrad_norm 2.6258 (2.1400)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][580/625]\teta 0:00:01 lr 0.000176\t wd 0.0100\ttime 0.0358 (0.0359)\tloss 0.4304 (0.4513)\tgrad_norm 3.4914 (2.1414)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][590/625]\teta 0:00:01 lr 0.000176\t wd 0.0100\ttime 0.0355 (0.0359)\tloss 0.4287 (0.4515)\tgrad_norm 2.4664 (2.1449)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][600/625]\teta 0:00:00 lr 0.000176\t wd 0.0100\ttime 0.0328 (0.0359)\tloss 0.4856 (0.4528)\tgrad_norm 2.3414 (2.1478)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][610/625]\teta 0:00:00 lr 0.000176\t wd 0.0100\ttime 0.0329 (0.0359)\tloss 0.3962 (0.4526)\tgrad_norm 1.8913 (2.1465)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [73/100][620/625]\teta 0:00:00 lr 0.000175\t wd 0.0100\ttime 0.0381 (0.0359)\tloss 0.6841 (0.4544)\tgrad_norm 2.4858 (2.1507)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 73 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_73.pth saving......\n",
      "./model_save/ckpt_epoch_73.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.7700 (0.7700)\tAcc@1 78.125 (78.125)\tAcc@5 98.438 (98.438)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.8438 (0.5882)\tAcc@1 73.438 (79.403)\tAcc@5 96.875 (99.290)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.016)\tLoss 0.7012 (0.5898)\tAcc@1 68.750 (79.613)\tAcc@5 100.000 (99.107)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.016)\tLoss 0.3640 (0.5892)\tAcc@1 84.375 (79.940)\tAcc@5 100.000 (99.194)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.6499 (0.5984)\tAcc@1 81.250 (79.688)\tAcc@5 96.875 (98.971)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.4937 (0.5927)\tAcc@1 82.812 (79.657)\tAcc@5 98.438 (99.020)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.016 (0.015)\tLoss 0.3438 (0.5892)\tAcc@1 89.062 (79.688)\tAcc@5 100.000 (99.001)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.5869 (0.5943)\tAcc@1 84.375 (79.599)\tAcc@5 95.312 (98.922)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.7661 (0.6013)\tAcc@1 76.562 (79.475)\tAcc@5 100.000 (98.823)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.4055 (0.5955)\tAcc@1 85.938 (79.584)\tAcc@5 100.000 (98.901)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.7207 (0.5868)\tAcc@1 75.000 (79.703)\tAcc@5 96.875 (98.933)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.5757 (0.5833)\tAcc@1 79.688 (79.828)\tAcc@5 100.000 (98.944)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.4670 (0.5815)\tAcc@1 84.375 (79.881)\tAcc@5 100.000 (98.941)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.5347 (0.5813)\tAcc@1 73.438 (79.938)\tAcc@5 100.000 (98.962)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.4038 (0.5787)\tAcc@1 82.812 (79.976)\tAcc@5 100.000 (98.969)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.7769 (0.5789)\tAcc@1 71.875 (80.019)\tAcc@5 100.000 (98.965)\tMem 455MB\n",
      " * Acc@1 80.020 Acc@5 98.950\n",
      "Accuracy of the network on the 10000 test images: 80.0%\n",
      "Max accuracy: 80.02%\n",
      "Train: [74/100][0/625]\teta 0:00:21 lr 0.000175\t wd 0.0100\ttime 0.0352 (0.0352)\tloss 0.4287 (0.4287)\tgrad_norm 2.1592 (2.1592)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][10/625]\teta 0:00:21 lr 0.000175\t wd 0.0100\ttime 0.0341 (0.0344)\tloss 0.2981 (0.4082)\tgrad_norm 1.4164 (2.1487)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][20/625]\teta 0:00:21 lr 0.000175\t wd 0.0100\ttime 0.0393 (0.0350)\tloss 0.6172 (0.4216)\tgrad_norm 3.2378 (2.1905)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][30/625]\teta 0:00:21 lr 0.000175\t wd 0.0100\ttime 0.0355 (0.0359)\tloss 0.4421 (0.4416)\tgrad_norm 2.0426 (2.1950)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][40/625]\teta 0:00:20 lr 0.000175\t wd 0.0100\ttime 0.0397 (0.0359)\tloss 0.4919 (0.4382)\tgrad_norm 1.8869 (2.1319)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][50/625]\teta 0:00:20 lr 0.000174\t wd 0.0100\ttime 0.0356 (0.0361)\tloss 0.3867 (0.4456)\tgrad_norm 1.8864 (2.1344)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][60/625]\teta 0:00:20 lr 0.000174\t wd 0.0100\ttime 0.0361 (0.0361)\tloss 0.4031 (0.4414)\tgrad_norm 2.0570 (2.1434)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][70/625]\teta 0:00:19 lr 0.000174\t wd 0.0100\ttime 0.0358 (0.0360)\tloss 0.6079 (0.4414)\tgrad_norm 2.2916 (2.1234)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][80/625]\teta 0:00:19 lr 0.000174\t wd 0.0100\ttime 0.0330 (0.0358)\tloss 0.6660 (0.4502)\tgrad_norm 2.9254 (2.1438)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][90/625]\teta 0:00:19 lr 0.000174\t wd 0.0100\ttime 0.0374 (0.0358)\tloss 0.3364 (0.4484)\tgrad_norm 2.1778 (2.1482)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][100/625]\teta 0:00:18 lr 0.000173\t wd 0.0100\ttime 0.0377 (0.0358)\tloss 0.4517 (0.4451)\tgrad_norm 1.8020 (2.1442)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][110/625]\teta 0:00:18 lr 0.000173\t wd 0.0100\ttime 0.0326 (0.0358)\tloss 0.4299 (0.4481)\tgrad_norm 2.2437 (2.1609)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][120/625]\teta 0:00:18 lr 0.000173\t wd 0.0100\ttime 0.0361 (0.0358)\tloss 0.4236 (0.4508)\tgrad_norm 1.9815 (2.1816)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][130/625]\teta 0:00:17 lr 0.000173\t wd 0.0100\ttime 0.0352 (0.0358)\tloss 0.4414 (0.4502)\tgrad_norm 2.2227 (2.1832)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][140/625]\teta 0:00:17 lr 0.000173\t wd 0.0100\ttime 0.0326 (0.0357)\tloss 0.3286 (0.4523)\tgrad_norm 2.3031 (2.2013)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][150/625]\teta 0:00:16 lr 0.000173\t wd 0.0100\ttime 0.0326 (0.0356)\tloss 0.2896 (0.4491)\tgrad_norm 1.4453 (2.1928)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][160/625]\teta 0:00:16 lr 0.000172\t wd 0.0100\ttime 0.0364 (0.0355)\tloss 0.3945 (0.4477)\tgrad_norm 1.6646 (2.1927)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][170/625]\teta 0:00:16 lr 0.000172\t wd 0.0100\ttime 0.0324 (0.0355)\tloss 0.3706 (0.4481)\tgrad_norm 2.1113 (2.1876)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][180/625]\teta 0:00:15 lr 0.000172\t wd 0.0100\ttime 0.0351 (0.0354)\tloss 0.3264 (0.4470)\tgrad_norm 2.0238 (2.1872)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][190/625]\teta 0:00:15 lr 0.000172\t wd 0.0100\ttime 0.0394 (0.0355)\tloss 0.3894 (0.4457)\tgrad_norm 1.9234 (2.1774)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][200/625]\teta 0:00:15 lr 0.000172\t wd 0.0100\ttime 0.0356 (0.0355)\tloss 0.3418 (0.4445)\tgrad_norm 2.3833 (2.1708)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][210/625]\teta 0:00:14 lr 0.000171\t wd 0.0100\ttime 0.0326 (0.0355)\tloss 0.3743 (0.4440)\tgrad_norm 1.8247 (2.1654)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][220/625]\teta 0:00:14 lr 0.000171\t wd 0.0100\ttime 0.0329 (0.0355)\tloss 0.3889 (0.4432)\tgrad_norm 1.9366 (2.1667)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][230/625]\teta 0:00:14 lr 0.000171\t wd 0.0100\ttime 0.0326 (0.0355)\tloss 0.4258 (0.4462)\tgrad_norm 2.0625 (2.1665)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][240/625]\teta 0:00:13 lr 0.000171\t wd 0.0100\ttime 0.0327 (0.0355)\tloss 0.3345 (0.4478)\tgrad_norm 1.8677 (2.1758)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][250/625]\teta 0:00:13 lr 0.000171\t wd 0.0100\ttime 0.0358 (0.0356)\tloss 0.3572 (0.4473)\tgrad_norm 2.0067 (2.1665)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][260/625]\teta 0:00:12 lr 0.000170\t wd 0.0100\ttime 0.0326 (0.0356)\tloss 0.4065 (0.4477)\tgrad_norm 2.1679 (2.1643)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][270/625]\teta 0:00:12 lr 0.000170\t wd 0.0100\ttime 0.0355 (0.0355)\tloss 0.7168 (0.4497)\tgrad_norm 2.6448 (2.1700)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][280/625]\teta 0:00:12 lr 0.000170\t wd 0.0100\ttime 0.0355 (0.0355)\tloss 0.3167 (0.4502)\tgrad_norm 1.3815 (2.1701)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][290/625]\teta 0:00:11 lr 0.000170\t wd 0.0100\ttime 0.0326 (0.0354)\tloss 0.4319 (0.4502)\tgrad_norm 1.8057 (2.1712)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][300/625]\teta 0:00:11 lr 0.000170\t wd 0.0100\ttime 0.0327 (0.0354)\tloss 0.5288 (0.4493)\tgrad_norm 2.3764 (2.1602)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][310/625]\teta 0:00:11 lr 0.000169\t wd 0.0100\ttime 0.0355 (0.0353)\tloss 0.3940 (0.4469)\tgrad_norm 2.3590 (2.1503)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][320/625]\teta 0:00:10 lr 0.000169\t wd 0.0100\ttime 0.0334 (0.0353)\tloss 0.4417 (0.4464)\tgrad_norm 2.5245 (2.1506)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][330/625]\teta 0:00:10 lr 0.000169\t wd 0.0100\ttime 0.0347 (0.0352)\tloss 0.3352 (0.4457)\tgrad_norm 1.8428 (2.1480)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][340/625]\teta 0:00:10 lr 0.000169\t wd 0.0100\ttime 0.0359 (0.0353)\tloss 0.5952 (0.4453)\tgrad_norm 2.4456 (2.1522)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][350/625]\teta 0:00:09 lr 0.000169\t wd 0.0100\ttime 0.0458 (0.0353)\tloss 0.5869 (0.4475)\tgrad_norm 2.8126 (2.1604)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][360/625]\teta 0:00:09 lr 0.000169\t wd 0.0100\ttime 0.0358 (0.0353)\tloss 0.3330 (0.4489)\tgrad_norm 1.3788 (2.1639)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][370/625]\teta 0:00:09 lr 0.000168\t wd 0.0100\ttime 0.0387 (0.0354)\tloss 0.3813 (0.4496)\tgrad_norm 1.7114 (2.1648)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][380/625]\teta 0:00:08 lr 0.000168\t wd 0.0100\ttime 0.0395 (0.0354)\tloss 0.4202 (0.4498)\tgrad_norm 2.1096 (2.1698)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][390/625]\teta 0:00:08 lr 0.000168\t wd 0.0100\ttime 0.0383 (0.0355)\tloss 0.4658 (0.4515)\tgrad_norm 2.3684 (2.1716)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][400/625]\teta 0:00:07 lr 0.000168\t wd 0.0100\ttime 0.0392 (0.0355)\tloss 0.2927 (0.4529)\tgrad_norm 1.7323 (2.1726)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][410/625]\teta 0:00:07 lr 0.000168\t wd 0.0100\ttime 0.0347 (0.0355)\tloss 0.2827 (0.4527)\tgrad_norm 1.6239 (2.1702)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][420/625]\teta 0:00:07 lr 0.000167\t wd 0.0100\ttime 0.0357 (0.0356)\tloss 0.4346 (0.4536)\tgrad_norm 2.2163 (2.1728)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][430/625]\teta 0:00:06 lr 0.000167\t wd 0.0100\ttime 0.0356 (0.0356)\tloss 0.5508 (0.4540)\tgrad_norm 1.9345 (2.1681)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][440/625]\teta 0:00:06 lr 0.000167\t wd 0.0100\ttime 0.0358 (0.0356)\tloss 0.2487 (0.4532)\tgrad_norm 1.7146 (2.1650)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][450/625]\teta 0:00:06 lr 0.000167\t wd 0.0100\ttime 0.0393 (0.0356)\tloss 0.4421 (0.4539)\tgrad_norm 2.4970 (2.1673)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][460/625]\teta 0:00:05 lr 0.000167\t wd 0.0100\ttime 0.0387 (0.0356)\tloss 0.4954 (0.4534)\tgrad_norm 1.5908 (2.1700)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][470/625]\teta 0:00:05 lr 0.000166\t wd 0.0100\ttime 0.0390 (0.0356)\tloss 0.3357 (0.4519)\tgrad_norm 2.3825 (2.1648)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][480/625]\teta 0:00:05 lr 0.000166\t wd 0.0100\ttime 0.0360 (0.0356)\tloss 0.3914 (0.4510)\tgrad_norm 1.7489 (2.1597)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][490/625]\teta 0:00:04 lr 0.000166\t wd 0.0100\ttime 0.0353 (0.0356)\tloss 0.3445 (0.4508)\tgrad_norm 2.0972 (2.1585)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][500/625]\teta 0:00:04 lr 0.000166\t wd 0.0100\ttime 0.0355 (0.0356)\tloss 0.3132 (0.4505)\tgrad_norm 2.0724 (2.1584)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][510/625]\teta 0:00:04 lr 0.000166\t wd 0.0100\ttime 0.0384 (0.0356)\tloss 0.3250 (0.4495)\tgrad_norm 2.0474 (2.1626)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [74/100][520/625]\teta 0:00:03 lr 0.000166\t wd 0.0100\ttime 0.0323 (0.0356)\tloss 0.2688 (0.4482)\tgrad_norm 1.8375 (2.1628)\tloss_scale 65536.0000 (32830.8944)\tmem 455MB\n",
      "Train: [74/100][530/625]\teta 0:00:03 lr 0.000165\t wd 0.0100\ttime 0.0331 (0.0356)\tloss 0.4465 (0.4476)\tgrad_norm 2.4121 (nan)\tloss_scale 32768.0000 (32829.7100)\tmem 455MB\n",
      "Train: [74/100][540/625]\teta 0:00:03 lr 0.000165\t wd 0.0100\ttime 0.0389 (0.0356)\tloss 0.4380 (0.4472)\tgrad_norm 2.5016 (nan)\tloss_scale 32768.0000 (32828.5693)\tmem 455MB\n",
      "Train: [74/100][550/625]\teta 0:00:02 lr 0.000165\t wd 0.0100\ttime 0.0356 (0.0356)\tloss 0.2328 (0.4476)\tgrad_norm 1.9020 (nan)\tloss_scale 32768.0000 (32827.4701)\tmem 455MB\n",
      "Train: [74/100][560/625]\teta 0:00:02 lr 0.000165\t wd 0.0100\ttime 0.0367 (0.0356)\tloss 0.4543 (0.4481)\tgrad_norm 2.2370 (nan)\tloss_scale 32768.0000 (32826.4100)\tmem 455MB\n",
      "Train: [74/100][570/625]\teta 0:00:01 lr 0.000165\t wd 0.0100\ttime 0.0379 (0.0357)\tloss 0.4419 (0.4485)\tgrad_norm 2.3758 (nan)\tloss_scale 32768.0000 (32825.3870)\tmem 455MB\n",
      "Train: [74/100][580/625]\teta 0:00:01 lr 0.000164\t wd 0.0100\ttime 0.0327 (0.0357)\tloss 0.3093 (0.4486)\tgrad_norm 2.0382 (nan)\tloss_scale 32768.0000 (32824.3993)\tmem 455MB\n",
      "Train: [74/100][590/625]\teta 0:00:01 lr 0.000164\t wd 0.0100\ttime 0.0323 (0.0356)\tloss 0.4844 (0.4484)\tgrad_norm 2.3553 (nan)\tloss_scale 32768.0000 (32823.4450)\tmem 455MB\n",
      "Train: [74/100][600/625]\teta 0:00:00 lr 0.000164\t wd 0.0100\ttime 0.0391 (0.0356)\tloss 0.4663 (0.4484)\tgrad_norm 2.2019 (nan)\tloss_scale 32768.0000 (32822.5225)\tmem 455MB\n",
      "Train: [74/100][610/625]\teta 0:00:00 lr 0.000164\t wd 0.0100\ttime 0.0325 (0.0356)\tloss 0.5151 (0.4493)\tgrad_norm 2.3134 (nan)\tloss_scale 32768.0000 (32821.6301)\tmem 455MB\n",
      "Train: [74/100][620/625]\teta 0:00:00 lr 0.000164\t wd 0.0100\ttime 0.0349 (0.0356)\tloss 0.4685 (0.4494)\tgrad_norm 2.6506 (nan)\tloss_scale 32768.0000 (32820.7665)\tmem 455MB\n",
      "EPOCH 74 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_74.pth saving......\n",
      "./model_save/ckpt_epoch_74.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.5532 (0.5532)\tAcc@1 87.500 (87.500)\tAcc@5 100.000 (100.000)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.016 (0.016)\tLoss 0.5767 (0.5946)\tAcc@1 81.250 (77.841)\tAcc@5 100.000 (99.716)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.016 (0.016)\tLoss 0.4521 (0.6275)\tAcc@1 82.812 (77.381)\tAcc@5 100.000 (99.107)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.016)\tLoss 0.7988 (0.6174)\tAcc@1 73.438 (78.226)\tAcc@5 96.875 (98.992)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.016 (0.016)\tLoss 0.5044 (0.6175)\tAcc@1 79.688 (78.392)\tAcc@5 98.438 (99.009)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.016)\tLoss 0.9092 (0.6357)\tAcc@1 71.875 (77.880)\tAcc@5 96.875 (98.897)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.016 (0.016)\tLoss 0.5732 (0.6370)\tAcc@1 78.125 (78.125)\tAcc@5 100.000 (98.899)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.016 (0.016)\tLoss 0.3191 (0.6206)\tAcc@1 85.938 (78.675)\tAcc@5 100.000 (98.878)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.016)\tLoss 0.4746 (0.6059)\tAcc@1 84.375 (79.147)\tAcc@5 100.000 (98.978)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.016)\tLoss 0.8115 (0.6025)\tAcc@1 75.000 (79.241)\tAcc@5 100.000 (99.021)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.016 (0.016)\tLoss 0.5371 (0.5914)\tAcc@1 82.812 (79.579)\tAcc@5 100.000 (99.056)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.016)\tLoss 0.4333 (0.5941)\tAcc@1 85.938 (79.490)\tAcc@5 100.000 (99.015)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.016)\tLoss 0.4407 (0.5941)\tAcc@1 82.812 (79.442)\tAcc@5 100.000 (99.019)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.016)\tLoss 0.6602 (0.5945)\tAcc@1 79.688 (79.509)\tAcc@5 98.438 (99.046)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.016)\tLoss 0.6538 (0.5924)\tAcc@1 76.562 (79.610)\tAcc@5 98.438 (99.058)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.4539 (0.5893)\tAcc@1 82.812 (79.770)\tAcc@5 98.438 (99.069)\tMem 455MB\n",
      " * Acc@1 79.770 Acc@5 99.060\n",
      "Accuracy of the network on the 10000 test images: 79.8%\n",
      "Max accuracy: 80.02%\n",
      "Train: [75/100][0/625]\teta 0:00:21 lr 0.000164\t wd 0.0100\ttime 0.0348 (0.0348)\tloss 0.5107 (0.5107)\tgrad_norm 1.9081 (1.9081)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][10/625]\teta 0:00:20 lr 0.000163\t wd 0.0100\ttime 0.0326 (0.0333)\tloss 0.5869 (0.4705)\tgrad_norm 2.2160 (2.1592)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][20/625]\teta 0:00:20 lr 0.000163\t wd 0.0100\ttime 0.0353 (0.0338)\tloss 0.3318 (0.4513)\tgrad_norm 1.7502 (2.1508)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][30/625]\teta 0:00:20 lr 0.000163\t wd 0.0100\ttime 0.0322 (0.0338)\tloss 0.4287 (0.4718)\tgrad_norm 1.9950 (2.1932)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][40/625]\teta 0:00:20 lr 0.000163\t wd 0.0100\ttime 0.0392 (0.0343)\tloss 0.5020 (0.4636)\tgrad_norm 1.9000 (2.1558)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][50/625]\teta 0:00:19 lr 0.000163\t wd 0.0100\ttime 0.0326 (0.0346)\tloss 0.5034 (0.4560)\tgrad_norm 2.4521 (2.1162)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][60/625]\teta 0:00:19 lr 0.000162\t wd 0.0100\ttime 0.0383 (0.0349)\tloss 0.5425 (0.4499)\tgrad_norm 1.9269 (2.1052)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][70/625]\teta 0:00:19 lr 0.000162\t wd 0.0100\ttime 0.0327 (0.0350)\tloss 0.4744 (0.4445)\tgrad_norm 2.7390 (2.1052)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][80/625]\teta 0:00:19 lr 0.000162\t wd 0.0100\ttime 0.0391 (0.0353)\tloss 0.2681 (0.4475)\tgrad_norm 1.3918 (2.1131)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][90/625]\teta 0:00:18 lr 0.000162\t wd 0.0100\ttime 0.0385 (0.0353)\tloss 0.4077 (0.4423)\tgrad_norm 1.8100 (2.1003)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][100/625]\teta 0:00:18 lr 0.000162\t wd 0.0100\ttime 0.0362 (0.0353)\tloss 0.3186 (0.4401)\tgrad_norm 2.0061 (2.1053)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][110/625]\teta 0:00:18 lr 0.000162\t wd 0.0100\ttime 0.0373 (0.0354)\tloss 0.3125 (0.4391)\tgrad_norm 2.2700 (2.1145)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][120/625]\teta 0:00:17 lr 0.000161\t wd 0.0100\ttime 0.0329 (0.0354)\tloss 0.4890 (0.4410)\tgrad_norm 1.9103 (2.1294)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][130/625]\teta 0:00:17 lr 0.000161\t wd 0.0100\ttime 0.0361 (0.0354)\tloss 0.6514 (0.4464)\tgrad_norm 2.6497 (2.1671)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][140/625]\teta 0:00:17 lr 0.000161\t wd 0.0100\ttime 0.0330 (0.0355)\tloss 0.3875 (0.4445)\tgrad_norm 2.1753 (2.1675)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][150/625]\teta 0:00:16 lr 0.000161\t wd 0.0100\ttime 0.0351 (0.0355)\tloss 0.4004 (0.4426)\tgrad_norm 2.0566 (2.1575)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][160/625]\teta 0:00:16 lr 0.000161\t wd 0.0100\ttime 0.0341 (0.0356)\tloss 0.4343 (0.4449)\tgrad_norm 2.1977 (2.1645)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][170/625]\teta 0:00:16 lr 0.000160\t wd 0.0100\ttime 0.0370 (0.0355)\tloss 0.3914 (0.4449)\tgrad_norm 1.8953 (2.1650)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][180/625]\teta 0:00:15 lr 0.000160\t wd 0.0100\ttime 0.0394 (0.0356)\tloss 0.3528 (0.4439)\tgrad_norm 1.9288 (2.1556)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][190/625]\teta 0:00:15 lr 0.000160\t wd 0.0100\ttime 0.0384 (0.0356)\tloss 0.3977 (0.4425)\tgrad_norm 2.2397 (2.1569)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][200/625]\teta 0:00:15 lr 0.000160\t wd 0.0100\ttime 0.0325 (0.0356)\tloss 0.6880 (0.4447)\tgrad_norm 2.4570 (2.1606)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][210/625]\teta 0:00:14 lr 0.000160\t wd 0.0100\ttime 0.0385 (0.0356)\tloss 0.4944 (0.4462)\tgrad_norm 1.6148 (2.1532)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][220/625]\teta 0:00:14 lr 0.000160\t wd 0.0100\ttime 0.0336 (0.0356)\tloss 0.4646 (0.4465)\tgrad_norm 2.8021 (2.1568)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][230/625]\teta 0:00:14 lr 0.000159\t wd 0.0100\ttime 0.0355 (0.0355)\tloss 0.4614 (0.4451)\tgrad_norm 1.7020 (2.1507)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][240/625]\teta 0:00:13 lr 0.000159\t wd 0.0100\ttime 0.0325 (0.0355)\tloss 0.2817 (0.4432)\tgrad_norm 1.9861 (2.1602)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][250/625]\teta 0:00:13 lr 0.000159\t wd 0.0100\ttime 0.0358 (0.0355)\tloss 0.5723 (0.4471)\tgrad_norm 2.4806 (2.1699)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][260/625]\teta 0:00:12 lr 0.000159\t wd 0.0100\ttime 0.0358 (0.0355)\tloss 0.3037 (0.4464)\tgrad_norm 1.5933 (2.1682)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][270/625]\teta 0:00:12 lr 0.000159\t wd 0.0100\ttime 0.0391 (0.0355)\tloss 0.4172 (0.4477)\tgrad_norm 2.5212 (2.1715)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][280/625]\teta 0:00:12 lr 0.000158\t wd 0.0100\ttime 0.0393 (0.0355)\tloss 0.5107 (0.4456)\tgrad_norm 2.4977 (2.1740)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][290/625]\teta 0:00:11 lr 0.000158\t wd 0.0100\ttime 0.0357 (0.0356)\tloss 0.6968 (0.4455)\tgrad_norm 2.8766 (2.1720)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][300/625]\teta 0:00:11 lr 0.000158\t wd 0.0100\ttime 0.0380 (0.0356)\tloss 0.3708 (0.4462)\tgrad_norm 1.9906 (2.1731)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][310/625]\teta 0:00:11 lr 0.000158\t wd 0.0100\ttime 0.0396 (0.0357)\tloss 0.2708 (0.4446)\tgrad_norm 1.5634 (2.1679)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][320/625]\teta 0:00:10 lr 0.000158\t wd 0.0100\ttime 0.0322 (0.0357)\tloss 0.5435 (0.4470)\tgrad_norm 2.2840 (2.1750)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][330/625]\teta 0:00:10 lr 0.000158\t wd 0.0100\ttime 0.0379 (0.0357)\tloss 0.3335 (0.4453)\tgrad_norm 2.1165 (2.1705)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][340/625]\teta 0:00:10 lr 0.000157\t wd 0.0100\ttime 0.0324 (0.0357)\tloss 0.3674 (0.4443)\tgrad_norm 2.1034 (2.1737)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][350/625]\teta 0:00:09 lr 0.000157\t wd 0.0100\ttime 0.0326 (0.0357)\tloss 0.4673 (0.4442)\tgrad_norm 2.3005 (2.1712)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][360/625]\teta 0:00:09 lr 0.000157\t wd 0.0100\ttime 0.0377 (0.0357)\tloss 0.5967 (0.4442)\tgrad_norm 2.4104 (2.1708)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][370/625]\teta 0:00:09 lr 0.000157\t wd 0.0100\ttime 0.0323 (0.0357)\tloss 0.6768 (0.4445)\tgrad_norm 2.3358 (2.1708)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][380/625]\teta 0:00:08 lr 0.000157\t wd 0.0100\ttime 0.0322 (0.0356)\tloss 0.4263 (0.4443)\tgrad_norm 2.3308 (2.1748)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][390/625]\teta 0:00:08 lr 0.000156\t wd 0.0100\ttime 0.0327 (0.0356)\tloss 0.5386 (0.4445)\tgrad_norm 2.7687 (2.1792)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][400/625]\teta 0:00:07 lr 0.000156\t wd 0.0100\ttime 0.0324 (0.0355)\tloss 0.5454 (0.4432)\tgrad_norm 2.1336 (2.1757)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][410/625]\teta 0:00:07 lr 0.000156\t wd 0.0100\ttime 0.0364 (0.0355)\tloss 0.6812 (0.4424)\tgrad_norm 2.6647 (2.1698)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][420/625]\teta 0:00:07 lr 0.000156\t wd 0.0100\ttime 0.0335 (0.0355)\tloss 0.3918 (0.4428)\tgrad_norm 1.8721 (2.1705)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][430/625]\teta 0:00:06 lr 0.000156\t wd 0.0100\ttime 0.0357 (0.0355)\tloss 0.3984 (0.4429)\tgrad_norm 2.3940 (2.1695)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][440/625]\teta 0:00:06 lr 0.000156\t wd 0.0100\ttime 0.0361 (0.0355)\tloss 0.2947 (0.4424)\tgrad_norm 2.5115 (2.1753)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][450/625]\teta 0:00:06 lr 0.000155\t wd 0.0100\ttime 0.0326 (0.0355)\tloss 0.5308 (0.4435)\tgrad_norm 1.8339 (2.1746)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][460/625]\teta 0:00:05 lr 0.000155\t wd 0.0100\ttime 0.0394 (0.0356)\tloss 0.3179 (0.4440)\tgrad_norm 2.1436 (2.1753)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][470/625]\teta 0:00:05 lr 0.000155\t wd 0.0100\ttime 0.0323 (0.0356)\tloss 0.5557 (0.4440)\tgrad_norm 1.8832 (2.1764)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][480/625]\teta 0:00:05 lr 0.000155\t wd 0.0100\ttime 0.0362 (0.0356)\tloss 0.3320 (0.4438)\tgrad_norm 1.6961 (2.1738)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][490/625]\teta 0:00:04 lr 0.000155\t wd 0.0100\ttime 0.0451 (0.0356)\tloss 0.4868 (0.4431)\tgrad_norm 1.6584 (2.1699)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][500/625]\teta 0:00:04 lr 0.000154\t wd 0.0100\ttime 0.0358 (0.0356)\tloss 0.2568 (0.4419)\tgrad_norm 1.6873 (2.1683)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][510/625]\teta 0:00:04 lr 0.000154\t wd 0.0100\ttime 0.0395 (0.0356)\tloss 0.3762 (0.4422)\tgrad_norm 2.2930 (2.1752)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][520/625]\teta 0:00:03 lr 0.000154\t wd 0.0100\ttime 0.0355 (0.0356)\tloss 0.6182 (0.4425)\tgrad_norm 2.6154 (2.1838)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][530/625]\teta 0:00:03 lr 0.000154\t wd 0.0100\ttime 0.0335 (0.0356)\tloss 0.6030 (0.4425)\tgrad_norm 2.7255 (2.1870)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][540/625]\teta 0:00:03 lr 0.000154\t wd 0.0100\ttime 0.0359 (0.0356)\tloss 0.3262 (0.4417)\tgrad_norm 1.7790 (2.1895)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][550/625]\teta 0:00:02 lr 0.000154\t wd 0.0100\ttime 0.0387 (0.0357)\tloss 0.5830 (0.4418)\tgrad_norm 2.6651 (2.1898)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][560/625]\teta 0:00:02 lr 0.000153\t wd 0.0100\ttime 0.0328 (0.0357)\tloss 0.6099 (0.4426)\tgrad_norm 2.8773 (2.1918)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][570/625]\teta 0:00:01 lr 0.000153\t wd 0.0100\ttime 0.0365 (0.0357)\tloss 0.5156 (0.4431)\tgrad_norm 2.1471 (2.1935)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][580/625]\teta 0:00:01 lr 0.000153\t wd 0.0100\ttime 0.0327 (0.0357)\tloss 0.2395 (0.4425)\tgrad_norm 1.7799 (2.1924)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][590/625]\teta 0:00:01 lr 0.000153\t wd 0.0100\ttime 0.0356 (0.0357)\tloss 0.7036 (0.4418)\tgrad_norm 2.6003 (2.1914)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][600/625]\teta 0:00:00 lr 0.000153\t wd 0.0100\ttime 0.0325 (0.0357)\tloss 0.2722 (0.4407)\tgrad_norm 1.3587 (2.1894)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][610/625]\teta 0:00:00 lr 0.000152\t wd 0.0100\ttime 0.0330 (0.0357)\tloss 0.3730 (0.4400)\tgrad_norm 2.1892 (2.1868)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [75/100][620/625]\teta 0:00:00 lr 0.000152\t wd 0.0100\ttime 0.0384 (0.0357)\tloss 0.5874 (0.4397)\tgrad_norm 2.1303 (2.1877)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 75 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_75.pth saving......\n",
      "./model_save/ckpt_epoch_75.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.7290 (0.7290)\tAcc@1 79.688 (79.688)\tAcc@5 96.875 (96.875)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.3704 (0.4917)\tAcc@1 85.938 (82.955)\tAcc@5 100.000 (99.006)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.5537 (0.5463)\tAcc@1 81.250 (81.027)\tAcc@5 100.000 (99.107)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.4822 (0.5658)\tAcc@1 82.812 (80.696)\tAcc@5 100.000 (98.942)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.5498 (0.5693)\tAcc@1 78.125 (80.450)\tAcc@5 100.000 (98.933)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.5249 (0.5709)\tAcc@1 81.250 (80.270)\tAcc@5 100.000 (98.897)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.5132 (0.5717)\tAcc@1 84.375 (80.251)\tAcc@5 100.000 (98.873)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.5596 (0.5665)\tAcc@1 82.812 (80.128)\tAcc@5 96.875 (98.900)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.016 (0.015)\tLoss 0.5195 (0.5701)\tAcc@1 84.375 (80.131)\tAcc@5 98.438 (98.843)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.5405 (0.5776)\tAcc@1 81.250 (79.928)\tAcc@5 98.438 (98.781)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.016 (0.015)\tLoss 0.4961 (0.5751)\tAcc@1 79.688 (80.198)\tAcc@5 98.438 (98.824)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.7471 (0.5707)\tAcc@1 73.438 (80.363)\tAcc@5 100.000 (98.902)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.7847 (0.5683)\tAcc@1 68.750 (80.385)\tAcc@5 100.000 (98.954)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.7578 (0.5701)\tAcc@1 75.000 (80.451)\tAcc@5 98.438 (98.915)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.6421 (0.5764)\tAcc@1 81.250 (80.419)\tAcc@5 98.438 (98.925)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.6440 (0.5811)\tAcc@1 75.000 (80.329)\tAcc@5 100.000 (98.893)\tMem 455MB\n",
      " * Acc@1 80.280 Acc@5 98.910\n",
      "Accuracy of the network on the 10000 test images: 80.3%\n",
      "Max accuracy: 80.28%\n",
      "Train: [76/100][0/625]\teta 0:00:21 lr 0.000152\t wd 0.0100\ttime 0.0346 (0.0346)\tloss 0.4043 (0.4043)\tgrad_norm 2.6997 (2.6997)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][10/625]\teta 0:00:21 lr 0.000152\t wd 0.0100\ttime 0.0367 (0.0350)\tloss 0.5015 (0.3546)\tgrad_norm 2.6158 (1.9478)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][20/625]\teta 0:00:21 lr 0.000152\t wd 0.0100\ttime 0.0325 (0.0359)\tloss 0.3745 (0.4135)\tgrad_norm 1.9098 (2.0582)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][30/625]\teta 0:00:21 lr 0.000152\t wd 0.0100\ttime 0.0348 (0.0359)\tloss 0.4602 (0.4173)\tgrad_norm 2.0738 (2.1109)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][40/625]\teta 0:00:21 lr 0.000151\t wd 0.0100\ttime 0.0359 (0.0360)\tloss 0.4375 (0.4206)\tgrad_norm 1.7773 (2.1245)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][50/625]\teta 0:00:20 lr 0.000151\t wd 0.0100\ttime 0.0360 (0.0362)\tloss 0.5542 (0.4318)\tgrad_norm 2.2236 (2.1983)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][60/625]\teta 0:00:20 lr 0.000151\t wd 0.0100\ttime 0.0391 (0.0362)\tloss 0.5361 (0.4411)\tgrad_norm 2.5044 (2.2247)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][70/625]\teta 0:00:20 lr 0.000151\t wd 0.0100\ttime 0.0325 (0.0361)\tloss 0.4497 (0.4484)\tgrad_norm 2.6156 (2.2510)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][80/625]\teta 0:00:19 lr 0.000151\t wd 0.0100\ttime 0.0347 (0.0361)\tloss 0.3196 (0.4539)\tgrad_norm 1.6607 (2.2628)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][90/625]\teta 0:00:19 lr 0.000151\t wd 0.0100\ttime 0.0323 (0.0358)\tloss 0.3027 (0.4523)\tgrad_norm 2.1841 (2.2507)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][100/625]\teta 0:00:18 lr 0.000150\t wd 0.0100\ttime 0.0327 (0.0357)\tloss 0.5645 (0.4542)\tgrad_norm 1.7692 (2.2327)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][110/625]\teta 0:00:18 lr 0.000150\t wd 0.0100\ttime 0.0351 (0.0357)\tloss 0.3687 (0.4562)\tgrad_norm 1.6239 (2.2289)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][120/625]\teta 0:00:18 lr 0.000150\t wd 0.0100\ttime 0.0356 (0.0357)\tloss 0.4119 (0.4570)\tgrad_norm 1.8787 (2.2193)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][130/625]\teta 0:00:17 lr 0.000150\t wd 0.0100\ttime 0.0355 (0.0357)\tloss 0.4390 (0.4538)\tgrad_norm 2.7177 (2.2126)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][140/625]\teta 0:00:17 lr 0.000150\t wd 0.0100\ttime 0.0382 (0.0358)\tloss 0.5181 (0.4498)\tgrad_norm 2.3761 (2.2049)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][150/625]\teta 0:00:17 lr 0.000149\t wd 0.0100\ttime 0.0328 (0.0358)\tloss 0.6558 (0.4518)\tgrad_norm 2.6858 (2.2148)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][160/625]\teta 0:00:16 lr 0.000149\t wd 0.0100\ttime 0.0354 (0.0359)\tloss 0.4160 (0.4483)\tgrad_norm 2.1539 (2.2107)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][170/625]\teta 0:00:16 lr 0.000149\t wd 0.0100\ttime 0.0355 (0.0359)\tloss 0.3584 (0.4529)\tgrad_norm 1.8792 (2.2158)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][180/625]\teta 0:00:15 lr 0.000149\t wd 0.0100\ttime 0.0330 (0.0359)\tloss 0.5107 (0.4512)\tgrad_norm 2.0516 (2.2197)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][190/625]\teta 0:00:15 lr 0.000149\t wd 0.0100\ttime 0.0356 (0.0359)\tloss 0.3889 (0.4481)\tgrad_norm 1.7184 (2.2111)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][200/625]\teta 0:00:15 lr 0.000149\t wd 0.0100\ttime 0.0328 (0.0358)\tloss 0.4802 (0.4477)\tgrad_norm 1.9307 (2.2061)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][210/625]\teta 0:00:14 lr 0.000148\t wd 0.0100\ttime 0.0364 (0.0357)\tloss 0.3076 (0.4463)\tgrad_norm 1.3318 (2.1914)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][220/625]\teta 0:00:14 lr 0.000148\t wd 0.0100\ttime 0.0326 (0.0356)\tloss 0.4250 (0.4466)\tgrad_norm 2.0760 (2.1932)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][230/625]\teta 0:00:14 lr 0.000148\t wd 0.0100\ttime 0.0391 (0.0356)\tloss 0.5103 (0.4483)\tgrad_norm 2.2843 (2.2086)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][240/625]\teta 0:00:13 lr 0.000148\t wd 0.0100\ttime 0.0354 (0.0356)\tloss 0.4404 (0.4476)\tgrad_norm 2.3759 (2.2127)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][250/625]\teta 0:00:13 lr 0.000148\t wd 0.0100\ttime 0.0391 (0.0356)\tloss 0.5796 (0.4469)\tgrad_norm 2.5456 (2.2187)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][260/625]\teta 0:00:13 lr 0.000148\t wd 0.0100\ttime 0.0354 (0.0357)\tloss 0.4756 (0.4444)\tgrad_norm 2.2573 (2.2103)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][270/625]\teta 0:00:12 lr 0.000147\t wd 0.0100\ttime 0.0325 (0.0356)\tloss 0.4985 (0.4457)\tgrad_norm 1.9179 (2.2166)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][280/625]\teta 0:00:12 lr 0.000147\t wd 0.0100\ttime 0.0330 (0.0356)\tloss 0.4336 (0.4439)\tgrad_norm 2.2712 (2.2137)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][290/625]\teta 0:00:11 lr 0.000147\t wd 0.0100\ttime 0.0327 (0.0355)\tloss 0.4294 (0.4439)\tgrad_norm 2.9896 (2.2180)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][300/625]\teta 0:00:11 lr 0.000147\t wd 0.0100\ttime 0.0340 (0.0355)\tloss 0.3999 (0.4433)\tgrad_norm 2.3511 (2.2205)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][310/625]\teta 0:00:11 lr 0.000147\t wd 0.0100\ttime 0.0397 (0.0356)\tloss 0.6953 (0.4432)\tgrad_norm 3.5522 (2.2179)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][320/625]\teta 0:00:10 lr 0.000146\t wd 0.0100\ttime 0.0328 (0.0356)\tloss 0.3325 (0.4432)\tgrad_norm 1.9974 (2.2137)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][330/625]\teta 0:00:10 lr 0.000146\t wd 0.0100\ttime 0.0365 (0.0356)\tloss 0.4592 (0.4437)\tgrad_norm 2.0212 (2.2120)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][340/625]\teta 0:00:10 lr 0.000146\t wd 0.0100\ttime 0.0353 (0.0356)\tloss 0.2998 (0.4425)\tgrad_norm 1.6054 (2.2076)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][350/625]\teta 0:00:09 lr 0.000146\t wd 0.0100\ttime 0.0353 (0.0357)\tloss 0.4294 (0.4422)\tgrad_norm 2.0479 (2.2074)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][360/625]\teta 0:00:09 lr 0.000146\t wd 0.0100\ttime 0.0389 (0.0357)\tloss 0.4507 (0.4409)\tgrad_norm 2.2352 (2.2038)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][370/625]\teta 0:00:09 lr 0.000146\t wd 0.0100\ttime 0.0329 (0.0356)\tloss 0.3557 (0.4408)\tgrad_norm 1.7954 (2.2050)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][380/625]\teta 0:00:08 lr 0.000145\t wd 0.0100\ttime 0.0325 (0.0356)\tloss 0.5718 (0.4409)\tgrad_norm 2.3378 (2.2047)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][390/625]\teta 0:00:08 lr 0.000145\t wd 0.0100\ttime 0.0394 (0.0356)\tloss 0.4541 (0.4402)\tgrad_norm 2.2613 (2.2046)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][400/625]\teta 0:00:08 lr 0.000145\t wd 0.0100\ttime 0.0351 (0.0356)\tloss 0.2969 (0.4395)\tgrad_norm 1.7591 (2.2015)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][410/625]\teta 0:00:07 lr 0.000145\t wd 0.0100\ttime 0.0360 (0.0356)\tloss 0.4714 (0.4387)\tgrad_norm 1.8757 (2.1961)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][420/625]\teta 0:00:07 lr 0.000145\t wd 0.0100\ttime 0.0392 (0.0356)\tloss 0.5337 (0.4389)\tgrad_norm 2.2130 (2.1947)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][430/625]\teta 0:00:06 lr 0.000145\t wd 0.0100\ttime 0.0352 (0.0356)\tloss 0.5034 (0.4400)\tgrad_norm 2.4252 (2.1974)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][440/625]\teta 0:00:06 lr 0.000144\t wd 0.0100\ttime 0.0398 (0.0357)\tloss 0.4148 (0.4395)\tgrad_norm 1.8134 (2.1962)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][450/625]\teta 0:00:06 lr 0.000144\t wd 0.0100\ttime 0.0353 (0.0356)\tloss 0.7114 (0.4392)\tgrad_norm 2.4139 (2.1917)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][460/625]\teta 0:00:05 lr 0.000144\t wd 0.0100\ttime 0.0363 (0.0356)\tloss 0.4482 (0.4380)\tgrad_norm 2.1629 (2.1887)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][470/625]\teta 0:00:05 lr 0.000144\t wd 0.0100\ttime 0.0322 (0.0356)\tloss 0.6123 (0.4391)\tgrad_norm 2.4000 (2.1887)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][480/625]\teta 0:00:05 lr 0.000144\t wd 0.0100\ttime 0.0329 (0.0356)\tloss 0.3149 (0.4398)\tgrad_norm 1.5624 (2.1874)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][490/625]\teta 0:00:04 lr 0.000143\t wd 0.0100\ttime 0.0360 (0.0355)\tloss 0.5044 (0.4396)\tgrad_norm 3.3184 (2.1854)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][500/625]\teta 0:00:04 lr 0.000143\t wd 0.0100\ttime 0.0329 (0.0356)\tloss 0.3335 (0.4396)\tgrad_norm 2.0687 (2.1859)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][510/625]\teta 0:00:04 lr 0.000143\t wd 0.0100\ttime 0.0358 (0.0356)\tloss 0.5146 (0.4396)\tgrad_norm 2.2194 (2.1865)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][520/625]\teta 0:00:03 lr 0.000143\t wd 0.0100\ttime 0.0327 (0.0356)\tloss 0.2825 (0.4389)\tgrad_norm 1.4069 (2.1855)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][530/625]\teta 0:00:03 lr 0.000143\t wd 0.0100\ttime 0.0376 (0.0356)\tloss 0.3911 (0.4392)\tgrad_norm 1.9935 (2.1864)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][540/625]\teta 0:00:03 lr 0.000143\t wd 0.0100\ttime 0.0352 (0.0356)\tloss 0.3970 (0.4393)\tgrad_norm 2.2971 (2.1911)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][550/625]\teta 0:00:02 lr 0.000142\t wd 0.0100\ttime 0.0360 (0.0356)\tloss 0.3774 (0.4390)\tgrad_norm 1.6510 (2.1908)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][560/625]\teta 0:00:02 lr 0.000142\t wd 0.0100\ttime 0.0391 (0.0356)\tloss 0.4336 (0.4390)\tgrad_norm 1.9666 (2.1881)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][570/625]\teta 0:00:01 lr 0.000142\t wd 0.0100\ttime 0.0382 (0.0356)\tloss 0.5107 (0.4383)\tgrad_norm 2.1377 (2.1843)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][580/625]\teta 0:00:01 lr 0.000142\t wd 0.0100\ttime 0.0330 (0.0356)\tloss 0.5752 (0.4376)\tgrad_norm 2.4959 (2.1831)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][590/625]\teta 0:00:01 lr 0.000142\t wd 0.0100\ttime 0.0361 (0.0356)\tloss 0.3054 (0.4377)\tgrad_norm 2.2972 (2.1834)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][600/625]\teta 0:00:00 lr 0.000142\t wd 0.0100\ttime 0.0399 (0.0357)\tloss 0.4697 (0.4373)\tgrad_norm 1.7578 (2.1839)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][610/625]\teta 0:00:00 lr 0.000141\t wd 0.0100\ttime 0.0391 (0.0357)\tloss 0.3130 (0.4378)\tgrad_norm 1.5203 (2.1872)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [76/100][620/625]\teta 0:00:00 lr 0.000141\t wd 0.0100\ttime 0.0357 (0.0357)\tloss 0.4856 (0.4382)\tgrad_norm 2.5391 (2.1886)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 76 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_76.pth saving......\n",
      "./model_save/ckpt_epoch_76.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.6426 (0.6426)\tAcc@1 79.688 (79.688)\tAcc@5 100.000 (100.000)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.9175 (0.6518)\tAcc@1 75.000 (77.983)\tAcc@5 96.875 (99.290)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.016)\tLoss 0.7646 (0.6201)\tAcc@1 75.000 (78.943)\tAcc@5 98.438 (99.405)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.5000 (0.6184)\tAcc@1 84.375 (79.335)\tAcc@5 98.438 (99.143)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.016)\tLoss 0.6206 (0.5981)\tAcc@1 73.438 (79.573)\tAcc@5 98.438 (99.085)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.5996 (0.5982)\tAcc@1 78.125 (79.657)\tAcc@5 98.438 (99.020)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.4893 (0.6004)\tAcc@1 84.375 (79.534)\tAcc@5 100.000 (99.103)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.5420 (0.5994)\tAcc@1 84.375 (79.599)\tAcc@5 98.438 (99.142)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.6729 (0.5962)\tAcc@1 78.125 (79.649)\tAcc@5 100.000 (99.132)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.5894 (0.6036)\tAcc@1 79.688 (79.584)\tAcc@5 96.875 (98.987)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.2964 (0.5968)\tAcc@1 92.188 (79.765)\tAcc@5 100.000 (99.010)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.7637 (0.5970)\tAcc@1 68.750 (79.702)\tAcc@5 100.000 (99.001)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.7612 (0.5953)\tAcc@1 78.125 (79.842)\tAcc@5 100.000 (99.044)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.5659 (0.5925)\tAcc@1 73.438 (79.974)\tAcc@5 100.000 (99.046)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.5508 (0.5910)\tAcc@1 71.875 (79.942)\tAcc@5 100.000 (99.058)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.5952 (0.5918)\tAcc@1 81.250 (79.957)\tAcc@5 100.000 (99.100)\tMem 455MB\n",
      " * Acc@1 80.010 Acc@5 99.100\n",
      "Accuracy of the network on the 10000 test images: 80.0%\n",
      "Max accuracy: 80.28%\n",
      "Train: [77/100][0/625]\teta 0:00:23 lr 0.000141\t wd 0.0100\ttime 0.0369 (0.0369)\tloss 0.5757 (0.5757)\tgrad_norm 2.8306 (2.8306)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][10/625]\teta 0:00:21 lr 0.000141\t wd 0.0100\ttime 0.0362 (0.0349)\tloss 0.4861 (0.4134)\tgrad_norm 2.3725 (2.1159)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][20/625]\teta 0:00:20 lr 0.000141\t wd 0.0100\ttime 0.0323 (0.0345)\tloss 0.2815 (0.4141)\tgrad_norm 1.5654 (2.1658)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][30/625]\teta 0:00:20 lr 0.000141\t wd 0.0100\ttime 0.0383 (0.0350)\tloss 0.4758 (0.4316)\tgrad_norm 2.0786 (2.1980)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][40/625]\teta 0:00:20 lr 0.000140\t wd 0.0100\ttime 0.0355 (0.0353)\tloss 0.4019 (0.4285)\tgrad_norm 2.2897 (2.1528)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][50/625]\teta 0:00:20 lr 0.000140\t wd 0.0100\ttime 0.0365 (0.0353)\tloss 0.3789 (0.4254)\tgrad_norm 1.6564 (2.1701)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][60/625]\teta 0:00:20 lr 0.000140\t wd 0.0100\ttime 0.0381 (0.0355)\tloss 0.2627 (0.4256)\tgrad_norm 1.5989 (2.1400)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][70/625]\teta 0:00:19 lr 0.000140\t wd 0.0100\ttime 0.0324 (0.0356)\tloss 0.3611 (0.4162)\tgrad_norm 1.6119 (2.1144)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][80/625]\teta 0:00:19 lr 0.000140\t wd 0.0100\ttime 0.0385 (0.0356)\tloss 0.5083 (0.4205)\tgrad_norm 3.0338 (2.1263)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][90/625]\teta 0:00:19 lr 0.000140\t wd 0.0100\ttime 0.0386 (0.0355)\tloss 0.3745 (0.4279)\tgrad_norm 1.9141 (2.1490)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][100/625]\teta 0:00:18 lr 0.000139\t wd 0.0100\ttime 0.0330 (0.0355)\tloss 0.4851 (0.4272)\tgrad_norm 2.1221 (2.1388)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][110/625]\teta 0:00:18 lr 0.000139\t wd 0.0100\ttime 0.0355 (0.0356)\tloss 0.5337 (0.4320)\tgrad_norm 2.0073 (2.1648)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][120/625]\teta 0:00:17 lr 0.000139\t wd 0.0100\ttime 0.0364 (0.0356)\tloss 0.4436 (0.4312)\tgrad_norm 1.7052 (2.1512)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][130/625]\teta 0:00:17 lr 0.000139\t wd 0.0100\ttime 0.0328 (0.0355)\tloss 0.5200 (0.4318)\tgrad_norm 2.1765 (2.1553)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][140/625]\teta 0:00:17 lr 0.000139\t wd 0.0100\ttime 0.0326 (0.0355)\tloss 0.5776 (0.4377)\tgrad_norm 2.2906 (2.1762)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][150/625]\teta 0:00:16 lr 0.000139\t wd 0.0100\ttime 0.0347 (0.0355)\tloss 0.3220 (0.4342)\tgrad_norm 1.9314 (2.1717)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][160/625]\teta 0:00:16 lr 0.000138\t wd 0.0100\ttime 0.0383 (0.0356)\tloss 0.5771 (0.4368)\tgrad_norm 2.6346 (2.1774)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][170/625]\teta 0:00:16 lr 0.000138\t wd 0.0100\ttime 0.0354 (0.0356)\tloss 0.4346 (0.4370)\tgrad_norm 2.1679 (2.1771)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][180/625]\teta 0:00:15 lr 0.000138\t wd 0.0100\ttime 0.0323 (0.0356)\tloss 0.3860 (0.4349)\tgrad_norm 2.2046 (2.1845)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][190/625]\teta 0:00:15 lr 0.000138\t wd 0.0100\ttime 0.0330 (0.0356)\tloss 0.4504 (0.4372)\tgrad_norm 1.8204 (2.1898)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][200/625]\teta 0:00:15 lr 0.000138\t wd 0.0100\ttime 0.0324 (0.0356)\tloss 0.5210 (0.4373)\tgrad_norm 2.2200 (2.2039)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][210/625]\teta 0:00:14 lr 0.000137\t wd 0.0100\ttime 0.0356 (0.0355)\tloss 0.3738 (0.4389)\tgrad_norm 1.9453 (2.1974)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][220/625]\teta 0:00:14 lr 0.000137\t wd 0.0100\ttime 0.0325 (0.0355)\tloss 0.1476 (0.4338)\tgrad_norm 1.5157 (2.1852)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][230/625]\teta 0:00:14 lr 0.000137\t wd 0.0100\ttime 0.0327 (0.0354)\tloss 0.2891 (0.4340)\tgrad_norm 1.6563 (2.2108)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][240/625]\teta 0:00:13 lr 0.000137\t wd 0.0100\ttime 0.0337 (0.0353)\tloss 0.3066 (0.4325)\tgrad_norm 2.0478 (2.2189)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][250/625]\teta 0:00:13 lr 0.000137\t wd 0.0100\ttime 0.0357 (0.0353)\tloss 0.4424 (0.4318)\tgrad_norm 2.5019 (2.2125)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][260/625]\teta 0:00:12 lr 0.000137\t wd 0.0100\ttime 0.0365 (0.0353)\tloss 0.3225 (0.4306)\tgrad_norm 1.9379 (2.2099)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][270/625]\teta 0:00:12 lr 0.000136\t wd 0.0100\ttime 0.0330 (0.0354)\tloss 0.5234 (0.4310)\tgrad_norm 2.3058 (2.2107)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][280/625]\teta 0:00:12 lr 0.000136\t wd 0.0100\ttime 0.0392 (0.0354)\tloss 0.4248 (0.4308)\tgrad_norm 1.8224 (2.2100)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][290/625]\teta 0:00:11 lr 0.000136\t wd 0.0100\ttime 0.0362 (0.0355)\tloss 0.4634 (0.4304)\tgrad_norm 2.5882 (2.2065)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][300/625]\teta 0:00:11 lr 0.000136\t wd 0.0100\ttime 0.0395 (0.0355)\tloss 0.5942 (0.4301)\tgrad_norm 1.9569 (2.2001)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][310/625]\teta 0:00:11 lr 0.000136\t wd 0.0100\ttime 0.0326 (0.0355)\tloss 0.3606 (0.4305)\tgrad_norm 1.9485 (2.2045)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][320/625]\teta 0:00:10 lr 0.000136\t wd 0.0100\ttime 0.0326 (0.0354)\tloss 0.5962 (0.4319)\tgrad_norm 2.8223 (2.2080)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][330/625]\teta 0:00:10 lr 0.000135\t wd 0.0100\ttime 0.0326 (0.0354)\tloss 0.4211 (0.4312)\tgrad_norm 2.6461 (2.2085)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][340/625]\teta 0:00:10 lr 0.000135\t wd 0.0100\ttime 0.0323 (0.0354)\tloss 0.4888 (0.4316)\tgrad_norm 2.7487 (2.2113)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][350/625]\teta 0:00:09 lr 0.000135\t wd 0.0100\ttime 0.0346 (0.0354)\tloss 0.3665 (0.4321)\tgrad_norm 2.1371 (2.2130)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][360/625]\teta 0:00:09 lr 0.000135\t wd 0.0100\ttime 0.0323 (0.0354)\tloss 0.5400 (0.4319)\tgrad_norm 2.0823 (2.2099)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][370/625]\teta 0:00:09 lr 0.000135\t wd 0.0100\ttime 0.0435 (0.0354)\tloss 0.3643 (0.4323)\tgrad_norm 2.0127 (2.2103)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][380/625]\teta 0:00:08 lr 0.000135\t wd 0.0100\ttime 0.0398 (0.0354)\tloss 0.2222 (0.4325)\tgrad_norm 1.9029 (2.2089)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][390/625]\teta 0:00:08 lr 0.000134\t wd 0.0100\ttime 0.0392 (0.0355)\tloss 0.5688 (0.4326)\tgrad_norm 2.8455 (2.2093)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][400/625]\teta 0:00:07 lr 0.000134\t wd 0.0100\ttime 0.0328 (0.0355)\tloss 0.3650 (0.4328)\tgrad_norm 2.3262 (2.2100)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][410/625]\teta 0:00:07 lr 0.000134\t wd 0.0100\ttime 0.0360 (0.0355)\tloss 0.5303 (0.4350)\tgrad_norm 1.9990 (2.2121)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][420/625]\teta 0:00:07 lr 0.000134\t wd 0.0100\ttime 0.0328 (0.0355)\tloss 0.5591 (0.4347)\tgrad_norm 3.0900 (2.2138)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][430/625]\teta 0:00:06 lr 0.000134\t wd 0.0100\ttime 0.0357 (0.0355)\tloss 0.4001 (0.4346)\tgrad_norm 2.4767 (2.2129)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][440/625]\teta 0:00:06 lr 0.000134\t wd 0.0100\ttime 0.0375 (0.0356)\tloss 0.6084 (0.4354)\tgrad_norm 2.4805 (2.2088)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][450/625]\teta 0:00:06 lr 0.000133\t wd 0.0100\ttime 0.0393 (0.0356)\tloss 0.4746 (0.4357)\tgrad_norm 2.3416 (2.2039)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][460/625]\teta 0:00:05 lr 0.000133\t wd 0.0100\ttime 0.0384 (0.0356)\tloss 0.3748 (0.4354)\tgrad_norm 2.0585 (2.2047)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][470/625]\teta 0:00:05 lr 0.000133\t wd 0.0100\ttime 0.0382 (0.0356)\tloss 0.5132 (0.4358)\tgrad_norm 2.4535 (2.2039)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][480/625]\teta 0:00:05 lr 0.000133\t wd 0.0100\ttime 0.0393 (0.0357)\tloss 0.3088 (0.4357)\tgrad_norm 1.7835 (2.2032)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][490/625]\teta 0:00:04 lr 0.000133\t wd 0.0100\ttime 0.0365 (0.0357)\tloss 0.6309 (0.4353)\tgrad_norm 2.7342 (2.1994)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][500/625]\teta 0:00:04 lr 0.000133\t wd 0.0100\ttime 0.0388 (0.0357)\tloss 0.5762 (0.4356)\tgrad_norm 2.3958 (2.1988)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][510/625]\teta 0:00:04 lr 0.000132\t wd 0.0100\ttime 0.0360 (0.0357)\tloss 0.5708 (0.4362)\tgrad_norm 2.7509 (2.1987)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][520/625]\teta 0:00:03 lr 0.000132\t wd 0.0100\ttime 0.0333 (0.0357)\tloss 0.4373 (0.4358)\tgrad_norm 1.7926 (2.1951)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][530/625]\teta 0:00:03 lr 0.000132\t wd 0.0100\ttime 0.0352 (0.0358)\tloss 0.3774 (0.4346)\tgrad_norm 1.8887 (2.1916)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][540/625]\teta 0:00:03 lr 0.000132\t wd 0.0100\ttime 0.0326 (0.0358)\tloss 0.5269 (0.4345)\tgrad_norm 2.9355 (2.1919)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][550/625]\teta 0:00:02 lr 0.000132\t wd 0.0100\ttime 0.0361 (0.0358)\tloss 0.4504 (0.4347)\tgrad_norm 2.1810 (2.1981)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][560/625]\teta 0:00:02 lr 0.000132\t wd 0.0100\ttime 0.0389 (0.0358)\tloss 0.2688 (0.4337)\tgrad_norm 1.5418 (2.1969)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][570/625]\teta 0:00:01 lr 0.000131\t wd 0.0100\ttime 0.0356 (0.0358)\tloss 0.5083 (0.4344)\tgrad_norm 2.3087 (2.1971)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][580/625]\teta 0:00:01 lr 0.000131\t wd 0.0100\ttime 0.0324 (0.0358)\tloss 0.3738 (0.4340)\tgrad_norm 1.6904 (2.1956)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][590/625]\teta 0:00:01 lr 0.000131\t wd 0.0100\ttime 0.0378 (0.0358)\tloss 0.7324 (0.4343)\tgrad_norm 2.5556 (2.1976)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][600/625]\teta 0:00:00 lr 0.000131\t wd 0.0100\ttime 0.0331 (0.0358)\tloss 0.3428 (0.4347)\tgrad_norm 2.0087 (2.1986)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][610/625]\teta 0:00:00 lr 0.000131\t wd 0.0100\ttime 0.0358 (0.0358)\tloss 0.4973 (0.4346)\tgrad_norm 2.0771 (2.1986)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [77/100][620/625]\teta 0:00:00 lr 0.000131\t wd 0.0100\ttime 0.0403 (0.0358)\tloss 0.3728 (0.4354)\tgrad_norm 1.7122 (2.1997)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 77 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_77.pth saving......\n",
      "./model_save/ckpt_epoch_77.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.9326 (0.9326)\tAcc@1 64.062 (64.062)\tAcc@5 100.000 (100.000)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.016)\tLoss 0.6797 (0.6938)\tAcc@1 75.000 (76.562)\tAcc@5 98.438 (98.864)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.016)\tLoss 0.3335 (0.6275)\tAcc@1 90.625 (79.018)\tAcc@5 100.000 (98.884)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.7036 (0.6197)\tAcc@1 81.250 (79.385)\tAcc@5 96.875 (98.942)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.4558 (0.5828)\tAcc@1 89.062 (80.678)\tAcc@5 98.438 (98.971)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.7441 (0.5836)\tAcc@1 70.312 (80.453)\tAcc@5 100.000 (99.020)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.6821 (0.5895)\tAcc@1 71.875 (80.097)\tAcc@5 100.000 (98.950)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.6006 (0.5932)\tAcc@1 81.250 (79.908)\tAcc@5 98.438 (98.988)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.5928 (0.5962)\tAcc@1 79.688 (79.842)\tAcc@5 98.438 (98.900)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.6460 (0.5933)\tAcc@1 79.688 (79.722)\tAcc@5 98.438 (98.884)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.4221 (0.5906)\tAcc@1 85.938 (79.827)\tAcc@5 100.000 (98.902)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.4868 (0.5864)\tAcc@1 82.812 (79.969)\tAcc@5 100.000 (98.944)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.6348 (0.5878)\tAcc@1 76.562 (79.972)\tAcc@5 100.000 (98.980)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.6118 (0.5881)\tAcc@1 78.125 (80.010)\tAcc@5 100.000 (99.034)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.8315 (0.5877)\tAcc@1 68.750 (79.865)\tAcc@5 98.438 (99.025)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.2815 (0.5842)\tAcc@1 89.062 (79.967)\tAcc@5 100.000 (99.058)\tMem 455MB\n",
      " * Acc@1 79.970 Acc@5 99.070\n",
      "Accuracy of the network on the 10000 test images: 80.0%\n",
      "Max accuracy: 80.28%\n",
      "Train: [78/100][0/625]\teta 0:00:25 lr 0.000130\t wd 0.0100\ttime 0.0400 (0.0400)\tloss 0.4749 (0.4749)\tgrad_norm 2.5318 (2.5318)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [78/100][10/625]\teta 0:00:22 lr 0.000130\t wd 0.0100\ttime 0.0333 (0.0363)\tloss 0.3264 (0.3807)\tgrad_norm 2.7488 (1.9996)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [78/100][20/625]\teta 0:00:21 lr 0.000130\t wd 0.0100\ttime 0.0325 (0.0359)\tloss 0.5347 (0.4018)\tgrad_norm 2.4956 (2.0474)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [78/100][30/625]\teta 0:00:21 lr 0.000130\t wd 0.0100\ttime 0.0343 (0.0357)\tloss 0.4348 (0.3967)\tgrad_norm 2.0246 (nan)\tloss_scale 32768.0000 (33825.0323)\tmem 455MB\n",
      "Train: [78/100][40/625]\teta 0:00:20 lr 0.000130\t wd 0.0100\ttime 0.0390 (0.0357)\tloss 0.4504 (0.4073)\tgrad_norm 2.2410 (nan)\tloss_scale 32768.0000 (33567.2195)\tmem 455MB\n",
      "Train: [78/100][50/625]\teta 0:00:20 lr 0.000130\t wd 0.0100\ttime 0.0355 (0.0356)\tloss 0.3899 (0.4000)\tgrad_norm 1.8676 (nan)\tloss_scale 32768.0000 (33410.5098)\tmem 455MB\n",
      "Train: [78/100][60/625]\teta 0:00:20 lr 0.000129\t wd 0.0100\ttime 0.0352 (0.0356)\tloss 0.4053 (0.4040)\tgrad_norm 2.1334 (nan)\tloss_scale 32768.0000 (33305.1803)\tmem 455MB\n",
      "Train: [78/100][70/625]\teta 0:00:19 lr 0.000129\t wd 0.0100\ttime 0.0360 (0.0357)\tloss 0.3125 (0.4028)\tgrad_norm 1.5899 (nan)\tloss_scale 32768.0000 (33229.5211)\tmem 455MB\n",
      "Train: [78/100][80/625]\teta 0:00:19 lr 0.000129\t wd 0.0100\ttime 0.0323 (0.0358)\tloss 0.2954 (0.4028)\tgrad_norm 1.6778 (nan)\tloss_scale 32768.0000 (33172.5432)\tmem 455MB\n",
      "Train: [78/100][90/625]\teta 0:00:19 lr 0.000129\t wd 0.0100\ttime 0.0324 (0.0358)\tloss 0.3933 (0.4030)\tgrad_norm 2.1738 (nan)\tloss_scale 32768.0000 (33128.0879)\tmem 455MB\n",
      "Train: [78/100][100/625]\teta 0:00:18 lr 0.000129\t wd 0.0100\ttime 0.0323 (0.0357)\tloss 0.3757 (0.4047)\tgrad_norm 2.8267 (nan)\tloss_scale 32768.0000 (33092.4356)\tmem 455MB\n",
      "Train: [78/100][110/625]\teta 0:00:18 lr 0.000129\t wd 0.0100\ttime 0.0361 (0.0356)\tloss 0.6416 (0.4121)\tgrad_norm 2.8293 (nan)\tloss_scale 32768.0000 (33063.2072)\tmem 455MB\n",
      "Train: [78/100][120/625]\teta 0:00:17 lr 0.000128\t wd 0.0100\ttime 0.0326 (0.0356)\tloss 0.4514 (0.4114)\tgrad_norm 2.1185 (nan)\tloss_scale 32768.0000 (33038.8099)\tmem 455MB\n",
      "Train: [78/100][130/625]\teta 0:00:17 lr 0.000128\t wd 0.0100\ttime 0.0359 (0.0357)\tloss 0.5020 (0.4134)\tgrad_norm 2.0486 (nan)\tloss_scale 32768.0000 (33018.1374)\tmem 455MB\n",
      "Train: [78/100][140/625]\teta 0:00:17 lr 0.000128\t wd 0.0100\ttime 0.0395 (0.0356)\tloss 0.6919 (0.4172)\tgrad_norm 2.0684 (nan)\tloss_scale 32768.0000 (33000.3972)\tmem 455MB\n",
      "Train: [78/100][150/625]\teta 0:00:16 lr 0.000128\t wd 0.0100\ttime 0.0365 (0.0357)\tloss 0.5664 (0.4215)\tgrad_norm 2.5258 (nan)\tloss_scale 32768.0000 (32985.0066)\tmem 455MB\n",
      "Train: [78/100][160/625]\teta 0:00:16 lr 0.000128\t wd 0.0100\ttime 0.0397 (0.0358)\tloss 0.3948 (0.4225)\tgrad_norm 3.4009 (nan)\tloss_scale 32768.0000 (32971.5280)\tmem 455MB\n",
      "Train: [78/100][170/625]\teta 0:00:16 lr 0.000128\t wd 0.0100\ttime 0.0360 (0.0358)\tloss 0.4856 (0.4236)\tgrad_norm 2.2429 (nan)\tloss_scale 32768.0000 (32959.6257)\tmem 455MB\n",
      "Train: [78/100][180/625]\teta 0:00:15 lr 0.000127\t wd 0.0100\ttime 0.0325 (0.0357)\tloss 0.3706 (0.4237)\tgrad_norm 1.9944 (nan)\tloss_scale 32768.0000 (32949.0387)\tmem 455MB\n",
      "Train: [78/100][190/625]\teta 0:00:15 lr 0.000127\t wd 0.0100\ttime 0.0332 (0.0357)\tloss 0.3748 (0.4248)\tgrad_norm 1.9469 (nan)\tloss_scale 32768.0000 (32939.5602)\tmem 455MB\n",
      "Train: [78/100][200/625]\teta 0:00:15 lr 0.000127\t wd 0.0100\ttime 0.0327 (0.0357)\tloss 0.5200 (0.4244)\tgrad_norm 1.9282 (nan)\tloss_scale 32768.0000 (32931.0249)\tmem 455MB\n",
      "Train: [78/100][210/625]\teta 0:00:14 lr 0.000127\t wd 0.0100\ttime 0.0331 (0.0357)\tloss 0.3303 (0.4241)\tgrad_norm 1.8466 (nan)\tloss_scale 32768.0000 (32923.2986)\tmem 455MB\n",
      "Train: [78/100][220/625]\teta 0:00:14 lr 0.000127\t wd 0.0100\ttime 0.0354 (0.0357)\tloss 0.6060 (0.4258)\tgrad_norm 2.4613 (nan)\tloss_scale 32768.0000 (32916.2715)\tmem 455MB\n",
      "Train: [78/100][230/625]\teta 0:00:14 lr 0.000127\t wd 0.0100\ttime 0.0342 (0.0356)\tloss 0.4805 (0.4290)\tgrad_norm 2.3711 (nan)\tloss_scale 32768.0000 (32909.8528)\tmem 455MB\n",
      "Train: [78/100][240/625]\teta 0:00:13 lr 0.000126\t wd 0.0100\ttime 0.0390 (0.0356)\tloss 0.1658 (0.4283)\tgrad_norm 1.2941 (nan)\tloss_scale 32768.0000 (32903.9668)\tmem 455MB\n",
      "Train: [78/100][250/625]\teta 0:00:13 lr 0.000126\t wd 0.0100\ttime 0.0328 (0.0356)\tloss 0.6802 (0.4287)\tgrad_norm 2.4301 (nan)\tloss_scale 32768.0000 (32898.5498)\tmem 455MB\n",
      "Train: [78/100][260/625]\teta 0:00:12 lr 0.000126\t wd 0.0100\ttime 0.0324 (0.0355)\tloss 0.3750 (0.4265)\tgrad_norm 2.1365 (nan)\tloss_scale 32768.0000 (32893.5479)\tmem 455MB\n",
      "Train: [78/100][270/625]\teta 0:00:12 lr 0.000126\t wd 0.0100\ttime 0.0356 (0.0355)\tloss 0.4604 (0.4259)\tgrad_norm 1.8097 (nan)\tloss_scale 32768.0000 (32888.9151)\tmem 455MB\n",
      "Train: [78/100][280/625]\teta 0:00:12 lr 0.000126\t wd 0.0100\ttime 0.0358 (0.0355)\tloss 0.3069 (0.4248)\tgrad_norm 1.4849 (nan)\tloss_scale 32768.0000 (32884.6121)\tmem 455MB\n",
      "Train: [78/100][290/625]\teta 0:00:11 lr 0.000126\t wd 0.0100\ttime 0.0325 (0.0354)\tloss 0.5654 (0.4274)\tgrad_norm 2.4831 (nan)\tloss_scale 32768.0000 (32880.6048)\tmem 455MB\n",
      "Train: [78/100][300/625]\teta 0:00:11 lr 0.000125\t wd 0.0100\ttime 0.0326 (0.0354)\tloss 0.4126 (0.4271)\tgrad_norm 2.6913 (nan)\tloss_scale 32768.0000 (32876.8638)\tmem 455MB\n",
      "Train: [78/100][310/625]\teta 0:00:11 lr 0.000125\t wd 0.0100\ttime 0.0329 (0.0354)\tloss 0.3896 (0.4261)\tgrad_norm 3.0541 (nan)\tloss_scale 32768.0000 (32873.3633)\tmem 455MB\n",
      "Train: [78/100][320/625]\teta 0:00:10 lr 0.000125\t wd 0.0100\ttime 0.0387 (0.0355)\tloss 0.3923 (0.4263)\tgrad_norm 1.9713 (nan)\tloss_scale 32768.0000 (32870.0810)\tmem 455MB\n",
      "Train: [78/100][330/625]\teta 0:00:10 lr 0.000125\t wd 0.0100\ttime 0.0390 (0.0355)\tloss 0.3906 (0.4271)\tgrad_norm 1.5990 (nan)\tloss_scale 32768.0000 (32866.9970)\tmem 455MB\n",
      "Train: [78/100][340/625]\teta 0:00:10 lr 0.000125\t wd 0.0100\ttime 0.0324 (0.0355)\tloss 0.4194 (0.4261)\tgrad_norm 2.5376 (nan)\tloss_scale 32768.0000 (32864.0938)\tmem 455MB\n",
      "Train: [78/100][350/625]\teta 0:00:09 lr 0.000125\t wd 0.0100\ttime 0.0328 (0.0354)\tloss 0.2284 (0.4237)\tgrad_norm 1.8629 (nan)\tloss_scale 32768.0000 (32861.3561)\tmem 455MB\n",
      "Train: [78/100][360/625]\teta 0:00:09 lr 0.000124\t wd 0.0100\ttime 0.0325 (0.0354)\tloss 0.4465 (0.4249)\tgrad_norm 2.5631 (nan)\tloss_scale 32768.0000 (32858.7701)\tmem 455MB\n",
      "Train: [78/100][370/625]\teta 0:00:09 lr 0.000124\t wd 0.0100\ttime 0.0359 (0.0355)\tloss 0.5190 (0.4257)\tgrad_norm 1.9486 (nan)\tloss_scale 32768.0000 (32856.3235)\tmem 455MB\n",
      "Train: [78/100][380/625]\teta 0:00:08 lr 0.000124\t wd 0.0100\ttime 0.0327 (0.0355)\tloss 0.3423 (0.4256)\tgrad_norm 3.0065 (nan)\tloss_scale 32768.0000 (32854.0052)\tmem 455MB\n",
      "Train: [78/100][390/625]\teta 0:00:08 lr 0.000124\t wd 0.0100\ttime 0.0325 (0.0354)\tloss 0.3091 (0.4251)\tgrad_norm 1.8445 (nan)\tloss_scale 32768.0000 (32851.8056)\tmem 455MB\n",
      "Train: [78/100][400/625]\teta 0:00:07 lr 0.000124\t wd 0.0100\ttime 0.0330 (0.0355)\tloss 0.4446 (0.4249)\tgrad_norm 1.9880 (nan)\tloss_scale 32768.0000 (32849.7157)\tmem 455MB\n",
      "Train: [78/100][410/625]\teta 0:00:07 lr 0.000124\t wd 0.0100\ttime 0.0333 (0.0354)\tloss 0.2458 (0.4251)\tgrad_norm 1.2086 (nan)\tloss_scale 32768.0000 (32847.7275)\tmem 455MB\n",
      "Train: [78/100][420/625]\teta 0:00:07 lr 0.000123\t wd 0.0100\ttime 0.0330 (0.0355)\tloss 0.2949 (0.4241)\tgrad_norm 2.3306 (nan)\tloss_scale 32768.0000 (32845.8337)\tmem 455MB\n",
      "Train: [78/100][430/625]\teta 0:00:06 lr 0.000123\t wd 0.0100\ttime 0.0389 (0.0355)\tloss 0.6704 (0.4254)\tgrad_norm 2.4211 (nan)\tloss_scale 32768.0000 (32844.0278)\tmem 455MB\n",
      "Train: [78/100][440/625]\teta 0:00:06 lr 0.000123\t wd 0.0100\ttime 0.0392 (0.0355)\tloss 0.4729 (0.4248)\tgrad_norm 2.1511 (nan)\tloss_scale 32768.0000 (32842.3039)\tmem 455MB\n",
      "Train: [78/100][450/625]\teta 0:00:06 lr 0.000123\t wd 0.0100\ttime 0.0328 (0.0355)\tloss 0.2566 (0.4243)\tgrad_norm 2.2200 (nan)\tloss_scale 32768.0000 (32840.6563)\tmem 455MB\n",
      "Train: [78/100][460/625]\teta 0:00:05 lr 0.000123\t wd 0.0100\ttime 0.0349 (0.0355)\tloss 0.1611 (0.4235)\tgrad_norm 0.8772 (nan)\tloss_scale 32768.0000 (32839.0803)\tmem 455MB\n",
      "Train: [78/100][470/625]\teta 0:00:05 lr 0.000123\t wd 0.0100\ttime 0.0327 (0.0356)\tloss 0.3523 (0.4240)\tgrad_norm 2.0298 (nan)\tloss_scale 32768.0000 (32837.5711)\tmem 455MB\n",
      "Train: [78/100][480/625]\teta 0:00:05 lr 0.000122\t wd 0.0100\ttime 0.0351 (0.0356)\tloss 0.4172 (0.4230)\tgrad_norm 2.5202 (nan)\tloss_scale 32768.0000 (32836.1247)\tmem 455MB\n",
      "Train: [78/100][490/625]\teta 0:00:04 lr 0.000122\t wd 0.0100\ttime 0.0325 (0.0355)\tloss 0.3735 (0.4221)\tgrad_norm 2.8031 (nan)\tloss_scale 32768.0000 (32834.7373)\tmem 455MB\n",
      "Train: [78/100][500/625]\teta 0:00:04 lr 0.000122\t wd 0.0100\ttime 0.0360 (0.0355)\tloss 0.3313 (0.4231)\tgrad_norm 2.4330 (nan)\tloss_scale 32768.0000 (32833.4052)\tmem 455MB\n",
      "Train: [78/100][510/625]\teta 0:00:04 lr 0.000122\t wd 0.0100\ttime 0.0376 (0.0356)\tloss 0.2844 (0.4238)\tgrad_norm 2.1289 (nan)\tloss_scale 32768.0000 (32832.1252)\tmem 455MB\n",
      "Train: [78/100][520/625]\teta 0:00:03 lr 0.000122\t wd 0.0100\ttime 0.0358 (0.0356)\tloss 0.3667 (0.4246)\tgrad_norm 1.3517 (nan)\tloss_scale 32768.0000 (32830.8944)\tmem 455MB\n",
      "Train: [78/100][530/625]\teta 0:00:03 lr 0.000122\t wd 0.0100\ttime 0.0391 (0.0356)\tloss 0.2922 (0.4246)\tgrad_norm 1.9609 (nan)\tloss_scale 32768.0000 (32829.7100)\tmem 455MB\n",
      "Train: [78/100][540/625]\teta 0:00:03 lr 0.000122\t wd 0.0100\ttime 0.0329 (0.0356)\tloss 0.2438 (0.4238)\tgrad_norm 1.6741 (nan)\tloss_scale 32768.0000 (32828.5693)\tmem 455MB\n",
      "Train: [78/100][550/625]\teta 0:00:02 lr 0.000121\t wd 0.0100\ttime 0.0360 (0.0357)\tloss 0.3901 (0.4232)\tgrad_norm 2.0564 (nan)\tloss_scale 32768.0000 (32827.4701)\tmem 455MB\n",
      "Train: [78/100][560/625]\teta 0:00:02 lr 0.000121\t wd 0.0100\ttime 0.0332 (0.0357)\tloss 0.3438 (0.4224)\tgrad_norm 1.6635 (nan)\tloss_scale 32768.0000 (32826.4100)\tmem 455MB\n",
      "Train: [78/100][570/625]\teta 0:00:01 lr 0.000121\t wd 0.0100\ttime 0.0329 (0.0357)\tloss 0.3857 (0.4218)\tgrad_norm 2.3618 (nan)\tloss_scale 32768.0000 (32825.3870)\tmem 455MB\n",
      "Train: [78/100][580/625]\teta 0:00:01 lr 0.000121\t wd 0.0100\ttime 0.0328 (0.0357)\tloss 0.3735 (0.4226)\tgrad_norm 1.5871 (nan)\tloss_scale 32768.0000 (32824.3993)\tmem 455MB\n",
      "Train: [78/100][590/625]\teta 0:00:01 lr 0.000121\t wd 0.0100\ttime 0.0358 (0.0357)\tloss 0.7568 (0.4237)\tgrad_norm 3.5758 (nan)\tloss_scale 32768.0000 (32823.4450)\tmem 455MB\n",
      "Train: [78/100][600/625]\teta 0:00:00 lr 0.000121\t wd 0.0100\ttime 0.0357 (0.0357)\tloss 0.5264 (0.4238)\tgrad_norm 2.1246 (nan)\tloss_scale 32768.0000 (32822.5225)\tmem 455MB\n",
      "Train: [78/100][610/625]\teta 0:00:00 lr 0.000120\t wd 0.0100\ttime 0.0370 (0.0358)\tloss 0.3411 (0.4231)\tgrad_norm 2.1579 (nan)\tloss_scale 32768.0000 (32821.6301)\tmem 455MB\n",
      "Train: [78/100][620/625]\teta 0:00:00 lr 0.000120\t wd 0.0100\ttime 0.0333 (0.0358)\tloss 0.4250 (0.4229)\tgrad_norm 1.6763 (nan)\tloss_scale 32768.0000 (32820.7665)\tmem 455MB\n",
      "EPOCH 78 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_78.pth saving......\n",
      "./model_save/ckpt_epoch_78.pth saved !!!\n",
      "Test: [0/157]\tTime 0.018 (0.018)\tLoss 0.6455 (0.6455)\tAcc@1 73.438 (73.438)\tAcc@5 96.875 (96.875)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.5186 (0.6190)\tAcc@1 81.250 (77.557)\tAcc@5 98.438 (98.864)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.5381 (0.5811)\tAcc@1 85.938 (79.688)\tAcc@5 98.438 (99.107)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.4287 (0.5978)\tAcc@1 87.500 (79.940)\tAcc@5 100.000 (98.841)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.6274 (0.6072)\tAcc@1 87.500 (79.726)\tAcc@5 96.875 (99.009)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.6577 (0.5983)\tAcc@1 79.688 (80.055)\tAcc@5 98.438 (98.989)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.6060 (0.5851)\tAcc@1 84.375 (80.328)\tAcc@5 96.875 (99.027)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.5654 (0.5767)\tAcc@1 82.812 (80.656)\tAcc@5 98.438 (99.054)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.7305 (0.5876)\tAcc@1 71.875 (80.363)\tAcc@5 98.438 (98.997)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.6929 (0.5897)\tAcc@1 78.125 (80.357)\tAcc@5 100.000 (99.021)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.5298 (0.5849)\tAcc@1 78.125 (80.368)\tAcc@5 100.000 (99.072)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.3792 (0.5779)\tAcc@1 84.375 (80.659)\tAcc@5 98.438 (99.043)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.6982 (0.5760)\tAcc@1 73.438 (80.798)\tAcc@5 96.875 (99.019)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.8276 (0.5803)\tAcc@1 75.000 (80.630)\tAcc@5 96.875 (98.998)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.6475 (0.5811)\tAcc@1 76.562 (80.552)\tAcc@5 98.438 (98.992)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.7007 (0.5835)\tAcc@1 79.688 (80.484)\tAcc@5 96.875 (98.955)\tMem 455MB\n",
      " * Acc@1 80.420 Acc@5 98.960\n",
      "Accuracy of the network on the 10000 test images: 80.4%\n",
      "Max accuracy: 80.42%\n",
      "Train: [79/100][0/625]\teta 0:00:23 lr 0.000120\t wd 0.0100\ttime 0.0382 (0.0382)\tloss 0.6582 (0.6582)\tgrad_norm 2.1174 (2.1174)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][10/625]\teta 0:00:21 lr 0.000120\t wd 0.0100\ttime 0.0359 (0.0354)\tloss 0.3740 (0.4215)\tgrad_norm 1.9141 (2.1812)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][20/625]\teta 0:00:21 lr 0.000120\t wd 0.0100\ttime 0.0356 (0.0361)\tloss 0.4080 (0.4336)\tgrad_norm 2.3103 (2.2329)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][30/625]\teta 0:00:21 lr 0.000120\t wd 0.0100\ttime 0.0386 (0.0367)\tloss 0.4626 (0.4337)\tgrad_norm 2.6222 (2.3108)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][40/625]\teta 0:00:21 lr 0.000120\t wd 0.0100\ttime 0.0402 (0.0367)\tloss 0.5874 (0.4312)\tgrad_norm 2.1043 (2.2952)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][50/625]\teta 0:00:20 lr 0.000119\t wd 0.0100\ttime 0.0354 (0.0365)\tloss 0.4578 (0.4352)\tgrad_norm 1.8706 (2.2813)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][60/625]\teta 0:00:20 lr 0.000119\t wd 0.0100\ttime 0.0324 (0.0363)\tloss 0.5308 (0.4267)\tgrad_norm 2.2103 (2.2524)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][70/625]\teta 0:00:20 lr 0.000119\t wd 0.0100\ttime 0.0344 (0.0362)\tloss 0.2993 (0.4267)\tgrad_norm 2.2721 (2.2633)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][80/625]\teta 0:00:19 lr 0.000119\t wd 0.0100\ttime 0.0355 (0.0360)\tloss 0.4421 (0.4343)\tgrad_norm 2.3115 (2.2916)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][90/625]\teta 0:00:19 lr 0.000119\t wd 0.0100\ttime 0.0356 (0.0359)\tloss 0.4028 (0.4351)\tgrad_norm 2.7764 (2.3065)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][100/625]\teta 0:00:18 lr 0.000119\t wd 0.0100\ttime 0.0353 (0.0359)\tloss 0.3462 (0.4357)\tgrad_norm 1.9686 (2.3190)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][110/625]\teta 0:00:18 lr 0.000118\t wd 0.0100\ttime 0.0326 (0.0358)\tloss 0.4546 (0.4402)\tgrad_norm 2.2527 (2.3201)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][120/625]\teta 0:00:18 lr 0.000118\t wd 0.0100\ttime 0.0327 (0.0358)\tloss 0.3452 (0.4316)\tgrad_norm 2.5089 (2.3022)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][130/625]\teta 0:00:17 lr 0.000118\t wd 0.0100\ttime 0.0415 (0.0359)\tloss 0.3394 (0.4302)\tgrad_norm 1.6924 (2.2851)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][140/625]\teta 0:00:17 lr 0.000118\t wd 0.0100\ttime 0.0357 (0.0358)\tloss 0.6260 (0.4298)\tgrad_norm 2.8150 (2.2770)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][150/625]\teta 0:00:16 lr 0.000118\t wd 0.0100\ttime 0.0399 (0.0358)\tloss 0.3516 (0.4310)\tgrad_norm 1.8086 (2.2710)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][160/625]\teta 0:00:16 lr 0.000118\t wd 0.0100\ttime 0.0326 (0.0358)\tloss 0.3599 (0.4311)\tgrad_norm 1.9944 (2.2614)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][170/625]\teta 0:00:16 lr 0.000117\t wd 0.0100\ttime 0.0326 (0.0357)\tloss 0.5225 (0.4327)\tgrad_norm 1.8507 (2.2615)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][180/625]\teta 0:00:15 lr 0.000117\t wd 0.0100\ttime 0.0355 (0.0357)\tloss 0.4475 (0.4306)\tgrad_norm 2.9794 (2.2492)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][190/625]\teta 0:00:15 lr 0.000117\t wd 0.0100\ttime 0.0328 (0.0357)\tloss 0.5308 (0.4273)\tgrad_norm 2.1615 (2.2415)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][200/625]\teta 0:00:15 lr 0.000117\t wd 0.0100\ttime 0.0325 (0.0356)\tloss 0.2451 (0.4259)\tgrad_norm 2.2057 (2.2443)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][210/625]\teta 0:00:14 lr 0.000117\t wd 0.0100\ttime 0.0360 (0.0356)\tloss 0.4590 (0.4256)\tgrad_norm 2.2739 (2.2478)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][220/625]\teta 0:00:14 lr 0.000117\t wd 0.0100\ttime 0.0323 (0.0356)\tloss 0.4844 (0.4256)\tgrad_norm 2.9341 (2.2423)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][230/625]\teta 0:00:14 lr 0.000116\t wd 0.0100\ttime 0.0393 (0.0357)\tloss 0.3342 (0.4262)\tgrad_norm 4.1796 (2.2596)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][240/625]\teta 0:00:13 lr 0.000116\t wd 0.0100\ttime 0.0324 (0.0356)\tloss 0.3582 (0.4272)\tgrad_norm 1.8398 (2.2581)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][250/625]\teta 0:00:13 lr 0.000116\t wd 0.0100\ttime 0.0393 (0.0357)\tloss 0.3232 (0.4261)\tgrad_norm 1.8953 (2.2558)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][260/625]\teta 0:00:13 lr 0.000116\t wd 0.0100\ttime 0.0361 (0.0357)\tloss 0.2695 (0.4252)\tgrad_norm 1.3665 (2.2509)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][270/625]\teta 0:00:12 lr 0.000116\t wd 0.0100\ttime 0.0330 (0.0357)\tloss 0.4001 (0.4248)\tgrad_norm 2.2289 (2.2462)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][280/625]\teta 0:00:12 lr 0.000116\t wd 0.0100\ttime 0.0326 (0.0357)\tloss 0.4111 (0.4252)\tgrad_norm 2.0619 (2.2538)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][290/625]\teta 0:00:11 lr 0.000116\t wd 0.0100\ttime 0.0332 (0.0357)\tloss 0.4351 (0.4257)\tgrad_norm 2.2735 (2.2532)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][300/625]\teta 0:00:11 lr 0.000115\t wd 0.0100\ttime 0.0392 (0.0358)\tloss 0.4473 (0.4241)\tgrad_norm 3.4260 (2.2517)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][310/625]\teta 0:00:11 lr 0.000115\t wd 0.0100\ttime 0.0344 (0.0358)\tloss 0.3979 (0.4225)\tgrad_norm 2.0011 (2.2414)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][320/625]\teta 0:00:10 lr 0.000115\t wd 0.0100\ttime 0.0329 (0.0358)\tloss 0.6040 (0.4238)\tgrad_norm 2.8554 (2.2443)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][330/625]\teta 0:00:10 lr 0.000115\t wd 0.0100\ttime 0.0392 (0.0358)\tloss 0.4893 (0.4238)\tgrad_norm 2.7205 (2.2452)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][340/625]\teta 0:00:10 lr 0.000115\t wd 0.0100\ttime 0.0336 (0.0358)\tloss 0.3733 (0.4231)\tgrad_norm 1.8137 (2.2469)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][350/625]\teta 0:00:09 lr 0.000115\t wd 0.0100\ttime 0.0326 (0.0358)\tloss 0.7173 (0.4234)\tgrad_norm 2.7193 (2.2516)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][360/625]\teta 0:00:09 lr 0.000114\t wd 0.0100\ttime 0.0327 (0.0358)\tloss 0.4146 (0.4234)\tgrad_norm 2.3153 (2.2536)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][370/625]\teta 0:00:09 lr 0.000114\t wd 0.0100\ttime 0.0343 (0.0358)\tloss 0.4749 (0.4234)\tgrad_norm 3.2276 (2.2535)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][380/625]\teta 0:00:08 lr 0.000114\t wd 0.0100\ttime 0.0360 (0.0357)\tloss 0.4595 (0.4235)\tgrad_norm 2.2215 (2.2506)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][390/625]\teta 0:00:08 lr 0.000114\t wd 0.0100\ttime 0.0325 (0.0357)\tloss 0.3706 (0.4232)\tgrad_norm 2.3726 (2.2489)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][400/625]\teta 0:00:08 lr 0.000114\t wd 0.0100\ttime 0.0328 (0.0357)\tloss 0.5596 (0.4220)\tgrad_norm 2.2678 (2.2479)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][410/625]\teta 0:00:07 lr 0.000114\t wd 0.0100\ttime 0.0353 (0.0357)\tloss 0.3220 (0.4215)\tgrad_norm 2.5096 (2.2464)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][420/625]\teta 0:00:07 lr 0.000113\t wd 0.0100\ttime 0.0387 (0.0357)\tloss 0.4954 (0.4214)\tgrad_norm 2.3399 (2.2488)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][430/625]\teta 0:00:06 lr 0.000113\t wd 0.0100\ttime 0.0383 (0.0357)\tloss 0.5972 (0.4228)\tgrad_norm 2.6804 (2.2483)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][440/625]\teta 0:00:06 lr 0.000113\t wd 0.0100\ttime 0.0355 (0.0357)\tloss 0.3975 (0.4225)\tgrad_norm 2.5152 (2.2475)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][450/625]\teta 0:00:06 lr 0.000113\t wd 0.0100\ttime 0.0329 (0.0357)\tloss 0.4377 (0.4235)\tgrad_norm 2.6360 (2.2484)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][460/625]\teta 0:00:05 lr 0.000113\t wd 0.0100\ttime 0.0358 (0.0357)\tloss 0.5381 (0.4228)\tgrad_norm 2.1820 (2.2423)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][470/625]\teta 0:00:05 lr 0.000113\t wd 0.0100\ttime 0.0359 (0.0357)\tloss 0.5142 (0.4228)\tgrad_norm 2.0183 (2.2373)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][480/625]\teta 0:00:05 lr 0.000113\t wd 0.0100\ttime 0.0330 (0.0357)\tloss 0.4534 (0.4234)\tgrad_norm 2.2971 (2.2361)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][490/625]\teta 0:00:04 lr 0.000112\t wd 0.0100\ttime 0.0355 (0.0357)\tloss 0.3347 (0.4230)\tgrad_norm 2.0724 (2.2323)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][500/625]\teta 0:00:04 lr 0.000112\t wd 0.0100\ttime 0.0391 (0.0358)\tloss 0.3220 (0.4221)\tgrad_norm 1.7646 (2.2272)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][510/625]\teta 0:00:04 lr 0.000112\t wd 0.0100\ttime 0.0327 (0.0358)\tloss 0.7095 (0.4228)\tgrad_norm 2.4858 (2.2282)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][520/625]\teta 0:00:03 lr 0.000112\t wd 0.0100\ttime 0.0357 (0.0358)\tloss 0.4795 (0.4236)\tgrad_norm 2.1043 (2.2290)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][530/625]\teta 0:00:03 lr 0.000112\t wd 0.0100\ttime 0.0359 (0.0358)\tloss 0.5513 (0.4238)\tgrad_norm 2.1734 (2.2288)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][540/625]\teta 0:00:03 lr 0.000112\t wd 0.0100\ttime 0.0329 (0.0358)\tloss 0.5620 (0.4241)\tgrad_norm 2.3316 (2.2270)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][550/625]\teta 0:00:02 lr 0.000111\t wd 0.0100\ttime 0.0330 (0.0358)\tloss 0.4658 (0.4243)\tgrad_norm 2.0675 (2.2288)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][560/625]\teta 0:00:02 lr 0.000111\t wd 0.0100\ttime 0.0398 (0.0358)\tloss 0.3167 (0.4247)\tgrad_norm 1.8315 (2.2267)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][570/625]\teta 0:00:01 lr 0.000111\t wd 0.0100\ttime 0.0328 (0.0358)\tloss 0.2610 (0.4242)\tgrad_norm 1.3313 (2.2212)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][580/625]\teta 0:00:01 lr 0.000111\t wd 0.0100\ttime 0.0357 (0.0358)\tloss 0.4604 (0.4246)\tgrad_norm 1.9392 (2.2220)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][590/625]\teta 0:00:01 lr 0.000111\t wd 0.0100\ttime 0.0325 (0.0358)\tloss 0.3691 (0.4244)\tgrad_norm 1.8586 (2.2209)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][600/625]\teta 0:00:00 lr 0.000111\t wd 0.0100\ttime 0.0396 (0.0358)\tloss 0.4478 (0.4241)\tgrad_norm 2.6298 (2.2185)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][610/625]\teta 0:00:00 lr 0.000110\t wd 0.0100\ttime 0.0324 (0.0358)\tloss 0.4021 (0.4238)\tgrad_norm 2.5319 (2.2177)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [79/100][620/625]\teta 0:00:00 lr 0.000110\t wd 0.0100\ttime 0.0327 (0.0358)\tloss 0.4019 (0.4241)\tgrad_norm 2.2637 (2.2202)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 79 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_79.pth saving......\n",
      "./model_save/ckpt_epoch_79.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.8257 (0.8257)\tAcc@1 70.312 (70.312)\tAcc@5 100.000 (100.000)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.4275 (0.5887)\tAcc@1 87.500 (80.256)\tAcc@5 100.000 (99.432)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.5493 (0.5450)\tAcc@1 81.250 (81.548)\tAcc@5 98.438 (99.330)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.5679 (0.5494)\tAcc@1 81.250 (81.300)\tAcc@5 98.438 (99.345)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.5625 (0.5461)\tAcc@1 81.250 (81.288)\tAcc@5 98.438 (99.276)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.9155 (0.5691)\tAcc@1 68.750 (80.790)\tAcc@5 98.438 (99.081)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.3936 (0.5722)\tAcc@1 89.062 (80.763)\tAcc@5 98.438 (99.129)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.7539 (0.5774)\tAcc@1 75.000 (80.458)\tAcc@5 98.438 (99.120)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.5903 (0.5847)\tAcc@1 84.375 (80.285)\tAcc@5 95.312 (99.035)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.6069 (0.5833)\tAcc@1 79.688 (80.203)\tAcc@5 98.438 (99.038)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.3823 (0.5836)\tAcc@1 87.500 (80.198)\tAcc@5 100.000 (99.072)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.6094 (0.5795)\tAcc@1 78.125 (80.349)\tAcc@5 100.000 (99.071)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.6602 (0.5800)\tAcc@1 78.125 (80.372)\tAcc@5 100.000 (99.083)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.8042 (0.5830)\tAcc@1 79.688 (80.308)\tAcc@5 100.000 (99.094)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 1.0752 (0.5885)\tAcc@1 67.188 (80.253)\tAcc@5 100.000 (99.080)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.6885 (0.5923)\tAcc@1 76.562 (80.039)\tAcc@5 100.000 (99.100)\tMem 455MB\n",
      " * Acc@1 80.080 Acc@5 99.100\n",
      "Accuracy of the network on the 10000 test images: 80.1%\n",
      "Max accuracy: 80.42%\n",
      "Train: [80/100][0/625]\teta 0:00:22 lr 0.000110\t wd 0.0100\ttime 0.0355 (0.0355)\tloss 0.2898 (0.2898)\tgrad_norm 1.7955 (1.7955)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][10/625]\teta 0:00:22 lr 0.000110\t wd 0.0100\ttime 0.0334 (0.0370)\tloss 0.2749 (0.3995)\tgrad_norm 1.7098 (2.0582)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][20/625]\teta 0:00:22 lr 0.000110\t wd 0.0100\ttime 0.0326 (0.0366)\tloss 0.6777 (0.3980)\tgrad_norm 3.0326 (2.1445)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][30/625]\teta 0:00:21 lr 0.000110\t wd 0.0100\ttime 0.0386 (0.0367)\tloss 0.4434 (0.4141)\tgrad_norm 2.4859 (2.1810)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][40/625]\teta 0:00:21 lr 0.000110\t wd 0.0100\ttime 0.0323 (0.0359)\tloss 0.3896 (0.4210)\tgrad_norm 1.9308 (2.1677)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][50/625]\teta 0:00:20 lr 0.000109\t wd 0.0100\ttime 0.0396 (0.0361)\tloss 0.5703 (0.4200)\tgrad_norm 3.2628 (2.2001)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][60/625]\teta 0:00:20 lr 0.000109\t wd 0.0100\ttime 0.0369 (0.0361)\tloss 0.4795 (0.4119)\tgrad_norm 2.4091 (2.1511)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][70/625]\teta 0:00:20 lr 0.000109\t wd 0.0100\ttime 0.0353 (0.0362)\tloss 0.7031 (0.4244)\tgrad_norm 2.9787 (2.1783)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][80/625]\teta 0:00:19 lr 0.000109\t wd 0.0100\ttime 0.0328 (0.0361)\tloss 0.4482 (0.4173)\tgrad_norm 2.5941 (2.1660)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][90/625]\teta 0:00:19 lr 0.000109\t wd 0.0100\ttime 0.0325 (0.0361)\tloss 0.4236 (0.4145)\tgrad_norm 3.1853 (2.1647)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][100/625]\teta 0:00:18 lr 0.000109\t wd 0.0100\ttime 0.0327 (0.0358)\tloss 0.5117 (0.4124)\tgrad_norm 2.6102 (2.1656)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][110/625]\teta 0:00:18 lr 0.000109\t wd 0.0100\ttime 0.0356 (0.0356)\tloss 0.4778 (0.4153)\tgrad_norm 2.1688 (2.1665)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][120/625]\teta 0:00:17 lr 0.000108\t wd 0.0100\ttime 0.0361 (0.0356)\tloss 0.2766 (0.4139)\tgrad_norm 1.9680 (2.1786)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][130/625]\teta 0:00:17 lr 0.000108\t wd 0.0100\ttime 0.0359 (0.0355)\tloss 0.6694 (0.4165)\tgrad_norm 2.9276 (2.1850)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][140/625]\teta 0:00:17 lr 0.000108\t wd 0.0100\ttime 0.0325 (0.0354)\tloss 0.3306 (0.4120)\tgrad_norm 2.1860 (2.1793)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][150/625]\teta 0:00:16 lr 0.000108\t wd 0.0100\ttime 0.0358 (0.0355)\tloss 0.4250 (0.4132)\tgrad_norm 2.4163 (2.1863)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][160/625]\teta 0:00:16 lr 0.000108\t wd 0.0100\ttime 0.0331 (0.0356)\tloss 0.5747 (0.4121)\tgrad_norm 2.1684 (2.1800)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][170/625]\teta 0:00:16 lr 0.000108\t wd 0.0100\ttime 0.0366 (0.0356)\tloss 0.4519 (0.4143)\tgrad_norm 1.9998 (2.1794)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][180/625]\teta 0:00:15 lr 0.000107\t wd 0.0100\ttime 0.0357 (0.0357)\tloss 0.3198 (0.4127)\tgrad_norm 2.0878 (2.1797)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][190/625]\teta 0:00:15 lr 0.000107\t wd 0.0100\ttime 0.0352 (0.0358)\tloss 0.3904 (0.4124)\tgrad_norm 2.3193 (2.1844)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][200/625]\teta 0:00:15 lr 0.000107\t wd 0.0100\ttime 0.0323 (0.0357)\tloss 0.3950 (0.4136)\tgrad_norm 2.3697 (2.1904)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][210/625]\teta 0:00:14 lr 0.000107\t wd 0.0100\ttime 0.0328 (0.0357)\tloss 0.4631 (0.4148)\tgrad_norm 2.8441 (2.1970)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][220/625]\teta 0:00:14 lr 0.000107\t wd 0.0100\ttime 0.0323 (0.0357)\tloss 0.3782 (0.4153)\tgrad_norm 1.4479 (2.1940)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][230/625]\teta 0:00:14 lr 0.000107\t wd 0.0100\ttime 0.0330 (0.0357)\tloss 0.4373 (0.4158)\tgrad_norm 2.4680 (2.1954)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][240/625]\teta 0:00:13 lr 0.000107\t wd 0.0100\ttime 0.0328 (0.0357)\tloss 0.4207 (0.4179)\tgrad_norm 1.7053 (2.1992)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][250/625]\teta 0:00:13 lr 0.000106\t wd 0.0100\ttime 0.0327 (0.0357)\tloss 0.5996 (0.4197)\tgrad_norm 2.1492 (2.2019)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][260/625]\teta 0:00:13 lr 0.000106\t wd 0.0100\ttime 0.0370 (0.0357)\tloss 0.4683 (0.4184)\tgrad_norm 2.1566 (2.2029)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][270/625]\teta 0:00:12 lr 0.000106\t wd 0.0100\ttime 0.0324 (0.0357)\tloss 0.6367 (0.4173)\tgrad_norm 2.6018 (2.2036)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][280/625]\teta 0:00:12 lr 0.000106\t wd 0.0100\ttime 0.0326 (0.0357)\tloss 0.2350 (0.4158)\tgrad_norm 2.1054 (2.2031)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][290/625]\teta 0:00:11 lr 0.000106\t wd 0.0100\ttime 0.0368 (0.0357)\tloss 0.5688 (0.4160)\tgrad_norm 2.5344 (2.2027)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][300/625]\teta 0:00:11 lr 0.000106\t wd 0.0100\ttime 0.0362 (0.0357)\tloss 0.4077 (0.4153)\tgrad_norm 2.9650 (2.1983)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][310/625]\teta 0:00:11 lr 0.000106\t wd 0.0100\ttime 0.0363 (0.0358)\tloss 0.5249 (0.4170)\tgrad_norm 2.4803 (2.2046)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][320/625]\teta 0:00:10 lr 0.000105\t wd 0.0100\ttime 0.0392 (0.0358)\tloss 0.4717 (0.4153)\tgrad_norm 3.3034 (2.2011)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][330/625]\teta 0:00:10 lr 0.000105\t wd 0.0100\ttime 0.0327 (0.0358)\tloss 0.4263 (0.4135)\tgrad_norm 2.5890 (2.1970)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][340/625]\teta 0:00:10 lr 0.000105\t wd 0.0100\ttime 0.0326 (0.0358)\tloss 0.4736 (0.4156)\tgrad_norm 1.9814 (2.1974)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][350/625]\teta 0:00:09 lr 0.000105\t wd 0.0100\ttime 0.0353 (0.0358)\tloss 0.3838 (0.4145)\tgrad_norm 2.1746 (2.1952)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][360/625]\teta 0:00:09 lr 0.000105\t wd 0.0100\ttime 0.0327 (0.0358)\tloss 0.4016 (0.4136)\tgrad_norm 2.9729 (2.1895)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][370/625]\teta 0:00:09 lr 0.000105\t wd 0.0100\ttime 0.0358 (0.0358)\tloss 0.4419 (0.4132)\tgrad_norm 2.5440 (2.1923)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][380/625]\teta 0:00:08 lr 0.000104\t wd 0.0100\ttime 0.0350 (0.0357)\tloss 0.3428 (0.4122)\tgrad_norm 1.8591 (2.1902)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][390/625]\teta 0:00:08 lr 0.000104\t wd 0.0100\ttime 0.0384 (0.0358)\tloss 0.2976 (0.4123)\tgrad_norm 1.7393 (2.1879)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][400/625]\teta 0:00:08 lr 0.000104\t wd 0.0100\ttime 0.0327 (0.0357)\tloss 0.5386 (0.4131)\tgrad_norm 2.4300 (2.1897)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][410/625]\teta 0:00:07 lr 0.000104\t wd 0.0100\ttime 0.0381 (0.0357)\tloss 0.4963 (0.4150)\tgrad_norm 2.1244 (2.1922)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][420/625]\teta 0:00:07 lr 0.000104\t wd 0.0100\ttime 0.0353 (0.0357)\tloss 0.5215 (0.4156)\tgrad_norm 2.2471 (2.1968)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][430/625]\teta 0:00:06 lr 0.000104\t wd 0.0100\ttime 0.0349 (0.0358)\tloss 0.5342 (0.4148)\tgrad_norm 2.3817 (2.1973)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][440/625]\teta 0:00:06 lr 0.000104\t wd 0.0100\ttime 0.0388 (0.0357)\tloss 0.3215 (0.4140)\tgrad_norm 2.2749 (2.1943)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][450/625]\teta 0:00:06 lr 0.000103\t wd 0.0100\ttime 0.0390 (0.0358)\tloss 0.4297 (0.4128)\tgrad_norm 1.9186 (2.1909)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][460/625]\teta 0:00:05 lr 0.000103\t wd 0.0100\ttime 0.0369 (0.0358)\tloss 0.6177 (0.4136)\tgrad_norm 2.4881 (2.1924)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][470/625]\teta 0:00:05 lr 0.000103\t wd 0.0100\ttime 0.0324 (0.0358)\tloss 0.4292 (0.4132)\tgrad_norm 2.1698 (2.1941)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][480/625]\teta 0:00:05 lr 0.000103\t wd 0.0100\ttime 0.0327 (0.0358)\tloss 0.5674 (0.4131)\tgrad_norm 2.8944 (2.1978)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][490/625]\teta 0:00:04 lr 0.000103\t wd 0.0100\ttime 0.0350 (0.0358)\tloss 0.3896 (0.4135)\tgrad_norm 2.3220 (2.2016)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][500/625]\teta 0:00:04 lr 0.000103\t wd 0.0100\ttime 0.0325 (0.0358)\tloss 0.4556 (0.4139)\tgrad_norm 2.5651 (2.2087)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][510/625]\teta 0:00:04 lr 0.000103\t wd 0.0100\ttime 0.0354 (0.0357)\tloss 0.4033 (0.4134)\tgrad_norm 2.4562 (2.2056)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][520/625]\teta 0:00:03 lr 0.000102\t wd 0.0100\ttime 0.0359 (0.0358)\tloss 0.6050 (0.4134)\tgrad_norm 3.0426 (2.2062)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][530/625]\teta 0:00:03 lr 0.000102\t wd 0.0100\ttime 0.0397 (0.0358)\tloss 0.4922 (0.4137)\tgrad_norm 2.7628 (2.2050)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][540/625]\teta 0:00:03 lr 0.000102\t wd 0.0100\ttime 0.0355 (0.0358)\tloss 0.4290 (0.4134)\tgrad_norm 1.9738 (2.2033)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][550/625]\teta 0:00:02 lr 0.000102\t wd 0.0100\ttime 0.0330 (0.0358)\tloss 0.3411 (0.4135)\tgrad_norm 2.0324 (2.2030)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][560/625]\teta 0:00:02 lr 0.000102\t wd 0.0100\ttime 0.0355 (0.0358)\tloss 0.3450 (0.4128)\tgrad_norm 2.3347 (2.2048)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][570/625]\teta 0:00:01 lr 0.000102\t wd 0.0100\ttime 0.0362 (0.0358)\tloss 0.3657 (0.4131)\tgrad_norm 2.2337 (2.2068)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][580/625]\teta 0:00:01 lr 0.000101\t wd 0.0100\ttime 0.0354 (0.0358)\tloss 0.4485 (0.4120)\tgrad_norm 2.2650 (2.2013)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][590/625]\teta 0:00:01 lr 0.000101\t wd 0.0100\ttime 0.0354 (0.0358)\tloss 0.2405 (0.4115)\tgrad_norm 1.3832 (2.2002)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][600/625]\teta 0:00:00 lr 0.000101\t wd 0.0100\ttime 0.0347 (0.0358)\tloss 0.6685 (0.4130)\tgrad_norm 2.8642 (2.2033)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][610/625]\teta 0:00:00 lr 0.000101\t wd 0.0100\ttime 0.0354 (0.0358)\tloss 0.4302 (0.4132)\tgrad_norm 2.3896 (2.2052)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [80/100][620/625]\teta 0:00:00 lr 0.000101\t wd 0.0100\ttime 0.0329 (0.0358)\tloss 0.4094 (0.4128)\tgrad_norm 2.2723 (2.2055)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 80 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_80.pth saving......\n",
      "./model_save/ckpt_epoch_80.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.4524 (0.4524)\tAcc@1 82.812 (82.812)\tAcc@5 98.438 (98.438)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.6157 (0.5147)\tAcc@1 82.812 (83.239)\tAcc@5 98.438 (99.290)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.7964 (0.5424)\tAcc@1 73.438 (82.068)\tAcc@5 96.875 (98.958)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.4612 (0.5257)\tAcc@1 84.375 (81.956)\tAcc@5 100.000 (99.143)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.5659 (0.5348)\tAcc@1 79.688 (81.326)\tAcc@5 100.000 (99.238)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.5571 (0.5266)\tAcc@1 79.688 (81.464)\tAcc@5 100.000 (99.295)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.4519 (0.5324)\tAcc@1 85.938 (81.762)\tAcc@5 98.438 (99.103)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.4399 (0.5512)\tAcc@1 82.812 (81.008)\tAcc@5 100.000 (99.032)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.6729 (0.5550)\tAcc@1 79.688 (81.173)\tAcc@5 100.000 (98.978)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.6260 (0.5611)\tAcc@1 81.250 (81.130)\tAcc@5 98.438 (98.901)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.6987 (0.5683)\tAcc@1 79.688 (80.770)\tAcc@5 100.000 (98.933)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.9541 (0.5774)\tAcc@1 71.875 (80.490)\tAcc@5 98.438 (98.958)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.4966 (0.5798)\tAcc@1 78.125 (80.269)\tAcc@5 100.000 (98.954)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.8457 (0.5831)\tAcc@1 73.438 (80.212)\tAcc@5 98.438 (98.986)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.5142 (0.5813)\tAcc@1 79.688 (80.253)\tAcc@5 100.000 (99.014)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.6138 (0.5800)\tAcc@1 75.000 (80.298)\tAcc@5 100.000 (99.038)\tMem 455MB\n",
      " * Acc@1 80.310 Acc@5 99.070\n",
      "Accuracy of the network on the 10000 test images: 80.3%\n",
      "Max accuracy: 80.42%\n",
      "Train: [81/100][0/625]\teta 0:00:21 lr 0.000101\t wd 0.0100\ttime 0.0341 (0.0341)\tloss 0.4402 (0.4402)\tgrad_norm 2.3323 (2.3323)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [81/100][10/625]\teta 0:00:20 lr 0.000101\t wd 0.0100\ttime 0.0322 (0.0334)\tloss 0.5195 (0.3972)\tgrad_norm 2.3695 (2.2286)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [81/100][20/625]\teta 0:00:20 lr 0.000101\t wd 0.0100\ttime 0.0363 (0.0340)\tloss 0.5186 (0.3780)\tgrad_norm 3.0225 (2.1830)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [81/100][30/625]\teta 0:00:20 lr 0.000100\t wd 0.0100\ttime 0.0327 (0.0339)\tloss 0.5259 (0.3683)\tgrad_norm 2.5982 (2.1485)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [81/100][40/625]\teta 0:00:19 lr 0.000100\t wd 0.0100\ttime 0.0355 (0.0339)\tloss 0.4727 (0.3789)\tgrad_norm 3.0828 (2.2155)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [81/100][50/625]\teta 0:00:19 lr 0.000100\t wd 0.0100\ttime 0.0340 (0.0344)\tloss 0.4160 (0.3945)\tgrad_norm 2.1276 (2.2609)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [81/100][60/625]\teta 0:00:19 lr 0.000100\t wd 0.0100\ttime 0.0328 (0.0347)\tloss 0.3167 (0.3915)\tgrad_norm 1.8512 (2.2136)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [81/100][70/625]\teta 0:00:19 lr 0.000100\t wd 0.0100\ttime 0.0323 (0.0348)\tloss 0.4177 (0.3972)\tgrad_norm 2.1149 (2.1982)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [81/100][80/625]\teta 0:00:18 lr 0.000100\t wd 0.0100\ttime 0.0355 (0.0348)\tloss 0.3062 (0.3998)\tgrad_norm 2.2586 (2.2092)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [81/100][90/625]\teta 0:00:18 lr 0.000099\t wd 0.0100\ttime 0.0326 (0.0349)\tloss 0.4470 (0.4024)\tgrad_norm 2.0952 (2.1994)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [81/100][100/625]\teta 0:00:18 lr 0.000099\t wd 0.0100\ttime 0.0340 (0.0349)\tloss 0.4365 (0.3999)\tgrad_norm 3.1410 (2.2062)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [81/100][110/625]\teta 0:00:17 lr 0.000099\t wd 0.0100\ttime 0.0327 (0.0348)\tloss 0.5654 (0.4037)\tgrad_norm 2.5323 (2.2143)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [81/100][120/625]\teta 0:00:17 lr 0.000099\t wd 0.0100\ttime 0.0330 (0.0347)\tloss 0.2839 (0.4026)\tgrad_norm 1.6951 (2.2028)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [81/100][130/625]\teta 0:00:17 lr 0.000099\t wd 0.0100\ttime 0.0398 (0.0349)\tloss 0.2964 (0.3997)\tgrad_norm 1.6883 (2.1882)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [81/100][140/625]\teta 0:00:17 lr 0.000099\t wd 0.0100\ttime 0.0396 (0.0351)\tloss 0.4509 (0.3993)\tgrad_norm 2.4406 (2.1743)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [81/100][150/625]\teta 0:00:16 lr 0.000099\t wd 0.0100\ttime 0.0357 (0.0351)\tloss 0.4368 (0.4014)\tgrad_norm 3.1343 (nan)\tloss_scale 32768.0000 (32985.0066)\tmem 455MB\n",
      "Train: [81/100][160/625]\teta 0:00:16 lr 0.000098\t wd 0.0100\ttime 0.0364 (0.0352)\tloss 0.3835 (0.4014)\tgrad_norm 2.0384 (nan)\tloss_scale 32768.0000 (32971.5280)\tmem 455MB\n",
      "Train: [81/100][170/625]\teta 0:00:16 lr 0.000098\t wd 0.0100\ttime 0.0352 (0.0352)\tloss 0.2905 (0.4033)\tgrad_norm 1.8068 (nan)\tloss_scale 32768.0000 (32959.6257)\tmem 455MB\n",
      "Train: [81/100][180/625]\teta 0:00:15 lr 0.000098\t wd 0.0100\ttime 0.0325 (0.0353)\tloss 0.3445 (0.4027)\tgrad_norm 1.6473 (nan)\tloss_scale 32768.0000 (32949.0387)\tmem 455MB\n",
      "Train: [81/100][190/625]\teta 0:00:15 lr 0.000098\t wd 0.0100\ttime 0.0326 (0.0354)\tloss 0.3416 (0.4010)\tgrad_norm 2.0997 (nan)\tloss_scale 32768.0000 (32939.5602)\tmem 455MB\n",
      "Train: [81/100][200/625]\teta 0:00:15 lr 0.000098\t wd 0.0100\ttime 0.0341 (0.0354)\tloss 0.4670 (0.4011)\tgrad_norm 2.1568 (nan)\tloss_scale 32768.0000 (32931.0249)\tmem 455MB\n",
      "Train: [81/100][210/625]\teta 0:00:14 lr 0.000098\t wd 0.0100\ttime 0.0326 (0.0354)\tloss 0.3049 (0.4006)\tgrad_norm 1.9609 (nan)\tloss_scale 32768.0000 (32923.2986)\tmem 455MB\n",
      "Train: [81/100][220/625]\teta 0:00:14 lr 0.000098\t wd 0.0100\ttime 0.0363 (0.0355)\tloss 0.4792 (0.4040)\tgrad_norm 2.3566 (nan)\tloss_scale 32768.0000 (32916.2715)\tmem 455MB\n",
      "Train: [81/100][230/625]\teta 0:00:14 lr 0.000097\t wd 0.0100\ttime 0.0391 (0.0355)\tloss 0.3430 (0.4045)\tgrad_norm 2.1895 (nan)\tloss_scale 32768.0000 (32909.8528)\tmem 455MB\n",
      "Train: [81/100][240/625]\teta 0:00:13 lr 0.000097\t wd 0.0100\ttime 0.0329 (0.0355)\tloss 0.2727 (0.4051)\tgrad_norm 2.0123 (nan)\tloss_scale 32768.0000 (32903.9668)\tmem 455MB\n",
      "Train: [81/100][250/625]\teta 0:00:13 lr 0.000097\t wd 0.0100\ttime 0.0353 (0.0355)\tloss 0.3589 (0.4041)\tgrad_norm 1.8069 (nan)\tloss_scale 32768.0000 (32898.5498)\tmem 455MB\n",
      "Train: [81/100][260/625]\teta 0:00:12 lr 0.000097\t wd 0.0100\ttime 0.0330 (0.0355)\tloss 0.5859 (0.4061)\tgrad_norm 3.0206 (nan)\tloss_scale 32768.0000 (32893.5479)\tmem 455MB\n",
      "Train: [81/100][270/625]\teta 0:00:12 lr 0.000097\t wd 0.0100\ttime 0.0326 (0.0354)\tloss 0.4148 (0.4056)\tgrad_norm 2.6712 (nan)\tloss_scale 32768.0000 (32888.9151)\tmem 455MB\n",
      "Train: [81/100][280/625]\teta 0:00:12 lr 0.000097\t wd 0.0100\ttime 0.0325 (0.0355)\tloss 0.4229 (0.4061)\tgrad_norm 2.5254 (nan)\tloss_scale 32768.0000 (32884.6121)\tmem 455MB\n",
      "Train: [81/100][290/625]\teta 0:00:11 lr 0.000097\t wd 0.0100\ttime 0.0380 (0.0355)\tloss 0.3669 (0.4057)\tgrad_norm 2.3874 (nan)\tloss_scale 32768.0000 (32880.6048)\tmem 455MB\n",
      "Train: [81/100][300/625]\teta 0:00:11 lr 0.000096\t wd 0.0100\ttime 0.0356 (0.0355)\tloss 0.4148 (0.4056)\tgrad_norm 1.7572 (nan)\tloss_scale 32768.0000 (32876.8638)\tmem 455MB\n",
      "Train: [81/100][310/625]\teta 0:00:11 lr 0.000096\t wd 0.0100\ttime 0.0358 (0.0355)\tloss 0.4407 (0.4056)\tgrad_norm 2.1973 (nan)\tloss_scale 32768.0000 (32873.3633)\tmem 455MB\n",
      "Train: [81/100][320/625]\teta 0:00:10 lr 0.000096\t wd 0.0100\ttime 0.0326 (0.0355)\tloss 0.3494 (0.4057)\tgrad_norm 2.3493 (nan)\tloss_scale 32768.0000 (32870.0810)\tmem 455MB\n",
      "Train: [81/100][330/625]\teta 0:00:10 lr 0.000096\t wd 0.0100\ttime 0.0362 (0.0355)\tloss 0.3403 (0.4058)\tgrad_norm 2.1956 (nan)\tloss_scale 32768.0000 (32866.9970)\tmem 455MB\n",
      "Train: [81/100][340/625]\teta 0:00:10 lr 0.000096\t wd 0.0100\ttime 0.0353 (0.0354)\tloss 0.4185 (0.4058)\tgrad_norm 1.7463 (nan)\tloss_scale 32768.0000 (32864.0938)\tmem 455MB\n",
      "Train: [81/100][350/625]\teta 0:00:09 lr 0.000096\t wd 0.0100\ttime 0.0385 (0.0355)\tloss 0.4385 (0.4062)\tgrad_norm 2.4489 (nan)\tloss_scale 32768.0000 (32861.3561)\tmem 455MB\n",
      "Train: [81/100][360/625]\teta 0:00:09 lr 0.000096\t wd 0.0100\ttime 0.0324 (0.0355)\tloss 0.4312 (0.4055)\tgrad_norm 2.5424 (nan)\tloss_scale 32768.0000 (32858.7701)\tmem 455MB\n",
      "Train: [81/100][370/625]\teta 0:00:09 lr 0.000095\t wd 0.0100\ttime 0.0325 (0.0354)\tloss 0.3276 (0.4051)\tgrad_norm 2.4173 (nan)\tloss_scale 32768.0000 (32856.3235)\tmem 455MB\n",
      "Train: [81/100][380/625]\teta 0:00:08 lr 0.000095\t wd 0.0100\ttime 0.0386 (0.0354)\tloss 0.3179 (0.4048)\tgrad_norm 1.9482 (nan)\tloss_scale 32768.0000 (32854.0052)\tmem 455MB\n",
      "Train: [81/100][390/625]\teta 0:00:08 lr 0.000095\t wd 0.0100\ttime 0.0326 (0.0354)\tloss 0.2935 (0.4049)\tgrad_norm 1.8034 (nan)\tloss_scale 32768.0000 (32851.8056)\tmem 455MB\n",
      "Train: [81/100][400/625]\teta 0:00:07 lr 0.000095\t wd 0.0100\ttime 0.0322 (0.0354)\tloss 0.4302 (0.4056)\tgrad_norm 2.0835 (nan)\tloss_scale 32768.0000 (32849.7157)\tmem 455MB\n",
      "Train: [81/100][410/625]\teta 0:00:07 lr 0.000095\t wd 0.0100\ttime 0.0391 (0.0354)\tloss 0.5815 (0.4060)\tgrad_norm 2.3187 (nan)\tloss_scale 32768.0000 (32847.7275)\tmem 455MB\n",
      "Train: [81/100][420/625]\teta 0:00:07 lr 0.000095\t wd 0.0100\ttime 0.0355 (0.0354)\tloss 0.3550 (0.4061)\tgrad_norm 1.7530 (nan)\tloss_scale 32768.0000 (32845.8337)\tmem 455MB\n",
      "Train: [81/100][430/625]\teta 0:00:06 lr 0.000095\t wd 0.0100\ttime 0.0327 (0.0354)\tloss 0.4170 (0.4061)\tgrad_norm 2.1849 (nan)\tloss_scale 32768.0000 (32844.0278)\tmem 455MB\n",
      "Train: [81/100][440/625]\teta 0:00:06 lr 0.000094\t wd 0.0100\ttime 0.0328 (0.0354)\tloss 0.5078 (0.4068)\tgrad_norm 2.2903 (nan)\tloss_scale 32768.0000 (32842.3039)\tmem 455MB\n",
      "Train: [81/100][450/625]\teta 0:00:06 lr 0.000094\t wd 0.0100\ttime 0.0356 (0.0355)\tloss 0.5254 (0.4078)\tgrad_norm 2.5041 (nan)\tloss_scale 32768.0000 (32840.6563)\tmem 455MB\n",
      "Train: [81/100][460/625]\teta 0:00:05 lr 0.000094\t wd 0.0100\ttime 0.0329 (0.0355)\tloss 0.2742 (0.4072)\tgrad_norm 1.9081 (nan)\tloss_scale 32768.0000 (32839.0803)\tmem 455MB\n",
      "Train: [81/100][470/625]\teta 0:00:05 lr 0.000094\t wd 0.0100\ttime 0.0328 (0.0355)\tloss 0.5117 (0.4082)\tgrad_norm 3.3727 (nan)\tloss_scale 32768.0000 (32837.5711)\tmem 455MB\n",
      "Train: [81/100][480/625]\teta 0:00:05 lr 0.000094\t wd 0.0100\ttime 0.0392 (0.0355)\tloss 0.3657 (0.4082)\tgrad_norm 2.0354 (nan)\tloss_scale 32768.0000 (32836.1247)\tmem 455MB\n",
      "Train: [81/100][490/625]\teta 0:00:04 lr 0.000094\t wd 0.0100\ttime 0.0329 (0.0355)\tloss 0.6147 (0.4076)\tgrad_norm 2.5156 (nan)\tloss_scale 32768.0000 (32834.7373)\tmem 455MB\n",
      "Train: [81/100][500/625]\teta 0:00:04 lr 0.000094\t wd 0.0100\ttime 0.0327 (0.0355)\tloss 0.2725 (0.4080)\tgrad_norm 1.4301 (nan)\tloss_scale 32768.0000 (32833.4052)\tmem 455MB\n",
      "Train: [81/100][510/625]\teta 0:00:04 lr 0.000093\t wd 0.0100\ttime 0.0351 (0.0355)\tloss 0.4382 (0.4073)\tgrad_norm 2.3593 (nan)\tloss_scale 32768.0000 (32832.1252)\tmem 455MB\n",
      "Train: [81/100][520/625]\teta 0:00:03 lr 0.000093\t wd 0.0100\ttime 0.0360 (0.0355)\tloss 0.3503 (0.4069)\tgrad_norm 1.7439 (nan)\tloss_scale 32768.0000 (32830.8944)\tmem 455MB\n",
      "Train: [81/100][530/625]\teta 0:00:03 lr 0.000093\t wd 0.0100\ttime 0.0357 (0.0355)\tloss 0.2463 (0.4064)\tgrad_norm 1.5968 (nan)\tloss_scale 32768.0000 (32829.7100)\tmem 455MB\n",
      "Train: [81/100][540/625]\teta 0:00:03 lr 0.000093\t wd 0.0100\ttime 0.0326 (0.0355)\tloss 0.4800 (0.4072)\tgrad_norm 2.7922 (nan)\tloss_scale 32768.0000 (32828.5693)\tmem 455MB\n",
      "Train: [81/100][550/625]\teta 0:00:02 lr 0.000093\t wd 0.0100\ttime 0.0324 (0.0355)\tloss 0.4736 (0.4084)\tgrad_norm 1.9486 (nan)\tloss_scale 32768.0000 (32827.4701)\tmem 455MB\n",
      "Train: [81/100][560/625]\teta 0:00:02 lr 0.000093\t wd 0.0100\ttime 0.0326 (0.0355)\tloss 0.3425 (0.4078)\tgrad_norm 2.0325 (nan)\tloss_scale 32768.0000 (32826.4100)\tmem 455MB\n",
      "Train: [81/100][570/625]\teta 0:00:01 lr 0.000093\t wd 0.0100\ttime 0.0371 (0.0355)\tloss 0.3784 (0.4081)\tgrad_norm 2.0184 (nan)\tloss_scale 32768.0000 (32825.3870)\tmem 455MB\n",
      "Train: [81/100][580/625]\teta 0:00:01 lr 0.000092\t wd 0.0100\ttime 0.0330 (0.0355)\tloss 0.3689 (0.4081)\tgrad_norm 2.2922 (nan)\tloss_scale 32768.0000 (32824.3993)\tmem 455MB\n",
      "Train: [81/100][590/625]\teta 0:00:01 lr 0.000092\t wd 0.0100\ttime 0.0322 (0.0355)\tloss 0.2976 (0.4084)\tgrad_norm 2.2481 (nan)\tloss_scale 32768.0000 (32823.4450)\tmem 455MB\n",
      "Train: [81/100][600/625]\teta 0:00:00 lr 0.000092\t wd 0.0100\ttime 0.0397 (0.0355)\tloss 0.1942 (0.4082)\tgrad_norm 1.3482 (nan)\tloss_scale 32768.0000 (32822.5225)\tmem 455MB\n",
      "Train: [81/100][610/625]\teta 0:00:00 lr 0.000092\t wd 0.0100\ttime 0.0322 (0.0355)\tloss 0.4185 (0.4079)\tgrad_norm 2.4423 (nan)\tloss_scale 32768.0000 (32821.6301)\tmem 455MB\n",
      "Train: [81/100][620/625]\teta 0:00:00 lr 0.000092\t wd 0.0100\ttime 0.0364 (0.0355)\tloss 0.4565 (0.4085)\tgrad_norm 2.7591 (nan)\tloss_scale 32768.0000 (32820.7665)\tmem 455MB\n",
      "EPOCH 81 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_81.pth saving......\n",
      "./model_save/ckpt_epoch_81.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.6392 (0.6392)\tAcc@1 70.312 (70.312)\tAcc@5 100.000 (100.000)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.016)\tLoss 0.6362 (0.5963)\tAcc@1 81.250 (79.403)\tAcc@5 100.000 (99.432)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.5117 (0.5759)\tAcc@1 82.812 (80.060)\tAcc@5 100.000 (99.330)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.6675 (0.5660)\tAcc@1 81.250 (80.746)\tAcc@5 98.438 (99.496)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.4526 (0.5592)\tAcc@1 81.250 (80.869)\tAcc@5 100.000 (99.466)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.5488 (0.5633)\tAcc@1 84.375 (80.913)\tAcc@5 98.438 (99.295)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.6455 (0.5640)\tAcc@1 75.000 (80.994)\tAcc@5 100.000 (99.257)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.6650 (0.5737)\tAcc@1 73.438 (80.678)\tAcc@5 100.000 (99.208)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.5728 (0.5675)\tAcc@1 79.688 (80.845)\tAcc@5 100.000 (99.171)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.4768 (0.5810)\tAcc@1 84.375 (80.701)\tAcc@5 100.000 (99.056)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.5562 (0.5845)\tAcc@1 81.250 (80.430)\tAcc@5 100.000 (99.103)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.4238 (0.5797)\tAcc@1 89.062 (80.532)\tAcc@5 98.438 (99.043)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.7954 (0.5836)\tAcc@1 76.562 (80.566)\tAcc@5 98.438 (99.057)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.4153 (0.5883)\tAcc@1 79.688 (80.320)\tAcc@5 100.000 (99.058)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.4392 (0.5850)\tAcc@1 84.375 (80.242)\tAcc@5 98.438 (99.058)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.7261 (0.5816)\tAcc@1 79.688 (80.267)\tAcc@5 100.000 (99.069)\tMem 455MB\n",
      " * Acc@1 80.380 Acc@5 99.080\n",
      "Accuracy of the network on the 10000 test images: 80.4%\n",
      "Max accuracy: 80.42%\n",
      "Train: [82/100][0/625]\teta 0:00:20 lr 0.000092\t wd 0.0100\ttime 0.0335 (0.0335)\tloss 0.4888 (0.4888)\tgrad_norm 3.2338 (3.2338)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][10/625]\teta 0:00:21 lr 0.000092\t wd 0.0100\ttime 0.0329 (0.0343)\tloss 0.3782 (0.3895)\tgrad_norm 1.8820 (2.2493)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][20/625]\teta 0:00:21 lr 0.000091\t wd 0.0100\ttime 0.0325 (0.0349)\tloss 0.4233 (0.4068)\tgrad_norm 2.6944 (2.2569)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][30/625]\teta 0:00:21 lr 0.000091\t wd 0.0100\ttime 0.0356 (0.0354)\tloss 0.2537 (0.3921)\tgrad_norm 1.7770 (2.1872)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][40/625]\teta 0:00:20 lr 0.000091\t wd 0.0100\ttime 0.0384 (0.0355)\tloss 0.3965 (0.4029)\tgrad_norm 2.0644 (2.2148)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][50/625]\teta 0:00:20 lr 0.000091\t wd 0.0100\ttime 0.0359 (0.0354)\tloss 0.4377 (0.4131)\tgrad_norm 2.1845 (2.2429)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][60/625]\teta 0:00:19 lr 0.000091\t wd 0.0100\ttime 0.0333 (0.0354)\tloss 0.3979 (0.4115)\tgrad_norm 2.2628 (2.2370)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][70/625]\teta 0:00:19 lr 0.000091\t wd 0.0100\ttime 0.0391 (0.0354)\tloss 0.4131 (0.4121)\tgrad_norm 1.6652 (2.2452)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][80/625]\teta 0:00:19 lr 0.000091\t wd 0.0100\ttime 0.0348 (0.0354)\tloss 0.4497 (0.4113)\tgrad_norm 3.1004 (2.2565)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][90/625]\teta 0:00:18 lr 0.000090\t wd 0.0100\ttime 0.0324 (0.0353)\tloss 0.5498 (0.4051)\tgrad_norm 2.2665 (2.2260)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][100/625]\teta 0:00:18 lr 0.000090\t wd 0.0100\ttime 0.0329 (0.0352)\tloss 0.4363 (0.4077)\tgrad_norm 2.7931 (2.2436)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][110/625]\teta 0:00:18 lr 0.000090\t wd 0.0100\ttime 0.0324 (0.0352)\tloss 0.4802 (0.4091)\tgrad_norm 2.4010 (2.2475)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][120/625]\teta 0:00:17 lr 0.000090\t wd 0.0100\ttime 0.0396 (0.0353)\tloss 0.4963 (0.4097)\tgrad_norm 3.1925 (2.2625)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][130/625]\teta 0:00:17 lr 0.000090\t wd 0.0100\ttime 0.0359 (0.0354)\tloss 0.2981 (0.4109)\tgrad_norm 2.1245 (2.2654)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][140/625]\teta 0:00:17 lr 0.000090\t wd 0.0100\ttime 0.0399 (0.0355)\tloss 0.4575 (0.4119)\tgrad_norm 2.8667 (2.2751)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][150/625]\teta 0:00:16 lr 0.000090\t wd 0.0100\ttime 0.0333 (0.0355)\tloss 0.1881 (0.4086)\tgrad_norm 1.9678 (2.2591)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][160/625]\teta 0:00:16 lr 0.000090\t wd 0.0100\ttime 0.0353 (0.0355)\tloss 0.3950 (0.4067)\tgrad_norm 1.9679 (2.2519)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][170/625]\teta 0:00:16 lr 0.000089\t wd 0.0100\ttime 0.0398 (0.0356)\tloss 0.5264 (0.4076)\tgrad_norm 2.1388 (2.2356)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][180/625]\teta 0:00:15 lr 0.000089\t wd 0.0100\ttime 0.0357 (0.0356)\tloss 0.6875 (0.4087)\tgrad_norm 2.5745 (2.2389)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][190/625]\teta 0:00:15 lr 0.000089\t wd 0.0100\ttime 0.0324 (0.0356)\tloss 0.5024 (0.4096)\tgrad_norm 1.9347 (2.2385)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][200/625]\teta 0:00:15 lr 0.000089\t wd 0.0100\ttime 0.0391 (0.0356)\tloss 0.3562 (0.4081)\tgrad_norm 1.9180 (2.2241)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][210/625]\teta 0:00:14 lr 0.000089\t wd 0.0100\ttime 0.0356 (0.0357)\tloss 0.3547 (0.4052)\tgrad_norm 2.0980 (2.2112)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][220/625]\teta 0:00:14 lr 0.000089\t wd 0.0100\ttime 0.0354 (0.0356)\tloss 0.2825 (0.4067)\tgrad_norm 2.5357 (2.2192)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][230/625]\teta 0:00:14 lr 0.000089\t wd 0.0100\ttime 0.0352 (0.0356)\tloss 0.4014 (0.4070)\tgrad_norm 1.8941 (2.2184)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][240/625]\teta 0:00:13 lr 0.000088\t wd 0.0100\ttime 0.0327 (0.0356)\tloss 0.3679 (0.4052)\tgrad_norm 2.6054 (2.2169)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][250/625]\teta 0:00:13 lr 0.000088\t wd 0.0100\ttime 0.0327 (0.0356)\tloss 0.5532 (0.4053)\tgrad_norm 3.2829 (2.2167)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][260/625]\teta 0:00:12 lr 0.000088\t wd 0.0100\ttime 0.0349 (0.0356)\tloss 0.3958 (0.4062)\tgrad_norm 2.3544 (2.2165)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][270/625]\teta 0:00:12 lr 0.000088\t wd 0.0100\ttime 0.0324 (0.0356)\tloss 0.3970 (0.4066)\tgrad_norm 2.2450 (2.2137)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][280/625]\teta 0:00:12 lr 0.000088\t wd 0.0100\ttime 0.0323 (0.0356)\tloss 0.6133 (0.4076)\tgrad_norm 2.5924 (2.2199)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][290/625]\teta 0:00:11 lr 0.000088\t wd 0.0100\ttime 0.0363 (0.0355)\tloss 0.7310 (0.4087)\tgrad_norm 3.0673 (2.2238)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][300/625]\teta 0:00:11 lr 0.000088\t wd 0.0100\ttime 0.0328 (0.0355)\tloss 0.4260 (0.4094)\tgrad_norm 2.6419 (2.2233)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][310/625]\teta 0:00:11 lr 0.000087\t wd 0.0100\ttime 0.0367 (0.0355)\tloss 0.3931 (0.4107)\tgrad_norm 2.4765 (2.2245)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][320/625]\teta 0:00:10 lr 0.000087\t wd 0.0100\ttime 0.0394 (0.0356)\tloss 0.5474 (0.4095)\tgrad_norm 2.6832 (2.2207)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][330/625]\teta 0:00:10 lr 0.000087\t wd 0.0100\ttime 0.0327 (0.0356)\tloss 0.3972 (0.4097)\tgrad_norm 2.4441 (2.2261)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][340/625]\teta 0:00:10 lr 0.000087\t wd 0.0100\ttime 0.0321 (0.0355)\tloss 0.3296 (0.4081)\tgrad_norm 1.6626 (2.2199)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][350/625]\teta 0:00:09 lr 0.000087\t wd 0.0100\ttime 0.0354 (0.0355)\tloss 0.3218 (0.4071)\tgrad_norm 2.2861 (2.2231)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][360/625]\teta 0:00:09 lr 0.000087\t wd 0.0100\ttime 0.0362 (0.0355)\tloss 0.4924 (0.4077)\tgrad_norm 2.6551 (2.2293)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][370/625]\teta 0:00:09 lr 0.000087\t wd 0.0100\ttime 0.0363 (0.0355)\tloss 0.4917 (0.4080)\tgrad_norm 2.2013 (2.2273)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][380/625]\teta 0:00:08 lr 0.000086\t wd 0.0100\ttime 0.0330 (0.0355)\tloss 0.2737 (0.4081)\tgrad_norm 3.0451 (2.2267)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][390/625]\teta 0:00:08 lr 0.000086\t wd 0.0100\ttime 0.0401 (0.0356)\tloss 0.3406 (0.4094)\tgrad_norm 1.9899 (2.2262)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][400/625]\teta 0:00:08 lr 0.000086\t wd 0.0100\ttime 0.0371 (0.0356)\tloss 0.3799 (0.4090)\tgrad_norm 2.0930 (2.2282)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][410/625]\teta 0:00:07 lr 0.000086\t wd 0.0100\ttime 0.0326 (0.0356)\tloss 0.4016 (0.4081)\tgrad_norm 1.7545 (2.2204)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][420/625]\teta 0:00:07 lr 0.000086\t wd 0.0100\ttime 0.0357 (0.0356)\tloss 0.5117 (0.4080)\tgrad_norm 2.4876 (2.2164)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][430/625]\teta 0:00:06 lr 0.000086\t wd 0.0100\ttime 0.0360 (0.0356)\tloss 0.3242 (0.4070)\tgrad_norm 1.6509 (2.2153)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][440/625]\teta 0:00:06 lr 0.000086\t wd 0.0100\ttime 0.0354 (0.0356)\tloss 0.4692 (0.4067)\tgrad_norm 2.3831 (2.2135)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][450/625]\teta 0:00:06 lr 0.000086\t wd 0.0100\ttime 0.0356 (0.0356)\tloss 0.4690 (0.4073)\tgrad_norm 1.9219 (2.2119)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][460/625]\teta 0:00:05 lr 0.000085\t wd 0.0100\ttime 0.0392 (0.0356)\tloss 0.3850 (0.4069)\tgrad_norm 2.3298 (2.2092)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][470/625]\teta 0:00:05 lr 0.000085\t wd 0.0100\ttime 0.0361 (0.0357)\tloss 0.4165 (0.4063)\tgrad_norm 1.6963 (2.2059)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][480/625]\teta 0:00:05 lr 0.000085\t wd 0.0100\ttime 0.0358 (0.0357)\tloss 0.4666 (0.4058)\tgrad_norm 2.1332 (2.2066)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][490/625]\teta 0:00:04 lr 0.000085\t wd 0.0100\ttime 0.0384 (0.0357)\tloss 0.3135 (0.4054)\tgrad_norm 1.6999 (2.2065)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][500/625]\teta 0:00:04 lr 0.000085\t wd 0.0100\ttime 0.0393 (0.0357)\tloss 0.6255 (0.4059)\tgrad_norm 2.3177 (2.2058)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][510/625]\teta 0:00:04 lr 0.000085\t wd 0.0100\ttime 0.0357 (0.0357)\tloss 0.4260 (0.4056)\tgrad_norm 2.0200 (2.2044)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][520/625]\teta 0:00:03 lr 0.000085\t wd 0.0100\ttime 0.0352 (0.0357)\tloss 0.3242 (0.4050)\tgrad_norm 1.7775 (2.1994)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][530/625]\teta 0:00:03 lr 0.000084\t wd 0.0100\ttime 0.0328 (0.0357)\tloss 0.4795 (0.4065)\tgrad_norm 3.0889 (2.2034)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][540/625]\teta 0:00:03 lr 0.000084\t wd 0.0100\ttime 0.0361 (0.0357)\tloss 0.3208 (0.4068)\tgrad_norm 1.4334 (2.2021)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][550/625]\teta 0:00:02 lr 0.000084\t wd 0.0100\ttime 0.0359 (0.0357)\tloss 0.2986 (0.4064)\tgrad_norm 1.7471 (2.1956)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][560/625]\teta 0:00:02 lr 0.000084\t wd 0.0100\ttime 0.0352 (0.0357)\tloss 0.3621 (0.4063)\tgrad_norm 1.8247 (2.1928)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][570/625]\teta 0:00:01 lr 0.000084\t wd 0.0100\ttime 0.0352 (0.0357)\tloss 0.2917 (0.4057)\tgrad_norm 2.2500 (2.1915)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][580/625]\teta 0:00:01 lr 0.000084\t wd 0.0100\ttime 0.0323 (0.0357)\tloss 0.3601 (0.4064)\tgrad_norm 1.6154 (2.1913)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][590/625]\teta 0:00:01 lr 0.000084\t wd 0.0100\ttime 0.0330 (0.0357)\tloss 0.4497 (0.4069)\tgrad_norm 2.5614 (2.1930)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][600/625]\teta 0:00:00 lr 0.000083\t wd 0.0100\ttime 0.0323 (0.0356)\tloss 0.4265 (0.4073)\tgrad_norm 2.1898 (2.1932)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][610/625]\teta 0:00:00 lr 0.000083\t wd 0.0100\ttime 0.0328 (0.0356)\tloss 0.3564 (0.4071)\tgrad_norm 2.4195 (2.1928)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [82/100][620/625]\teta 0:00:00 lr 0.000083\t wd 0.0100\ttime 0.0326 (0.0356)\tloss 0.5005 (0.4068)\tgrad_norm 2.6314 (2.1906)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 82 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_82.pth saving......\n",
      "./model_save/ckpt_epoch_82.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.6094 (0.6094)\tAcc@1 75.000 (75.000)\tAcc@5 100.000 (100.000)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.5747 (0.5273)\tAcc@1 87.500 (81.676)\tAcc@5 98.438 (99.432)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.4438 (0.5385)\tAcc@1 84.375 (81.399)\tAcc@5 100.000 (99.479)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.5200 (0.5691)\tAcc@1 84.375 (80.746)\tAcc@5 100.000 (99.244)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.4846 (0.5682)\tAcc@1 82.812 (80.678)\tAcc@5 100.000 (99.276)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.5698 (0.5659)\tAcc@1 82.812 (80.944)\tAcc@5 100.000 (99.234)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.7051 (0.5780)\tAcc@1 85.938 (80.430)\tAcc@5 98.438 (99.206)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.6323 (0.5856)\tAcc@1 78.125 (80.238)\tAcc@5 96.875 (99.120)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.6377 (0.5904)\tAcc@1 75.000 (80.015)\tAcc@5 98.438 (99.074)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.5581 (0.5864)\tAcc@1 82.812 (80.203)\tAcc@5 98.438 (99.021)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.8691 (0.5880)\tAcc@1 71.875 (80.183)\tAcc@5 100.000 (99.041)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.5703 (0.5880)\tAcc@1 76.562 (80.138)\tAcc@5 98.438 (99.085)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.4692 (0.5844)\tAcc@1 76.562 (80.294)\tAcc@5 100.000 (99.109)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.4692 (0.5817)\tAcc@1 85.938 (80.439)\tAcc@5 98.438 (99.094)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.4727 (0.5775)\tAcc@1 85.938 (80.496)\tAcc@5 100.000 (99.080)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.3926 (0.5792)\tAcc@1 85.938 (80.536)\tAcc@5 100.000 (99.038)\tMem 455MB\n",
      " * Acc@1 80.590 Acc@5 99.070\n",
      "Accuracy of the network on the 10000 test images: 80.6%\n",
      "Max accuracy: 80.59%\n",
      "Train: [83/100][0/625]\teta 0:00:23 lr 0.000083\t wd 0.0100\ttime 0.0369 (0.0369)\tloss 0.4468 (0.4468)\tgrad_norm 1.9102 (1.9102)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][10/625]\teta 0:00:22 lr 0.000083\t wd 0.0100\ttime 0.0381 (0.0362)\tloss 0.3105 (0.3478)\tgrad_norm 1.7439 (1.9837)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][20/625]\teta 0:00:22 lr 0.000083\t wd 0.0100\ttime 0.0353 (0.0364)\tloss 0.5254 (0.3950)\tgrad_norm 2.0861 (2.0584)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][30/625]\teta 0:00:21 lr 0.000083\t wd 0.0100\ttime 0.0338 (0.0362)\tloss 0.3672 (0.4195)\tgrad_norm 1.6983 (2.1739)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][40/625]\teta 0:00:21 lr 0.000083\t wd 0.0100\ttime 0.0327 (0.0365)\tloss 0.3489 (0.4111)\tgrad_norm 1.8078 (2.2132)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][50/625]\teta 0:00:21 lr 0.000082\t wd 0.0100\ttime 0.0390 (0.0366)\tloss 0.4841 (0.4210)\tgrad_norm 3.0973 (2.2785)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][60/625]\teta 0:00:20 lr 0.000082\t wd 0.0100\ttime 0.0381 (0.0366)\tloss 0.3696 (0.4154)\tgrad_norm 2.2781 (2.2899)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][70/625]\teta 0:00:20 lr 0.000082\t wd 0.0100\ttime 0.0335 (0.0366)\tloss 0.5474 (0.4164)\tgrad_norm 2.6424 (2.3007)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][80/625]\teta 0:00:19 lr 0.000082\t wd 0.0100\ttime 0.0393 (0.0365)\tloss 0.1575 (0.4151)\tgrad_norm 1.1190 (2.3137)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][90/625]\teta 0:00:19 lr 0.000082\t wd 0.0100\ttime 0.0329 (0.0365)\tloss 0.3479 (0.4120)\tgrad_norm 2.1153 (2.3017)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][100/625]\teta 0:00:19 lr 0.000082\t wd 0.0100\ttime 0.0325 (0.0365)\tloss 0.3015 (0.4073)\tgrad_norm 1.6164 (2.2760)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][110/625]\teta 0:00:18 lr 0.000082\t wd 0.0100\ttime 0.0370 (0.0365)\tloss 0.2886 (0.4028)\tgrad_norm 1.8814 (2.2675)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][120/625]\teta 0:00:18 lr 0.000082\t wd 0.0100\ttime 0.0329 (0.0363)\tloss 0.3938 (0.4047)\tgrad_norm 2.3847 (2.2707)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][130/625]\teta 0:00:18 lr 0.000081\t wd 0.0100\ttime 0.0390 (0.0364)\tloss 0.5879 (0.4070)\tgrad_norm 3.1910 (2.2690)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][140/625]\teta 0:00:17 lr 0.000081\t wd 0.0100\ttime 0.0370 (0.0365)\tloss 0.4255 (0.4033)\tgrad_norm 1.9882 (2.2778)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][150/625]\teta 0:00:17 lr 0.000081\t wd 0.0100\ttime 0.0326 (0.0366)\tloss 0.2607 (0.4039)\tgrad_norm 2.0948 (2.2701)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][160/625]\teta 0:00:16 lr 0.000081\t wd 0.0100\ttime 0.0342 (0.0365)\tloss 0.4373 (0.4038)\tgrad_norm 2.4779 (2.2731)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][170/625]\teta 0:00:16 lr 0.000081\t wd 0.0100\ttime 0.0358 (0.0365)\tloss 0.6172 (0.4021)\tgrad_norm 2.3850 (2.2667)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][180/625]\teta 0:00:16 lr 0.000081\t wd 0.0100\ttime 0.0406 (0.0365)\tloss 0.2515 (0.4014)\tgrad_norm 1.6246 (2.2616)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][190/625]\teta 0:00:15 lr 0.000081\t wd 0.0100\ttime 0.0392 (0.0364)\tloss 0.4961 (0.4059)\tgrad_norm 2.4482 (2.2775)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][200/625]\teta 0:00:15 lr 0.000080\t wd 0.0100\ttime 0.0323 (0.0364)\tloss 0.3809 (0.4061)\tgrad_norm 3.1476 (2.2764)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][210/625]\teta 0:00:15 lr 0.000080\t wd 0.0100\ttime 0.0324 (0.0364)\tloss 0.5889 (0.4069)\tgrad_norm 2.1882 (2.2674)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][220/625]\teta 0:00:14 lr 0.000080\t wd 0.0100\ttime 0.0329 (0.0364)\tloss 0.4167 (0.4062)\tgrad_norm 2.6816 (2.2643)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][230/625]\teta 0:00:14 lr 0.000080\t wd 0.0100\ttime 0.0391 (0.0364)\tloss 0.4460 (0.4080)\tgrad_norm 2.1887 (2.2614)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][240/625]\teta 0:00:14 lr 0.000080\t wd 0.0100\ttime 0.0401 (0.0364)\tloss 0.4448 (0.4090)\tgrad_norm 1.9577 (2.2647)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][250/625]\teta 0:00:13 lr 0.000080\t wd 0.0100\ttime 0.0326 (0.0363)\tloss 0.4673 (0.4106)\tgrad_norm 2.0809 (2.2747)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][260/625]\teta 0:00:13 lr 0.000080\t wd 0.0100\ttime 0.0392 (0.0363)\tloss 0.3271 (0.4124)\tgrad_norm 2.5595 (2.2735)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][270/625]\teta 0:00:12 lr 0.000080\t wd 0.0100\ttime 0.0365 (0.0363)\tloss 0.2964 (0.4134)\tgrad_norm 2.1804 (2.2780)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][280/625]\teta 0:00:12 lr 0.000079\t wd 0.0100\ttime 0.0345 (0.0363)\tloss 0.4241 (0.4124)\tgrad_norm 1.8490 (2.2729)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][290/625]\teta 0:00:12 lr 0.000079\t wd 0.0100\ttime 0.0397 (0.0363)\tloss 0.4746 (0.4108)\tgrad_norm 2.7309 (2.2677)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][300/625]\teta 0:00:11 lr 0.000079\t wd 0.0100\ttime 0.0324 (0.0363)\tloss 0.4138 (0.4117)\tgrad_norm 2.2073 (2.2666)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][310/625]\teta 0:00:11 lr 0.000079\t wd 0.0100\ttime 0.0329 (0.0363)\tloss 0.3870 (0.4113)\tgrad_norm 2.6864 (2.2638)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][320/625]\teta 0:00:11 lr 0.000079\t wd 0.0100\ttime 0.0345 (0.0363)\tloss 0.4109 (0.4126)\tgrad_norm 2.5396 (2.2673)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][330/625]\teta 0:00:10 lr 0.000079\t wd 0.0100\ttime 0.0326 (0.0363)\tloss 0.3911 (0.4122)\tgrad_norm 1.8192 (2.2642)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][340/625]\teta 0:00:10 lr 0.000079\t wd 0.0100\ttime 0.0352 (0.0363)\tloss 0.3962 (0.4134)\tgrad_norm 2.3293 (2.2657)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][350/625]\teta 0:00:09 lr 0.000079\t wd 0.0100\ttime 0.0346 (0.0363)\tloss 0.3904 (0.4151)\tgrad_norm 1.9001 (2.2705)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][360/625]\teta 0:00:09 lr 0.000078\t wd 0.0100\ttime 0.0355 (0.0364)\tloss 0.3196 (0.4141)\tgrad_norm 3.1782 (2.2687)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][370/625]\teta 0:00:09 lr 0.000078\t wd 0.0100\ttime 0.0334 (0.0364)\tloss 0.2542 (0.4134)\tgrad_norm 1.8984 (2.2679)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][380/625]\teta 0:00:08 lr 0.000078\t wd 0.0100\ttime 0.0402 (0.0364)\tloss 0.4790 (0.4118)\tgrad_norm 2.8123 (2.2608)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][390/625]\teta 0:00:08 lr 0.000078\t wd 0.0100\ttime 0.0332 (0.0364)\tloss 0.3284 (0.4111)\tgrad_norm 1.5212 (2.2597)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][400/625]\teta 0:00:08 lr 0.000078\t wd 0.0100\ttime 0.0366 (0.0363)\tloss 0.3943 (0.4104)\tgrad_norm 1.8348 (2.2590)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][410/625]\teta 0:00:07 lr 0.000078\t wd 0.0100\ttime 0.0389 (0.0363)\tloss 0.3950 (0.4100)\tgrad_norm 1.8014 (2.2557)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][420/625]\teta 0:00:07 lr 0.000078\t wd 0.0100\ttime 0.0352 (0.0363)\tloss 0.3926 (0.4088)\tgrad_norm 2.0025 (2.2508)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][430/625]\teta 0:00:07 lr 0.000077\t wd 0.0100\ttime 0.0362 (0.0363)\tloss 0.4253 (0.4083)\tgrad_norm 2.4331 (2.2558)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][440/625]\teta 0:00:06 lr 0.000077\t wd 0.0100\ttime 0.0357 (0.0363)\tloss 0.4065 (0.4080)\tgrad_norm 2.0679 (2.2563)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][450/625]\teta 0:00:06 lr 0.000077\t wd 0.0100\ttime 0.0358 (0.0363)\tloss 0.3667 (0.4085)\tgrad_norm 2.0977 (2.2555)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][460/625]\teta 0:00:05 lr 0.000077\t wd 0.0100\ttime 0.0359 (0.0363)\tloss 0.5498 (0.4088)\tgrad_norm 2.7322 (2.2599)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][470/625]\teta 0:00:05 lr 0.000077\t wd 0.0100\ttime 0.0328 (0.0363)\tloss 0.3799 (0.4090)\tgrad_norm 2.0418 (2.2591)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][480/625]\teta 0:00:05 lr 0.000077\t wd 0.0100\ttime 0.0389 (0.0363)\tloss 0.5376 (0.4091)\tgrad_norm 2.0435 (2.2539)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][490/625]\teta 0:00:04 lr 0.000077\t wd 0.0100\ttime 0.0349 (0.0363)\tloss 0.3792 (0.4091)\tgrad_norm 1.8646 (2.2543)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][500/625]\teta 0:00:04 lr 0.000077\t wd 0.0100\ttime 0.0360 (0.0363)\tloss 0.4700 (0.4096)\tgrad_norm 2.5137 (2.2569)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][510/625]\teta 0:00:04 lr 0.000076\t wd 0.0100\ttime 0.0354 (0.0363)\tloss 0.4382 (0.4090)\tgrad_norm 2.1677 (2.2561)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][520/625]\teta 0:00:03 lr 0.000076\t wd 0.0100\ttime 0.0388 (0.0363)\tloss 0.3489 (0.4074)\tgrad_norm 2.3551 (2.2527)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][530/625]\teta 0:00:03 lr 0.000076\t wd 0.0100\ttime 0.0361 (0.0363)\tloss 0.3293 (0.4076)\tgrad_norm 1.9579 (2.2524)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][540/625]\teta 0:00:03 lr 0.000076\t wd 0.0100\ttime 0.0365 (0.0363)\tloss 0.3591 (0.4073)\tgrad_norm 2.0280 (2.2487)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][550/625]\teta 0:00:02 lr 0.000076\t wd 0.0100\ttime 0.0325 (0.0363)\tloss 0.5493 (0.4073)\tgrad_norm 3.3225 (2.2513)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][560/625]\teta 0:00:02 lr 0.000076\t wd 0.0100\ttime 0.0323 (0.0362)\tloss 0.2096 (0.4071)\tgrad_norm 1.7985 (2.2507)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][570/625]\teta 0:00:01 lr 0.000076\t wd 0.0100\ttime 0.0330 (0.0362)\tloss 0.3186 (0.4072)\tgrad_norm 2.2792 (2.2534)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][580/625]\teta 0:00:01 lr 0.000076\t wd 0.0100\ttime 0.0353 (0.0362)\tloss 0.2722 (0.4068)\tgrad_norm 1.4985 (2.2544)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][590/625]\teta 0:00:01 lr 0.000075\t wd 0.0100\ttime 0.0388 (0.0362)\tloss 0.2891 (0.4060)\tgrad_norm 1.8306 (2.2509)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][600/625]\teta 0:00:00 lr 0.000075\t wd 0.0100\ttime 0.0392 (0.0362)\tloss 0.5869 (0.4062)\tgrad_norm 3.1975 (2.2538)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][610/625]\teta 0:00:00 lr 0.000075\t wd 0.0100\ttime 0.0345 (0.0362)\tloss 0.3259 (0.4055)\tgrad_norm 2.7015 (2.2547)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [83/100][620/625]\teta 0:00:00 lr 0.000075\t wd 0.0100\ttime 0.0356 (0.0362)\tloss 0.3591 (0.4058)\tgrad_norm 1.6618 (2.2569)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 83 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_83.pth saving......\n",
      "./model_save/ckpt_epoch_83.pth saved !!!\n",
      "Test: [0/157]\tTime 0.017 (0.017)\tLoss 0.8828 (0.8828)\tAcc@1 68.750 (68.750)\tAcc@5 100.000 (100.000)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.016 (0.016)\tLoss 0.6255 (0.5648)\tAcc@1 79.688 (79.545)\tAcc@5 100.000 (100.000)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.016)\tLoss 0.5205 (0.5661)\tAcc@1 84.375 (80.208)\tAcc@5 100.000 (99.554)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.016)\tLoss 0.5356 (0.5504)\tAcc@1 84.375 (81.048)\tAcc@5 100.000 (99.496)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.016)\tLoss 0.3704 (0.5583)\tAcc@1 87.500 (80.945)\tAcc@5 98.438 (99.314)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.5039 (0.5652)\tAcc@1 78.125 (80.852)\tAcc@5 98.438 (99.234)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.016 (0.015)\tLoss 0.5195 (0.5591)\tAcc@1 81.250 (80.866)\tAcc@5 100.000 (99.206)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.5293 (0.5561)\tAcc@1 84.375 (81.184)\tAcc@5 96.875 (99.164)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.5771 (0.5580)\tAcc@1 81.250 (81.173)\tAcc@5 100.000 (99.171)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.5513 (0.5515)\tAcc@1 81.250 (81.405)\tAcc@5 100.000 (99.193)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.016 (0.015)\tLoss 0.5996 (0.5570)\tAcc@1 78.125 (81.126)\tAcc@5 98.438 (99.165)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.9849 (0.5582)\tAcc@1 71.875 (81.053)\tAcc@5 96.875 (99.184)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.016 (0.015)\tLoss 0.8467 (0.5645)\tAcc@1 73.438 (81.030)\tAcc@5 96.875 (99.148)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.016 (0.015)\tLoss 0.6338 (0.5730)\tAcc@1 76.562 (80.868)\tAcc@5 100.000 (99.094)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.016 (0.015)\tLoss 0.5898 (0.5758)\tAcc@1 79.688 (80.618)\tAcc@5 100.000 (99.113)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.4695 (0.5745)\tAcc@1 84.375 (80.691)\tAcc@5 100.000 (99.120)\tMem 455MB\n",
      " * Acc@1 80.810 Acc@5 99.120\n",
      "Accuracy of the network on the 10000 test images: 80.8%\n",
      "Max accuracy: 80.81%\n",
      "Train: [84/100][0/625]\teta 0:00:22 lr 0.000075\t wd 0.0100\ttime 0.0363 (0.0363)\tloss 0.3774 (0.3774)\tgrad_norm 2.2238 (2.2238)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [84/100][10/625]\teta 0:00:23 lr 0.000075\t wd 0.0100\ttime 0.0388 (0.0378)\tloss 0.5479 (0.4312)\tgrad_norm 2.3652 (2.1389)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [84/100][20/625]\teta 0:00:22 lr 0.000075\t wd 0.0100\ttime 0.0364 (0.0373)\tloss 0.3572 (0.3984)\tgrad_norm 1.6955 (2.1471)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [84/100][30/625]\teta 0:00:22 lr 0.000075\t wd 0.0100\ttime 0.0364 (0.0370)\tloss 0.2371 (0.3905)\tgrad_norm 1.5285 (2.1203)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [84/100][40/625]\teta 0:00:21 lr 0.000074\t wd 0.0100\ttime 0.0353 (0.0368)\tloss 0.4619 (0.3847)\tgrad_norm 2.1908 (2.1060)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [84/100][50/625]\teta 0:00:21 lr 0.000074\t wd 0.0100\ttime 0.0396 (0.0368)\tloss 0.3479 (0.3835)\tgrad_norm 1.6554 (2.0997)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [84/100][60/625]\teta 0:00:20 lr 0.000074\t wd 0.0100\ttime 0.0351 (0.0366)\tloss 0.3835 (0.3886)\tgrad_norm 2.0836 (2.1389)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [84/100][70/625]\teta 0:00:20 lr 0.000074\t wd 0.0100\ttime 0.0330 (0.0365)\tloss 0.3306 (0.3872)\tgrad_norm 2.2216 (2.1275)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [84/100][80/625]\teta 0:00:19 lr 0.000074\t wd 0.0100\ttime 0.0402 (0.0364)\tloss 0.2791 (0.3928)\tgrad_norm 1.9145 (2.1422)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [84/100][90/625]\teta 0:00:19 lr 0.000074\t wd 0.0100\ttime 0.0330 (0.0364)\tloss 0.5239 (0.3939)\tgrad_norm 2.5144 (2.1574)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [84/100][100/625]\teta 0:00:19 lr 0.000074\t wd 0.0100\ttime 0.0398 (0.0364)\tloss 0.3958 (0.3989)\tgrad_norm 2.1837 (2.1881)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [84/100][110/625]\teta 0:00:18 lr 0.000074\t wd 0.0100\ttime 0.0366 (0.0364)\tloss 0.3916 (0.3999)\tgrad_norm 1.5732 (2.1940)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [84/100][120/625]\teta 0:00:18 lr 0.000073\t wd 0.0100\ttime 0.0362 (0.0364)\tloss 0.4041 (0.3994)\tgrad_norm 2.3586 (2.1998)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [84/100][130/625]\teta 0:00:17 lr 0.000073\t wd 0.0100\ttime 0.0331 (0.0362)\tloss 0.3481 (0.3982)\tgrad_norm 2.6288 (2.1886)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [84/100][140/625]\teta 0:00:17 lr 0.000073\t wd 0.0100\ttime 0.0338 (0.0361)\tloss 0.5127 (0.3964)\tgrad_norm 3.2224 (2.1869)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [84/100][150/625]\teta 0:00:17 lr 0.000073\t wd 0.0100\ttime 0.0329 (0.0359)\tloss 0.2620 (0.3945)\tgrad_norm 1.3782 (2.1692)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [84/100][160/625]\teta 0:00:16 lr 0.000073\t wd 0.0100\ttime 0.0344 (0.0358)\tloss 0.4331 (0.3940)\tgrad_norm 2.2139 (2.1667)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [84/100][170/625]\teta 0:00:16 lr 0.000073\t wd 0.0100\ttime 0.0328 (0.0357)\tloss 0.1733 (0.3936)\tgrad_norm 1.3252 (2.1682)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [84/100][180/625]\teta 0:00:15 lr 0.000073\t wd 0.0100\ttime 0.0331 (0.0356)\tloss 0.2930 (0.3936)\tgrad_norm 1.5982 (2.1754)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [84/100][190/625]\teta 0:00:15 lr 0.000073\t wd 0.0100\ttime 0.0398 (0.0356)\tloss 0.5322 (0.3916)\tgrad_norm 2.8379 (2.1743)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [84/100][200/625]\teta 0:00:15 lr 0.000072\t wd 0.0100\ttime 0.0328 (0.0357)\tloss 0.4741 (0.3925)\tgrad_norm 1.9914 (2.1772)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [84/100][210/625]\teta 0:00:14 lr 0.000072\t wd 0.0100\ttime 0.0331 (0.0356)\tloss 0.2076 (0.3934)\tgrad_norm 1.6038 (2.1812)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [84/100][220/625]\teta 0:00:14 lr 0.000072\t wd 0.0100\ttime 0.0325 (0.0355)\tloss 0.4773 (0.3940)\tgrad_norm 2.7894 (2.1771)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [84/100][230/625]\teta 0:00:14 lr 0.000072\t wd 0.0100\ttime 0.0361 (0.0355)\tloss 0.3723 (0.3947)\tgrad_norm 2.0782 (2.1752)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [84/100][240/625]\teta 0:00:13 lr 0.000072\t wd 0.0100\ttime 0.0392 (0.0355)\tloss 0.4370 (0.3966)\tgrad_norm 2.1646 (2.1846)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [84/100][250/625]\teta 0:00:13 lr 0.000072\t wd 0.0100\ttime 0.0326 (0.0355)\tloss 0.6182 (0.4008)\tgrad_norm 2.8207 (2.1966)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [84/100][260/625]\teta 0:00:12 lr 0.000072\t wd 0.0100\ttime 0.0389 (0.0356)\tloss 0.2800 (0.3997)\tgrad_norm 1.5305 (2.1994)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [84/100][270/625]\teta 0:00:12 lr 0.000072\t wd 0.0100\ttime 0.0323 (0.0356)\tloss 0.3835 (0.3999)\tgrad_norm 2.3037 (2.2035)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [84/100][280/625]\teta 0:00:12 lr 0.000071\t wd 0.0100\ttime 0.0331 (0.0355)\tloss 0.2981 (0.4005)\tgrad_norm 2.3277 (nan)\tloss_scale 32768.0000 (32884.6121)\tmem 455MB\n",
      "Train: [84/100][290/625]\teta 0:00:11 lr 0.000071\t wd 0.0100\ttime 0.0362 (0.0355)\tloss 0.3210 (0.4002)\tgrad_norm 2.1140 (nan)\tloss_scale 32768.0000 (32880.6048)\tmem 455MB\n",
      "Train: [84/100][300/625]\teta 0:00:11 lr 0.000071\t wd 0.0100\ttime 0.0354 (0.0355)\tloss 0.4390 (0.4015)\tgrad_norm 4.6087 (nan)\tloss_scale 32768.0000 (32876.8638)\tmem 455MB\n",
      "Train: [84/100][310/625]\teta 0:00:11 lr 0.000071\t wd 0.0100\ttime 0.0357 (0.0355)\tloss 0.4077 (0.4026)\tgrad_norm 2.4476 (nan)\tloss_scale 32768.0000 (32873.3633)\tmem 455MB\n",
      "Train: [84/100][320/625]\teta 0:00:10 lr 0.000071\t wd 0.0100\ttime 0.0369 (0.0356)\tloss 0.4932 (0.4037)\tgrad_norm 2.6361 (nan)\tloss_scale 32768.0000 (32870.0810)\tmem 455MB\n",
      "Train: [84/100][330/625]\teta 0:00:10 lr 0.000071\t wd 0.0100\ttime 0.0355 (0.0356)\tloss 0.5850 (0.4048)\tgrad_norm 2.3303 (nan)\tloss_scale 32768.0000 (32866.9970)\tmem 455MB\n",
      "Train: [84/100][340/625]\teta 0:00:10 lr 0.000071\t wd 0.0100\ttime 0.0354 (0.0356)\tloss 0.2406 (0.4039)\tgrad_norm 2.1946 (nan)\tloss_scale 32768.0000 (32864.0938)\tmem 455MB\n",
      "Train: [84/100][350/625]\teta 0:00:09 lr 0.000071\t wd 0.0100\ttime 0.0334 (0.0356)\tloss 0.2231 (0.4024)\tgrad_norm 1.7411 (nan)\tloss_scale 32768.0000 (32861.3561)\tmem 455MB\n",
      "Train: [84/100][360/625]\teta 0:00:09 lr 0.000070\t wd 0.0100\ttime 0.0322 (0.0356)\tloss 0.6074 (0.4022)\tgrad_norm 3.1525 (nan)\tloss_scale 32768.0000 (32858.7701)\tmem 455MB\n",
      "Train: [84/100][370/625]\teta 0:00:09 lr 0.000070\t wd 0.0100\ttime 0.0395 (0.0355)\tloss 0.4529 (0.4016)\tgrad_norm 2.2344 (nan)\tloss_scale 32768.0000 (32856.3235)\tmem 455MB\n",
      "Train: [84/100][380/625]\teta 0:00:08 lr 0.000070\t wd 0.0100\ttime 0.0361 (0.0355)\tloss 0.4399 (0.4022)\tgrad_norm 2.6765 (nan)\tloss_scale 32768.0000 (32854.0052)\tmem 455MB\n",
      "Train: [84/100][390/625]\teta 0:00:08 lr 0.000070\t wd 0.0100\ttime 0.0327 (0.0356)\tloss 0.2524 (0.4009)\tgrad_norm 1.5602 (nan)\tloss_scale 32768.0000 (32851.8056)\tmem 455MB\n",
      "Train: [84/100][400/625]\teta 0:00:08 lr 0.000070\t wd 0.0100\ttime 0.0390 (0.0356)\tloss 0.4573 (0.3991)\tgrad_norm 2.7950 (nan)\tloss_scale 32768.0000 (32849.7157)\tmem 455MB\n",
      "Train: [84/100][410/625]\teta 0:00:07 lr 0.000070\t wd 0.0100\ttime 0.0391 (0.0356)\tloss 0.5498 (0.3997)\tgrad_norm 2.6706 (nan)\tloss_scale 32768.0000 (32847.7275)\tmem 455MB\n",
      "Train: [84/100][420/625]\teta 0:00:07 lr 0.000070\t wd 0.0100\ttime 0.0330 (0.0356)\tloss 0.2002 (0.3996)\tgrad_norm 1.5849 (nan)\tloss_scale 32768.0000 (32845.8337)\tmem 455MB\n",
      "Train: [84/100][430/625]\teta 0:00:06 lr 0.000070\t wd 0.0100\ttime 0.0351 (0.0356)\tloss 0.3420 (0.4002)\tgrad_norm 1.9705 (nan)\tloss_scale 32768.0000 (32844.0278)\tmem 455MB\n",
      "Train: [84/100][440/625]\teta 0:00:06 lr 0.000070\t wd 0.0100\ttime 0.0324 (0.0356)\tloss 0.4404 (0.4004)\tgrad_norm 2.9643 (nan)\tloss_scale 32768.0000 (32842.3039)\tmem 455MB\n",
      "Train: [84/100][450/625]\teta 0:00:06 lr 0.000069\t wd 0.0100\ttime 0.0324 (0.0356)\tloss 0.3579 (0.4003)\tgrad_norm 2.2467 (nan)\tloss_scale 32768.0000 (32840.6563)\tmem 455MB\n",
      "Train: [84/100][460/625]\teta 0:00:05 lr 0.000069\t wd 0.0100\ttime 0.0326 (0.0355)\tloss 0.3916 (0.4006)\tgrad_norm 2.7483 (nan)\tloss_scale 32768.0000 (32839.0803)\tmem 455MB\n",
      "Train: [84/100][470/625]\teta 0:00:05 lr 0.000069\t wd 0.0100\ttime 0.0360 (0.0355)\tloss 0.4688 (0.4004)\tgrad_norm 2.4272 (nan)\tloss_scale 32768.0000 (32837.5711)\tmem 455MB\n",
      "Train: [84/100][480/625]\teta 0:00:05 lr 0.000069\t wd 0.0100\ttime 0.0324 (0.0355)\tloss 0.4822 (0.4010)\tgrad_norm 2.6560 (nan)\tloss_scale 32768.0000 (32836.1247)\tmem 455MB\n",
      "Train: [84/100][490/625]\teta 0:00:04 lr 0.000069\t wd 0.0100\ttime 0.0328 (0.0354)\tloss 0.3057 (0.4011)\tgrad_norm 2.7602 (nan)\tloss_scale 32768.0000 (32834.7373)\tmem 455MB\n",
      "Train: [84/100][500/625]\teta 0:00:04 lr 0.000069\t wd 0.0100\ttime 0.0324 (0.0354)\tloss 0.4485 (0.4016)\tgrad_norm 2.3360 (nan)\tloss_scale 32768.0000 (32833.4052)\tmem 455MB\n",
      "Train: [84/100][510/625]\teta 0:00:04 lr 0.000069\t wd 0.0100\ttime 0.0385 (0.0355)\tloss 0.4385 (0.4025)\tgrad_norm 2.1610 (nan)\tloss_scale 32768.0000 (32832.1252)\tmem 455MB\n",
      "Train: [84/100][520/625]\teta 0:00:03 lr 0.000069\t wd 0.0100\ttime 0.0325 (0.0355)\tloss 0.2189 (0.4031)\tgrad_norm 1.2726 (nan)\tloss_scale 32768.0000 (32830.8944)\tmem 455MB\n",
      "Train: [84/100][530/625]\teta 0:00:03 lr 0.000068\t wd 0.0100\ttime 0.0359 (0.0354)\tloss 0.3640 (0.4028)\tgrad_norm 1.8442 (nan)\tloss_scale 32768.0000 (32829.7100)\tmem 455MB\n",
      "Train: [84/100][540/625]\teta 0:00:03 lr 0.000068\t wd 0.0100\ttime 0.0389 (0.0355)\tloss 0.3459 (0.4030)\tgrad_norm 2.3035 (nan)\tloss_scale 32768.0000 (32828.5693)\tmem 455MB\n",
      "Train: [84/100][550/625]\teta 0:00:02 lr 0.000068\t wd 0.0100\ttime 0.0355 (0.0355)\tloss 0.4319 (0.4020)\tgrad_norm 2.4840 (nan)\tloss_scale 32768.0000 (32827.4701)\tmem 455MB\n",
      "Train: [84/100][560/625]\teta 0:00:02 lr 0.000068\t wd 0.0100\ttime 0.0359 (0.0355)\tloss 0.4065 (0.4014)\tgrad_norm 2.4425 (nan)\tloss_scale 32768.0000 (32826.4100)\tmem 455MB\n",
      "Train: [84/100][570/625]\teta 0:00:01 lr 0.000068\t wd 0.0100\ttime 0.0393 (0.0355)\tloss 0.4001 (0.4018)\tgrad_norm 2.3414 (nan)\tloss_scale 32768.0000 (32825.3870)\tmem 455MB\n",
      "Train: [84/100][580/625]\teta 0:00:01 lr 0.000068\t wd 0.0100\ttime 0.0324 (0.0355)\tloss 0.4265 (0.4015)\tgrad_norm 2.3663 (nan)\tloss_scale 32768.0000 (32824.3993)\tmem 455MB\n",
      "Train: [84/100][590/625]\teta 0:00:01 lr 0.000068\t wd 0.0100\ttime 0.0388 (0.0356)\tloss 0.3784 (0.4022)\tgrad_norm 2.9484 (nan)\tloss_scale 32768.0000 (32823.4450)\tmem 455MB\n",
      "Train: [84/100][600/625]\teta 0:00:00 lr 0.000068\t wd 0.0100\ttime 0.0356 (0.0356)\tloss 0.4810 (0.4024)\tgrad_norm 1.9570 (nan)\tloss_scale 32768.0000 (32822.5225)\tmem 455MB\n",
      "Train: [84/100][610/625]\teta 0:00:00 lr 0.000067\t wd 0.0100\ttime 0.0353 (0.0356)\tloss 0.4065 (0.4020)\tgrad_norm 2.0277 (nan)\tloss_scale 32768.0000 (32821.6301)\tmem 455MB\n",
      "Train: [84/100][620/625]\teta 0:00:00 lr 0.000067\t wd 0.0100\ttime 0.0388 (0.0356)\tloss 0.3960 (0.4021)\tgrad_norm 1.8108 (nan)\tloss_scale 32768.0000 (32820.7665)\tmem 455MB\n",
      "EPOCH 84 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_84.pth saving......\n",
      "./model_save/ckpt_epoch_84.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.6250 (0.6250)\tAcc@1 82.812 (82.812)\tAcc@5 98.438 (98.438)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.9077 (0.6441)\tAcc@1 73.438 (79.688)\tAcc@5 95.312 (98.864)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.4966 (0.6012)\tAcc@1 79.688 (80.432)\tAcc@5 100.000 (99.107)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.6777 (0.6030)\tAcc@1 76.562 (80.040)\tAcc@5 98.438 (99.194)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.3672 (0.5811)\tAcc@1 87.500 (80.678)\tAcc@5 100.000 (99.200)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.7070 (0.5734)\tAcc@1 76.562 (80.729)\tAcc@5 100.000 (99.203)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.3103 (0.5809)\tAcc@1 90.625 (80.482)\tAcc@5 98.438 (99.155)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.6362 (0.5719)\tAcc@1 78.125 (80.964)\tAcc@5 100.000 (99.164)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.7075 (0.5770)\tAcc@1 76.562 (80.845)\tAcc@5 96.875 (99.171)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.7515 (0.5874)\tAcc@1 70.312 (80.340)\tAcc@5 100.000 (99.193)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.8394 (0.5868)\tAcc@1 76.562 (80.384)\tAcc@5 93.750 (99.134)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.3606 (0.5808)\tAcc@1 85.938 (80.546)\tAcc@5 100.000 (99.169)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.7300 (0.5809)\tAcc@1 75.000 (80.566)\tAcc@5 98.438 (99.161)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.5161 (0.5826)\tAcc@1 78.125 (80.463)\tAcc@5 100.000 (99.177)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.3936 (0.5784)\tAcc@1 84.375 (80.530)\tAcc@5 100.000 (99.191)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.4678 (0.5779)\tAcc@1 82.812 (80.598)\tAcc@5 96.875 (99.172)\tMem 455MB\n",
      " * Acc@1 80.680 Acc@5 99.170\n",
      "Accuracy of the network on the 10000 test images: 80.7%\n",
      "Max accuracy: 80.81%\n",
      "Train: [85/100][0/625]\teta 0:00:25 lr 0.000067\t wd 0.0100\ttime 0.0409 (0.0409)\tloss 0.3157 (0.3157)\tgrad_norm 2.0185 (2.0185)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][10/625]\teta 0:00:22 lr 0.000067\t wd 0.0100\ttime 0.0359 (0.0369)\tloss 0.5000 (0.3907)\tgrad_norm 2.4666 (2.2481)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][20/625]\teta 0:00:22 lr 0.000067\t wd 0.0100\ttime 0.0348 (0.0365)\tloss 0.3215 (0.3969)\tgrad_norm 1.9362 (2.2838)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][30/625]\teta 0:00:21 lr 0.000067\t wd 0.0100\ttime 0.0328 (0.0365)\tloss 0.4009 (0.3986)\tgrad_norm 1.8770 (2.1912)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][40/625]\teta 0:00:21 lr 0.000067\t wd 0.0100\ttime 0.0325 (0.0363)\tloss 0.4443 (0.3924)\tgrad_norm 2.1539 (2.1432)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][50/625]\teta 0:00:20 lr 0.000067\t wd 0.0100\ttime 0.0358 (0.0363)\tloss 0.3359 (0.3925)\tgrad_norm 1.9009 (2.1674)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][60/625]\teta 0:00:20 lr 0.000067\t wd 0.0100\ttime 0.0387 (0.0362)\tloss 0.4988 (0.4004)\tgrad_norm 2.5671 (2.2193)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][70/625]\teta 0:00:20 lr 0.000066\t wd 0.0100\ttime 0.0390 (0.0364)\tloss 0.4768 (0.4034)\tgrad_norm 2.0002 (2.2495)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][80/625]\teta 0:00:19 lr 0.000066\t wd 0.0100\ttime 0.0327 (0.0362)\tloss 0.4678 (0.4080)\tgrad_norm 2.5273 (2.2689)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][90/625]\teta 0:00:19 lr 0.000066\t wd 0.0100\ttime 0.0350 (0.0362)\tloss 0.2893 (0.4073)\tgrad_norm 1.6080 (2.2811)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][100/625]\teta 0:00:19 lr 0.000066\t wd 0.0100\ttime 0.0358 (0.0362)\tloss 0.2974 (0.4043)\tgrad_norm 2.0900 (2.2846)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][110/625]\teta 0:00:18 lr 0.000066\t wd 0.0100\ttime 0.0385 (0.0362)\tloss 0.6953 (0.4058)\tgrad_norm 2.6929 (2.2979)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][120/625]\teta 0:00:18 lr 0.000066\t wd 0.0100\ttime 0.0344 (0.0363)\tloss 0.4790 (0.4023)\tgrad_norm 2.5785 (2.2786)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][130/625]\teta 0:00:18 lr 0.000066\t wd 0.0100\ttime 0.0357 (0.0364)\tloss 0.3918 (0.4048)\tgrad_norm 2.8899 (2.2967)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][140/625]\teta 0:00:17 lr 0.000066\t wd 0.0100\ttime 0.0357 (0.0364)\tloss 0.3394 (0.4062)\tgrad_norm 2.4509 (2.2980)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][150/625]\teta 0:00:17 lr 0.000065\t wd 0.0100\ttime 0.0362 (0.0365)\tloss 0.5562 (0.4050)\tgrad_norm 2.0423 (2.2870)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][160/625]\teta 0:00:16 lr 0.000065\t wd 0.0100\ttime 0.0358 (0.0365)\tloss 0.3560 (0.4029)\tgrad_norm 2.3141 (2.2989)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][170/625]\teta 0:00:16 lr 0.000065\t wd 0.0100\ttime 0.0397 (0.0365)\tloss 0.6216 (0.4059)\tgrad_norm 2.5562 (2.2964)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][180/625]\teta 0:00:16 lr 0.000065\t wd 0.0100\ttime 0.0327 (0.0365)\tloss 0.3496 (0.4044)\tgrad_norm 2.0961 (2.3026)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][190/625]\teta 0:00:15 lr 0.000065\t wd 0.0100\ttime 0.0356 (0.0365)\tloss 0.7456 (0.4066)\tgrad_norm 2.5103 (2.3015)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][200/625]\teta 0:00:15 lr 0.000065\t wd 0.0100\ttime 0.0383 (0.0364)\tloss 0.2749 (0.4064)\tgrad_norm 2.2603 (2.3051)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][210/625]\teta 0:00:15 lr 0.000065\t wd 0.0100\ttime 0.0328 (0.0364)\tloss 0.4136 (0.4045)\tgrad_norm 2.1438 (2.3062)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][220/625]\teta 0:00:14 lr 0.000065\t wd 0.0100\ttime 0.0396 (0.0364)\tloss 0.1709 (0.4025)\tgrad_norm 1.3594 (2.2955)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][230/625]\teta 0:00:14 lr 0.000065\t wd 0.0100\ttime 0.0353 (0.0364)\tloss 0.3813 (0.4000)\tgrad_norm 1.9093 (2.2861)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][240/625]\teta 0:00:14 lr 0.000064\t wd 0.0100\ttime 0.0333 (0.0364)\tloss 0.4436 (0.4027)\tgrad_norm 2.0796 (2.2883)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][250/625]\teta 0:00:13 lr 0.000064\t wd 0.0100\ttime 0.0359 (0.0364)\tloss 0.3359 (0.4019)\tgrad_norm 2.2964 (2.2850)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][260/625]\teta 0:00:13 lr 0.000064\t wd 0.0100\ttime 0.0360 (0.0363)\tloss 0.1207 (0.4001)\tgrad_norm 0.9206 (2.2751)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][270/625]\teta 0:00:12 lr 0.000064\t wd 0.0100\ttime 0.0323 (0.0362)\tloss 0.4092 (0.4023)\tgrad_norm 2.5860 (2.2757)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][280/625]\teta 0:00:12 lr 0.000064\t wd 0.0100\ttime 0.0331 (0.0362)\tloss 0.5117 (0.4027)\tgrad_norm 2.3190 (2.2716)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][290/625]\teta 0:00:12 lr 0.000064\t wd 0.0100\ttime 0.0328 (0.0362)\tloss 0.1549 (0.4008)\tgrad_norm 1.2108 (2.2594)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][300/625]\teta 0:00:11 lr 0.000064\t wd 0.0100\ttime 0.0323 (0.0362)\tloss 0.3323 (0.3998)\tgrad_norm 1.7808 (2.2561)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][310/625]\teta 0:00:11 lr 0.000064\t wd 0.0100\ttime 0.0328 (0.0361)\tloss 0.2288 (0.3996)\tgrad_norm 1.5888 (2.2587)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][320/625]\teta 0:00:11 lr 0.000064\t wd 0.0100\ttime 0.0357 (0.0361)\tloss 0.4080 (0.3975)\tgrad_norm 3.3841 (2.2591)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][330/625]\teta 0:00:10 lr 0.000063\t wd 0.0100\ttime 0.0353 (0.0361)\tloss 0.2158 (0.3984)\tgrad_norm 1.6365 (2.2623)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][340/625]\teta 0:00:10 lr 0.000063\t wd 0.0100\ttime 0.0357 (0.0361)\tloss 0.3352 (0.3984)\tgrad_norm 1.7121 (2.2650)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][350/625]\teta 0:00:09 lr 0.000063\t wd 0.0100\ttime 0.0352 (0.0361)\tloss 0.3813 (0.3983)\tgrad_norm 2.9154 (2.2666)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][360/625]\teta 0:00:09 lr 0.000063\t wd 0.0100\ttime 0.0327 (0.0361)\tloss 0.4517 (0.3997)\tgrad_norm 2.2398 (2.2717)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][370/625]\teta 0:00:09 lr 0.000063\t wd 0.0100\ttime 0.0358 (0.0361)\tloss 0.4641 (0.4007)\tgrad_norm 2.4802 (2.2785)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][380/625]\teta 0:00:08 lr 0.000063\t wd 0.0100\ttime 0.0356 (0.0361)\tloss 0.2693 (0.3995)\tgrad_norm 1.8717 (2.2776)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][390/625]\teta 0:00:08 lr 0.000063\t wd 0.0100\ttime 0.0356 (0.0361)\tloss 0.4353 (0.4000)\tgrad_norm 2.3944 (2.2834)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][400/625]\teta 0:00:08 lr 0.000063\t wd 0.0100\ttime 0.0359 (0.0362)\tloss 0.3420 (0.3989)\tgrad_norm 2.0241 (2.2772)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][410/625]\teta 0:00:07 lr 0.000062\t wd 0.0100\ttime 0.0355 (0.0361)\tloss 0.4673 (0.4003)\tgrad_norm 2.5679 (2.2751)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][420/625]\teta 0:00:07 lr 0.000062\t wd 0.0100\ttime 0.0360 (0.0361)\tloss 0.4272 (0.4017)\tgrad_norm 1.7580 (2.2752)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][430/625]\teta 0:00:07 lr 0.000062\t wd 0.0100\ttime 0.0350 (0.0361)\tloss 0.3311 (0.4016)\tgrad_norm 1.8464 (2.2743)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][440/625]\teta 0:00:06 lr 0.000062\t wd 0.0100\ttime 0.0392 (0.0362)\tloss 0.3779 (0.4002)\tgrad_norm 2.6762 (2.2720)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][450/625]\teta 0:00:06 lr 0.000062\t wd 0.0100\ttime 0.0329 (0.0362)\tloss 0.3508 (0.4000)\tgrad_norm 2.1679 (2.2696)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][460/625]\teta 0:00:05 lr 0.000062\t wd 0.0100\ttime 0.0359 (0.0362)\tloss 0.4094 (0.4003)\tgrad_norm 2.7232 (2.2718)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][470/625]\teta 0:00:05 lr 0.000062\t wd 0.0100\ttime 0.0367 (0.0363)\tloss 0.4888 (0.4004)\tgrad_norm 2.1428 (2.2726)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][480/625]\teta 0:00:05 lr 0.000062\t wd 0.0100\ttime 0.0394 (0.0363)\tloss 0.2820 (0.3998)\tgrad_norm 1.7977 (2.2690)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][490/625]\teta 0:00:04 lr 0.000062\t wd 0.0100\ttime 0.0382 (0.0363)\tloss 0.3884 (0.4006)\tgrad_norm 1.9547 (2.2710)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][500/625]\teta 0:00:04 lr 0.000061\t wd 0.0100\ttime 0.0322 (0.0363)\tloss 0.4165 (0.4008)\tgrad_norm 2.1311 (2.2706)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][510/625]\teta 0:00:04 lr 0.000061\t wd 0.0100\ttime 0.0325 (0.0362)\tloss 0.5610 (0.4012)\tgrad_norm 3.2984 (2.2719)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][520/625]\teta 0:00:03 lr 0.000061\t wd 0.0100\ttime 0.0325 (0.0362)\tloss 0.6196 (0.4023)\tgrad_norm 3.1008 (2.2749)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][530/625]\teta 0:00:03 lr 0.000061\t wd 0.0100\ttime 0.0353 (0.0362)\tloss 0.2700 (0.4013)\tgrad_norm 1.9680 (2.2719)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][540/625]\teta 0:00:03 lr 0.000061\t wd 0.0100\ttime 0.0323 (0.0362)\tloss 0.4741 (0.4024)\tgrad_norm 2.8607 (2.2727)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][550/625]\teta 0:00:02 lr 0.000061\t wd 0.0100\ttime 0.0320 (0.0361)\tloss 0.2032 (0.4017)\tgrad_norm 1.5415 (2.2694)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][560/625]\teta 0:00:02 lr 0.000061\t wd 0.0100\ttime 0.0332 (0.0361)\tloss 0.4819 (0.4023)\tgrad_norm 2.4122 (2.2681)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][570/625]\teta 0:00:01 lr 0.000061\t wd 0.0100\ttime 0.0343 (0.0361)\tloss 0.4553 (0.4019)\tgrad_norm 2.3230 (2.2632)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][580/625]\teta 0:00:01 lr 0.000061\t wd 0.0100\ttime 0.0330 (0.0361)\tloss 0.4209 (0.4028)\tgrad_norm 1.9399 (2.2657)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][590/625]\teta 0:00:01 lr 0.000060\t wd 0.0100\ttime 0.0332 (0.0360)\tloss 0.4001 (0.4025)\tgrad_norm 2.1106 (2.2659)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][600/625]\teta 0:00:00 lr 0.000060\t wd 0.0100\ttime 0.0327 (0.0360)\tloss 0.4956 (0.4034)\tgrad_norm 2.1191 (2.2651)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][610/625]\teta 0:00:00 lr 0.000060\t wd 0.0100\ttime 0.0360 (0.0360)\tloss 0.4641 (0.4035)\tgrad_norm 2.7950 (2.2657)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [85/100][620/625]\teta 0:00:00 lr 0.000060\t wd 0.0100\ttime 0.0326 (0.0360)\tloss 0.3757 (0.4034)\tgrad_norm 2.3105 (2.2653)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 85 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_85.pth saving......\n",
      "./model_save/ckpt_epoch_85.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.5903 (0.5903)\tAcc@1 79.688 (79.688)\tAcc@5 98.438 (98.438)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.6533 (0.5620)\tAcc@1 78.125 (81.108)\tAcc@5 98.438 (99.290)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.4529 (0.5503)\tAcc@1 84.375 (81.771)\tAcc@5 100.000 (99.330)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.5259 (0.5247)\tAcc@1 81.250 (82.863)\tAcc@5 98.438 (99.244)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.6421 (0.5528)\tAcc@1 81.250 (82.241)\tAcc@5 100.000 (99.238)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.6143 (0.5622)\tAcc@1 82.812 (82.322)\tAcc@5 100.000 (99.173)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.3687 (0.5545)\tAcc@1 81.250 (82.044)\tAcc@5 100.000 (99.180)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.6675 (0.5535)\tAcc@1 82.812 (81.866)\tAcc@5 98.438 (99.252)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.3884 (0.5530)\tAcc@1 85.938 (81.809)\tAcc@5 100.000 (99.228)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.5737 (0.5620)\tAcc@1 82.812 (81.645)\tAcc@5 100.000 (99.176)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.8491 (0.5696)\tAcc@1 75.000 (81.296)\tAcc@5 98.438 (99.165)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.5967 (0.5663)\tAcc@1 78.125 (81.433)\tAcc@5 100.000 (99.184)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.4814 (0.5679)\tAcc@1 81.250 (81.431)\tAcc@5 100.000 (99.161)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.5571 (0.5690)\tAcc@1 76.562 (81.167)\tAcc@5 98.438 (99.189)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.8237 (0.5709)\tAcc@1 76.562 (81.150)\tAcc@5 98.438 (99.158)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.8091 (0.5729)\tAcc@1 79.688 (81.074)\tAcc@5 100.000 (99.131)\tMem 455MB\n",
      " * Acc@1 81.000 Acc@5 99.150\n",
      "Accuracy of the network on the 10000 test images: 81.0%\n",
      "Max accuracy: 81.00%\n",
      "Train: [86/100][0/625]\teta 0:00:22 lr 0.000060\t wd 0.0100\ttime 0.0366 (0.0366)\tloss 0.5415 (0.5415)\tgrad_norm 2.1548 (2.1548)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][10/625]\teta 0:00:21 lr 0.000060\t wd 0.0100\ttime 0.0384 (0.0357)\tloss 0.3232 (0.3745)\tgrad_norm 2.7316 (2.1378)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][20/625]\teta 0:00:21 lr 0.000060\t wd 0.0100\ttime 0.0344 (0.0356)\tloss 0.3479 (0.4002)\tgrad_norm 1.6792 (2.1446)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][30/625]\teta 0:00:21 lr 0.000060\t wd 0.0100\ttime 0.0371 (0.0360)\tloss 0.4304 (0.3869)\tgrad_norm 2.6211 (2.1347)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][40/625]\teta 0:00:21 lr 0.000060\t wd 0.0100\ttime 0.0347 (0.0361)\tloss 0.3035 (0.3802)\tgrad_norm 2.2819 (2.1172)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][50/625]\teta 0:00:20 lr 0.000059\t wd 0.0100\ttime 0.0328 (0.0360)\tloss 0.3499 (0.3789)\tgrad_norm 2.0072 (2.1493)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][60/625]\teta 0:00:20 lr 0.000059\t wd 0.0100\ttime 0.0327 (0.0356)\tloss 0.3569 (0.3770)\tgrad_norm 1.9573 (2.1331)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][70/625]\teta 0:00:19 lr 0.000059\t wd 0.0100\ttime 0.0374 (0.0357)\tloss 0.2922 (0.3773)\tgrad_norm 1.6133 (2.1567)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][80/625]\teta 0:00:19 lr 0.000059\t wd 0.0100\ttime 0.0332 (0.0356)\tloss 0.4863 (0.3764)\tgrad_norm 2.2659 (2.1648)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][90/625]\teta 0:00:19 lr 0.000059\t wd 0.0100\ttime 0.0355 (0.0356)\tloss 0.5938 (0.3810)\tgrad_norm 3.1412 (2.1866)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][100/625]\teta 0:00:18 lr 0.000059\t wd 0.0100\ttime 0.0358 (0.0356)\tloss 0.2781 (0.3798)\tgrad_norm 2.1796 (2.1797)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][110/625]\teta 0:00:18 lr 0.000059\t wd 0.0100\ttime 0.0324 (0.0357)\tloss 0.2942 (0.3793)\tgrad_norm 1.5982 (2.1800)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][120/625]\teta 0:00:17 lr 0.000059\t wd 0.0100\ttime 0.0362 (0.0355)\tloss 0.5527 (0.3791)\tgrad_norm 2.2360 (2.1698)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][130/625]\teta 0:00:17 lr 0.000059\t wd 0.0100\ttime 0.0326 (0.0354)\tloss 0.2812 (0.3773)\tgrad_norm 2.0605 (2.1683)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][140/625]\teta 0:00:17 lr 0.000058\t wd 0.0100\ttime 0.0332 (0.0352)\tloss 0.4597 (0.3818)\tgrad_norm 2.1965 (2.1677)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][150/625]\teta 0:00:16 lr 0.000058\t wd 0.0100\ttime 0.0350 (0.0352)\tloss 0.3967 (0.3801)\tgrad_norm 2.1910 (2.1578)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][160/625]\teta 0:00:16 lr 0.000058\t wd 0.0100\ttime 0.0361 (0.0353)\tloss 0.3513 (0.3801)\tgrad_norm 2.3599 (2.1635)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][170/625]\teta 0:00:16 lr 0.000058\t wd 0.0100\ttime 0.0325 (0.0353)\tloss 0.3311 (0.3805)\tgrad_norm 1.8909 (2.1640)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][180/625]\teta 0:00:15 lr 0.000058\t wd 0.0100\ttime 0.0327 (0.0353)\tloss 0.2920 (0.3790)\tgrad_norm 2.6583 (2.1583)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][190/625]\teta 0:00:15 lr 0.000058\t wd 0.0100\ttime 0.0325 (0.0353)\tloss 0.5396 (0.3794)\tgrad_norm 2.5704 (2.1599)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][200/625]\teta 0:00:15 lr 0.000058\t wd 0.0100\ttime 0.0357 (0.0353)\tloss 0.4873 (0.3828)\tgrad_norm 2.3615 (2.1672)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][210/625]\teta 0:00:14 lr 0.000058\t wd 0.0100\ttime 0.0328 (0.0353)\tloss 0.3511 (0.3841)\tgrad_norm 1.6753 (2.1730)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][220/625]\teta 0:00:14 lr 0.000058\t wd 0.0100\ttime 0.0364 (0.0354)\tloss 0.5312 (0.3863)\tgrad_norm 2.7398 (2.1891)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][230/625]\teta 0:00:13 lr 0.000057\t wd 0.0100\ttime 0.0376 (0.0354)\tloss 0.4426 (0.3857)\tgrad_norm 2.3547 (2.1863)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][240/625]\teta 0:00:13 lr 0.000057\t wd 0.0100\ttime 0.0328 (0.0355)\tloss 0.6470 (0.3855)\tgrad_norm 2.9215 (2.1904)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][250/625]\teta 0:00:13 lr 0.000057\t wd 0.0100\ttime 0.0386 (0.0355)\tloss 0.4023 (0.3864)\tgrad_norm 2.4551 (2.1956)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][260/625]\teta 0:00:12 lr 0.000057\t wd 0.0100\ttime 0.0361 (0.0356)\tloss 0.3730 (0.3862)\tgrad_norm 2.8645 (2.1937)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][270/625]\teta 0:00:12 lr 0.000057\t wd 0.0100\ttime 0.0361 (0.0356)\tloss 0.3506 (0.3847)\tgrad_norm 1.6904 (2.1898)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][280/625]\teta 0:00:12 lr 0.000057\t wd 0.0100\ttime 0.0357 (0.0357)\tloss 0.4517 (0.3837)\tgrad_norm 2.9335 (2.1886)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][290/625]\teta 0:00:11 lr 0.000057\t wd 0.0100\ttime 0.0358 (0.0357)\tloss 0.3674 (0.3849)\tgrad_norm 2.1209 (2.1961)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][300/625]\teta 0:00:11 lr 0.000057\t wd 0.0100\ttime 0.0343 (0.0357)\tloss 0.2820 (0.3849)\tgrad_norm 1.7110 (2.1953)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][310/625]\teta 0:00:11 lr 0.000057\t wd 0.0100\ttime 0.0355 (0.0357)\tloss 0.5034 (0.3871)\tgrad_norm 2.5687 (2.2016)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][320/625]\teta 0:00:10 lr 0.000056\t wd 0.0100\ttime 0.0342 (0.0357)\tloss 0.1880 (0.3876)\tgrad_norm 1.3122 (2.2016)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][330/625]\teta 0:00:10 lr 0.000056\t wd 0.0100\ttime 0.0343 (0.0357)\tloss 0.2634 (0.3882)\tgrad_norm 1.8204 (2.2068)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][340/625]\teta 0:00:10 lr 0.000056\t wd 0.0100\ttime 0.0359 (0.0357)\tloss 0.4819 (0.3882)\tgrad_norm 3.0392 (2.2131)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][350/625]\teta 0:00:09 lr 0.000056\t wd 0.0100\ttime 0.0323 (0.0357)\tloss 0.4666 (0.3892)\tgrad_norm 2.6929 (2.2209)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][360/625]\teta 0:00:09 lr 0.000056\t wd 0.0100\ttime 0.0323 (0.0356)\tloss 0.2279 (0.3912)\tgrad_norm 2.4180 (2.2270)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][370/625]\teta 0:00:09 lr 0.000056\t wd 0.0100\ttime 0.0348 (0.0355)\tloss 0.3367 (0.3904)\tgrad_norm 1.8803 (2.2286)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][380/625]\teta 0:00:08 lr 0.000056\t wd 0.0100\ttime 0.0360 (0.0356)\tloss 0.3176 (0.3897)\tgrad_norm 1.9495 (2.2313)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][390/625]\teta 0:00:08 lr 0.000056\t wd 0.0100\ttime 0.0356 (0.0356)\tloss 0.5000 (0.3917)\tgrad_norm 3.1716 (2.2450)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][400/625]\teta 0:00:08 lr 0.000056\t wd 0.0100\ttime 0.0356 (0.0356)\tloss 0.2686 (0.3922)\tgrad_norm 1.8788 (2.2432)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][410/625]\teta 0:00:07 lr 0.000056\t wd 0.0100\ttime 0.0354 (0.0356)\tloss 0.4312 (0.3937)\tgrad_norm 3.3927 (2.2514)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][420/625]\teta 0:00:07 lr 0.000055\t wd 0.0100\ttime 0.0356 (0.0356)\tloss 0.4158 (0.3945)\tgrad_norm 2.2347 (2.2551)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][430/625]\teta 0:00:06 lr 0.000055\t wd 0.0100\ttime 0.0325 (0.0357)\tloss 0.4688 (0.3950)\tgrad_norm 2.6685 (2.2567)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][440/625]\teta 0:00:06 lr 0.000055\t wd 0.0100\ttime 0.0384 (0.0356)\tloss 0.4885 (0.3949)\tgrad_norm 2.2514 (2.2566)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][450/625]\teta 0:00:06 lr 0.000055\t wd 0.0100\ttime 0.0328 (0.0356)\tloss 0.2913 (0.3941)\tgrad_norm 2.3435 (2.2542)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][460/625]\teta 0:00:05 lr 0.000055\t wd 0.0100\ttime 0.0396 (0.0356)\tloss 0.3428 (0.3939)\tgrad_norm 3.0397 (2.2543)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][470/625]\teta 0:00:05 lr 0.000055\t wd 0.0100\ttime 0.0354 (0.0357)\tloss 0.4429 (0.3944)\tgrad_norm 3.3015 (2.2575)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][480/625]\teta 0:00:05 lr 0.000055\t wd 0.0100\ttime 0.0348 (0.0357)\tloss 0.3416 (0.3938)\tgrad_norm 2.1825 (2.2534)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][490/625]\teta 0:00:04 lr 0.000055\t wd 0.0100\ttime 0.0401 (0.0356)\tloss 0.3298 (0.3936)\tgrad_norm 2.3219 (2.2570)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][500/625]\teta 0:00:04 lr 0.000055\t wd 0.0100\ttime 0.0325 (0.0357)\tloss 0.3298 (0.3930)\tgrad_norm 2.5477 (2.2555)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][510/625]\teta 0:00:04 lr 0.000054\t wd 0.0100\ttime 0.0327 (0.0357)\tloss 0.2343 (0.3925)\tgrad_norm 1.9515 (2.2537)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][520/625]\teta 0:00:03 lr 0.000054\t wd 0.0100\ttime 0.0349 (0.0357)\tloss 0.7241 (0.3933)\tgrad_norm 3.2043 (2.2553)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][530/625]\teta 0:00:03 lr 0.000054\t wd 0.0100\ttime 0.0350 (0.0357)\tloss 0.3245 (0.3933)\tgrad_norm 2.5687 (2.2553)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][540/625]\teta 0:00:03 lr 0.000054\t wd 0.0100\ttime 0.0395 (0.0356)\tloss 0.3164 (0.3936)\tgrad_norm 2.4691 (2.2542)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][550/625]\teta 0:00:02 lr 0.000054\t wd 0.0100\ttime 0.0355 (0.0357)\tloss 0.1914 (0.3937)\tgrad_norm 1.8888 (2.2551)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][560/625]\teta 0:00:02 lr 0.000054\t wd 0.0100\ttime 0.0396 (0.0356)\tloss 0.4661 (0.3939)\tgrad_norm 2.0976 (2.2553)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][570/625]\teta 0:00:01 lr 0.000054\t wd 0.0100\ttime 0.0365 (0.0357)\tloss 0.3423 (0.3939)\tgrad_norm 1.7754 (2.2529)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][580/625]\teta 0:00:01 lr 0.000054\t wd 0.0100\ttime 0.0328 (0.0357)\tloss 0.3625 (0.3934)\tgrad_norm 2.0097 (2.2504)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][590/625]\teta 0:00:01 lr 0.000054\t wd 0.0100\ttime 0.0325 (0.0357)\tloss 0.3857 (0.3936)\tgrad_norm 1.8698 (2.2505)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][600/625]\teta 0:00:00 lr 0.000053\t wd 0.0100\ttime 0.0332 (0.0357)\tloss 0.3933 (0.3941)\tgrad_norm 2.8192 (2.2539)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][610/625]\teta 0:00:00 lr 0.000053\t wd 0.0100\ttime 0.0366 (0.0357)\tloss 0.4233 (0.3944)\tgrad_norm 2.0770 (2.2527)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [86/100][620/625]\teta 0:00:00 lr 0.000053\t wd 0.0100\ttime 0.0371 (0.0357)\tloss 0.5171 (0.3945)\tgrad_norm 1.8953 (2.2534)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 86 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_86.pth saving......\n",
      "./model_save/ckpt_epoch_86.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.5078 (0.5078)\tAcc@1 84.375 (84.375)\tAcc@5 100.000 (100.000)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.4990 (0.5389)\tAcc@1 79.688 (82.386)\tAcc@5 100.000 (98.864)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.6885 (0.5788)\tAcc@1 75.000 (81.176)\tAcc@5 98.438 (98.958)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.4805 (0.5789)\tAcc@1 84.375 (81.250)\tAcc@5 98.438 (98.992)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.8931 (0.5841)\tAcc@1 70.312 (80.678)\tAcc@5 98.438 (98.971)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.4187 (0.5763)\tAcc@1 82.812 (80.913)\tAcc@5 100.000 (98.989)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.8501 (0.5865)\tAcc@1 73.438 (80.686)\tAcc@5 98.438 (99.027)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.5269 (0.5781)\tAcc@1 76.562 (80.876)\tAcc@5 96.875 (99.054)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.4468 (0.5688)\tAcc@1 82.812 (81.173)\tAcc@5 100.000 (99.055)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.4888 (0.5681)\tAcc@1 84.375 (80.992)\tAcc@5 100.000 (99.124)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.5161 (0.5657)\tAcc@1 82.812 (81.018)\tAcc@5 100.000 (99.118)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.4526 (0.5659)\tAcc@1 82.812 (81.039)\tAcc@5 100.000 (99.099)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.7139 (0.5653)\tAcc@1 75.000 (81.095)\tAcc@5 98.438 (99.083)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.4766 (0.5664)\tAcc@1 81.250 (81.047)\tAcc@5 100.000 (99.058)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.6318 (0.5661)\tAcc@1 81.250 (81.161)\tAcc@5 96.875 (99.025)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.8169 (0.5680)\tAcc@1 75.000 (81.033)\tAcc@5 95.312 (99.027)\tMem 455MB\n",
      " * Acc@1 81.090 Acc@5 99.030\n",
      "Accuracy of the network on the 10000 test images: 81.1%\n",
      "Max accuracy: 81.09%\n",
      "Train: [87/100][0/625]\teta 0:00:25 lr 0.000053\t wd 0.0100\ttime 0.0402 (0.0402)\tloss 0.3464 (0.3464)\tgrad_norm 2.3161 (2.3161)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [87/100][10/625]\teta 0:00:21 lr 0.000053\t wd 0.0100\ttime 0.0330 (0.0348)\tloss 0.4316 (0.3945)\tgrad_norm 2.2113 (2.2447)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [87/100][20/625]\teta 0:00:21 lr 0.000053\t wd 0.0100\ttime 0.0393 (0.0362)\tloss 0.3062 (0.3682)\tgrad_norm 1.6998 (2.1625)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [87/100][30/625]\teta 0:00:21 lr 0.000053\t wd 0.0100\ttime 0.0353 (0.0365)\tloss 0.3252 (0.3822)\tgrad_norm 2.5324 (2.1618)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [87/100][40/625]\teta 0:00:21 lr 0.000053\t wd 0.0100\ttime 0.0395 (0.0368)\tloss 0.4211 (0.3817)\tgrad_norm 2.4771 (2.1873)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [87/100][50/625]\teta 0:00:21 lr 0.000053\t wd 0.0100\ttime 0.0354 (0.0370)\tloss 0.4360 (0.3841)\tgrad_norm 1.9945 (2.1746)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [87/100][60/625]\teta 0:00:20 lr 0.000053\t wd 0.0100\ttime 0.0332 (0.0366)\tloss 0.3984 (0.3885)\tgrad_norm 1.9931 (2.1769)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [87/100][70/625]\teta 0:00:20 lr 0.000052\t wd 0.0100\ttime 0.0322 (0.0365)\tloss 0.3242 (0.3895)\tgrad_norm 2.1033 (2.1902)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [87/100][80/625]\teta 0:00:19 lr 0.000052\t wd 0.0100\ttime 0.0396 (0.0364)\tloss 0.2710 (0.3840)\tgrad_norm 1.5465 (2.1990)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [87/100][90/625]\teta 0:00:19 lr 0.000052\t wd 0.0100\ttime 0.0327 (0.0363)\tloss 0.5498 (0.3812)\tgrad_norm 2.3367 (2.1915)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [87/100][100/625]\teta 0:00:19 lr 0.000052\t wd 0.0100\ttime 0.0357 (0.0363)\tloss 0.5630 (0.3844)\tgrad_norm 2.2223 (2.1798)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [87/100][110/625]\teta 0:00:18 lr 0.000052\t wd 0.0100\ttime 0.0324 (0.0362)\tloss 0.6006 (0.3859)\tgrad_norm 2.5454 (2.1967)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [87/100][120/625]\teta 0:00:18 lr 0.000052\t wd 0.0100\ttime 0.0356 (0.0363)\tloss 0.4751 (0.3867)\tgrad_norm 2.2915 (2.1900)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [87/100][130/625]\teta 0:00:17 lr 0.000052\t wd 0.0100\ttime 0.0331 (0.0362)\tloss 0.2617 (0.3824)\tgrad_norm 2.2380 (2.1884)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [87/100][140/625]\teta 0:00:17 lr 0.000052\t wd 0.0100\ttime 0.0326 (0.0361)\tloss 0.3884 (0.3816)\tgrad_norm 2.0053 (2.1917)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [87/100][150/625]\teta 0:00:17 lr 0.000052\t wd 0.0100\ttime 0.0333 (0.0361)\tloss 0.2839 (0.3839)\tgrad_norm 2.0342 (2.2089)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [87/100][160/625]\teta 0:00:16 lr 0.000052\t wd 0.0100\ttime 0.0326 (0.0360)\tloss 0.4573 (0.3828)\tgrad_norm 2.4993 (2.2174)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [87/100][170/625]\teta 0:00:16 lr 0.000051\t wd 0.0100\ttime 0.0328 (0.0360)\tloss 0.2754 (0.3828)\tgrad_norm 1.9267 (2.2188)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [87/100][180/625]\teta 0:00:15 lr 0.000051\t wd 0.0100\ttime 0.0325 (0.0359)\tloss 0.4731 (0.3803)\tgrad_norm 2.0186 (2.2034)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [87/100][190/625]\teta 0:00:15 lr 0.000051\t wd 0.0100\ttime 0.0388 (0.0359)\tloss 0.4600 (0.3810)\tgrad_norm 2.4137 (2.2037)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [87/100][200/625]\teta 0:00:15 lr 0.000051\t wd 0.0100\ttime 0.0325 (0.0359)\tloss 0.4592 (0.3803)\tgrad_norm 2.1414 (2.1894)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [87/100][210/625]\teta 0:00:14 lr 0.000051\t wd 0.0100\ttime 0.0330 (0.0358)\tloss 0.4438 (0.3802)\tgrad_norm 2.2161 (2.1916)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [87/100][220/625]\teta 0:00:14 lr 0.000051\t wd 0.0100\ttime 0.0357 (0.0359)\tloss 0.4893 (0.3793)\tgrad_norm 1.8593 (2.1841)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [87/100][230/625]\teta 0:00:14 lr 0.000051\t wd 0.0100\ttime 0.0325 (0.0359)\tloss 0.2218 (0.3795)\tgrad_norm 1.3732 (2.1874)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [87/100][240/625]\teta 0:00:13 lr 0.000051\t wd 0.0100\ttime 0.0329 (0.0359)\tloss 0.5942 (0.3812)\tgrad_norm 2.9963 (2.1969)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [87/100][250/625]\teta 0:00:13 lr 0.000051\t wd 0.0100\ttime 0.0392 (0.0359)\tloss 0.5044 (0.3812)\tgrad_norm 2.8320 (2.1955)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [87/100][260/625]\teta 0:00:13 lr 0.000051\t wd 0.0100\ttime 0.0359 (0.0359)\tloss 0.2253 (0.3828)\tgrad_norm 1.8345 (2.1955)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [87/100][270/625]\teta 0:00:12 lr 0.000050\t wd 0.0100\ttime 0.0354 (0.0358)\tloss 0.4490 (0.3845)\tgrad_norm 2.5462 (2.1997)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [87/100][280/625]\teta 0:00:12 lr 0.000050\t wd 0.0100\ttime 0.0379 (0.0358)\tloss 0.2998 (0.3840)\tgrad_norm 2.5845 (2.1995)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [87/100][290/625]\teta 0:00:12 lr 0.000050\t wd 0.0100\ttime 0.0330 (0.0358)\tloss 0.4185 (0.3855)\tgrad_norm 2.5542 (2.2026)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [87/100][300/625]\teta 0:00:11 lr 0.000050\t wd 0.0100\ttime 0.0355 (0.0359)\tloss 0.2439 (0.3837)\tgrad_norm 1.4486 (2.1956)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [87/100][310/625]\teta 0:00:11 lr 0.000050\t wd 0.0100\ttime 0.0372 (0.0359)\tloss 0.5142 (0.3848)\tgrad_norm 2.6654 (2.2011)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [87/100][320/625]\teta 0:00:10 lr 0.000050\t wd 0.0100\ttime 0.0395 (0.0359)\tloss 0.4111 (0.3849)\tgrad_norm 1.9375 (2.1997)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [87/100][330/625]\teta 0:00:10 lr 0.000050\t wd 0.0100\ttime 0.0328 (0.0358)\tloss 0.3091 (0.3841)\tgrad_norm 1.4008 (2.1943)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [87/100][340/625]\teta 0:00:10 lr 0.000050\t wd 0.0100\ttime 0.0322 (0.0358)\tloss 0.5488 (0.3834)\tgrad_norm 2.3941 (2.1907)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [87/100][350/625]\teta 0:00:09 lr 0.000050\t wd 0.0100\ttime 0.0391 (0.0358)\tloss 0.3564 (0.3823)\tgrad_norm 2.1626 (2.1892)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [87/100][360/625]\teta 0:00:09 lr 0.000050\t wd 0.0100\ttime 0.0388 (0.0358)\tloss 0.3264 (0.3820)\tgrad_norm 2.1991 (2.1904)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [87/100][370/625]\teta 0:00:09 lr 0.000049\t wd 0.0100\ttime 0.0327 (0.0358)\tloss 0.3623 (0.3835)\tgrad_norm 2.2727 (2.1939)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [87/100][380/625]\teta 0:00:08 lr 0.000049\t wd 0.0100\ttime 0.0394 (0.0358)\tloss 0.5513 (0.3843)\tgrad_norm 2.7576 (2.1978)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [87/100][390/625]\teta 0:00:08 lr 0.000049\t wd 0.0100\ttime 0.0329 (0.0358)\tloss 0.3845 (0.3846)\tgrad_norm 1.6415 (2.1951)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [87/100][400/625]\teta 0:00:08 lr 0.000049\t wd 0.0100\ttime 0.0284 (0.0358)\tloss 0.4016 (0.3850)\tgrad_norm nan (nan)\tloss_scale 32768.0000 (32849.7157)\tmem 455MB\n",
      "Train: [87/100][410/625]\teta 0:00:07 lr 0.000049\t wd 0.0100\ttime 0.0380 (0.0358)\tloss 0.2979 (0.3850)\tgrad_norm 1.4460 (nan)\tloss_scale 32768.0000 (32847.7275)\tmem 455MB\n",
      "Train: [87/100][420/625]\teta 0:00:07 lr 0.000049\t wd 0.0100\ttime 0.0329 (0.0358)\tloss 0.3608 (0.3856)\tgrad_norm 2.5017 (nan)\tloss_scale 32768.0000 (32845.8337)\tmem 455MB\n",
      "Train: [87/100][430/625]\teta 0:00:06 lr 0.000049\t wd 0.0100\ttime 0.0327 (0.0357)\tloss 0.4038 (0.3852)\tgrad_norm 2.0500 (nan)\tloss_scale 32768.0000 (32844.0278)\tmem 455MB\n",
      "Train: [87/100][440/625]\teta 0:00:06 lr 0.000049\t wd 0.0100\ttime 0.0382 (0.0357)\tloss 0.3970 (0.3865)\tgrad_norm 1.7202 (nan)\tloss_scale 32768.0000 (32842.3039)\tmem 455MB\n",
      "Train: [87/100][450/625]\teta 0:00:06 lr 0.000049\t wd 0.0100\ttime 0.0327 (0.0358)\tloss 0.3977 (0.3863)\tgrad_norm 2.1659 (nan)\tloss_scale 32768.0000 (32840.6563)\tmem 455MB\n",
      "Train: [87/100][460/625]\teta 0:00:05 lr 0.000049\t wd 0.0100\ttime 0.0356 (0.0358)\tloss 0.4348 (0.3867)\tgrad_norm 3.0242 (nan)\tloss_scale 32768.0000 (32839.0803)\tmem 455MB\n",
      "Train: [87/100][470/625]\teta 0:00:05 lr 0.000048\t wd 0.0100\ttime 0.0327 (0.0358)\tloss 0.3604 (0.3877)\tgrad_norm 1.6164 (nan)\tloss_scale 32768.0000 (32837.5711)\tmem 455MB\n",
      "Train: [87/100][480/625]\teta 0:00:05 lr 0.000048\t wd 0.0100\ttime 0.0327 (0.0357)\tloss 0.2391 (0.3871)\tgrad_norm 1.7099 (nan)\tloss_scale 32768.0000 (32836.1247)\tmem 455MB\n",
      "Train: [87/100][490/625]\teta 0:00:04 lr 0.000048\t wd 0.0100\ttime 0.0358 (0.0357)\tloss 0.5142 (0.3881)\tgrad_norm 3.5606 (nan)\tloss_scale 32768.0000 (32834.7373)\tmem 455MB\n",
      "Train: [87/100][500/625]\teta 0:00:04 lr 0.000048\t wd 0.0100\ttime 0.0356 (0.0357)\tloss 0.3875 (0.3882)\tgrad_norm 1.8950 (nan)\tloss_scale 32768.0000 (32833.4052)\tmem 455MB\n",
      "Train: [87/100][510/625]\teta 0:00:04 lr 0.000048\t wd 0.0100\ttime 0.0368 (0.0357)\tloss 0.4731 (0.3871)\tgrad_norm 2.5974 (nan)\tloss_scale 32768.0000 (32832.1252)\tmem 455MB\n",
      "Train: [87/100][520/625]\teta 0:00:03 lr 0.000048\t wd 0.0100\ttime 0.0335 (0.0357)\tloss 0.2388 (0.3870)\tgrad_norm 1.9558 (nan)\tloss_scale 32768.0000 (32830.8944)\tmem 455MB\n",
      "Train: [87/100][530/625]\teta 0:00:03 lr 0.000048\t wd 0.0100\ttime 0.0334 (0.0357)\tloss 0.3245 (0.3867)\tgrad_norm 2.1514 (nan)\tloss_scale 32768.0000 (32829.7100)\tmem 455MB\n",
      "Train: [87/100][540/625]\teta 0:00:03 lr 0.000048\t wd 0.0100\ttime 0.0386 (0.0357)\tloss 0.4500 (0.3874)\tgrad_norm 3.2398 (nan)\tloss_scale 32768.0000 (32828.5693)\tmem 455MB\n",
      "Train: [87/100][550/625]\teta 0:00:02 lr 0.000048\t wd 0.0100\ttime 0.0341 (0.0358)\tloss 0.4121 (0.3881)\tgrad_norm 2.3170 (nan)\tloss_scale 32768.0000 (32827.4701)\tmem 455MB\n",
      "Train: [87/100][560/625]\teta 0:00:02 lr 0.000048\t wd 0.0100\ttime 0.0330 (0.0358)\tloss 0.3857 (0.3888)\tgrad_norm 1.7472 (nan)\tloss_scale 32768.0000 (32826.4100)\tmem 455MB\n",
      "Train: [87/100][570/625]\teta 0:00:01 lr 0.000047\t wd 0.0100\ttime 0.0400 (0.0358)\tloss 0.3044 (0.3880)\tgrad_norm 1.9821 (nan)\tloss_scale 32768.0000 (32825.3870)\tmem 455MB\n",
      "Train: [87/100][580/625]\teta 0:00:01 lr 0.000047\t wd 0.0100\ttime 0.0364 (0.0358)\tloss 0.3127 (0.3874)\tgrad_norm 1.9187 (nan)\tloss_scale 32768.0000 (32824.3993)\tmem 455MB\n",
      "Train: [87/100][590/625]\teta 0:00:01 lr 0.000047\t wd 0.0100\ttime 0.0363 (0.0358)\tloss 0.4644 (0.3881)\tgrad_norm 2.0284 (nan)\tloss_scale 32768.0000 (32823.4450)\tmem 455MB\n",
      "Train: [87/100][600/625]\teta 0:00:00 lr 0.000047\t wd 0.0100\ttime 0.0326 (0.0358)\tloss 0.3623 (0.3883)\tgrad_norm 2.4623 (nan)\tloss_scale 32768.0000 (32822.5225)\tmem 455MB\n",
      "Train: [87/100][610/625]\teta 0:00:00 lr 0.000047\t wd 0.0100\ttime 0.0347 (0.0357)\tloss 0.3381 (0.3885)\tgrad_norm 2.1720 (nan)\tloss_scale 32768.0000 (32821.6301)\tmem 455MB\n",
      "Train: [87/100][620/625]\teta 0:00:00 lr 0.000047\t wd 0.0100\ttime 0.0320 (0.0357)\tloss 0.4485 (0.3883)\tgrad_norm 2.2467 (nan)\tloss_scale 32768.0000 (32820.7665)\tmem 455MB\n",
      "EPOCH 87 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_87.pth saving......\n",
      "./model_save/ckpt_epoch_87.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.8765 (0.8765)\tAcc@1 73.438 (73.438)\tAcc@5 96.875 (96.875)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.4565 (0.6040)\tAcc@1 84.375 (80.114)\tAcc@5 100.000 (98.153)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.4343 (0.5434)\tAcc@1 89.062 (82.664)\tAcc@5 98.438 (98.512)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.5820 (0.5351)\tAcc@1 78.125 (82.409)\tAcc@5 100.000 (98.891)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.5127 (0.5472)\tAcc@1 79.688 (81.784)\tAcc@5 100.000 (99.009)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.5532 (0.5398)\tAcc@1 75.000 (81.924)\tAcc@5 100.000 (99.081)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.3391 (0.5374)\tAcc@1 85.938 (81.993)\tAcc@5 100.000 (99.129)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.6777 (0.5428)\tAcc@1 79.688 (81.866)\tAcc@5 98.438 (99.076)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.4333 (0.5499)\tAcc@1 82.812 (81.752)\tAcc@5 100.000 (99.035)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.6118 (0.5627)\tAcc@1 81.250 (81.370)\tAcc@5 96.875 (99.004)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.7920 (0.5652)\tAcc@1 73.438 (81.204)\tAcc@5 100.000 (99.072)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.5068 (0.5623)\tAcc@1 82.812 (81.334)\tAcc@5 100.000 (99.127)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.5542 (0.5590)\tAcc@1 84.375 (81.457)\tAcc@5 98.438 (99.148)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.4744 (0.5591)\tAcc@1 79.688 (81.465)\tAcc@5 100.000 (99.213)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.5029 (0.5599)\tAcc@1 81.250 (81.438)\tAcc@5 98.438 (99.180)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.6836 (0.5613)\tAcc@1 79.688 (81.364)\tAcc@5 96.875 (99.183)\tMem 455MB\n",
      " * Acc@1 81.240 Acc@5 99.200\n",
      "Accuracy of the network on the 10000 test images: 81.2%\n",
      "Max accuracy: 81.24%\n",
      "Train: [88/100][0/625]\teta 0:00:23 lr 0.000047\t wd 0.0100\ttime 0.0380 (0.0380)\tloss 0.4553 (0.4553)\tgrad_norm 2.4014 (2.4014)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][10/625]\teta 0:00:23 lr 0.000047\t wd 0.0100\ttime 0.0399 (0.0379)\tloss 0.5586 (0.3462)\tgrad_norm 2.7968 (2.1121)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][20/625]\teta 0:00:22 lr 0.000047\t wd 0.0100\ttime 0.0322 (0.0366)\tloss 0.3403 (0.3751)\tgrad_norm 1.7095 (2.4108)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][30/625]\teta 0:00:21 lr 0.000047\t wd 0.0100\ttime 0.0325 (0.0358)\tloss 0.3655 (0.3797)\tgrad_norm 2.1152 (2.3073)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][40/625]\teta 0:00:20 lr 0.000047\t wd 0.0100\ttime 0.0361 (0.0354)\tloss 0.5718 (0.3820)\tgrad_norm 3.2265 (2.3229)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][50/625]\teta 0:00:20 lr 0.000046\t wd 0.0100\ttime 0.0343 (0.0351)\tloss 0.3552 (0.3768)\tgrad_norm 1.9757 (2.2465)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][60/625]\teta 0:00:20 lr 0.000046\t wd 0.0100\ttime 0.0390 (0.0354)\tloss 0.4458 (0.3860)\tgrad_norm 2.6540 (2.2958)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][70/625]\teta 0:00:19 lr 0.000046\t wd 0.0100\ttime 0.0327 (0.0355)\tloss 0.4729 (0.3879)\tgrad_norm 2.6448 (2.3122)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][80/625]\teta 0:00:19 lr 0.000046\t wd 0.0100\ttime 0.0352 (0.0355)\tloss 0.3257 (0.3842)\tgrad_norm 1.9534 (2.3080)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][90/625]\teta 0:00:18 lr 0.000046\t wd 0.0100\ttime 0.0339 (0.0355)\tloss 0.2240 (0.3810)\tgrad_norm 1.6579 (2.2943)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][100/625]\teta 0:00:18 lr 0.000046\t wd 0.0100\ttime 0.0360 (0.0354)\tloss 0.2842 (0.3796)\tgrad_norm 2.1469 (2.2982)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][110/625]\teta 0:00:18 lr 0.000046\t wd 0.0100\ttime 0.0361 (0.0353)\tloss 0.4065 (0.3802)\tgrad_norm 2.2502 (2.2847)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][120/625]\teta 0:00:17 lr 0.000046\t wd 0.0100\ttime 0.0365 (0.0354)\tloss 0.4812 (0.3770)\tgrad_norm 2.6781 (2.2707)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][130/625]\teta 0:00:17 lr 0.000046\t wd 0.0100\ttime 0.0327 (0.0354)\tloss 0.5356 (0.3768)\tgrad_norm 2.4725 (2.2647)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][140/625]\teta 0:00:17 lr 0.000046\t wd 0.0100\ttime 0.0323 (0.0352)\tloss 0.4521 (0.3767)\tgrad_norm 2.4039 (2.2563)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][150/625]\teta 0:00:16 lr 0.000045\t wd 0.0100\ttime 0.0323 (0.0352)\tloss 0.4333 (0.3774)\tgrad_norm 1.9683 (2.2489)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][160/625]\teta 0:00:16 lr 0.000045\t wd 0.0100\ttime 0.0330 (0.0350)\tloss 0.3545 (0.3768)\tgrad_norm 2.2819 (2.2449)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][170/625]\teta 0:00:15 lr 0.000045\t wd 0.0100\ttime 0.0326 (0.0349)\tloss 0.2622 (0.3795)\tgrad_norm 2.6783 (2.2481)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][180/625]\teta 0:00:15 lr 0.000045\t wd 0.0100\ttime 0.0362 (0.0350)\tloss 0.4172 (0.3825)\tgrad_norm 2.1541 (2.2528)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][190/625]\teta 0:00:15 lr 0.000045\t wd 0.0100\ttime 0.0331 (0.0350)\tloss 0.3674 (0.3824)\tgrad_norm 3.6247 (2.2512)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][200/625]\teta 0:00:14 lr 0.000045\t wd 0.0100\ttime 0.0362 (0.0351)\tloss 0.4194 (0.3810)\tgrad_norm 1.5509 (2.2419)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][210/625]\teta 0:00:14 lr 0.000045\t wd 0.0100\ttime 0.0353 (0.0352)\tloss 0.3965 (0.3825)\tgrad_norm 1.6189 (2.2379)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][220/625]\teta 0:00:14 lr 0.000045\t wd 0.0100\ttime 0.0354 (0.0352)\tloss 0.3137 (0.3820)\tgrad_norm 1.7100 (2.2348)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][230/625]\teta 0:00:13 lr 0.000045\t wd 0.0100\ttime 0.0360 (0.0351)\tloss 0.6753 (0.3824)\tgrad_norm 2.9782 (2.2354)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][240/625]\teta 0:00:13 lr 0.000045\t wd 0.0100\ttime 0.0325 (0.0351)\tloss 0.4387 (0.3820)\tgrad_norm 2.7254 (2.2281)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][250/625]\teta 0:00:13 lr 0.000045\t wd 0.0100\ttime 0.0342 (0.0352)\tloss 0.4250 (0.3812)\tgrad_norm 2.1441 (2.2190)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][260/625]\teta 0:00:12 lr 0.000044\t wd 0.0100\ttime 0.0325 (0.0352)\tloss 0.4844 (0.3810)\tgrad_norm 2.6368 (2.2143)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][270/625]\teta 0:00:12 lr 0.000044\t wd 0.0100\ttime 0.0379 (0.0353)\tloss 0.4160 (0.3820)\tgrad_norm 2.1714 (2.2161)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][280/625]\teta 0:00:12 lr 0.000044\t wd 0.0100\ttime 0.0328 (0.0353)\tloss 0.3616 (0.3810)\tgrad_norm 2.5272 (2.2173)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][290/625]\teta 0:00:11 lr 0.000044\t wd 0.0100\ttime 0.0324 (0.0353)\tloss 0.2281 (0.3802)\tgrad_norm 1.2186 (2.2186)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][300/625]\teta 0:00:11 lr 0.000044\t wd 0.0100\ttime 0.0341 (0.0353)\tloss 0.3472 (0.3823)\tgrad_norm 1.6833 (2.2226)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][310/625]\teta 0:00:11 lr 0.000044\t wd 0.0100\ttime 0.0356 (0.0353)\tloss 0.4270 (0.3824)\tgrad_norm 2.2518 (2.2180)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][320/625]\teta 0:00:10 lr 0.000044\t wd 0.0100\ttime 0.0391 (0.0353)\tloss 0.4038 (0.3815)\tgrad_norm 2.1014 (2.2108)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][330/625]\teta 0:00:10 lr 0.000044\t wd 0.0100\ttime 0.0394 (0.0353)\tloss 0.5894 (0.3816)\tgrad_norm 3.5423 (2.2089)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][340/625]\teta 0:00:10 lr 0.000044\t wd 0.0100\ttime 0.0346 (0.0353)\tloss 0.4624 (0.3821)\tgrad_norm 2.1142 (2.2081)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][350/625]\teta 0:00:09 lr 0.000044\t wd 0.0100\ttime 0.0326 (0.0353)\tloss 0.3711 (0.3819)\tgrad_norm 2.2209 (2.2025)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][360/625]\teta 0:00:09 lr 0.000043\t wd 0.0100\ttime 0.0330 (0.0353)\tloss 0.3928 (0.3815)\tgrad_norm 3.0088 (2.1973)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][370/625]\teta 0:00:08 lr 0.000043\t wd 0.0100\ttime 0.0329 (0.0353)\tloss 0.5195 (0.3823)\tgrad_norm 2.6000 (2.2011)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][380/625]\teta 0:00:08 lr 0.000043\t wd 0.0100\ttime 0.0395 (0.0353)\tloss 0.2529 (0.3828)\tgrad_norm 1.4798 (2.2033)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][390/625]\teta 0:00:08 lr 0.000043\t wd 0.0100\ttime 0.0324 (0.0353)\tloss 0.2893 (0.3820)\tgrad_norm 1.8319 (2.2025)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][400/625]\teta 0:00:07 lr 0.000043\t wd 0.0100\ttime 0.0328 (0.0352)\tloss 0.3806 (0.3819)\tgrad_norm 2.6196 (2.2031)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][410/625]\teta 0:00:07 lr 0.000043\t wd 0.0100\ttime 0.0350 (0.0352)\tloss 0.3230 (0.3827)\tgrad_norm 1.9016 (2.2081)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][420/625]\teta 0:00:07 lr 0.000043\t wd 0.0100\ttime 0.0329 (0.0353)\tloss 0.4861 (0.3836)\tgrad_norm 2.6869 (2.2103)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][430/625]\teta 0:00:06 lr 0.000043\t wd 0.0100\ttime 0.0389 (0.0353)\tloss 0.6177 (0.3848)\tgrad_norm 3.4599 (2.2183)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][440/625]\teta 0:00:06 lr 0.000043\t wd 0.0100\ttime 0.0365 (0.0353)\tloss 0.5112 (0.3857)\tgrad_norm 2.3355 (2.2233)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][450/625]\teta 0:00:06 lr 0.000043\t wd 0.0100\ttime 0.0392 (0.0354)\tloss 0.4089 (0.3847)\tgrad_norm 2.4712 (2.2213)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][460/625]\teta 0:00:05 lr 0.000043\t wd 0.0100\ttime 0.0352 (0.0354)\tloss 0.4204 (0.3852)\tgrad_norm 2.7580 (2.2227)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][470/625]\teta 0:00:05 lr 0.000042\t wd 0.0100\ttime 0.0346 (0.0354)\tloss 0.4712 (0.3862)\tgrad_norm 2.3678 (2.2265)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][480/625]\teta 0:00:05 lr 0.000042\t wd 0.0100\ttime 0.0324 (0.0353)\tloss 0.4922 (0.3868)\tgrad_norm 2.7064 (2.2255)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][490/625]\teta 0:00:04 lr 0.000042\t wd 0.0100\ttime 0.0345 (0.0353)\tloss 0.3801 (0.3867)\tgrad_norm 1.7676 (2.2276)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][500/625]\teta 0:00:04 lr 0.000042\t wd 0.0100\ttime 0.0354 (0.0353)\tloss 0.3796 (0.3871)\tgrad_norm 2.3290 (2.2302)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][510/625]\teta 0:00:04 lr 0.000042\t wd 0.0100\ttime 0.0365 (0.0353)\tloss 0.1761 (0.3865)\tgrad_norm 1.0575 (2.2281)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][520/625]\teta 0:00:03 lr 0.000042\t wd 0.0100\ttime 0.0390 (0.0354)\tloss 0.5078 (0.3864)\tgrad_norm 2.1982 (2.2268)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][530/625]\teta 0:00:03 lr 0.000042\t wd 0.0100\ttime 0.0360 (0.0354)\tloss 0.4404 (0.3867)\tgrad_norm 2.1738 (2.2276)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][540/625]\teta 0:00:03 lr 0.000042\t wd 0.0100\ttime 0.0354 (0.0354)\tloss 0.5317 (0.3869)\tgrad_norm 3.5423 (2.2328)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][550/625]\teta 0:00:02 lr 0.000042\t wd 0.0100\ttime 0.0397 (0.0354)\tloss 0.2334 (0.3871)\tgrad_norm 1.6959 (2.2334)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][560/625]\teta 0:00:02 lr 0.000042\t wd 0.0100\ttime 0.0353 (0.0354)\tloss 0.4417 (0.3873)\tgrad_norm 1.9569 (2.2365)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][570/625]\teta 0:00:01 lr 0.000042\t wd 0.0100\ttime 0.0324 (0.0354)\tloss 0.3997 (0.3871)\tgrad_norm 2.5497 (2.2365)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][580/625]\teta 0:00:01 lr 0.000041\t wd 0.0100\ttime 0.0357 (0.0354)\tloss 0.4253 (0.3873)\tgrad_norm 1.9839 (2.2388)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][590/625]\teta 0:00:01 lr 0.000041\t wd 0.0100\ttime 0.0331 (0.0354)\tloss 0.2788 (0.3876)\tgrad_norm 2.4366 (2.2412)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][600/625]\teta 0:00:00 lr 0.000041\t wd 0.0100\ttime 0.0383 (0.0354)\tloss 0.4238 (0.3887)\tgrad_norm 2.0081 (2.2440)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][610/625]\teta 0:00:00 lr 0.000041\t wd 0.0100\ttime 0.0360 (0.0354)\tloss 0.4392 (0.3889)\tgrad_norm 2.8407 (2.2447)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [88/100][620/625]\teta 0:00:00 lr 0.000041\t wd 0.0100\ttime 0.0324 (0.0355)\tloss 0.3555 (0.3886)\tgrad_norm 2.3722 (2.2439)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 88 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_88.pth saving......\n",
      "./model_save/ckpt_epoch_88.pth saved !!!\n",
      "Test: [0/157]\tTime 0.020 (0.020)\tLoss 0.6079 (0.6079)\tAcc@1 84.375 (84.375)\tAcc@5 96.875 (96.875)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.7827 (0.6308)\tAcc@1 78.125 (82.528)\tAcc@5 98.438 (97.727)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.7515 (0.6255)\tAcc@1 76.562 (81.027)\tAcc@5 100.000 (98.586)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.6963 (0.6009)\tAcc@1 76.562 (81.452)\tAcc@5 100.000 (98.790)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.5840 (0.6057)\tAcc@1 78.125 (80.983)\tAcc@5 98.438 (98.666)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.5615 (0.6093)\tAcc@1 79.688 (80.576)\tAcc@5 100.000 (98.744)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.3503 (0.5955)\tAcc@1 87.500 (80.943)\tAcc@5 100.000 (98.822)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.8921 (0.5975)\tAcc@1 68.750 (80.568)\tAcc@5 100.000 (98.900)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.6934 (0.5854)\tAcc@1 78.125 (80.806)\tAcc@5 98.438 (98.939)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.7466 (0.5873)\tAcc@1 67.188 (80.580)\tAcc@5 100.000 (98.918)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.3506 (0.5813)\tAcc@1 87.500 (80.801)\tAcc@5 98.438 (98.979)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.3530 (0.5792)\tAcc@1 90.625 (80.870)\tAcc@5 98.438 (98.958)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.5923 (0.5726)\tAcc@1 76.562 (81.005)\tAcc@5 100.000 (98.993)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.5728 (0.5713)\tAcc@1 76.562 (81.047)\tAcc@5 100.000 (99.034)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.7153 (0.5736)\tAcc@1 76.562 (81.062)\tAcc@5 95.312 (99.025)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.6436 (0.5715)\tAcc@1 82.812 (81.157)\tAcc@5 98.438 (99.017)\tMem 455MB\n",
      " * Acc@1 81.100 Acc@5 99.030\n",
      "Accuracy of the network on the 10000 test images: 81.1%\n",
      "Max accuracy: 81.24%\n",
      "Train: [89/100][0/625]\teta 0:00:22 lr 0.000041\t wd 0.0100\ttime 0.0357 (0.0357)\tloss 0.5420 (0.5420)\tgrad_norm 3.0096 (3.0096)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][10/625]\teta 0:00:22 lr 0.000041\t wd 0.0100\ttime 0.0361 (0.0360)\tloss 0.4692 (0.4158)\tgrad_norm 2.3236 (2.5323)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][20/625]\teta 0:00:21 lr 0.000041\t wd 0.0100\ttime 0.0330 (0.0356)\tloss 0.4248 (0.4411)\tgrad_norm 2.1461 (2.3724)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][30/625]\teta 0:00:21 lr 0.000041\t wd 0.0100\ttime 0.0354 (0.0355)\tloss 0.4856 (0.4247)\tgrad_norm 2.0688 (2.3374)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][40/625]\teta 0:00:20 lr 0.000041\t wd 0.0100\ttime 0.0324 (0.0352)\tloss 0.2800 (0.4221)\tgrad_norm 1.7283 (2.3142)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][50/625]\teta 0:00:20 lr 0.000041\t wd 0.0100\ttime 0.0324 (0.0354)\tloss 0.2444 (0.4128)\tgrad_norm 1.5986 (2.2945)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][60/625]\teta 0:00:20 lr 0.000041\t wd 0.0100\ttime 0.0395 (0.0358)\tloss 0.5342 (0.4196)\tgrad_norm 2.2482 (2.3349)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][70/625]\teta 0:00:19 lr 0.000040\t wd 0.0100\ttime 0.0355 (0.0357)\tloss 0.3682 (0.4088)\tgrad_norm 1.9322 (2.3203)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][80/625]\teta 0:00:19 lr 0.000040\t wd 0.0100\ttime 0.0324 (0.0358)\tloss 0.2395 (0.4081)\tgrad_norm 2.0286 (2.3261)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][90/625]\teta 0:00:19 lr 0.000040\t wd 0.0100\ttime 0.0395 (0.0358)\tloss 0.4470 (0.4046)\tgrad_norm 2.3570 (2.3186)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][100/625]\teta 0:00:18 lr 0.000040\t wd 0.0100\ttime 0.0355 (0.0359)\tloss 0.3911 (0.4042)\tgrad_norm 1.8663 (2.3305)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][110/625]\teta 0:00:18 lr 0.000040\t wd 0.0100\ttime 0.0381 (0.0358)\tloss 0.4502 (0.4077)\tgrad_norm 2.1819 (2.3287)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][120/625]\teta 0:00:18 lr 0.000040\t wd 0.0100\ttime 0.0324 (0.0359)\tloss 0.3301 (0.4015)\tgrad_norm 1.6758 (2.2908)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][130/625]\teta 0:00:17 lr 0.000040\t wd 0.0100\ttime 0.0358 (0.0358)\tloss 0.3447 (0.4005)\tgrad_norm 2.2247 (2.2945)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][140/625]\teta 0:00:17 lr 0.000040\t wd 0.0100\ttime 0.0326 (0.0358)\tloss 0.3616 (0.4001)\tgrad_norm 1.9944 (2.2969)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][150/625]\teta 0:00:16 lr 0.000040\t wd 0.0100\ttime 0.0361 (0.0358)\tloss 0.3323 (0.3961)\tgrad_norm 2.8855 (2.2910)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][160/625]\teta 0:00:16 lr 0.000040\t wd 0.0100\ttime 0.0331 (0.0358)\tloss 0.4312 (0.3982)\tgrad_norm 2.1410 (2.2912)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][170/625]\teta 0:00:16 lr 0.000040\t wd 0.0100\ttime 0.0324 (0.0358)\tloss 0.4028 (0.4029)\tgrad_norm 2.1796 (2.2958)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][180/625]\teta 0:00:15 lr 0.000039\t wd 0.0100\ttime 0.0357 (0.0357)\tloss 0.2113 (0.4009)\tgrad_norm 1.8282 (2.2880)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][190/625]\teta 0:00:15 lr 0.000039\t wd 0.0100\ttime 0.0325 (0.0357)\tloss 0.3584 (0.4002)\tgrad_norm 2.3039 (2.2919)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][200/625]\teta 0:00:15 lr 0.000039\t wd 0.0100\ttime 0.0332 (0.0357)\tloss 0.3447 (0.3993)\tgrad_norm 1.7202 (2.2835)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][210/625]\teta 0:00:14 lr 0.000039\t wd 0.0100\ttime 0.0325 (0.0356)\tloss 0.2849 (0.3970)\tgrad_norm 1.7394 (2.2866)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][220/625]\teta 0:00:14 lr 0.000039\t wd 0.0100\ttime 0.0324 (0.0356)\tloss 0.3950 (0.3950)\tgrad_norm 2.1052 (2.2759)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][230/625]\teta 0:00:14 lr 0.000039\t wd 0.0100\ttime 0.0358 (0.0356)\tloss 0.2046 (0.3937)\tgrad_norm 1.4531 (2.2678)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][240/625]\teta 0:00:13 lr 0.000039\t wd 0.0100\ttime 0.0361 (0.0356)\tloss 0.3042 (0.3916)\tgrad_norm 2.3834 (2.2756)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][250/625]\teta 0:00:13 lr 0.000039\t wd 0.0100\ttime 0.0372 (0.0357)\tloss 0.3896 (0.3903)\tgrad_norm 1.9429 (2.2658)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][260/625]\teta 0:00:13 lr 0.000039\t wd 0.0100\ttime 0.0352 (0.0357)\tloss 0.3372 (0.3897)\tgrad_norm 1.9478 (2.2640)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][270/625]\teta 0:00:12 lr 0.000039\t wd 0.0100\ttime 0.0356 (0.0357)\tloss 0.3872 (0.3917)\tgrad_norm 2.2115 (2.2626)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][280/625]\teta 0:00:12 lr 0.000039\t wd 0.0100\ttime 0.0325 (0.0357)\tloss 0.4104 (0.3917)\tgrad_norm 2.2593 (2.2653)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][290/625]\teta 0:00:11 lr 0.000039\t wd 0.0100\ttime 0.0328 (0.0356)\tloss 0.3721 (0.3926)\tgrad_norm 2.2236 (2.2679)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][300/625]\teta 0:00:11 lr 0.000038\t wd 0.0100\ttime 0.0324 (0.0356)\tloss 0.4814 (0.3930)\tgrad_norm 2.3318 (2.2716)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][310/625]\teta 0:00:11 lr 0.000038\t wd 0.0100\ttime 0.0352 (0.0355)\tloss 0.3423 (0.3915)\tgrad_norm 2.1322 (2.2682)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][320/625]\teta 0:00:10 lr 0.000038\t wd 0.0100\ttime 0.0325 (0.0355)\tloss 0.3936 (0.3900)\tgrad_norm 2.4422 (2.2617)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][330/625]\teta 0:00:10 lr 0.000038\t wd 0.0100\ttime 0.0397 (0.0356)\tloss 0.3726 (0.3907)\tgrad_norm 2.3542 (2.2692)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][340/625]\teta 0:00:10 lr 0.000038\t wd 0.0100\ttime 0.0390 (0.0356)\tloss 0.4258 (0.3917)\tgrad_norm 2.3469 (2.2744)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][350/625]\teta 0:00:09 lr 0.000038\t wd 0.0100\ttime 0.0397 (0.0356)\tloss 0.3389 (0.3919)\tgrad_norm 1.6632 (2.2664)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][360/625]\teta 0:00:09 lr 0.000038\t wd 0.0100\ttime 0.0404 (0.0356)\tloss 0.3215 (0.3908)\tgrad_norm 2.1675 (2.2636)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][370/625]\teta 0:00:09 lr 0.000038\t wd 0.0100\ttime 0.0353 (0.0356)\tloss 0.2830 (0.3916)\tgrad_norm 1.9597 (2.2655)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][380/625]\teta 0:00:08 lr 0.000038\t wd 0.0100\ttime 0.0360 (0.0356)\tloss 0.3628 (0.3909)\tgrad_norm 2.2290 (2.2652)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][390/625]\teta 0:00:08 lr 0.000038\t wd 0.0100\ttime 0.0328 (0.0356)\tloss 0.3689 (0.3920)\tgrad_norm 2.6021 (2.2757)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][400/625]\teta 0:00:08 lr 0.000038\t wd 0.0100\ttime 0.0328 (0.0356)\tloss 0.3147 (0.3903)\tgrad_norm 3.5738 (2.2748)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][410/625]\teta 0:00:07 lr 0.000038\t wd 0.0100\ttime 0.0360 (0.0356)\tloss 0.2793 (0.3887)\tgrad_norm 2.5851 (2.2721)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][420/625]\teta 0:00:07 lr 0.000037\t wd 0.0100\ttime 0.0388 (0.0356)\tloss 0.3921 (0.3886)\tgrad_norm 2.0755 (2.2731)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][430/625]\teta 0:00:06 lr 0.000037\t wd 0.0100\ttime 0.0334 (0.0356)\tloss 0.2303 (0.3886)\tgrad_norm 2.2292 (2.2722)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][440/625]\teta 0:00:06 lr 0.000037\t wd 0.0100\ttime 0.0362 (0.0356)\tloss 0.4321 (0.3872)\tgrad_norm 1.9450 (2.2699)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][450/625]\teta 0:00:06 lr 0.000037\t wd 0.0100\ttime 0.0333 (0.0357)\tloss 0.4087 (0.3880)\tgrad_norm 2.3917 (2.2711)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][460/625]\teta 0:00:05 lr 0.000037\t wd 0.0100\ttime 0.0354 (0.0356)\tloss 0.3843 (0.3881)\tgrad_norm 2.1436 (2.2713)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][470/625]\teta 0:00:05 lr 0.000037\t wd 0.0100\ttime 0.0389 (0.0357)\tloss 0.4172 (0.3877)\tgrad_norm 2.0329 (2.2685)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][480/625]\teta 0:00:05 lr 0.000037\t wd 0.0100\ttime 0.0347 (0.0357)\tloss 0.3838 (0.3879)\tgrad_norm 2.2573 (2.2683)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][490/625]\teta 0:00:04 lr 0.000037\t wd 0.0100\ttime 0.0356 (0.0357)\tloss 0.3403 (0.3871)\tgrad_norm 1.9906 (2.2646)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][500/625]\teta 0:00:04 lr 0.000037\t wd 0.0100\ttime 0.0358 (0.0356)\tloss 0.6484 (0.3877)\tgrad_norm 3.4202 (2.2686)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][510/625]\teta 0:00:04 lr 0.000037\t wd 0.0100\ttime 0.0324 (0.0356)\tloss 0.2301 (0.3887)\tgrad_norm 2.0870 (2.2707)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][520/625]\teta 0:00:03 lr 0.000037\t wd 0.0100\ttime 0.0324 (0.0356)\tloss 0.4438 (0.3888)\tgrad_norm 2.4542 (2.2663)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][530/625]\teta 0:00:03 lr 0.000037\t wd 0.0100\ttime 0.0390 (0.0356)\tloss 0.2783 (0.3876)\tgrad_norm 1.7555 (2.2631)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][540/625]\teta 0:00:03 lr 0.000036\t wd 0.0100\ttime 0.0354 (0.0356)\tloss 0.4805 (0.3879)\tgrad_norm 2.5760 (2.2634)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][550/625]\teta 0:00:02 lr 0.000036\t wd 0.0100\ttime 0.0326 (0.0356)\tloss 0.3013 (0.3879)\tgrad_norm 1.8288 (2.2669)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][560/625]\teta 0:00:02 lr 0.000036\t wd 0.0100\ttime 0.0388 (0.0357)\tloss 0.4048 (0.3881)\tgrad_norm 2.2352 (2.2634)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][570/625]\teta 0:00:01 lr 0.000036\t wd 0.0100\ttime 0.0375 (0.0357)\tloss 0.2401 (0.3875)\tgrad_norm 1.5388 (2.2575)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][580/625]\teta 0:00:01 lr 0.000036\t wd 0.0100\ttime 0.0327 (0.0357)\tloss 0.4980 (0.3875)\tgrad_norm 2.8888 (2.2576)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][590/625]\teta 0:00:01 lr 0.000036\t wd 0.0100\ttime 0.0360 (0.0357)\tloss 0.4321 (0.3873)\tgrad_norm 2.2386 (2.2550)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][600/625]\teta 0:00:00 lr 0.000036\t wd 0.0100\ttime 0.0324 (0.0357)\tloss 0.3503 (0.3879)\tgrad_norm 2.9486 (2.2578)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][610/625]\teta 0:00:00 lr 0.000036\t wd 0.0100\ttime 0.0365 (0.0357)\tloss 0.4536 (0.3879)\tgrad_norm 2.2709 (2.2609)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [89/100][620/625]\teta 0:00:00 lr 0.000036\t wd 0.0100\ttime 0.0337 (0.0357)\tloss 0.5146 (0.3885)\tgrad_norm 2.1665 (2.2627)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 89 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_89.pth saving......\n",
      "./model_save/ckpt_epoch_89.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.6938 (0.6938)\tAcc@1 78.125 (78.125)\tAcc@5 98.438 (98.438)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.5420 (0.5259)\tAcc@1 79.688 (81.534)\tAcc@5 100.000 (99.148)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.3643 (0.5209)\tAcc@1 87.500 (81.845)\tAcc@5 100.000 (99.256)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.5732 (0.5683)\tAcc@1 81.250 (80.696)\tAcc@5 100.000 (99.093)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.5566 (0.5644)\tAcc@1 79.688 (80.983)\tAcc@5 100.000 (99.009)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.4224 (0.5628)\tAcc@1 79.688 (80.821)\tAcc@5 100.000 (98.989)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.4009 (0.5819)\tAcc@1 84.375 (80.405)\tAcc@5 100.000 (98.924)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.6001 (0.5807)\tAcc@1 79.688 (80.546)\tAcc@5 98.438 (98.944)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.6460 (0.5874)\tAcc@1 75.000 (80.459)\tAcc@5 98.438 (98.900)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.4299 (0.5823)\tAcc@1 84.375 (80.495)\tAcc@5 100.000 (98.850)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.3611 (0.5824)\tAcc@1 85.938 (80.399)\tAcc@5 100.000 (98.886)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.5269 (0.5833)\tAcc@1 79.688 (80.448)\tAcc@5 100.000 (98.874)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.9106 (0.5776)\tAcc@1 70.312 (80.579)\tAcc@5 98.438 (98.928)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.7959 (0.5772)\tAcc@1 70.312 (80.558)\tAcc@5 98.438 (98.927)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.3376 (0.5718)\tAcc@1 85.938 (80.652)\tAcc@5 100.000 (98.992)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.5171 (0.5644)\tAcc@1 84.375 (80.846)\tAcc@5 100.000 (99.017)\tMem 455MB\n",
      " * Acc@1 80.910 Acc@5 99.030\n",
      "Accuracy of the network on the 10000 test images: 80.9%\n",
      "Max accuracy: 81.24%\n",
      "Train: [90/100][0/625]\teta 0:00:27 lr 0.000036\t wd 0.0100\ttime 0.0446 (0.0446)\tloss 0.4614 (0.4614)\tgrad_norm 2.6315 (2.6315)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][10/625]\teta 0:00:21 lr 0.000036\t wd 0.0100\ttime 0.0325 (0.0350)\tloss 0.3418 (0.3830)\tgrad_norm 2.0109 (2.2721)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][20/625]\teta 0:00:21 lr 0.000036\t wd 0.0100\ttime 0.0327 (0.0348)\tloss 0.4990 (0.3989)\tgrad_norm 2.2979 (2.2496)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][30/625]\teta 0:00:20 lr 0.000035\t wd 0.0100\ttime 0.0325 (0.0353)\tloss 0.5649 (0.3889)\tgrad_norm 2.9283 (2.2095)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][40/625]\teta 0:00:20 lr 0.000035\t wd 0.0100\ttime 0.0330 (0.0352)\tloss 0.3557 (0.3800)\tgrad_norm 2.7805 (2.2086)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][50/625]\teta 0:00:20 lr 0.000035\t wd 0.0100\ttime 0.0342 (0.0352)\tloss 0.2534 (0.3790)\tgrad_norm 2.4503 (2.2416)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][60/625]\teta 0:00:20 lr 0.000035\t wd 0.0100\ttime 0.0363 (0.0354)\tloss 0.3369 (0.3772)\tgrad_norm 1.5778 (2.2029)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][70/625]\teta 0:00:19 lr 0.000035\t wd 0.0100\ttime 0.0325 (0.0354)\tloss 0.3096 (0.3838)\tgrad_norm 2.0010 (2.2295)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][80/625]\teta 0:00:19 lr 0.000035\t wd 0.0100\ttime 0.0352 (0.0354)\tloss 0.3809 (0.3831)\tgrad_norm 2.1557 (2.2214)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][90/625]\teta 0:00:18 lr 0.000035\t wd 0.0100\ttime 0.0359 (0.0353)\tloss 0.3257 (0.3831)\tgrad_norm 1.7754 (2.2305)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][100/625]\teta 0:00:18 lr 0.000035\t wd 0.0100\ttime 0.0325 (0.0355)\tloss 0.3726 (0.3865)\tgrad_norm 3.1826 (2.2532)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][110/625]\teta 0:00:18 lr 0.000035\t wd 0.0100\ttime 0.0353 (0.0355)\tloss 0.5229 (0.3818)\tgrad_norm 2.3140 (2.2256)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][120/625]\teta 0:00:17 lr 0.000035\t wd 0.0100\ttime 0.0383 (0.0356)\tloss 0.4514 (0.3822)\tgrad_norm 3.1114 (2.2377)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][130/625]\teta 0:00:17 lr 0.000035\t wd 0.0100\ttime 0.0417 (0.0358)\tloss 0.3152 (0.3810)\tgrad_norm 1.8531 (2.2326)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][140/625]\teta 0:00:17 lr 0.000035\t wd 0.0100\ttime 0.0328 (0.0356)\tloss 0.3813 (0.3827)\tgrad_norm 2.0996 (2.2356)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][150/625]\teta 0:00:16 lr 0.000035\t wd 0.0100\ttime 0.0385 (0.0355)\tloss 0.3105 (0.3826)\tgrad_norm 1.8468 (2.2409)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][160/625]\teta 0:00:16 lr 0.000034\t wd 0.0100\ttime 0.0324 (0.0355)\tloss 0.3765 (0.3796)\tgrad_norm 2.7569 (2.2345)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][170/625]\teta 0:00:16 lr 0.000034\t wd 0.0100\ttime 0.0329 (0.0354)\tloss 0.3477 (0.3794)\tgrad_norm 2.3972 (2.2479)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][180/625]\teta 0:00:15 lr 0.000034\t wd 0.0100\ttime 0.0325 (0.0353)\tloss 0.5020 (0.3798)\tgrad_norm 2.7688 (2.2379)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][190/625]\teta 0:00:15 lr 0.000034\t wd 0.0100\ttime 0.0389 (0.0354)\tloss 0.4121 (0.3811)\tgrad_norm 2.3612 (2.2383)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][200/625]\teta 0:00:15 lr 0.000034\t wd 0.0100\ttime 0.0324 (0.0354)\tloss 0.5039 (0.3821)\tgrad_norm 2.5161 (2.2411)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][210/625]\teta 0:00:14 lr 0.000034\t wd 0.0100\ttime 0.0329 (0.0354)\tloss 0.4121 (0.3811)\tgrad_norm 2.1712 (2.2352)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][220/625]\teta 0:00:14 lr 0.000034\t wd 0.0100\ttime 0.0387 (0.0354)\tloss 0.4883 (0.3801)\tgrad_norm 3.0111 (2.2378)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][230/625]\teta 0:00:13 lr 0.000034\t wd 0.0100\ttime 0.0326 (0.0354)\tloss 0.4763 (0.3813)\tgrad_norm 2.6528 (2.2434)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][240/625]\teta 0:00:13 lr 0.000034\t wd 0.0100\ttime 0.0324 (0.0354)\tloss 0.4717 (0.3796)\tgrad_norm 2.0090 (2.2354)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][250/625]\teta 0:00:13 lr 0.000034\t wd 0.0100\ttime 0.0345 (0.0354)\tloss 0.3374 (0.3792)\tgrad_norm 2.7485 (2.2371)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][260/625]\teta 0:00:12 lr 0.000034\t wd 0.0100\ttime 0.0404 (0.0354)\tloss 0.5894 (0.3796)\tgrad_norm 3.1798 (2.2314)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][270/625]\teta 0:00:12 lr 0.000034\t wd 0.0100\ttime 0.0350 (0.0354)\tloss 0.3911 (0.3801)\tgrad_norm 2.2905 (2.2301)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][280/625]\teta 0:00:12 lr 0.000033\t wd 0.0100\ttime 0.0332 (0.0355)\tloss 0.2542 (0.3800)\tgrad_norm 1.5632 (2.2241)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][290/625]\teta 0:00:11 lr 0.000033\t wd 0.0100\ttime 0.0352 (0.0355)\tloss 0.2844 (0.3788)\tgrad_norm 1.9207 (2.2241)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][300/625]\teta 0:00:11 lr 0.000033\t wd 0.0100\ttime 0.0350 (0.0355)\tloss 0.2102 (0.3775)\tgrad_norm 1.9647 (2.2261)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][310/625]\teta 0:00:11 lr 0.000033\t wd 0.0100\ttime 0.0324 (0.0355)\tloss 0.4614 (0.3785)\tgrad_norm 3.2963 (2.2288)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][320/625]\teta 0:00:10 lr 0.000033\t wd 0.0100\ttime 0.0352 (0.0355)\tloss 0.3057 (0.3791)\tgrad_norm 1.9437 (2.2283)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][330/625]\teta 0:00:10 lr 0.000033\t wd 0.0100\ttime 0.0386 (0.0355)\tloss 0.3599 (0.3810)\tgrad_norm 2.3178 (2.2303)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][340/625]\teta 0:00:10 lr 0.000033\t wd 0.0100\ttime 0.0364 (0.0356)\tloss 0.4446 (0.3816)\tgrad_norm 2.6005 (2.2321)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][350/625]\teta 0:00:09 lr 0.000033\t wd 0.0100\ttime 0.0368 (0.0356)\tloss 0.2554 (0.3803)\tgrad_norm 1.9739 (2.2283)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][360/625]\teta 0:00:09 lr 0.000033\t wd 0.0100\ttime 0.0323 (0.0355)\tloss 0.2917 (0.3796)\tgrad_norm 1.9225 (2.2282)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][370/625]\teta 0:00:09 lr 0.000033\t wd 0.0100\ttime 0.0393 (0.0356)\tloss 0.2917 (0.3797)\tgrad_norm 1.7094 (2.2265)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][380/625]\teta 0:00:08 lr 0.000033\t wd 0.0100\ttime 0.0323 (0.0356)\tloss 0.3149 (0.3815)\tgrad_norm 2.8797 (2.2348)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][390/625]\teta 0:00:08 lr 0.000033\t wd 0.0100\ttime 0.0387 (0.0355)\tloss 0.3235 (0.3810)\tgrad_norm 2.1803 (2.2375)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][400/625]\teta 0:00:07 lr 0.000033\t wd 0.0100\ttime 0.0353 (0.0355)\tloss 0.3145 (0.3812)\tgrad_norm 1.6539 (2.2358)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][410/625]\teta 0:00:07 lr 0.000032\t wd 0.0100\ttime 0.0329 (0.0356)\tloss 0.3206 (0.3818)\tgrad_norm 1.6988 (2.2368)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][420/625]\teta 0:00:07 lr 0.000032\t wd 0.0100\ttime 0.0437 (0.0356)\tloss 0.4343 (0.3825)\tgrad_norm 3.4402 (2.2434)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][430/625]\teta 0:00:06 lr 0.000032\t wd 0.0100\ttime 0.0385 (0.0356)\tloss 0.4822 (0.3831)\tgrad_norm 2.2456 (2.2476)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][440/625]\teta 0:00:06 lr 0.000032\t wd 0.0100\ttime 0.0330 (0.0356)\tloss 0.4778 (0.3825)\tgrad_norm 3.4120 (2.2469)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][450/625]\teta 0:00:06 lr 0.000032\t wd 0.0100\ttime 0.0355 (0.0356)\tloss 0.4375 (0.3822)\tgrad_norm 2.4608 (2.2500)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][460/625]\teta 0:00:05 lr 0.000032\t wd 0.0100\ttime 0.0326 (0.0356)\tloss 0.4185 (0.3822)\tgrad_norm 3.0514 (2.2536)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][470/625]\teta 0:00:05 lr 0.000032\t wd 0.0100\ttime 0.0325 (0.0355)\tloss 0.3162 (0.3831)\tgrad_norm 1.6092 (2.2558)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][480/625]\teta 0:00:05 lr 0.000032\t wd 0.0100\ttime 0.0331 (0.0355)\tloss 0.6206 (0.3839)\tgrad_norm 2.9999 (2.2634)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][490/625]\teta 0:00:04 lr 0.000032\t wd 0.0100\ttime 0.0326 (0.0355)\tloss 0.4863 (0.3833)\tgrad_norm 2.5483 (2.2623)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][500/625]\teta 0:00:04 lr 0.000032\t wd 0.0100\ttime 0.0358 (0.0355)\tloss 0.3804 (0.3842)\tgrad_norm 1.6060 (2.2666)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][510/625]\teta 0:00:04 lr 0.000032\t wd 0.0100\ttime 0.0357 (0.0355)\tloss 0.6392 (0.3843)\tgrad_norm 3.2464 (2.2680)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][520/625]\teta 0:00:03 lr 0.000032\t wd 0.0100\ttime 0.0327 (0.0355)\tloss 0.4519 (0.3851)\tgrad_norm 2.6438 (2.2704)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [90/100][530/625]\teta 0:00:03 lr 0.000032\t wd 0.0100\ttime 0.0352 (0.0355)\tloss 0.3750 (0.3845)\tgrad_norm 2.3258 (nan)\tloss_scale 32768.0000 (32829.7100)\tmem 455MB\n",
      "Train: [90/100][540/625]\teta 0:00:03 lr 0.000032\t wd 0.0100\ttime 0.0372 (0.0355)\tloss 0.2761 (0.3842)\tgrad_norm 2.1121 (nan)\tloss_scale 32768.0000 (32828.5693)\tmem 455MB\n",
      "Train: [90/100][550/625]\teta 0:00:02 lr 0.000031\t wd 0.0100\ttime 0.0361 (0.0355)\tloss 0.3733 (0.3842)\tgrad_norm 2.0756 (nan)\tloss_scale 32768.0000 (32827.4701)\tmem 455MB\n",
      "Train: [90/100][560/625]\teta 0:00:02 lr 0.000031\t wd 0.0100\ttime 0.0324 (0.0355)\tloss 0.3315 (0.3841)\tgrad_norm 2.4595 (nan)\tloss_scale 32768.0000 (32826.4100)\tmem 455MB\n",
      "Train: [90/100][570/625]\teta 0:00:01 lr 0.000031\t wd 0.0100\ttime 0.0329 (0.0355)\tloss 0.2717 (0.3843)\tgrad_norm 2.7399 (nan)\tloss_scale 32768.0000 (32825.3870)\tmem 455MB\n",
      "Train: [90/100][580/625]\teta 0:00:01 lr 0.000031\t wd 0.0100\ttime 0.0363 (0.0355)\tloss 0.4419 (0.3846)\tgrad_norm 3.1639 (nan)\tloss_scale 32768.0000 (32824.3993)\tmem 455MB\n",
      "Train: [90/100][590/625]\teta 0:00:01 lr 0.000031\t wd 0.0100\ttime 0.0328 (0.0355)\tloss 0.2986 (0.3838)\tgrad_norm 1.8887 (nan)\tloss_scale 32768.0000 (32823.4450)\tmem 455MB\n",
      "Train: [90/100][600/625]\teta 0:00:00 lr 0.000031\t wd 0.0100\ttime 0.0324 (0.0355)\tloss 0.3376 (0.3835)\tgrad_norm 2.5471 (nan)\tloss_scale 32768.0000 (32822.5225)\tmem 455MB\n",
      "Train: [90/100][610/625]\teta 0:00:00 lr 0.000031\t wd 0.0100\ttime 0.0368 (0.0355)\tloss 0.4036 (0.3830)\tgrad_norm 1.8476 (nan)\tloss_scale 32768.0000 (32821.6301)\tmem 455MB\n",
      "Train: [90/100][620/625]\teta 0:00:00 lr 0.000031\t wd 0.0100\ttime 0.0359 (0.0355)\tloss 0.3447 (0.3825)\tgrad_norm 1.6224 (nan)\tloss_scale 32768.0000 (32820.7665)\tmem 455MB\n",
      "EPOCH 90 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_90.pth saving......\n",
      "./model_save/ckpt_epoch_90.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.6172 (0.6172)\tAcc@1 78.125 (78.125)\tAcc@5 100.000 (100.000)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.4211 (0.5601)\tAcc@1 84.375 (81.534)\tAcc@5 100.000 (99.290)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.5728 (0.5700)\tAcc@1 82.812 (81.622)\tAcc@5 100.000 (99.107)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.6611 (0.5869)\tAcc@1 75.000 (80.141)\tAcc@5 98.438 (99.244)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.5840 (0.5888)\tAcc@1 78.125 (80.297)\tAcc@5 100.000 (99.047)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.5723 (0.5828)\tAcc@1 85.938 (80.453)\tAcc@5 96.875 (99.050)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.6265 (0.5767)\tAcc@1 81.250 (80.738)\tAcc@5 98.438 (99.027)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.4941 (0.5853)\tAcc@1 82.812 (80.612)\tAcc@5 100.000 (99.010)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.5195 (0.5835)\tAcc@1 81.250 (80.594)\tAcc@5 100.000 (98.997)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.5122 (0.5795)\tAcc@1 82.812 (80.563)\tAcc@5 100.000 (99.021)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.5869 (0.5773)\tAcc@1 78.125 (80.770)\tAcc@5 100.000 (99.041)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.6655 (0.5684)\tAcc@1 85.938 (81.067)\tAcc@5 93.750 (99.015)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.8047 (0.5731)\tAcc@1 67.188 (80.863)\tAcc@5 100.000 (99.032)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.8970 (0.5746)\tAcc@1 68.750 (80.856)\tAcc@5 98.438 (99.082)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.6816 (0.5742)\tAcc@1 79.688 (80.851)\tAcc@5 100.000 (99.125)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.4563 (0.5742)\tAcc@1 84.375 (80.898)\tAcc@5 98.438 (99.120)\tMem 455MB\n",
      " * Acc@1 80.900 Acc@5 99.110\n",
      "Accuracy of the network on the 10000 test images: 80.9%\n",
      "Max accuracy: 81.24%\n",
      "Train: [91/100][0/625]\teta 0:00:25 lr 0.000031\t wd 0.0100\ttime 0.0412 (0.0412)\tloss 0.4446 (0.4446)\tgrad_norm 2.5791 (2.5791)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][10/625]\teta 0:00:23 lr 0.000031\t wd 0.0100\ttime 0.0397 (0.0382)\tloss 0.2651 (0.3612)\tgrad_norm 1.5752 (2.2104)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][20/625]\teta 0:00:22 lr 0.000031\t wd 0.0100\ttime 0.0348 (0.0367)\tloss 0.2456 (0.3720)\tgrad_norm 1.1914 (2.1946)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][30/625]\teta 0:00:21 lr 0.000031\t wd 0.0100\ttime 0.0326 (0.0360)\tloss 0.3606 (0.3719)\tgrad_norm 2.2318 (2.2013)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][40/625]\teta 0:00:20 lr 0.000031\t wd 0.0100\ttime 0.0355 (0.0357)\tloss 0.3821 (0.3855)\tgrad_norm 2.4131 (2.2429)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][50/625]\teta 0:00:20 lr 0.000031\t wd 0.0100\ttime 0.0328 (0.0358)\tloss 0.2335 (0.3904)\tgrad_norm 2.3546 (2.2267)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][60/625]\teta 0:00:20 lr 0.000030\t wd 0.0100\ttime 0.0354 (0.0356)\tloss 0.5933 (0.3815)\tgrad_norm 2.9922 (2.2211)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][70/625]\teta 0:00:19 lr 0.000030\t wd 0.0100\ttime 0.0359 (0.0354)\tloss 0.3542 (0.3803)\tgrad_norm 1.7775 (2.2246)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][80/625]\teta 0:00:19 lr 0.000030\t wd 0.0100\ttime 0.0326 (0.0355)\tloss 0.4238 (0.3806)\tgrad_norm 1.8791 (2.2268)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][90/625]\teta 0:00:19 lr 0.000030\t wd 0.0100\ttime 0.0324 (0.0356)\tloss 0.4504 (0.3820)\tgrad_norm 2.3655 (2.2451)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][100/625]\teta 0:00:18 lr 0.000030\t wd 0.0100\ttime 0.0326 (0.0355)\tloss 0.3379 (0.3819)\tgrad_norm 2.6330 (2.2364)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][110/625]\teta 0:00:18 lr 0.000030\t wd 0.0100\ttime 0.0350 (0.0356)\tloss 0.4734 (0.3778)\tgrad_norm 2.2441 (2.2140)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][120/625]\teta 0:00:18 lr 0.000030\t wd 0.0100\ttime 0.0362 (0.0357)\tloss 0.2959 (0.3787)\tgrad_norm 2.5634 (2.2529)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][130/625]\teta 0:00:17 lr 0.000030\t wd 0.0100\ttime 0.0358 (0.0358)\tloss 0.3804 (0.3799)\tgrad_norm 2.7171 (2.2699)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][140/625]\teta 0:00:17 lr 0.000030\t wd 0.0100\ttime 0.0362 (0.0357)\tloss 0.3325 (0.3788)\tgrad_norm 2.1578 (2.2565)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][150/625]\teta 0:00:16 lr 0.000030\t wd 0.0100\ttime 0.0331 (0.0357)\tloss 0.3398 (0.3745)\tgrad_norm 2.1082 (2.2415)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][160/625]\teta 0:00:16 lr 0.000030\t wd 0.0100\ttime 0.0329 (0.0357)\tloss 0.3586 (0.3754)\tgrad_norm 2.1679 (2.2336)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][170/625]\teta 0:00:16 lr 0.000030\t wd 0.0100\ttime 0.0326 (0.0356)\tloss 0.5845 (0.3759)\tgrad_norm 2.3431 (2.2310)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][180/625]\teta 0:00:15 lr 0.000030\t wd 0.0100\ttime 0.0361 (0.0356)\tloss 0.3340 (0.3776)\tgrad_norm 2.4912 (2.2384)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][190/625]\teta 0:00:15 lr 0.000030\t wd 0.0100\ttime 0.0324 (0.0355)\tloss 0.2455 (0.3789)\tgrad_norm 2.0023 (2.2391)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][200/625]\teta 0:00:15 lr 0.000029\t wd 0.0100\ttime 0.0326 (0.0354)\tloss 0.3301 (0.3766)\tgrad_norm 2.3069 (2.2304)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][210/625]\teta 0:00:14 lr 0.000029\t wd 0.0100\ttime 0.0322 (0.0354)\tloss 0.3345 (0.3762)\tgrad_norm 1.9430 (2.2255)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][220/625]\teta 0:00:14 lr 0.000029\t wd 0.0100\ttime 0.0359 (0.0354)\tloss 0.3240 (0.3769)\tgrad_norm 2.3640 (2.2260)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][230/625]\teta 0:00:13 lr 0.000029\t wd 0.0100\ttime 0.0325 (0.0354)\tloss 0.4653 (0.3784)\tgrad_norm 2.2999 (2.2259)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][240/625]\teta 0:00:13 lr 0.000029\t wd 0.0100\ttime 0.0350 (0.0354)\tloss 0.2932 (0.3763)\tgrad_norm 1.8503 (2.2214)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][250/625]\teta 0:00:13 lr 0.000029\t wd 0.0100\ttime 0.0398 (0.0355)\tloss 0.3999 (0.3770)\tgrad_norm 2.1967 (2.2159)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][260/625]\teta 0:00:12 lr 0.000029\t wd 0.0100\ttime 0.0327 (0.0355)\tloss 0.2747 (0.3762)\tgrad_norm 2.4418 (2.2138)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][270/625]\teta 0:00:12 lr 0.000029\t wd 0.0100\ttime 0.0407 (0.0356)\tloss 0.5063 (0.3778)\tgrad_norm 1.9908 (2.2139)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][280/625]\teta 0:00:12 lr 0.000029\t wd 0.0100\ttime 0.0379 (0.0356)\tloss 0.2864 (0.3769)\tgrad_norm 1.9154 (2.2140)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][290/625]\teta 0:00:11 lr 0.000029\t wd 0.0100\ttime 0.0326 (0.0356)\tloss 0.2820 (0.3751)\tgrad_norm 1.4189 (2.1988)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][300/625]\teta 0:00:11 lr 0.000029\t wd 0.0100\ttime 0.0326 (0.0356)\tloss 0.4729 (0.3757)\tgrad_norm 2.7577 (2.2045)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][310/625]\teta 0:00:11 lr 0.000029\t wd 0.0100\ttime 0.0358 (0.0356)\tloss 0.2566 (0.3761)\tgrad_norm 1.5195 (2.1996)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][320/625]\teta 0:00:10 lr 0.000029\t wd 0.0100\ttime 0.0327 (0.0356)\tloss 0.3811 (0.3754)\tgrad_norm 2.7992 (2.1978)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][330/625]\teta 0:00:10 lr 0.000029\t wd 0.0100\ttime 0.0391 (0.0356)\tloss 0.2710 (0.3756)\tgrad_norm 2.5420 (2.2074)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][340/625]\teta 0:00:10 lr 0.000028\t wd 0.0100\ttime 0.0352 (0.0357)\tloss 0.5088 (0.3766)\tgrad_norm 2.9006 (2.2146)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][350/625]\teta 0:00:09 lr 0.000028\t wd 0.0100\ttime 0.0342 (0.0357)\tloss 0.4094 (0.3773)\tgrad_norm 2.4239 (2.2159)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][360/625]\teta 0:00:09 lr 0.000028\t wd 0.0100\ttime 0.0356 (0.0357)\tloss 0.2522 (0.3779)\tgrad_norm 2.0151 (2.2165)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][370/625]\teta 0:00:09 lr 0.000028\t wd 0.0100\ttime 0.0354 (0.0357)\tloss 0.4312 (0.3778)\tgrad_norm 2.2745 (2.2225)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][380/625]\teta 0:00:08 lr 0.000028\t wd 0.0100\ttime 0.0396 (0.0357)\tloss 0.4756 (0.3786)\tgrad_norm 2.9869 (2.2298)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][390/625]\teta 0:00:08 lr 0.000028\t wd 0.0100\ttime 0.0350 (0.0357)\tloss 0.4451 (0.3786)\tgrad_norm 2.0525 (2.2265)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][400/625]\teta 0:00:08 lr 0.000028\t wd 0.0100\ttime 0.0327 (0.0357)\tloss 0.2891 (0.3779)\tgrad_norm 1.7845 (2.2240)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][410/625]\teta 0:00:07 lr 0.000028\t wd 0.0100\ttime 0.0350 (0.0357)\tloss 0.3911 (0.3781)\tgrad_norm 2.8997 (2.2289)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][420/625]\teta 0:00:07 lr 0.000028\t wd 0.0100\ttime 0.0388 (0.0356)\tloss 0.5063 (0.3797)\tgrad_norm 2.7881 (2.2345)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][430/625]\teta 0:00:06 lr 0.000028\t wd 0.0100\ttime 0.0362 (0.0357)\tloss 0.5483 (0.3797)\tgrad_norm 3.0694 (2.2304)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][440/625]\teta 0:00:06 lr 0.000028\t wd 0.0100\ttime 0.0327 (0.0356)\tloss 0.2793 (0.3812)\tgrad_norm 1.3894 (2.2346)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][450/625]\teta 0:00:06 lr 0.000028\t wd 0.0100\ttime 0.0389 (0.0356)\tloss 0.3940 (0.3827)\tgrad_norm 2.4192 (2.2460)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][460/625]\teta 0:00:05 lr 0.000028\t wd 0.0100\ttime 0.0330 (0.0356)\tloss 0.3223 (0.3824)\tgrad_norm 2.0485 (2.2424)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][470/625]\teta 0:00:05 lr 0.000028\t wd 0.0100\ttime 0.0360 (0.0357)\tloss 0.2603 (0.3823)\tgrad_norm 1.4607 (2.2408)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][480/625]\teta 0:00:05 lr 0.000027\t wd 0.0100\ttime 0.0353 (0.0356)\tloss 0.4480 (0.3825)\tgrad_norm 1.9758 (2.2409)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][490/625]\teta 0:00:04 lr 0.000027\t wd 0.0100\ttime 0.0360 (0.0356)\tloss 0.4189 (0.3828)\tgrad_norm 1.8536 (2.2435)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][500/625]\teta 0:00:04 lr 0.000027\t wd 0.0100\ttime 0.0356 (0.0357)\tloss 0.4573 (0.3821)\tgrad_norm 2.3215 (2.2403)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][510/625]\teta 0:00:04 lr 0.000027\t wd 0.0100\ttime 0.0351 (0.0357)\tloss 0.4250 (0.3826)\tgrad_norm 2.4257 (2.2414)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][520/625]\teta 0:00:03 lr 0.000027\t wd 0.0100\ttime 0.0328 (0.0357)\tloss 0.3071 (0.3826)\tgrad_norm 3.0424 (2.2441)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][530/625]\teta 0:00:03 lr 0.000027\t wd 0.0100\ttime 0.0376 (0.0357)\tloss 0.3538 (0.3831)\tgrad_norm 1.9417 (2.2462)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][540/625]\teta 0:00:03 lr 0.000027\t wd 0.0100\ttime 0.0361 (0.0357)\tloss 0.2487 (0.3841)\tgrad_norm 1.4593 (2.2483)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][550/625]\teta 0:00:02 lr 0.000027\t wd 0.0100\ttime 0.0331 (0.0357)\tloss 0.4661 (0.3842)\tgrad_norm 2.4708 (2.2467)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][560/625]\teta 0:00:02 lr 0.000027\t wd 0.0100\ttime 0.0364 (0.0358)\tloss 0.3384 (0.3832)\tgrad_norm 2.0701 (2.2434)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][570/625]\teta 0:00:01 lr 0.000027\t wd 0.0100\ttime 0.0388 (0.0358)\tloss 0.4956 (0.3832)\tgrad_norm 1.9863 (2.2453)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][580/625]\teta 0:00:01 lr 0.000027\t wd 0.0100\ttime 0.0358 (0.0358)\tloss 0.7378 (0.3834)\tgrad_norm 2.6761 (2.2484)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][590/625]\teta 0:00:01 lr 0.000027\t wd 0.0100\ttime 0.0328 (0.0358)\tloss 0.4697 (0.3841)\tgrad_norm 3.0178 (2.2531)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][600/625]\teta 0:00:00 lr 0.000027\t wd 0.0100\ttime 0.0363 (0.0358)\tloss 0.3608 (0.3835)\tgrad_norm 2.1121 (2.2497)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][610/625]\teta 0:00:00 lr 0.000027\t wd 0.0100\ttime 0.0343 (0.0358)\tloss 0.2209 (0.3830)\tgrad_norm 1.6365 (2.2447)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [91/100][620/625]\teta 0:00:00 lr 0.000027\t wd 0.0100\ttime 0.0436 (0.0358)\tloss 0.3435 (0.3830)\tgrad_norm 2.4152 (2.2468)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 91 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_91.pth saving......\n",
      "./model_save/ckpt_epoch_91.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.5586 (0.5586)\tAcc@1 76.562 (76.562)\tAcc@5 98.438 (98.438)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.016)\tLoss 0.4319 (0.5490)\tAcc@1 84.375 (81.676)\tAcc@5 100.000 (99.432)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.016)\tLoss 0.7593 (0.5694)\tAcc@1 76.562 (80.060)\tAcc@5 100.000 (99.405)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.016)\tLoss 0.8081 (0.5646)\tAcc@1 71.875 (80.141)\tAcc@5 100.000 (99.395)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.016)\tLoss 0.4961 (0.5580)\tAcc@1 81.250 (80.450)\tAcc@5 100.000 (99.276)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.7554 (0.5664)\tAcc@1 76.562 (80.331)\tAcc@5 100.000 (99.234)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.5337 (0.5692)\tAcc@1 82.812 (80.328)\tAcc@5 100.000 (99.308)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.7329 (0.5682)\tAcc@1 79.688 (80.568)\tAcc@5 98.438 (99.186)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.5791 (0.5706)\tAcc@1 78.125 (80.517)\tAcc@5 100.000 (99.209)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.4446 (0.5654)\tAcc@1 87.500 (80.649)\tAcc@5 100.000 (99.210)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.4678 (0.5616)\tAcc@1 79.688 (80.739)\tAcc@5 100.000 (99.211)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.3149 (0.5613)\tAcc@1 92.188 (80.983)\tAcc@5 98.438 (99.212)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.5073 (0.5564)\tAcc@1 85.938 (81.121)\tAcc@5 96.875 (99.199)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.016 (0.015)\tLoss 0.4719 (0.5599)\tAcc@1 87.500 (81.131)\tAcc@5 98.438 (99.165)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.016 (0.015)\tLoss 0.5327 (0.5633)\tAcc@1 82.812 (81.017)\tAcc@5 98.438 (99.169)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.4424 (0.5631)\tAcc@1 85.938 (81.064)\tAcc@5 100.000 (99.141)\tMem 455MB\n",
      " * Acc@1 81.080 Acc@5 99.130\n",
      "Accuracy of the network on the 10000 test images: 81.1%\n",
      "Max accuracy: 81.24%\n",
      "Train: [92/100][0/625]\teta 0:00:24 lr 0.000027\t wd 0.0100\ttime 0.0397 (0.0397)\tloss 0.2876 (0.2876)\tgrad_norm 1.7225 (1.7225)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][10/625]\teta 0:00:22 lr 0.000026\t wd 0.0100\ttime 0.0410 (0.0366)\tloss 0.3386 (0.3999)\tgrad_norm 2.0368 (2.1463)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][20/625]\teta 0:00:22 lr 0.000026\t wd 0.0100\ttime 0.0323 (0.0366)\tloss 0.4102 (0.4143)\tgrad_norm 2.4559 (2.2262)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][30/625]\teta 0:00:21 lr 0.000026\t wd 0.0100\ttime 0.0328 (0.0363)\tloss 0.3928 (0.4037)\tgrad_norm 1.8975 (2.2294)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][40/625]\teta 0:00:21 lr 0.000026\t wd 0.0100\ttime 0.0323 (0.0363)\tloss 0.2839 (0.3887)\tgrad_norm 1.5169 (2.2242)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][50/625]\teta 0:00:20 lr 0.000026\t wd 0.0100\ttime 0.0324 (0.0363)\tloss 0.6523 (0.3866)\tgrad_norm 3.0459 (2.2547)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][60/625]\teta 0:00:20 lr 0.000026\t wd 0.0100\ttime 0.0384 (0.0362)\tloss 0.2274 (0.3869)\tgrad_norm 1.5960 (2.2279)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][70/625]\teta 0:00:20 lr 0.000026\t wd 0.0100\ttime 0.0361 (0.0362)\tloss 0.2181 (0.3840)\tgrad_norm 1.8735 (2.2254)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][80/625]\teta 0:00:19 lr 0.000026\t wd 0.0100\ttime 0.0365 (0.0362)\tloss 0.2656 (0.3833)\tgrad_norm 1.9897 (2.2077)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][90/625]\teta 0:00:19 lr 0.000026\t wd 0.0100\ttime 0.0326 (0.0362)\tloss 0.3311 (0.3884)\tgrad_norm 1.9740 (2.2553)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][100/625]\teta 0:00:19 lr 0.000026\t wd 0.0100\ttime 0.0358 (0.0362)\tloss 0.3093 (0.3865)\tgrad_norm 2.1083 (2.2679)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][110/625]\teta 0:00:18 lr 0.000026\t wd 0.0100\ttime 0.0356 (0.0362)\tloss 0.5894 (0.3871)\tgrad_norm 2.3388 (2.2540)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][120/625]\teta 0:00:18 lr 0.000026\t wd 0.0100\ttime 0.0359 (0.0361)\tloss 0.5942 (0.3897)\tgrad_norm 2.3984 (2.2650)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][130/625]\teta 0:00:17 lr 0.000026\t wd 0.0100\ttime 0.0356 (0.0361)\tloss 0.3999 (0.3893)\tgrad_norm 2.6585 (2.2696)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][140/625]\teta 0:00:17 lr 0.000026\t wd 0.0100\ttime 0.0358 (0.0361)\tloss 0.3054 (0.3912)\tgrad_norm 2.0382 (2.2882)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][150/625]\teta 0:00:17 lr 0.000026\t wd 0.0100\ttime 0.0386 (0.0361)\tloss 0.4966 (0.3911)\tgrad_norm 2.0866 (2.2950)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][160/625]\teta 0:00:16 lr 0.000025\t wd 0.0100\ttime 0.0345 (0.0361)\tloss 0.2240 (0.3908)\tgrad_norm 1.9827 (2.3035)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][170/625]\teta 0:00:16 lr 0.000025\t wd 0.0100\ttime 0.0355 (0.0361)\tloss 0.3726 (0.3929)\tgrad_norm 2.4019 (2.3188)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][180/625]\teta 0:00:16 lr 0.000025\t wd 0.0100\ttime 0.0328 (0.0360)\tloss 0.2869 (0.3951)\tgrad_norm 1.3591 (2.3262)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][190/625]\teta 0:00:15 lr 0.000025\t wd 0.0100\ttime 0.0348 (0.0360)\tloss 0.3337 (0.3972)\tgrad_norm 1.8728 (2.3276)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][200/625]\teta 0:00:15 lr 0.000025\t wd 0.0100\ttime 0.0397 (0.0359)\tloss 0.3704 (0.3940)\tgrad_norm 2.3413 (2.3150)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][210/625]\teta 0:00:14 lr 0.000025\t wd 0.0100\ttime 0.0361 (0.0359)\tloss 0.3599 (0.3934)\tgrad_norm 1.7793 (2.3132)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][220/625]\teta 0:00:14 lr 0.000025\t wd 0.0100\ttime 0.0328 (0.0359)\tloss 0.3484 (0.3925)\tgrad_norm 1.9798 (2.3067)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][230/625]\teta 0:00:14 lr 0.000025\t wd 0.0100\ttime 0.0399 (0.0359)\tloss 0.3152 (0.3931)\tgrad_norm 1.8353 (2.2983)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][240/625]\teta 0:00:13 lr 0.000025\t wd 0.0100\ttime 0.0393 (0.0359)\tloss 0.4473 (0.3918)\tgrad_norm 2.0185 (2.2870)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][250/625]\teta 0:00:13 lr 0.000025\t wd 0.0100\ttime 0.0326 (0.0359)\tloss 0.4685 (0.3947)\tgrad_norm 1.9513 (2.2962)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][260/625]\teta 0:00:13 lr 0.000025\t wd 0.0100\ttime 0.0401 (0.0359)\tloss 0.3325 (0.3963)\tgrad_norm 2.3998 (2.3049)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][270/625]\teta 0:00:12 lr 0.000025\t wd 0.0100\ttime 0.0391 (0.0360)\tloss 0.4160 (0.3945)\tgrad_norm 2.2146 (2.2999)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][280/625]\teta 0:00:12 lr 0.000025\t wd 0.0100\ttime 0.0391 (0.0360)\tloss 0.4858 (0.3948)\tgrad_norm 2.2353 (2.3050)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][290/625]\teta 0:00:12 lr 0.000025\t wd 0.0100\ttime 0.0322 (0.0360)\tloss 0.5347 (0.3952)\tgrad_norm 2.1864 (2.3102)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][300/625]\teta 0:00:11 lr 0.000025\t wd 0.0100\ttime 0.0335 (0.0360)\tloss 0.2499 (0.3950)\tgrad_norm 1.8848 (2.3085)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][310/625]\teta 0:00:11 lr 0.000025\t wd 0.0100\ttime 0.0324 (0.0359)\tloss 0.4551 (0.3953)\tgrad_norm 2.0625 (2.3045)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][320/625]\teta 0:00:10 lr 0.000024\t wd 0.0100\ttime 0.0390 (0.0359)\tloss 0.3621 (0.3934)\tgrad_norm 2.1489 (2.2955)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][330/625]\teta 0:00:10 lr 0.000024\t wd 0.0100\ttime 0.0328 (0.0359)\tloss 0.3521 (0.3936)\tgrad_norm 2.0776 (2.2933)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][340/625]\teta 0:00:10 lr 0.000024\t wd 0.0100\ttime 0.0361 (0.0359)\tloss 0.3628 (0.3928)\tgrad_norm 1.8464 (2.2876)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][350/625]\teta 0:00:09 lr 0.000024\t wd 0.0100\ttime 0.0359 (0.0359)\tloss 0.4985 (0.3914)\tgrad_norm 3.0017 (2.2861)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][360/625]\teta 0:00:09 lr 0.000024\t wd 0.0100\ttime 0.0387 (0.0359)\tloss 0.3433 (0.3904)\tgrad_norm 2.0408 (2.2818)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][370/625]\teta 0:00:09 lr 0.000024\t wd 0.0100\ttime 0.0332 (0.0359)\tloss 0.4495 (0.3902)\tgrad_norm 2.5761 (2.2796)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][380/625]\teta 0:00:08 lr 0.000024\t wd 0.0100\ttime 0.0323 (0.0359)\tloss 0.3010 (0.3901)\tgrad_norm 1.7940 (2.2827)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][390/625]\teta 0:00:08 lr 0.000024\t wd 0.0100\ttime 0.0354 (0.0359)\tloss 0.2874 (0.3888)\tgrad_norm 1.4073 (2.2764)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][400/625]\teta 0:00:08 lr 0.000024\t wd 0.0100\ttime 0.0349 (0.0359)\tloss 0.3625 (0.3889)\tgrad_norm 2.7557 (2.2787)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][410/625]\teta 0:00:07 lr 0.000024\t wd 0.0100\ttime 0.0345 (0.0359)\tloss 0.5068 (0.3887)\tgrad_norm 2.4625 (2.2752)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][420/625]\teta 0:00:07 lr 0.000024\t wd 0.0100\ttime 0.0326 (0.0358)\tloss 0.3276 (0.3879)\tgrad_norm 1.5535 (2.2746)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][430/625]\teta 0:00:06 lr 0.000024\t wd 0.0100\ttime 0.0395 (0.0358)\tloss 0.4702 (0.3862)\tgrad_norm 2.6044 (2.2698)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][440/625]\teta 0:00:06 lr 0.000024\t wd 0.0100\ttime 0.0350 (0.0358)\tloss 0.2798 (0.3853)\tgrad_norm 2.7259 (2.2700)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][450/625]\teta 0:00:06 lr 0.000024\t wd 0.0100\ttime 0.0329 (0.0358)\tloss 0.3542 (0.3849)\tgrad_norm 1.7695 (2.2684)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][460/625]\teta 0:00:05 lr 0.000024\t wd 0.0100\ttime 0.0323 (0.0358)\tloss 0.3152 (0.3841)\tgrad_norm 2.3293 (2.2664)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][470/625]\teta 0:00:05 lr 0.000024\t wd 0.0100\ttime 0.0325 (0.0358)\tloss 0.5117 (0.3837)\tgrad_norm 2.3317 (2.2597)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][480/625]\teta 0:00:05 lr 0.000024\t wd 0.0100\ttime 0.0363 (0.0358)\tloss 0.4802 (0.3829)\tgrad_norm 2.3494 (2.2577)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][490/625]\teta 0:00:04 lr 0.000023\t wd 0.0100\ttime 0.0375 (0.0358)\tloss 0.2822 (0.3830)\tgrad_norm 1.9748 (2.2560)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][500/625]\teta 0:00:04 lr 0.000023\t wd 0.0100\ttime 0.0330 (0.0358)\tloss 0.3516 (0.3830)\tgrad_norm 2.0983 (2.2545)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][510/625]\teta 0:00:04 lr 0.000023\t wd 0.0100\ttime 0.0323 (0.0358)\tloss 0.4753 (0.3828)\tgrad_norm 2.2213 (2.2539)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][520/625]\teta 0:00:03 lr 0.000023\t wd 0.0100\ttime 0.0325 (0.0357)\tloss 0.4680 (0.3827)\tgrad_norm 2.5906 (2.2510)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][530/625]\teta 0:00:03 lr 0.000023\t wd 0.0100\ttime 0.0357 (0.0357)\tloss 0.3984 (0.3825)\tgrad_norm 2.2885 (2.2529)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][540/625]\teta 0:00:03 lr 0.000023\t wd 0.0100\ttime 0.0356 (0.0357)\tloss 0.3740 (0.3830)\tgrad_norm 2.9129 (2.2583)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][550/625]\teta 0:00:02 lr 0.000023\t wd 0.0100\ttime 0.0351 (0.0357)\tloss 0.2556 (0.3829)\tgrad_norm 1.8133 (2.2567)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][560/625]\teta 0:00:02 lr 0.000023\t wd 0.0100\ttime 0.0325 (0.0357)\tloss 0.3726 (0.3828)\tgrad_norm 2.6847 (2.2586)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][570/625]\teta 0:00:01 lr 0.000023\t wd 0.0100\ttime 0.0325 (0.0356)\tloss 0.4543 (0.3830)\tgrad_norm 2.1447 (2.2598)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][580/625]\teta 0:00:01 lr 0.000023\t wd 0.0100\ttime 0.0386 (0.0357)\tloss 0.3198 (0.3829)\tgrad_norm 2.7915 (2.2632)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][590/625]\teta 0:00:01 lr 0.000023\t wd 0.0100\ttime 0.0325 (0.0357)\tloss 0.3376 (0.3829)\tgrad_norm 2.2113 (2.2653)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][600/625]\teta 0:00:00 lr 0.000023\t wd 0.0100\ttime 0.0332 (0.0357)\tloss 0.3354 (0.3840)\tgrad_norm 1.6090 (2.2697)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][610/625]\teta 0:00:00 lr 0.000023\t wd 0.0100\ttime 0.0357 (0.0357)\tloss 0.3945 (0.3846)\tgrad_norm 1.9278 (2.2697)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [92/100][620/625]\teta 0:00:00 lr 0.000023\t wd 0.0100\ttime 0.0360 (0.0357)\tloss 0.2678 (0.3852)\tgrad_norm 1.5406 (2.2716)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 92 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_92.pth saving......\n",
      "./model_save/ckpt_epoch_92.pth saved !!!\n",
      "Test: [0/157]\tTime 0.022 (0.022)\tLoss 0.3345 (0.3345)\tAcc@1 90.625 (90.625)\tAcc@5 100.000 (100.000)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.016)\tLoss 0.7354 (0.5829)\tAcc@1 79.688 (80.256)\tAcc@5 98.438 (99.432)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.016)\tLoss 0.8652 (0.5944)\tAcc@1 68.750 (80.506)\tAcc@5 95.312 (98.884)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.4788 (0.5903)\tAcc@1 82.812 (79.990)\tAcc@5 100.000 (99.093)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.7051 (0.6169)\tAcc@1 79.688 (79.611)\tAcc@5 98.438 (98.971)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.5928 (0.6120)\tAcc@1 81.250 (79.963)\tAcc@5 98.438 (98.897)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.4673 (0.6007)\tAcc@1 89.062 (80.328)\tAcc@5 98.438 (98.924)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.4265 (0.5890)\tAcc@1 82.812 (80.612)\tAcc@5 100.000 (99.032)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.8174 (0.5865)\tAcc@1 73.438 (80.671)\tAcc@5 98.438 (99.074)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.5083 (0.5810)\tAcc@1 79.688 (80.889)\tAcc@5 100.000 (99.073)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.3918 (0.5812)\tAcc@1 87.500 (80.941)\tAcc@5 100.000 (99.087)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.6167 (0.5780)\tAcc@1 82.812 (80.926)\tAcc@5 98.438 (99.099)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.5942 (0.5735)\tAcc@1 82.812 (81.030)\tAcc@5 100.000 (99.148)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.6440 (0.5745)\tAcc@1 75.000 (80.892)\tAcc@5 98.438 (99.165)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.5225 (0.5759)\tAcc@1 78.125 (80.773)\tAcc@5 100.000 (99.169)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.4573 (0.5736)\tAcc@1 81.250 (80.784)\tAcc@5 100.000 (99.172)\tMem 455MB\n",
      " * Acc@1 80.830 Acc@5 99.170\n",
      "Accuracy of the network on the 10000 test images: 80.8%\n",
      "Max accuracy: 81.24%\n",
      "Train: [93/100][0/625]\teta 0:00:24 lr 0.000023\t wd 0.0100\ttime 0.0398 (0.0398)\tloss 0.2332 (0.2332)\tgrad_norm 1.4289 (1.4289)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][10/625]\teta 0:00:22 lr 0.000023\t wd 0.0100\ttime 0.0372 (0.0371)\tloss 0.3794 (0.3720)\tgrad_norm 2.0412 (2.3433)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][20/625]\teta 0:00:22 lr 0.000023\t wd 0.0100\ttime 0.0384 (0.0365)\tloss 0.3286 (0.3675)\tgrad_norm 2.0589 (2.3284)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][30/625]\teta 0:00:21 lr 0.000022\t wd 0.0100\ttime 0.0396 (0.0367)\tloss 0.4077 (0.3815)\tgrad_norm 2.3761 (2.3310)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][40/625]\teta 0:00:21 lr 0.000022\t wd 0.0100\ttime 0.0335 (0.0366)\tloss 0.2522 (0.3762)\tgrad_norm 1.9429 (2.3204)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][50/625]\teta 0:00:20 lr 0.000022\t wd 0.0100\ttime 0.0329 (0.0361)\tloss 0.3718 (0.3663)\tgrad_norm 2.4729 (2.3400)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][60/625]\teta 0:00:20 lr 0.000022\t wd 0.0100\ttime 0.0328 (0.0359)\tloss 0.3420 (0.3693)\tgrad_norm 2.6256 (2.3467)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][70/625]\teta 0:00:19 lr 0.000022\t wd 0.0100\ttime 0.0329 (0.0356)\tloss 0.2939 (0.3778)\tgrad_norm 3.1199 (2.3659)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][80/625]\teta 0:00:19 lr 0.000022\t wd 0.0100\ttime 0.0326 (0.0354)\tloss 0.5361 (0.3842)\tgrad_norm 2.8346 (2.3639)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][90/625]\teta 0:00:18 lr 0.000022\t wd 0.0100\ttime 0.0447 (0.0354)\tloss 0.3772 (0.3844)\tgrad_norm 2.4290 (2.3376)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][100/625]\teta 0:00:18 lr 0.000022\t wd 0.0100\ttime 0.0384 (0.0354)\tloss 0.3257 (0.3821)\tgrad_norm 1.8959 (2.3163)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][110/625]\teta 0:00:18 lr 0.000022\t wd 0.0100\ttime 0.0327 (0.0355)\tloss 0.2539 (0.3802)\tgrad_norm 1.8908 (2.3105)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][120/625]\teta 0:00:17 lr 0.000022\t wd 0.0100\ttime 0.0395 (0.0356)\tloss 0.4014 (0.3788)\tgrad_norm 2.9905 (2.3160)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][130/625]\teta 0:00:17 lr 0.000022\t wd 0.0100\ttime 0.0393 (0.0356)\tloss 0.2578 (0.3779)\tgrad_norm 1.8959 (2.2966)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][140/625]\teta 0:00:17 lr 0.000022\t wd 0.0100\ttime 0.0355 (0.0356)\tloss 0.2444 (0.3758)\tgrad_norm 1.7144 (2.2824)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][150/625]\teta 0:00:16 lr 0.000022\t wd 0.0100\ttime 0.0356 (0.0356)\tloss 0.4514 (0.3780)\tgrad_norm 2.3438 (2.2939)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][160/625]\teta 0:00:16 lr 0.000022\t wd 0.0100\ttime 0.0390 (0.0357)\tloss 0.2332 (0.3764)\tgrad_norm 1.6128 (2.2932)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][170/625]\teta 0:00:16 lr 0.000022\t wd 0.0100\ttime 0.0363 (0.0357)\tloss 0.3218 (0.3759)\tgrad_norm 2.3308 (2.2886)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][180/625]\teta 0:00:15 lr 0.000022\t wd 0.0100\ttime 0.0366 (0.0358)\tloss 0.3108 (0.3752)\tgrad_norm 1.9302 (2.2933)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][190/625]\teta 0:00:15 lr 0.000022\t wd 0.0100\ttime 0.0354 (0.0358)\tloss 0.4797 (0.3749)\tgrad_norm 2.5605 (2.2804)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][200/625]\teta 0:00:15 lr 0.000022\t wd 0.0100\ttime 0.0387 (0.0359)\tloss 0.3269 (0.3763)\tgrad_norm 2.0656 (2.2836)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][210/625]\teta 0:00:14 lr 0.000021\t wd 0.0100\ttime 0.0348 (0.0359)\tloss 0.3835 (0.3774)\tgrad_norm 2.2270 (2.2781)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][220/625]\teta 0:00:14 lr 0.000021\t wd 0.0100\ttime 0.0327 (0.0359)\tloss 0.6836 (0.3782)\tgrad_norm 2.4600 (2.2701)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][230/625]\teta 0:00:14 lr 0.000021\t wd 0.0100\ttime 0.0360 (0.0358)\tloss 0.3506 (0.3803)\tgrad_norm 2.2474 (2.2827)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][240/625]\teta 0:00:13 lr 0.000021\t wd 0.0100\ttime 0.0389 (0.0359)\tloss 0.3933 (0.3801)\tgrad_norm 2.4709 (2.2847)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][250/625]\teta 0:00:13 lr 0.000021\t wd 0.0100\ttime 0.0359 (0.0359)\tloss 0.4868 (0.3804)\tgrad_norm 3.3505 (2.2803)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][260/625]\teta 0:00:13 lr 0.000021\t wd 0.0100\ttime 0.0324 (0.0359)\tloss 0.4294 (0.3821)\tgrad_norm 1.9937 (2.2915)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][270/625]\teta 0:00:12 lr 0.000021\t wd 0.0100\ttime 0.0330 (0.0358)\tloss 0.2961 (0.3807)\tgrad_norm 2.5360 (2.2850)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][280/625]\teta 0:00:12 lr 0.000021\t wd 0.0100\ttime 0.0331 (0.0357)\tloss 0.4519 (0.3803)\tgrad_norm 2.3705 (2.2789)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][290/625]\teta 0:00:11 lr 0.000021\t wd 0.0100\ttime 0.0387 (0.0358)\tloss 0.4004 (0.3799)\tgrad_norm 1.9035 (2.2768)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][300/625]\teta 0:00:11 lr 0.000021\t wd 0.0100\ttime 0.0326 (0.0358)\tloss 0.3665 (0.3783)\tgrad_norm 2.2199 (2.2733)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][310/625]\teta 0:00:11 lr 0.000021\t wd 0.0100\ttime 0.0357 (0.0357)\tloss 0.4272 (0.3783)\tgrad_norm 2.3507 (2.2684)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][320/625]\teta 0:00:10 lr 0.000021\t wd 0.0100\ttime 0.0397 (0.0358)\tloss 0.4319 (0.3779)\tgrad_norm 2.5275 (2.2664)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][330/625]\teta 0:00:10 lr 0.000021\t wd 0.0100\ttime 0.0354 (0.0358)\tloss 0.2139 (0.3792)\tgrad_norm 1.9502 (2.2749)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][340/625]\teta 0:00:10 lr 0.000021\t wd 0.0100\ttime 0.0363 (0.0358)\tloss 0.4299 (0.3780)\tgrad_norm 2.9882 (2.2713)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][350/625]\teta 0:00:09 lr 0.000021\t wd 0.0100\ttime 0.0354 (0.0358)\tloss 0.2737 (0.3778)\tgrad_norm 2.2017 (2.2663)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][360/625]\teta 0:00:09 lr 0.000021\t wd 0.0100\ttime 0.0341 (0.0358)\tloss 0.3364 (0.3765)\tgrad_norm 2.5591 (2.2630)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][370/625]\teta 0:00:09 lr 0.000021\t wd 0.0100\ttime 0.0357 (0.0358)\tloss 0.5264 (0.3774)\tgrad_norm 2.3726 (2.2593)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][380/625]\teta 0:00:08 lr 0.000021\t wd 0.0100\ttime 0.0326 (0.0358)\tloss 0.3726 (0.3774)\tgrad_norm 3.4161 (2.2636)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][390/625]\teta 0:00:08 lr 0.000021\t wd 0.0100\ttime 0.0354 (0.0357)\tloss 0.3508 (0.3781)\tgrad_norm 2.3128 (2.2643)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][400/625]\teta 0:00:08 lr 0.000020\t wd 0.0100\ttime 0.0359 (0.0357)\tloss 0.2737 (0.3774)\tgrad_norm 2.3248 (2.2656)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][410/625]\teta 0:00:07 lr 0.000020\t wd 0.0100\ttime 0.0403 (0.0357)\tloss 0.4858 (0.3792)\tgrad_norm 2.3987 (2.2719)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][420/625]\teta 0:00:07 lr 0.000020\t wd 0.0100\ttime 0.0355 (0.0357)\tloss 0.3528 (0.3783)\tgrad_norm 2.6662 (2.2740)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][430/625]\teta 0:00:06 lr 0.000020\t wd 0.0100\ttime 0.0386 (0.0357)\tloss 0.3562 (0.3781)\tgrad_norm 1.8669 (2.2682)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][440/625]\teta 0:00:06 lr 0.000020\t wd 0.0100\ttime 0.0328 (0.0357)\tloss 0.2520 (0.3777)\tgrad_norm 1.6536 (2.2716)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][450/625]\teta 0:00:06 lr 0.000020\t wd 0.0100\ttime 0.0367 (0.0357)\tloss 0.4753 (0.3776)\tgrad_norm 2.7816 (2.2699)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][460/625]\teta 0:00:05 lr 0.000020\t wd 0.0100\ttime 0.0388 (0.0357)\tloss 0.2585 (0.3778)\tgrad_norm 1.9022 (2.2709)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][470/625]\teta 0:00:05 lr 0.000020\t wd 0.0100\ttime 0.0384 (0.0357)\tloss 0.5898 (0.3787)\tgrad_norm 2.9083 (2.2746)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][480/625]\teta 0:00:05 lr 0.000020\t wd 0.0100\ttime 0.0358 (0.0357)\tloss 0.4622 (0.3789)\tgrad_norm 2.2486 (2.2743)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][490/625]\teta 0:00:04 lr 0.000020\t wd 0.0100\ttime 0.0347 (0.0357)\tloss 0.3098 (0.3782)\tgrad_norm 2.5657 (2.2758)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][500/625]\teta 0:00:04 lr 0.000020\t wd 0.0100\ttime 0.0381 (0.0357)\tloss 0.3459 (0.3776)\tgrad_norm 1.6771 (2.2754)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][510/625]\teta 0:00:04 lr 0.000020\t wd 0.0100\ttime 0.0324 (0.0357)\tloss 0.2852 (0.3789)\tgrad_norm 1.6184 (2.2806)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][520/625]\teta 0:00:03 lr 0.000020\t wd 0.0100\ttime 0.0368 (0.0357)\tloss 0.3896 (0.3792)\tgrad_norm 2.8553 (2.2859)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][530/625]\teta 0:00:03 lr 0.000020\t wd 0.0100\ttime 0.0361 (0.0357)\tloss 0.3582 (0.3789)\tgrad_norm 2.3628 (2.2861)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][540/625]\teta 0:00:03 lr 0.000020\t wd 0.0100\ttime 0.0359 (0.0357)\tloss 0.2627 (0.3785)\tgrad_norm 2.2310 (2.2869)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][550/625]\teta 0:00:02 lr 0.000020\t wd 0.0100\ttime 0.0324 (0.0357)\tloss 0.4431 (0.3791)\tgrad_norm 2.1354 (2.2882)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][560/625]\teta 0:00:02 lr 0.000020\t wd 0.0100\ttime 0.0361 (0.0358)\tloss 0.4590 (0.3800)\tgrad_norm 2.7529 (2.2931)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][570/625]\teta 0:00:01 lr 0.000020\t wd 0.0100\ttime 0.0330 (0.0358)\tloss 0.5005 (0.3801)\tgrad_norm 2.7204 (2.2908)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][580/625]\teta 0:00:01 lr 0.000020\t wd 0.0100\ttime 0.0324 (0.0357)\tloss 0.4004 (0.3806)\tgrad_norm 1.8803 (2.2949)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][590/625]\teta 0:00:01 lr 0.000019\t wd 0.0100\ttime 0.0328 (0.0357)\tloss 0.3252 (0.3812)\tgrad_norm 2.1298 (2.2963)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][600/625]\teta 0:00:00 lr 0.000019\t wd 0.0100\ttime 0.0384 (0.0357)\tloss 0.3623 (0.3808)\tgrad_norm 2.2208 (2.2951)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][610/625]\teta 0:00:00 lr 0.000019\t wd 0.0100\ttime 0.0349 (0.0357)\tloss 0.4712 (0.3809)\tgrad_norm 1.7103 (2.2941)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [93/100][620/625]\teta 0:00:00 lr 0.000019\t wd 0.0100\ttime 0.0374 (0.0357)\tloss 0.3564 (0.3813)\tgrad_norm 2.4408 (2.2947)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 93 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_93.pth saving......\n",
      "./model_save/ckpt_epoch_93.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.6162 (0.6162)\tAcc@1 79.688 (79.688)\tAcc@5 98.438 (98.438)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.6636 (0.5775)\tAcc@1 84.375 (81.960)\tAcc@5 100.000 (99.148)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.5659 (0.5648)\tAcc@1 81.250 (82.217)\tAcc@5 96.875 (99.107)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.4619 (0.5625)\tAcc@1 84.375 (82.258)\tAcc@5 100.000 (98.992)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.6475 (0.5722)\tAcc@1 82.812 (81.784)\tAcc@5 100.000 (98.933)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.7466 (0.5804)\tAcc@1 73.438 (81.281)\tAcc@5 100.000 (98.866)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.016 (0.015)\tLoss 0.5151 (0.5813)\tAcc@1 82.812 (81.071)\tAcc@5 100.000 (98.950)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.5952 (0.5813)\tAcc@1 78.125 (81.052)\tAcc@5 100.000 (98.966)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.4929 (0.5864)\tAcc@1 82.812 (81.250)\tAcc@5 100.000 (98.939)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.6978 (0.5877)\tAcc@1 76.562 (81.233)\tAcc@5 98.438 (98.918)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.4136 (0.5765)\tAcc@1 87.500 (81.544)\tAcc@5 100.000 (98.979)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.5566 (0.5799)\tAcc@1 82.812 (81.292)\tAcc@5 98.438 (98.972)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.016 (0.015)\tLoss 0.5186 (0.5812)\tAcc@1 82.812 (81.237)\tAcc@5 100.000 (99.006)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.6201 (0.5769)\tAcc@1 79.688 (81.381)\tAcc@5 98.438 (99.046)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.5298 (0.5716)\tAcc@1 82.812 (81.438)\tAcc@5 100.000 (99.091)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.7227 (0.5735)\tAcc@1 78.125 (81.395)\tAcc@5 100.000 (99.100)\tMem 455MB\n",
      " * Acc@1 81.350 Acc@5 99.080\n",
      "Accuracy of the network on the 10000 test images: 81.3%\n",
      "Max accuracy: 81.35%\n",
      "Train: [94/100][0/625]\teta 0:00:23 lr 0.000019\t wd 0.0100\ttime 0.0368 (0.0368)\tloss 0.4363 (0.4363)\tgrad_norm 2.1437 (2.1437)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [94/100][10/625]\teta 0:00:21 lr 0.000019\t wd 0.0100\ttime 0.0385 (0.0357)\tloss 0.3640 (0.3581)\tgrad_norm 2.4266 (2.1046)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [94/100][20/625]\teta 0:00:21 lr 0.000019\t wd 0.0100\ttime 0.0325 (0.0360)\tloss 0.2729 (0.3716)\tgrad_norm 1.5103 (2.1106)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [94/100][30/625]\teta 0:00:21 lr 0.000019\t wd 0.0100\ttime 0.0324 (0.0358)\tloss 0.3582 (0.3786)\tgrad_norm 1.9823 (nan)\tloss_scale 32768.0000 (33825.0323)\tmem 455MB\n",
      "Train: [94/100][40/625]\teta 0:00:20 lr 0.000019\t wd 0.0100\ttime 0.0327 (0.0359)\tloss 0.3296 (0.3780)\tgrad_norm 1.6907 (nan)\tloss_scale 32768.0000 (33567.2195)\tmem 455MB\n",
      "Train: [94/100][50/625]\teta 0:00:20 lr 0.000019\t wd 0.0100\ttime 0.0326 (0.0355)\tloss 0.3340 (0.3741)\tgrad_norm 2.2425 (nan)\tloss_scale 32768.0000 (33410.5098)\tmem 455MB\n",
      "Train: [94/100][60/625]\teta 0:00:20 lr 0.000019\t wd 0.0100\ttime 0.0325 (0.0355)\tloss 0.4197 (0.3727)\tgrad_norm 2.3968 (nan)\tloss_scale 32768.0000 (33305.1803)\tmem 455MB\n",
      "Train: [94/100][70/625]\teta 0:00:19 lr 0.000019\t wd 0.0100\ttime 0.0361 (0.0353)\tloss 0.3010 (0.3742)\tgrad_norm 1.8497 (nan)\tloss_scale 32768.0000 (33229.5211)\tmem 455MB\n",
      "Train: [94/100][80/625]\teta 0:00:19 lr 0.000019\t wd 0.0100\ttime 0.0322 (0.0351)\tloss 0.3660 (0.3728)\tgrad_norm 1.9678 (nan)\tloss_scale 32768.0000 (33172.5432)\tmem 455MB\n",
      "Train: [94/100][90/625]\teta 0:00:18 lr 0.000019\t wd 0.0100\ttime 0.0328 (0.0349)\tloss 0.3457 (0.3799)\tgrad_norm 2.0332 (nan)\tloss_scale 32768.0000 (33128.0879)\tmem 455MB\n",
      "Train: [94/100][100/625]\teta 0:00:18 lr 0.000019\t wd 0.0100\ttime 0.0371 (0.0349)\tloss 0.2947 (0.3790)\tgrad_norm 2.2524 (nan)\tloss_scale 32768.0000 (33092.4356)\tmem 455MB\n",
      "Train: [94/100][110/625]\teta 0:00:18 lr 0.000019\t wd 0.0100\ttime 0.0401 (0.0351)\tloss 0.3818 (0.3799)\tgrad_norm 2.2096 (nan)\tloss_scale 32768.0000 (33063.2072)\tmem 455MB\n",
      "Train: [94/100][120/625]\teta 0:00:17 lr 0.000019\t wd 0.0100\ttime 0.0389 (0.0352)\tloss 0.3687 (0.3811)\tgrad_norm 2.6288 (nan)\tloss_scale 32768.0000 (33038.8099)\tmem 455MB\n",
      "Train: [94/100][130/625]\teta 0:00:17 lr 0.000019\t wd 0.0100\ttime 0.0341 (0.0354)\tloss 0.2642 (0.3760)\tgrad_norm 1.9763 (nan)\tloss_scale 32768.0000 (33018.1374)\tmem 455MB\n",
      "Train: [94/100][140/625]\teta 0:00:17 lr 0.000019\t wd 0.0100\ttime 0.0362 (0.0354)\tloss 0.4141 (0.3753)\tgrad_norm 2.1269 (nan)\tloss_scale 32768.0000 (33000.3972)\tmem 455MB\n",
      "Train: [94/100][150/625]\teta 0:00:16 lr 0.000019\t wd 0.0100\ttime 0.0391 (0.0355)\tloss 0.3542 (0.3720)\tgrad_norm 1.8625 (nan)\tloss_scale 32768.0000 (32985.0066)\tmem 455MB\n",
      "Train: [94/100][160/625]\teta 0:00:16 lr 0.000019\t wd 0.0100\ttime 0.0330 (0.0355)\tloss 0.3157 (0.3720)\tgrad_norm 1.7585 (nan)\tloss_scale 32768.0000 (32971.5280)\tmem 455MB\n",
      "Train: [94/100][170/625]\teta 0:00:16 lr 0.000018\t wd 0.0100\ttime 0.0390 (0.0356)\tloss 0.7104 (0.3774)\tgrad_norm 4.0497 (nan)\tloss_scale 32768.0000 (32959.6257)\tmem 455MB\n",
      "Train: [94/100][180/625]\teta 0:00:15 lr 0.000018\t wd 0.0100\ttime 0.0354 (0.0356)\tloss 0.2632 (0.3775)\tgrad_norm 1.7267 (nan)\tloss_scale 32768.0000 (32949.0387)\tmem 455MB\n",
      "Train: [94/100][190/625]\teta 0:00:15 lr 0.000018\t wd 0.0100\ttime 0.0326 (0.0357)\tloss 0.3923 (0.3782)\tgrad_norm 2.7034 (nan)\tloss_scale 32768.0000 (32939.5602)\tmem 455MB\n",
      "Train: [94/100][200/625]\teta 0:00:15 lr 0.000018\t wd 0.0100\ttime 0.0402 (0.0357)\tloss 0.4185 (0.3768)\tgrad_norm 2.0643 (nan)\tloss_scale 32768.0000 (32931.0249)\tmem 455MB\n",
      "Train: [94/100][210/625]\teta 0:00:14 lr 0.000018\t wd 0.0100\ttime 0.0350 (0.0357)\tloss 0.3655 (0.3775)\tgrad_norm 2.4341 (nan)\tloss_scale 32768.0000 (32923.2986)\tmem 455MB\n",
      "Train: [94/100][220/625]\teta 0:00:14 lr 0.000018\t wd 0.0100\ttime 0.0364 (0.0358)\tloss 0.5713 (0.3776)\tgrad_norm 2.5387 (nan)\tloss_scale 32768.0000 (32916.2715)\tmem 455MB\n",
      "Train: [94/100][230/625]\teta 0:00:14 lr 0.000018\t wd 0.0100\ttime 0.0358 (0.0358)\tloss 0.2834 (0.3761)\tgrad_norm 1.7849 (nan)\tloss_scale 32768.0000 (32909.8528)\tmem 455MB\n",
      "Train: [94/100][240/625]\teta 0:00:13 lr 0.000018\t wd 0.0100\ttime 0.0353 (0.0358)\tloss 0.3831 (0.3764)\tgrad_norm 1.9794 (nan)\tloss_scale 32768.0000 (32903.9668)\tmem 455MB\n",
      "Train: [94/100][250/625]\teta 0:00:13 lr 0.000018\t wd 0.0100\ttime 0.0367 (0.0358)\tloss 0.5020 (0.3784)\tgrad_norm 2.1452 (nan)\tloss_scale 32768.0000 (32898.5498)\tmem 455MB\n",
      "Train: [94/100][260/625]\teta 0:00:13 lr 0.000018\t wd 0.0100\ttime 0.0322 (0.0358)\tloss 0.4341 (0.3780)\tgrad_norm 2.3540 (nan)\tloss_scale 32768.0000 (32893.5479)\tmem 455MB\n",
      "Train: [94/100][270/625]\teta 0:00:12 lr 0.000018\t wd 0.0100\ttime 0.0326 (0.0357)\tloss 0.3594 (0.3771)\tgrad_norm 1.5511 (nan)\tloss_scale 32768.0000 (32888.9151)\tmem 455MB\n",
      "Train: [94/100][280/625]\teta 0:00:12 lr 0.000018\t wd 0.0100\ttime 0.0325 (0.0357)\tloss 0.2578 (0.3784)\tgrad_norm 1.4667 (nan)\tloss_scale 32768.0000 (32884.6121)\tmem 455MB\n",
      "Train: [94/100][290/625]\teta 0:00:11 lr 0.000018\t wd 0.0100\ttime 0.0358 (0.0356)\tloss 0.2908 (0.3776)\tgrad_norm 1.8819 (nan)\tloss_scale 32768.0000 (32880.6048)\tmem 455MB\n",
      "Train: [94/100][300/625]\teta 0:00:11 lr 0.000018\t wd 0.0100\ttime 0.0327 (0.0355)\tloss 0.4656 (0.3792)\tgrad_norm 2.2041 (nan)\tloss_scale 32768.0000 (32876.8638)\tmem 455MB\n",
      "Train: [94/100][310/625]\teta 0:00:11 lr 0.000018\t wd 0.0100\ttime 0.0367 (0.0355)\tloss 0.2805 (0.3786)\tgrad_norm 1.6900 (nan)\tloss_scale 32768.0000 (32873.3633)\tmem 455MB\n",
      "Train: [94/100][320/625]\teta 0:00:10 lr 0.000018\t wd 0.0100\ttime 0.0352 (0.0354)\tloss 0.2981 (0.3775)\tgrad_norm 1.8546 (nan)\tloss_scale 32768.0000 (32870.0810)\tmem 455MB\n",
      "Train: [94/100][330/625]\teta 0:00:10 lr 0.000018\t wd 0.0100\ttime 0.0327 (0.0354)\tloss 0.3186 (0.3766)\tgrad_norm 2.2427 (nan)\tloss_scale 32768.0000 (32866.9970)\tmem 455MB\n",
      "Train: [94/100][340/625]\teta 0:00:10 lr 0.000018\t wd 0.0100\ttime 0.0368 (0.0354)\tloss 0.3589 (0.3760)\tgrad_norm 2.1987 (nan)\tloss_scale 32768.0000 (32864.0938)\tmem 455MB\n",
      "Train: [94/100][350/625]\teta 0:00:09 lr 0.000018\t wd 0.0100\ttime 0.0327 (0.0355)\tloss 0.4170 (0.3775)\tgrad_norm 2.7123 (nan)\tloss_scale 32768.0000 (32861.3561)\tmem 455MB\n",
      "Train: [94/100][360/625]\teta 0:00:09 lr 0.000018\t wd 0.0100\ttime 0.0349 (0.0355)\tloss 0.2913 (0.3780)\tgrad_norm 2.0479 (nan)\tloss_scale 32768.0000 (32858.7701)\tmem 455MB\n",
      "Train: [94/100][370/625]\teta 0:00:09 lr 0.000018\t wd 0.0100\ttime 0.0352 (0.0355)\tloss 0.3770 (0.3769)\tgrad_norm 2.4689 (nan)\tloss_scale 32768.0000 (32856.3235)\tmem 455MB\n",
      "Train: [94/100][380/625]\teta 0:00:08 lr 0.000018\t wd 0.0100\ttime 0.0360 (0.0355)\tloss 0.4746 (0.3791)\tgrad_norm 2.7576 (nan)\tloss_scale 32768.0000 (32854.0052)\tmem 455MB\n",
      "Train: [94/100][390/625]\teta 0:00:08 lr 0.000017\t wd 0.0100\ttime 0.0360 (0.0355)\tloss 0.3857 (0.3779)\tgrad_norm 2.0189 (nan)\tloss_scale 32768.0000 (32851.8056)\tmem 455MB\n",
      "Train: [94/100][400/625]\teta 0:00:07 lr 0.000017\t wd 0.0100\ttime 0.0360 (0.0355)\tloss 0.2052 (0.3770)\tgrad_norm 1.5900 (nan)\tloss_scale 32768.0000 (32849.7157)\tmem 455MB\n",
      "Train: [94/100][410/625]\teta 0:00:07 lr 0.000017\t wd 0.0100\ttime 0.0356 (0.0355)\tloss 0.3684 (0.3774)\tgrad_norm 2.4410 (nan)\tloss_scale 32768.0000 (32847.7275)\tmem 455MB\n",
      "Train: [94/100][420/625]\teta 0:00:07 lr 0.000017\t wd 0.0100\ttime 0.0327 (0.0355)\tloss 0.2744 (0.3788)\tgrad_norm 2.1519 (nan)\tloss_scale 32768.0000 (32845.8337)\tmem 455MB\n",
      "Train: [94/100][430/625]\teta 0:00:06 lr 0.000017\t wd 0.0100\ttime 0.0329 (0.0355)\tloss 0.2480 (0.3793)\tgrad_norm 2.0458 (nan)\tloss_scale 32768.0000 (32844.0278)\tmem 455MB\n",
      "Train: [94/100][440/625]\teta 0:00:06 lr 0.000017\t wd 0.0100\ttime 0.0397 (0.0356)\tloss 0.2471 (0.3798)\tgrad_norm 2.0285 (nan)\tloss_scale 32768.0000 (32842.3039)\tmem 455MB\n",
      "Train: [94/100][450/625]\teta 0:00:06 lr 0.000017\t wd 0.0100\ttime 0.0353 (0.0356)\tloss 0.4751 (0.3799)\tgrad_norm 2.5407 (nan)\tloss_scale 32768.0000 (32840.6563)\tmem 455MB\n",
      "Train: [94/100][460/625]\teta 0:00:05 lr 0.000017\t wd 0.0100\ttime 0.0383 (0.0356)\tloss 0.4062 (0.3795)\tgrad_norm 2.2494 (nan)\tloss_scale 32768.0000 (32839.0803)\tmem 455MB\n",
      "Train: [94/100][470/625]\teta 0:00:05 lr 0.000017\t wd 0.0100\ttime 0.0323 (0.0356)\tloss 0.5107 (0.3808)\tgrad_norm 2.0283 (nan)\tloss_scale 32768.0000 (32837.5711)\tmem 455MB\n",
      "Train: [94/100][480/625]\teta 0:00:05 lr 0.000017\t wd 0.0100\ttime 0.0393 (0.0356)\tloss 0.3223 (0.3797)\tgrad_norm 2.1951 (nan)\tloss_scale 32768.0000 (32836.1247)\tmem 455MB\n",
      "Train: [94/100][490/625]\teta 0:00:04 lr 0.000017\t wd 0.0100\ttime 0.0360 (0.0357)\tloss 0.2913 (0.3791)\tgrad_norm 2.2488 (nan)\tloss_scale 32768.0000 (32834.7373)\tmem 455MB\n",
      "Train: [94/100][500/625]\teta 0:00:04 lr 0.000017\t wd 0.0100\ttime 0.0392 (0.0357)\tloss 0.4990 (0.3790)\tgrad_norm 2.5971 (nan)\tloss_scale 32768.0000 (32833.4052)\tmem 455MB\n",
      "Train: [94/100][510/625]\teta 0:00:04 lr 0.000017\t wd 0.0100\ttime 0.0326 (0.0357)\tloss 0.4197 (0.3790)\tgrad_norm 2.1716 (nan)\tloss_scale 32768.0000 (32832.1252)\tmem 455MB\n",
      "Train: [94/100][520/625]\teta 0:00:03 lr 0.000017\t wd 0.0100\ttime 0.0360 (0.0357)\tloss 0.5244 (0.3795)\tgrad_norm 2.2109 (nan)\tloss_scale 32768.0000 (32830.8944)\tmem 455MB\n",
      "Train: [94/100][530/625]\teta 0:00:03 lr 0.000017\t wd 0.0100\ttime 0.0335 (0.0357)\tloss 0.4290 (0.3789)\tgrad_norm 2.3184 (nan)\tloss_scale 32768.0000 (32829.7100)\tmem 455MB\n",
      "Train: [94/100][540/625]\teta 0:00:03 lr 0.000017\t wd 0.0100\ttime 0.0365 (0.0357)\tloss 0.3718 (0.3795)\tgrad_norm 1.8389 (nan)\tloss_scale 32768.0000 (32828.5693)\tmem 455MB\n",
      "Train: [94/100][550/625]\teta 0:00:02 lr 0.000017\t wd 0.0100\ttime 0.0324 (0.0357)\tloss 0.4585 (0.3801)\tgrad_norm 2.4520 (nan)\tloss_scale 32768.0000 (32827.4701)\tmem 455MB\n",
      "Train: [94/100][560/625]\teta 0:00:02 lr 0.000017\t wd 0.0100\ttime 0.0327 (0.0357)\tloss 0.4175 (0.3803)\tgrad_norm 2.0915 (nan)\tloss_scale 32768.0000 (32826.4100)\tmem 455MB\n",
      "Train: [94/100][570/625]\teta 0:00:01 lr 0.000017\t wd 0.0100\ttime 0.0466 (0.0358)\tloss 0.4543 (0.3808)\tgrad_norm 2.8085 (nan)\tloss_scale 32768.0000 (32825.3870)\tmem 455MB\n",
      "Train: [94/100][580/625]\teta 0:00:01 lr 0.000017\t wd 0.0100\ttime 0.0343 (0.0358)\tloss 0.3865 (0.3802)\tgrad_norm 2.1444 (nan)\tloss_scale 32768.0000 (32824.3993)\tmem 455MB\n",
      "Train: [94/100][590/625]\teta 0:00:01 lr 0.000017\t wd 0.0100\ttime 0.0394 (0.0358)\tloss 0.4939 (0.3808)\tgrad_norm 3.2332 (nan)\tloss_scale 32768.0000 (32823.4450)\tmem 455MB\n",
      "Train: [94/100][600/625]\teta 0:00:00 lr 0.000017\t wd 0.0100\ttime 0.0360 (0.0358)\tloss 0.3181 (0.3801)\tgrad_norm 1.9644 (nan)\tloss_scale 32768.0000 (32822.5225)\tmem 455MB\n",
      "Train: [94/100][610/625]\teta 0:00:00 lr 0.000017\t wd 0.0100\ttime 0.0336 (0.0358)\tloss 0.2683 (0.3800)\tgrad_norm 1.3568 (nan)\tloss_scale 32768.0000 (32821.6301)\tmem 455MB\n",
      "Train: [94/100][620/625]\teta 0:00:00 lr 0.000016\t wd 0.0100\ttime 0.0364 (0.0358)\tloss 0.5664 (0.3798)\tgrad_norm 3.4159 (nan)\tloss_scale 32768.0000 (32820.7665)\tmem 455MB\n",
      "EPOCH 94 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_94.pth saving......\n",
      "./model_save/ckpt_epoch_94.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.4363 (0.4363)\tAcc@1 82.812 (82.812)\tAcc@5 98.438 (98.438)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.7720 (0.5595)\tAcc@1 70.312 (80.682)\tAcc@5 96.875 (98.864)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.7466 (0.5717)\tAcc@1 78.125 (81.548)\tAcc@5 96.875 (98.512)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.6162 (0.5883)\tAcc@1 76.562 (80.343)\tAcc@5 98.438 (98.740)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.3721 (0.5711)\tAcc@1 89.062 (80.983)\tAcc@5 100.000 (98.933)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.7148 (0.5785)\tAcc@1 76.562 (80.270)\tAcc@5 98.438 (98.897)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.5156 (0.5858)\tAcc@1 82.812 (79.944)\tAcc@5 100.000 (99.001)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.5356 (0.5755)\tAcc@1 84.375 (80.260)\tAcc@5 98.438 (99.032)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.3662 (0.5850)\tAcc@1 84.375 (80.112)\tAcc@5 100.000 (99.016)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.5972 (0.5807)\tAcc@1 81.250 (80.288)\tAcc@5 98.438 (99.056)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.6006 (0.5729)\tAcc@1 85.938 (80.709)\tAcc@5 98.438 (99.118)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.4841 (0.5654)\tAcc@1 84.375 (81.025)\tAcc@5 100.000 (99.127)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.8882 (0.5698)\tAcc@1 76.562 (81.056)\tAcc@5 92.188 (99.070)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.4119 (0.5705)\tAcc@1 85.938 (81.035)\tAcc@5 98.438 (99.070)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.7617 (0.5761)\tAcc@1 68.750 (80.751)\tAcc@5 100.000 (99.058)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.6274 (0.5792)\tAcc@1 79.688 (80.774)\tAcc@5 98.438 (99.069)\tMem 455MB\n",
      " * Acc@1 80.780 Acc@5 99.070\n",
      "Accuracy of the network on the 10000 test images: 80.8%\n",
      "Max accuracy: 81.35%\n",
      "Train: [95/100][0/625]\teta 0:00:25 lr 0.000016\t wd 0.0100\ttime 0.0407 (0.0407)\tloss 0.5728 (0.5728)\tgrad_norm 3.4161 (3.4161)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][10/625]\teta 0:00:21 lr 0.000016\t wd 0.0100\ttime 0.0352 (0.0358)\tloss 0.3303 (0.3220)\tgrad_norm 2.2550 (2.0178)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][20/625]\teta 0:00:21 lr 0.000016\t wd 0.0100\ttime 0.0346 (0.0358)\tloss 0.3633 (0.3411)\tgrad_norm 2.1714 (2.1020)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][30/625]\teta 0:00:21 lr 0.000016\t wd 0.0100\ttime 0.0325 (0.0358)\tloss 0.4512 (0.3709)\tgrad_norm 2.5882 (2.1397)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][40/625]\teta 0:00:20 lr 0.000016\t wd 0.0100\ttime 0.0326 (0.0356)\tloss 0.3159 (0.3727)\tgrad_norm 2.1449 (2.1589)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][50/625]\teta 0:00:20 lr 0.000016\t wd 0.0100\ttime 0.0338 (0.0356)\tloss 0.3384 (0.3814)\tgrad_norm 2.1590 (2.2326)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][60/625]\teta 0:00:20 lr 0.000016\t wd 0.0100\ttime 0.0327 (0.0357)\tloss 0.2952 (0.3716)\tgrad_norm 1.8169 (2.2077)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][70/625]\teta 0:00:19 lr 0.000016\t wd 0.0100\ttime 0.0330 (0.0357)\tloss 0.4268 (0.3750)\tgrad_norm 1.9844 (2.1972)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][80/625]\teta 0:00:19 lr 0.000016\t wd 0.0100\ttime 0.0391 (0.0360)\tloss 0.3220 (0.3792)\tgrad_norm 2.2291 (2.2206)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][90/625]\teta 0:00:19 lr 0.000016\t wd 0.0100\ttime 0.0345 (0.0360)\tloss 0.3242 (0.3748)\tgrad_norm 2.5540 (2.2202)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][100/625]\teta 0:00:18 lr 0.000016\t wd 0.0100\ttime 0.0361 (0.0361)\tloss 0.2466 (0.3762)\tgrad_norm 1.6564 (2.2285)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][110/625]\teta 0:00:18 lr 0.000016\t wd 0.0100\ttime 0.0340 (0.0361)\tloss 0.3875 (0.3780)\tgrad_norm 1.9152 (2.2367)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][120/625]\teta 0:00:18 lr 0.000016\t wd 0.0100\ttime 0.0336 (0.0361)\tloss 0.1654 (0.3805)\tgrad_norm 1.2701 (2.2347)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][130/625]\teta 0:00:17 lr 0.000016\t wd 0.0100\ttime 0.0342 (0.0361)\tloss 0.4099 (0.3825)\tgrad_norm 3.0226 (2.2677)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][140/625]\teta 0:00:17 lr 0.000016\t wd 0.0100\ttime 0.0391 (0.0361)\tloss 0.4548 (0.3844)\tgrad_norm 2.1427 (2.2558)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][150/625]\teta 0:00:17 lr 0.000016\t wd 0.0100\ttime 0.0419 (0.0361)\tloss 0.4951 (0.3870)\tgrad_norm 2.3829 (2.2559)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][160/625]\teta 0:00:16 lr 0.000016\t wd 0.0100\ttime 0.0391 (0.0360)\tloss 0.4521 (0.3864)\tgrad_norm 2.4689 (2.2522)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][170/625]\teta 0:00:16 lr 0.000016\t wd 0.0100\ttime 0.0323 (0.0360)\tloss 0.4531 (0.3871)\tgrad_norm 2.1513 (2.2430)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][180/625]\teta 0:00:16 lr 0.000016\t wd 0.0100\ttime 0.0360 (0.0361)\tloss 0.3511 (0.3867)\tgrad_norm 2.5499 (2.2481)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][190/625]\teta 0:00:15 lr 0.000016\t wd 0.0100\ttime 0.0387 (0.0361)\tloss 0.4351 (0.3869)\tgrad_norm 2.4066 (2.2502)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][200/625]\teta 0:00:15 lr 0.000016\t wd 0.0100\ttime 0.0350 (0.0361)\tloss 0.4614 (0.3860)\tgrad_norm 2.5717 (2.2524)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][210/625]\teta 0:00:14 lr 0.000016\t wd 0.0100\ttime 0.0326 (0.0360)\tloss 0.3833 (0.3856)\tgrad_norm 2.0604 (2.2467)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][220/625]\teta 0:00:14 lr 0.000016\t wd 0.0100\ttime 0.0358 (0.0359)\tloss 0.3936 (0.3855)\tgrad_norm 2.6082 (2.2473)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][230/625]\teta 0:00:14 lr 0.000016\t wd 0.0100\ttime 0.0325 (0.0360)\tloss 0.4202 (0.3851)\tgrad_norm 2.7372 (2.2547)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][240/625]\teta 0:00:13 lr 0.000016\t wd 0.0100\ttime 0.0326 (0.0360)\tloss 0.3047 (0.3870)\tgrad_norm 1.9308 (2.2566)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][250/625]\teta 0:00:13 lr 0.000015\t wd 0.0100\ttime 0.0392 (0.0360)\tloss 0.3938 (0.3876)\tgrad_norm 2.3262 (2.2531)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][260/625]\teta 0:00:13 lr 0.000015\t wd 0.0100\ttime 0.0345 (0.0360)\tloss 0.3906 (0.3897)\tgrad_norm 2.3812 (2.2601)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][270/625]\teta 0:00:12 lr 0.000015\t wd 0.0100\ttime 0.0386 (0.0360)\tloss 0.4602 (0.3893)\tgrad_norm 2.8706 (2.2576)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][280/625]\teta 0:00:12 lr 0.000015\t wd 0.0100\ttime 0.0373 (0.0360)\tloss 0.4355 (0.3899)\tgrad_norm 2.0844 (2.2602)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][290/625]\teta 0:00:12 lr 0.000015\t wd 0.0100\ttime 0.0326 (0.0360)\tloss 0.2888 (0.3913)\tgrad_norm 2.1290 (2.2612)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][300/625]\teta 0:00:11 lr 0.000015\t wd 0.0100\ttime 0.0358 (0.0360)\tloss 0.2776 (0.3905)\tgrad_norm 1.6151 (2.2548)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][310/625]\teta 0:00:11 lr 0.000015\t wd 0.0100\ttime 0.0380 (0.0360)\tloss 0.2491 (0.3904)\tgrad_norm 2.0234 (2.2517)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][320/625]\teta 0:00:10 lr 0.000015\t wd 0.0100\ttime 0.0324 (0.0360)\tloss 0.3547 (0.3886)\tgrad_norm 1.9953 (2.2441)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][330/625]\teta 0:00:10 lr 0.000015\t wd 0.0100\ttime 0.0353 (0.0359)\tloss 0.3049 (0.3864)\tgrad_norm 2.1600 (2.2379)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][340/625]\teta 0:00:10 lr 0.000015\t wd 0.0100\ttime 0.0356 (0.0359)\tloss 0.1818 (0.3861)\tgrad_norm 1.3183 (2.2373)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][350/625]\teta 0:00:09 lr 0.000015\t wd 0.0100\ttime 0.0354 (0.0359)\tloss 0.3220 (0.3861)\tgrad_norm 1.6657 (2.2385)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][360/625]\teta 0:00:09 lr 0.000015\t wd 0.0100\ttime 0.0360 (0.0359)\tloss 0.5249 (0.3861)\tgrad_norm 2.5151 (2.2355)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][370/625]\teta 0:00:09 lr 0.000015\t wd 0.0100\ttime 0.0324 (0.0359)\tloss 0.2700 (0.3849)\tgrad_norm 2.1770 (2.2342)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][380/625]\teta 0:00:08 lr 0.000015\t wd 0.0100\ttime 0.0329 (0.0358)\tloss 0.4546 (0.3847)\tgrad_norm 2.5696 (2.2397)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][390/625]\teta 0:00:08 lr 0.000015\t wd 0.0100\ttime 0.0381 (0.0358)\tloss 0.2676 (0.3836)\tgrad_norm 1.5858 (2.2355)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][400/625]\teta 0:00:08 lr 0.000015\t wd 0.0100\ttime 0.0359 (0.0359)\tloss 0.3582 (0.3841)\tgrad_norm 2.4528 (2.2375)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][410/625]\teta 0:00:07 lr 0.000015\t wd 0.0100\ttime 0.0392 (0.0358)\tloss 0.1820 (0.3834)\tgrad_norm 1.5026 (2.2353)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][420/625]\teta 0:00:07 lr 0.000015\t wd 0.0100\ttime 0.0379 (0.0359)\tloss 0.3008 (0.3831)\tgrad_norm 2.0652 (2.2378)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][430/625]\teta 0:00:06 lr 0.000015\t wd 0.0100\ttime 0.0354 (0.0359)\tloss 0.4211 (0.3825)\tgrad_norm 2.1479 (2.2391)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][440/625]\teta 0:00:06 lr 0.000015\t wd 0.0100\ttime 0.0323 (0.0359)\tloss 0.4304 (0.3816)\tgrad_norm 2.8656 (2.2356)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][450/625]\teta 0:00:06 lr 0.000015\t wd 0.0100\ttime 0.0364 (0.0359)\tloss 0.2499 (0.3817)\tgrad_norm 2.1585 (2.2400)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][460/625]\teta 0:00:05 lr 0.000015\t wd 0.0100\ttime 0.0361 (0.0358)\tloss 0.3127 (0.3818)\tgrad_norm 1.9348 (2.2425)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][470/625]\teta 0:00:05 lr 0.000015\t wd 0.0100\ttime 0.0352 (0.0358)\tloss 0.5557 (0.3809)\tgrad_norm 2.4653 (2.2397)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][480/625]\teta 0:00:05 lr 0.000015\t wd 0.0100\ttime 0.0375 (0.0358)\tloss 0.2457 (0.3806)\tgrad_norm 1.7782 (2.2397)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][490/625]\teta 0:00:04 lr 0.000015\t wd 0.0100\ttime 0.0385 (0.0358)\tloss 0.3672 (0.3796)\tgrad_norm 2.3676 (2.2387)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][500/625]\teta 0:00:04 lr 0.000015\t wd 0.0100\ttime 0.0381 (0.0358)\tloss 0.3765 (0.3791)\tgrad_norm 2.0480 (2.2351)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][510/625]\teta 0:00:04 lr 0.000015\t wd 0.0100\ttime 0.0387 (0.0358)\tloss 0.3396 (0.3790)\tgrad_norm 2.0897 (2.2346)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][520/625]\teta 0:00:03 lr 0.000015\t wd 0.0100\ttime 0.0357 (0.0358)\tloss 0.6206 (0.3791)\tgrad_norm 2.8520 (2.2363)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][530/625]\teta 0:00:03 lr 0.000014\t wd 0.0100\ttime 0.0386 (0.0358)\tloss 0.6138 (0.3794)\tgrad_norm 2.4702 (2.2395)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][540/625]\teta 0:00:03 lr 0.000014\t wd 0.0100\ttime 0.0328 (0.0358)\tloss 0.3660 (0.3801)\tgrad_norm 2.7713 (2.2425)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][550/625]\teta 0:00:02 lr 0.000014\t wd 0.0100\ttime 0.0326 (0.0358)\tloss 0.4175 (0.3794)\tgrad_norm 1.9481 (2.2425)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][560/625]\teta 0:00:02 lr 0.000014\t wd 0.0100\ttime 0.0325 (0.0358)\tloss 0.4795 (0.3806)\tgrad_norm 2.3922 (2.2420)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][570/625]\teta 0:00:01 lr 0.000014\t wd 0.0100\ttime 0.0327 (0.0358)\tloss 0.3665 (0.3800)\tgrad_norm 1.9676 (2.2415)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][580/625]\teta 0:00:01 lr 0.000014\t wd 0.0100\ttime 0.0325 (0.0358)\tloss 0.4563 (0.3798)\tgrad_norm 2.6969 (2.2423)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][590/625]\teta 0:00:01 lr 0.000014\t wd 0.0100\ttime 0.0329 (0.0358)\tloss 0.3096 (0.3800)\tgrad_norm 1.9972 (2.2418)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][600/625]\teta 0:00:00 lr 0.000014\t wd 0.0100\ttime 0.0395 (0.0358)\tloss 0.3599 (0.3801)\tgrad_norm 2.3990 (2.2448)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][610/625]\teta 0:00:00 lr 0.000014\t wd 0.0100\ttime 0.0328 (0.0358)\tloss 0.5044 (0.3793)\tgrad_norm 4.0535 (2.2474)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [95/100][620/625]\teta 0:00:00 lr 0.000014\t wd 0.0100\ttime 0.0324 (0.0358)\tloss 0.4736 (0.3790)\tgrad_norm 3.1284 (2.2491)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 95 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_95.pth saving......\n",
      "./model_save/ckpt_epoch_95.pth saved !!!\n",
      "Test: [0/157]\tTime 0.020 (0.020)\tLoss 0.7012 (0.7012)\tAcc@1 79.688 (79.688)\tAcc@5 100.000 (100.000)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.016)\tLoss 0.6279 (0.6040)\tAcc@1 78.125 (80.540)\tAcc@5 100.000 (99.006)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.016)\tLoss 0.8418 (0.6175)\tAcc@1 76.562 (80.729)\tAcc@5 96.875 (98.735)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.2737 (0.5874)\tAcc@1 89.062 (81.452)\tAcc@5 100.000 (98.790)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.5322 (0.5808)\tAcc@1 81.250 (81.555)\tAcc@5 100.000 (98.895)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.4531 (0.5802)\tAcc@1 78.125 (81.403)\tAcc@5 100.000 (98.866)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.4851 (0.5723)\tAcc@1 82.812 (81.737)\tAcc@5 100.000 (98.899)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.3999 (0.5677)\tAcc@1 79.688 (81.756)\tAcc@5 100.000 (98.944)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.4868 (0.5740)\tAcc@1 87.500 (81.424)\tAcc@5 98.438 (98.958)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.4214 (0.5706)\tAcc@1 81.250 (81.559)\tAcc@5 100.000 (98.901)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.016 (0.015)\tLoss 0.5635 (0.5658)\tAcc@1 81.250 (81.606)\tAcc@5 100.000 (98.963)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.4424 (0.5691)\tAcc@1 84.375 (81.447)\tAcc@5 100.000 (98.986)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.6270 (0.5708)\tAcc@1 75.000 (81.327)\tAcc@5 100.000 (99.032)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.4031 (0.5727)\tAcc@1 87.500 (81.274)\tAcc@5 100.000 (98.974)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.6689 (0.5766)\tAcc@1 79.688 (81.172)\tAcc@5 100.000 (98.980)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.4248 (0.5771)\tAcc@1 84.375 (81.178)\tAcc@5 98.438 (98.976)\tMem 455MB\n",
      " * Acc@1 81.200 Acc@5 98.990\n",
      "Accuracy of the network on the 10000 test images: 81.2%\n",
      "Max accuracy: 81.35%\n",
      "Train: [96/100][0/625]\teta 0:00:23 lr 0.000014\t wd 0.0100\ttime 0.0384 (0.0384)\tloss 0.3918 (0.3918)\tgrad_norm 2.1184 (2.1184)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][10/625]\teta 0:00:22 lr 0.000014\t wd 0.0100\ttime 0.0412 (0.0363)\tloss 0.3604 (0.3698)\tgrad_norm 2.1645 (2.1904)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][20/625]\teta 0:00:21 lr 0.000014\t wd 0.0100\ttime 0.0324 (0.0356)\tloss 0.3845 (0.3825)\tgrad_norm 1.8287 (2.2173)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][30/625]\teta 0:00:21 lr 0.000014\t wd 0.0100\ttime 0.0383 (0.0359)\tloss 0.4333 (0.3852)\tgrad_norm 2.6837 (2.2023)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][40/625]\teta 0:00:21 lr 0.000014\t wd 0.0100\ttime 0.0395 (0.0363)\tloss 0.3127 (0.3664)\tgrad_norm 1.4742 (2.1205)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][50/625]\teta 0:00:20 lr 0.000014\t wd 0.0100\ttime 0.0347 (0.0361)\tloss 0.3098 (0.3579)\tgrad_norm 1.7019 (2.1284)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][60/625]\teta 0:00:20 lr 0.000014\t wd 0.0100\ttime 0.0398 (0.0361)\tloss 0.4163 (0.3605)\tgrad_norm 2.1787 (2.1281)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][70/625]\teta 0:00:19 lr 0.000014\t wd 0.0100\ttime 0.0381 (0.0359)\tloss 0.3120 (0.3604)\tgrad_norm 1.8464 (2.1619)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][80/625]\teta 0:00:19 lr 0.000014\t wd 0.0100\ttime 0.0333 (0.0360)\tloss 0.3860 (0.3635)\tgrad_norm 1.9714 (2.1598)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][90/625]\teta 0:00:19 lr 0.000014\t wd 0.0100\ttime 0.0328 (0.0360)\tloss 0.3223 (0.3691)\tgrad_norm 2.5311 (2.1903)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][100/625]\teta 0:00:18 lr 0.000014\t wd 0.0100\ttime 0.0325 (0.0362)\tloss 0.5547 (0.3716)\tgrad_norm 2.6490 (2.2202)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][110/625]\teta 0:00:18 lr 0.000014\t wd 0.0100\ttime 0.0326 (0.0361)\tloss 0.4358 (0.3757)\tgrad_norm 2.3659 (2.2497)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][120/625]\teta 0:00:18 lr 0.000014\t wd 0.0100\ttime 0.0324 (0.0360)\tloss 0.2820 (0.3721)\tgrad_norm 1.7965 (2.2369)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][130/625]\teta 0:00:17 lr 0.000014\t wd 0.0100\ttime 0.0393 (0.0361)\tloss 0.5894 (0.3697)\tgrad_norm 2.9560 (2.2300)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][140/625]\teta 0:00:17 lr 0.000014\t wd 0.0100\ttime 0.0354 (0.0360)\tloss 0.2335 (0.3686)\tgrad_norm 2.4273 (2.2355)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][150/625]\teta 0:00:17 lr 0.000014\t wd 0.0100\ttime 0.0326 (0.0360)\tloss 0.4424 (0.3644)\tgrad_norm 2.9839 (2.2280)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][160/625]\teta 0:00:16 lr 0.000014\t wd 0.0100\ttime 0.0357 (0.0359)\tloss 0.5830 (0.3686)\tgrad_norm 2.5239 (2.2348)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][170/625]\teta 0:00:16 lr 0.000014\t wd 0.0100\ttime 0.0341 (0.0359)\tloss 0.3108 (0.3724)\tgrad_norm 2.2639 (2.2445)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][180/625]\teta 0:00:15 lr 0.000014\t wd 0.0100\ttime 0.0323 (0.0358)\tloss 0.1555 (0.3687)\tgrad_norm 1.2307 (2.2283)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][190/625]\teta 0:00:15 lr 0.000014\t wd 0.0100\ttime 0.0351 (0.0358)\tloss 0.3777 (0.3697)\tgrad_norm 2.3128 (2.2341)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][200/625]\teta 0:00:15 lr 0.000014\t wd 0.0100\ttime 0.0390 (0.0358)\tloss 0.3650 (0.3690)\tgrad_norm 2.3965 (2.2400)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][210/625]\teta 0:00:14 lr 0.000013\t wd 0.0100\ttime 0.0326 (0.0358)\tloss 0.3621 (0.3686)\tgrad_norm 2.0305 (2.2350)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][220/625]\teta 0:00:14 lr 0.000013\t wd 0.0100\ttime 0.0375 (0.0358)\tloss 0.5142 (0.3680)\tgrad_norm 3.2062 (2.2377)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][230/625]\teta 0:00:14 lr 0.000013\t wd 0.0100\ttime 0.0352 (0.0358)\tloss 0.3650 (0.3688)\tgrad_norm 1.6622 (2.2344)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][240/625]\teta 0:00:13 lr 0.000013\t wd 0.0100\ttime 0.0346 (0.0358)\tloss 0.4688 (0.3715)\tgrad_norm 2.0923 (2.2486)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][250/625]\teta 0:00:13 lr 0.000013\t wd 0.0100\ttime 0.0381 (0.0359)\tloss 0.5322 (0.3712)\tgrad_norm 2.2542 (2.2446)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][260/625]\teta 0:00:13 lr 0.000013\t wd 0.0100\ttime 0.0325 (0.0359)\tloss 0.3333 (0.3704)\tgrad_norm 2.3367 (2.2444)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][270/625]\teta 0:00:12 lr 0.000013\t wd 0.0100\ttime 0.0328 (0.0359)\tloss 0.4890 (0.3725)\tgrad_norm 2.2663 (2.2568)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][280/625]\teta 0:00:12 lr 0.000013\t wd 0.0100\ttime 0.0367 (0.0359)\tloss 0.3914 (0.3723)\tgrad_norm 2.1014 (2.2493)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][290/625]\teta 0:00:12 lr 0.000013\t wd 0.0100\ttime 0.0361 (0.0359)\tloss 0.3799 (0.3709)\tgrad_norm 2.1485 (2.2442)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][300/625]\teta 0:00:11 lr 0.000013\t wd 0.0100\ttime 0.0365 (0.0359)\tloss 0.3450 (0.3694)\tgrad_norm 2.2375 (2.2400)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][310/625]\teta 0:00:11 lr 0.000013\t wd 0.0100\ttime 0.0326 (0.0359)\tloss 0.3721 (0.3704)\tgrad_norm 2.2268 (2.2469)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][320/625]\teta 0:00:10 lr 0.000013\t wd 0.0100\ttime 0.0364 (0.0359)\tloss 0.3010 (0.3707)\tgrad_norm 1.8667 (2.2438)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][330/625]\teta 0:00:10 lr 0.000013\t wd 0.0100\ttime 0.0391 (0.0359)\tloss 0.3076 (0.3717)\tgrad_norm 3.1538 (2.2477)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][340/625]\teta 0:00:10 lr 0.000013\t wd 0.0100\ttime 0.0357 (0.0359)\tloss 0.4346 (0.3719)\tgrad_norm 2.3407 (2.2533)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][350/625]\teta 0:00:09 lr 0.000013\t wd 0.0100\ttime 0.0386 (0.0359)\tloss 0.3748 (0.3734)\tgrad_norm 3.1261 (2.2613)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][360/625]\teta 0:00:09 lr 0.000013\t wd 0.0100\ttime 0.0350 (0.0359)\tloss 0.3171 (0.3737)\tgrad_norm 1.4437 (2.2571)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][370/625]\teta 0:00:09 lr 0.000013\t wd 0.0100\ttime 0.0351 (0.0360)\tloss 0.3342 (0.3736)\tgrad_norm 1.7418 (2.2588)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][380/625]\teta 0:00:08 lr 0.000013\t wd 0.0100\ttime 0.0327 (0.0359)\tloss 0.3550 (0.3751)\tgrad_norm 2.0731 (2.2656)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][390/625]\teta 0:00:08 lr 0.000013\t wd 0.0100\ttime 0.0324 (0.0359)\tloss 0.2300 (0.3779)\tgrad_norm 1.7729 (2.2702)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][400/625]\teta 0:00:08 lr 0.000013\t wd 0.0100\ttime 0.0398 (0.0359)\tloss 0.3198 (0.3786)\tgrad_norm 2.3380 (2.2703)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][410/625]\teta 0:00:07 lr 0.000013\t wd 0.0100\ttime 0.0398 (0.0360)\tloss 0.2869 (0.3780)\tgrad_norm 2.8032 (2.2707)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][420/625]\teta 0:00:07 lr 0.000013\t wd 0.0100\ttime 0.0362 (0.0360)\tloss 0.2722 (0.3782)\tgrad_norm 2.0015 (2.2728)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][430/625]\teta 0:00:07 lr 0.000013\t wd 0.0100\ttime 0.0348 (0.0360)\tloss 0.2913 (0.3775)\tgrad_norm 2.4452 (2.2720)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][440/625]\teta 0:00:06 lr 0.000013\t wd 0.0100\ttime 0.0394 (0.0360)\tloss 0.4187 (0.3783)\tgrad_norm 2.4655 (2.2739)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][450/625]\teta 0:00:06 lr 0.000013\t wd 0.0100\ttime 0.0327 (0.0360)\tloss 0.4443 (0.3781)\tgrad_norm 2.7365 (2.2725)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][460/625]\teta 0:00:05 lr 0.000013\t wd 0.0100\ttime 0.0326 (0.0359)\tloss 0.4609 (0.3789)\tgrad_norm 2.6845 (2.2821)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][470/625]\teta 0:00:05 lr 0.000013\t wd 0.0100\ttime 0.0332 (0.0359)\tloss 0.3374 (0.3792)\tgrad_norm 2.1669 (2.2824)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][480/625]\teta 0:00:05 lr 0.000013\t wd 0.0100\ttime 0.0323 (0.0359)\tloss 0.3428 (0.3800)\tgrad_norm 1.9293 (2.2889)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][490/625]\teta 0:00:04 lr 0.000013\t wd 0.0100\ttime 0.0329 (0.0359)\tloss 0.3228 (0.3790)\tgrad_norm 2.6109 (2.2850)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][500/625]\teta 0:00:04 lr 0.000013\t wd 0.0100\ttime 0.0329 (0.0359)\tloss 0.3503 (0.3799)\tgrad_norm 2.2818 (2.2889)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][510/625]\teta 0:00:04 lr 0.000013\t wd 0.0100\ttime 0.0392 (0.0359)\tloss 0.3723 (0.3796)\tgrad_norm 2.0321 (2.2857)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][520/625]\teta 0:00:03 lr 0.000013\t wd 0.0100\ttime 0.0351 (0.0359)\tloss 0.3208 (0.3800)\tgrad_norm 2.0861 (2.2853)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][530/625]\teta 0:00:03 lr 0.000013\t wd 0.0100\ttime 0.0354 (0.0359)\tloss 0.4124 (0.3796)\tgrad_norm 1.9037 (2.2842)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][540/625]\teta 0:00:03 lr 0.000013\t wd 0.0100\ttime 0.0398 (0.0359)\tloss 0.3103 (0.3793)\tgrad_norm 2.4505 (2.2838)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][550/625]\teta 0:00:02 lr 0.000013\t wd 0.0100\ttime 0.0358 (0.0359)\tloss 0.3198 (0.3784)\tgrad_norm 2.4795 (2.2816)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][560/625]\teta 0:00:02 lr 0.000012\t wd 0.0100\ttime 0.0385 (0.0359)\tloss 0.4675 (0.3784)\tgrad_norm 2.5205 (2.2850)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][570/625]\teta 0:00:01 lr 0.000012\t wd 0.0100\ttime 0.0321 (0.0359)\tloss 0.3496 (0.3782)\tgrad_norm 1.7355 (2.2823)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][580/625]\teta 0:00:01 lr 0.000012\t wd 0.0100\ttime 0.0363 (0.0358)\tloss 0.3928 (0.3783)\tgrad_norm 2.0381 (2.2774)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][590/625]\teta 0:00:01 lr 0.000012\t wd 0.0100\ttime 0.0324 (0.0358)\tloss 0.3420 (0.3776)\tgrad_norm 1.8734 (2.2741)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][600/625]\teta 0:00:00 lr 0.000012\t wd 0.0100\ttime 0.0341 (0.0358)\tloss 0.4712 (0.3775)\tgrad_norm 2.8569 (2.2732)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][610/625]\teta 0:00:00 lr 0.000012\t wd 0.0100\ttime 0.0352 (0.0358)\tloss 0.5225 (0.3778)\tgrad_norm 2.8691 (2.2710)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [96/100][620/625]\teta 0:00:00 lr 0.000012\t wd 0.0100\ttime 0.0327 (0.0358)\tloss 0.3340 (0.3780)\tgrad_norm 3.0568 (2.2707)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 96 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_96.pth saving......\n",
      "./model_save/ckpt_epoch_96.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.5923 (0.5923)\tAcc@1 85.938 (85.938)\tAcc@5 98.438 (98.438)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.7783 (0.5538)\tAcc@1 76.562 (81.108)\tAcc@5 100.000 (99.716)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.7222 (0.5668)\tAcc@1 78.125 (81.473)\tAcc@5 96.875 (99.405)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.7583 (0.5712)\tAcc@1 75.000 (81.452)\tAcc@5 100.000 (99.345)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.6646 (0.5833)\tAcc@1 79.688 (80.907)\tAcc@5 100.000 (99.314)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.3801 (0.5662)\tAcc@1 89.062 (81.587)\tAcc@5 98.438 (99.295)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.6226 (0.5663)\tAcc@1 82.812 (81.429)\tAcc@5 96.875 (99.232)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.7168 (0.5651)\tAcc@1 73.438 (81.470)\tAcc@5 98.438 (99.164)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.6997 (0.5726)\tAcc@1 82.812 (81.346)\tAcc@5 100.000 (99.093)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.016 (0.015)\tLoss 0.6050 (0.5712)\tAcc@1 82.812 (81.387)\tAcc@5 98.438 (99.124)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.5435 (0.5686)\tAcc@1 75.000 (81.312)\tAcc@5 100.000 (99.180)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.5645 (0.5750)\tAcc@1 78.125 (81.081)\tAcc@5 100.000 (99.127)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.5229 (0.5776)\tAcc@1 81.250 (80.992)\tAcc@5 100.000 (99.148)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.4636 (0.5752)\tAcc@1 81.250 (81.083)\tAcc@5 100.000 (99.153)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.3499 (0.5660)\tAcc@1 87.500 (81.438)\tAcc@5 100.000 (99.191)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.8223 (0.5653)\tAcc@1 75.000 (81.436)\tAcc@5 98.438 (99.183)\tMem 455MB\n",
      " * Acc@1 81.550 Acc@5 99.190\n",
      "Accuracy of the network on the 10000 test images: 81.5%\n",
      "Max accuracy: 81.55%\n",
      "Train: [97/100][0/625]\teta 0:00:28 lr 0.000012\t wd 0.0100\ttime 0.0452 (0.0452)\tloss 0.4023 (0.4023)\tgrad_norm 2.2404 (2.2404)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [97/100][10/625]\teta 0:00:21 lr 0.000012\t wd 0.0100\ttime 0.0327 (0.0353)\tloss 0.4150 (0.4088)\tgrad_norm 1.9803 (2.2883)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [97/100][20/625]\teta 0:00:21 lr 0.000012\t wd 0.0100\ttime 0.0366 (0.0354)\tloss 0.3982 (0.3851)\tgrad_norm 2.1726 (2.3160)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [97/100][30/625]\teta 0:00:21 lr 0.000012\t wd 0.0100\ttime 0.0350 (0.0353)\tloss 0.1605 (0.3712)\tgrad_norm 1.4319 (2.2870)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [97/100][40/625]\teta 0:00:20 lr 0.000012\t wd 0.0100\ttime 0.0366 (0.0355)\tloss 0.5195 (0.3757)\tgrad_norm 2.4169 (2.3286)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [97/100][50/625]\teta 0:00:20 lr 0.000012\t wd 0.0100\ttime 0.0325 (0.0356)\tloss 0.4473 (0.3760)\tgrad_norm 4.1381 (2.3235)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [97/100][60/625]\teta 0:00:19 lr 0.000012\t wd 0.0100\ttime 0.0330 (0.0354)\tloss 0.5361 (0.3744)\tgrad_norm 2.3278 (2.3218)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [97/100][70/625]\teta 0:00:19 lr 0.000012\t wd 0.0100\ttime 0.0348 (0.0354)\tloss 0.4617 (0.3762)\tgrad_norm 1.7389 (2.3136)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [97/100][80/625]\teta 0:00:19 lr 0.000012\t wd 0.0100\ttime 0.0355 (0.0355)\tloss 0.4612 (0.3720)\tgrad_norm 2.1190 (2.2801)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [97/100][90/625]\teta 0:00:19 lr 0.000012\t wd 0.0100\ttime 0.0392 (0.0356)\tloss 0.3494 (0.3709)\tgrad_norm 3.1946 (2.2817)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [97/100][100/625]\teta 0:00:18 lr 0.000012\t wd 0.0100\ttime 0.0359 (0.0356)\tloss 0.2438 (0.3705)\tgrad_norm 1.3199 (2.2667)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [97/100][110/625]\teta 0:00:18 lr 0.000012\t wd 0.0100\ttime 0.0334 (0.0354)\tloss 0.4751 (0.3705)\tgrad_norm 2.2669 (2.2537)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [97/100][120/625]\teta 0:00:17 lr 0.000012\t wd 0.0100\ttime 0.0327 (0.0354)\tloss 0.4258 (0.3690)\tgrad_norm 2.2074 (2.2628)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [97/100][130/625]\teta 0:00:17 lr 0.000012\t wd 0.0100\ttime 0.0329 (0.0355)\tloss 0.4800 (0.3691)\tgrad_norm 2.2558 (2.2625)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [97/100][140/625]\teta 0:00:17 lr 0.000012\t wd 0.0100\ttime 0.0389 (0.0356)\tloss 0.4243 (0.3663)\tgrad_norm 2.4416 (2.2706)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [97/100][150/625]\teta 0:00:16 lr 0.000012\t wd 0.0100\ttime 0.0360 (0.0356)\tloss 0.5176 (0.3674)\tgrad_norm 2.4973 (2.2699)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [97/100][160/625]\teta 0:00:16 lr 0.000012\t wd 0.0100\ttime 0.0352 (0.0356)\tloss 0.3137 (0.3679)\tgrad_norm 1.6478 (nan)\tloss_scale 32768.0000 (32971.5280)\tmem 455MB\n",
      "Train: [97/100][170/625]\teta 0:00:16 lr 0.000012\t wd 0.0100\ttime 0.0324 (0.0356)\tloss 0.4961 (0.3699)\tgrad_norm 2.0795 (nan)\tloss_scale 32768.0000 (32959.6257)\tmem 455MB\n",
      "Train: [97/100][180/625]\teta 0:00:15 lr 0.000012\t wd 0.0100\ttime 0.0350 (0.0356)\tloss 0.3594 (0.3682)\tgrad_norm 2.7421 (nan)\tloss_scale 32768.0000 (32949.0387)\tmem 455MB\n",
      "Train: [97/100][190/625]\teta 0:00:15 lr 0.000012\t wd 0.0100\ttime 0.0326 (0.0355)\tloss 0.2908 (0.3707)\tgrad_norm 1.7311 (nan)\tloss_scale 32768.0000 (32939.5602)\tmem 455MB\n",
      "Train: [97/100][200/625]\teta 0:00:15 lr 0.000012\t wd 0.0100\ttime 0.0322 (0.0354)\tloss 0.3608 (0.3711)\tgrad_norm 2.3384 (nan)\tloss_scale 32768.0000 (32931.0249)\tmem 455MB\n",
      "Train: [97/100][210/625]\teta 0:00:14 lr 0.000012\t wd 0.0100\ttime 0.0327 (0.0353)\tloss 0.3115 (0.3741)\tgrad_norm 1.9994 (nan)\tloss_scale 32768.0000 (32923.2986)\tmem 455MB\n",
      "Train: [97/100][220/625]\teta 0:00:14 lr 0.000012\t wd 0.0100\ttime 0.0325 (0.0353)\tloss 0.4009 (0.3748)\tgrad_norm 2.6309 (nan)\tloss_scale 32768.0000 (32916.2715)\tmem 455MB\n",
      "Train: [97/100][230/625]\teta 0:00:13 lr 0.000012\t wd 0.0100\ttime 0.0390 (0.0353)\tloss 0.3823 (0.3748)\tgrad_norm 2.5568 (nan)\tloss_scale 32768.0000 (32909.8528)\tmem 455MB\n",
      "Train: [97/100][240/625]\teta 0:00:13 lr 0.000012\t wd 0.0100\ttime 0.0396 (0.0354)\tloss 0.3237 (0.3733)\tgrad_norm 1.8350 (nan)\tloss_scale 32768.0000 (32903.9668)\tmem 455MB\n",
      "Train: [97/100][250/625]\teta 0:00:13 lr 0.000012\t wd 0.0100\ttime 0.0396 (0.0354)\tloss 0.2671 (0.3728)\tgrad_norm 2.1598 (nan)\tloss_scale 32768.0000 (32898.5498)\tmem 455MB\n",
      "Train: [97/100][260/625]\teta 0:00:12 lr 0.000012\t wd 0.0100\ttime 0.0352 (0.0354)\tloss 0.3518 (0.3707)\tgrad_norm 2.1020 (nan)\tloss_scale 32768.0000 (32893.5479)\tmem 455MB\n",
      "Train: [97/100][270/625]\teta 0:00:12 lr 0.000012\t wd 0.0100\ttime 0.0352 (0.0354)\tloss 0.3726 (0.3706)\tgrad_norm 2.1190 (nan)\tloss_scale 32768.0000 (32888.9151)\tmem 455MB\n",
      "Train: [97/100][280/625]\teta 0:00:12 lr 0.000012\t wd 0.0100\ttime 0.0327 (0.0354)\tloss 0.4363 (0.3722)\tgrad_norm 2.3808 (nan)\tloss_scale 32768.0000 (32884.6121)\tmem 455MB\n",
      "Train: [97/100][290/625]\teta 0:00:11 lr 0.000012\t wd 0.0100\ttime 0.0357 (0.0354)\tloss 0.2576 (0.3702)\tgrad_norm 1.8477 (nan)\tloss_scale 32768.0000 (32880.6048)\tmem 455MB\n",
      "Train: [97/100][300/625]\teta 0:00:11 lr 0.000012\t wd 0.0100\ttime 0.0328 (0.0355)\tloss 0.4368 (0.3705)\tgrad_norm 1.9632 (nan)\tloss_scale 32768.0000 (32876.8638)\tmem 455MB\n",
      "Train: [97/100][310/625]\teta 0:00:11 lr 0.000012\t wd 0.0100\ttime 0.0356 (0.0355)\tloss 0.2739 (0.3708)\tgrad_norm 1.9136 (nan)\tloss_scale 32768.0000 (32873.3633)\tmem 455MB\n",
      "Train: [97/100][320/625]\teta 0:00:10 lr 0.000012\t wd 0.0100\ttime 0.0383 (0.0355)\tloss 0.4346 (0.3705)\tgrad_norm 2.4858 (nan)\tloss_scale 32768.0000 (32870.0810)\tmem 455MB\n",
      "Train: [97/100][330/625]\teta 0:00:10 lr 0.000012\t wd 0.0100\ttime 0.0401 (0.0355)\tloss 0.1696 (0.3688)\tgrad_norm 1.4316 (nan)\tloss_scale 32768.0000 (32866.9970)\tmem 455MB\n",
      "Train: [97/100][340/625]\teta 0:00:10 lr 0.000012\t wd 0.0100\ttime 0.0372 (0.0355)\tloss 0.3083 (0.3691)\tgrad_norm 2.0489 (nan)\tloss_scale 32768.0000 (32864.0938)\tmem 455MB\n",
      "Train: [97/100][350/625]\teta 0:00:09 lr 0.000012\t wd 0.0100\ttime 0.0327 (0.0355)\tloss 0.4045 (0.3691)\tgrad_norm 2.2479 (nan)\tloss_scale 32768.0000 (32861.3561)\tmem 455MB\n",
      "Train: [97/100][360/625]\teta 0:00:09 lr 0.000012\t wd 0.0100\ttime 0.0357 (0.0355)\tloss 0.4038 (0.3697)\tgrad_norm 1.4439 (nan)\tloss_scale 32768.0000 (32858.7701)\tmem 455MB\n",
      "Train: [97/100][370/625]\teta 0:00:09 lr 0.000012\t wd 0.0100\ttime 0.0391 (0.0355)\tloss 0.5142 (0.3704)\tgrad_norm 2.5668 (nan)\tloss_scale 32768.0000 (32856.3235)\tmem 455MB\n",
      "Train: [97/100][380/625]\teta 0:00:08 lr 0.000011\t wd 0.0100\ttime 0.0328 (0.0355)\tloss 0.5059 (0.3696)\tgrad_norm 2.3423 (nan)\tloss_scale 32768.0000 (32854.0052)\tmem 455MB\n",
      "Train: [97/100][390/625]\teta 0:00:08 lr 0.000011\t wd 0.0100\ttime 0.0355 (0.0355)\tloss 0.3530 (0.3711)\tgrad_norm 1.9598 (nan)\tloss_scale 32768.0000 (32851.8056)\tmem 455MB\n",
      "Train: [97/100][400/625]\teta 0:00:08 lr 0.000011\t wd 0.0100\ttime 0.0361 (0.0356)\tloss 0.3669 (0.3715)\tgrad_norm 2.7575 (nan)\tloss_scale 32768.0000 (32849.7157)\tmem 455MB\n",
      "Train: [97/100][410/625]\teta 0:00:07 lr 0.000011\t wd 0.0100\ttime 0.0326 (0.0356)\tloss 0.3374 (0.3710)\tgrad_norm 2.2724 (nan)\tloss_scale 32768.0000 (32847.7275)\tmem 455MB\n",
      "Train: [97/100][420/625]\teta 0:00:07 lr 0.000011\t wd 0.0100\ttime 0.0349 (0.0355)\tloss 0.3088 (0.3707)\tgrad_norm 2.1108 (nan)\tloss_scale 32768.0000 (32845.8337)\tmem 455MB\n",
      "Train: [97/100][430/625]\teta 0:00:06 lr 0.000011\t wd 0.0100\ttime 0.0325 (0.0355)\tloss 0.3945 (0.3694)\tgrad_norm 2.3388 (nan)\tloss_scale 32768.0000 (32844.0278)\tmem 455MB\n",
      "Train: [97/100][440/625]\teta 0:00:06 lr 0.000011\t wd 0.0100\ttime 0.0394 (0.0355)\tloss 0.4038 (0.3700)\tgrad_norm 1.9641 (nan)\tloss_scale 32768.0000 (32842.3039)\tmem 455MB\n",
      "Train: [97/100][450/625]\teta 0:00:06 lr 0.000011\t wd 0.0100\ttime 0.0324 (0.0355)\tloss 0.3347 (0.3697)\tgrad_norm 2.5082 (nan)\tloss_scale 32768.0000 (32840.6563)\tmem 455MB\n",
      "Train: [97/100][460/625]\teta 0:00:05 lr 0.000011\t wd 0.0100\ttime 0.0326 (0.0355)\tloss 0.6060 (0.3708)\tgrad_norm 3.2353 (nan)\tloss_scale 32768.0000 (32839.0803)\tmem 455MB\n",
      "Train: [97/100][470/625]\teta 0:00:05 lr 0.000011\t wd 0.0100\ttime 0.0352 (0.0356)\tloss 0.4426 (0.3708)\tgrad_norm 2.2697 (nan)\tloss_scale 32768.0000 (32837.5711)\tmem 455MB\n",
      "Train: [97/100][480/625]\teta 0:00:05 lr 0.000011\t wd 0.0100\ttime 0.0358 (0.0356)\tloss 0.4155 (0.3713)\tgrad_norm 1.8880 (nan)\tloss_scale 32768.0000 (32836.1247)\tmem 455MB\n",
      "Train: [97/100][490/625]\teta 0:00:04 lr 0.000011\t wd 0.0100\ttime 0.0386 (0.0356)\tloss 0.4338 (0.3707)\tgrad_norm 2.0694 (nan)\tloss_scale 32768.0000 (32834.7373)\tmem 455MB\n",
      "Train: [97/100][500/625]\teta 0:00:04 lr 0.000011\t wd 0.0100\ttime 0.0326 (0.0356)\tloss 0.2954 (0.3715)\tgrad_norm 2.1366 (nan)\tloss_scale 32768.0000 (32833.4052)\tmem 455MB\n",
      "Train: [97/100][510/625]\teta 0:00:04 lr 0.000011\t wd 0.0100\ttime 0.0323 (0.0356)\tloss 0.4033 (0.3712)\tgrad_norm 2.1973 (nan)\tloss_scale 32768.0000 (32832.1252)\tmem 455MB\n",
      "Train: [97/100][520/625]\teta 0:00:03 lr 0.000011\t wd 0.0100\ttime 0.0359 (0.0356)\tloss 0.4072 (0.3713)\tgrad_norm 2.2817 (nan)\tloss_scale 32768.0000 (32830.8944)\tmem 455MB\n",
      "Train: [97/100][530/625]\teta 0:00:03 lr 0.000011\t wd 0.0100\ttime 0.0352 (0.0357)\tloss 0.3135 (0.3716)\tgrad_norm 2.2361 (nan)\tloss_scale 32768.0000 (32829.7100)\tmem 455MB\n",
      "Train: [97/100][540/625]\teta 0:00:03 lr 0.000011\t wd 0.0100\ttime 0.0358 (0.0356)\tloss 0.5688 (0.3721)\tgrad_norm 3.0475 (nan)\tloss_scale 32768.0000 (32828.5693)\tmem 455MB\n",
      "Train: [97/100][550/625]\teta 0:00:02 lr 0.000011\t wd 0.0100\ttime 0.0327 (0.0357)\tloss 0.2520 (0.3719)\tgrad_norm 1.6951 (nan)\tloss_scale 32768.0000 (32827.4701)\tmem 455MB\n",
      "Train: [97/100][560/625]\teta 0:00:02 lr 0.000011\t wd 0.0100\ttime 0.0371 (0.0357)\tloss 0.5347 (0.3718)\tgrad_norm 2.5260 (nan)\tloss_scale 32768.0000 (32826.4100)\tmem 455MB\n",
      "Train: [97/100][570/625]\teta 0:00:01 lr 0.000011\t wd 0.0100\ttime 0.0388 (0.0357)\tloss 0.5308 (0.3729)\tgrad_norm 3.3976 (nan)\tloss_scale 32768.0000 (32825.3870)\tmem 455MB\n",
      "Train: [97/100][580/625]\teta 0:00:01 lr 0.000011\t wd 0.0100\ttime 0.0342 (0.0357)\tloss 0.5576 (0.3734)\tgrad_norm 3.1653 (nan)\tloss_scale 32768.0000 (32824.3993)\tmem 455MB\n",
      "Train: [97/100][590/625]\teta 0:00:01 lr 0.000011\t wd 0.0100\ttime 0.0326 (0.0357)\tloss 0.5576 (0.3732)\tgrad_norm 3.3955 (nan)\tloss_scale 32768.0000 (32823.4450)\tmem 455MB\n",
      "Train: [97/100][600/625]\teta 0:00:00 lr 0.000011\t wd 0.0100\ttime 0.0322 (0.0357)\tloss 0.3618 (0.3724)\tgrad_norm 2.0312 (nan)\tloss_scale 32768.0000 (32822.5225)\tmem 455MB\n",
      "Train: [97/100][610/625]\teta 0:00:00 lr 0.000011\t wd 0.0100\ttime 0.0375 (0.0356)\tloss 0.3965 (0.3723)\tgrad_norm 2.4404 (nan)\tloss_scale 32768.0000 (32821.6301)\tmem 455MB\n",
      "Train: [97/100][620/625]\teta 0:00:00 lr 0.000011\t wd 0.0100\ttime 0.0344 (0.0357)\tloss 0.2830 (0.3718)\tgrad_norm 2.0216 (nan)\tloss_scale 32768.0000 (32820.7665)\tmem 455MB\n",
      "EPOCH 97 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_97.pth saving......\n",
      "./model_save/ckpt_epoch_97.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.7217 (0.7217)\tAcc@1 78.125 (78.125)\tAcc@5 98.438 (98.438)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.4939 (0.5183)\tAcc@1 79.688 (83.381)\tAcc@5 100.000 (99.006)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.016 (0.015)\tLoss 0.5073 (0.5167)\tAcc@1 79.688 (82.738)\tAcc@5 100.000 (99.182)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.016 (0.015)\tLoss 0.6860 (0.5440)\tAcc@1 75.000 (81.754)\tAcc@5 100.000 (98.992)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.5205 (0.5529)\tAcc@1 85.938 (81.517)\tAcc@5 100.000 (99.009)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.5908 (0.5554)\tAcc@1 81.250 (81.464)\tAcc@5 100.000 (99.081)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.3813 (0.5518)\tAcc@1 85.938 (81.532)\tAcc@5 100.000 (99.078)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.4688 (0.5513)\tAcc@1 82.812 (81.646)\tAcc@5 100.000 (99.164)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.015 (0.015)\tLoss 0.5952 (0.5582)\tAcc@1 81.250 (81.655)\tAcc@5 100.000 (99.113)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.5410 (0.5600)\tAcc@1 82.812 (81.542)\tAcc@5 100.000 (99.056)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.9404 (0.5746)\tAcc@1 73.438 (81.064)\tAcc@5 96.875 (99.072)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.5044 (0.5724)\tAcc@1 85.938 (81.137)\tAcc@5 98.438 (99.113)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.3223 (0.5735)\tAcc@1 82.812 (81.095)\tAcc@5 100.000 (99.109)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.3323 (0.5753)\tAcc@1 85.938 (81.131)\tAcc@5 100.000 (99.129)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.5273 (0.5770)\tAcc@1 82.812 (81.095)\tAcc@5 100.000 (99.125)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.6895 (0.5738)\tAcc@1 82.812 (81.188)\tAcc@5 98.438 (99.100)\tMem 455MB\n",
      " * Acc@1 81.190 Acc@5 99.120\n",
      "Accuracy of the network on the 10000 test images: 81.2%\n",
      "Max accuracy: 81.55%\n",
      "Train: [98/100][0/625]\teta 0:00:23 lr 0.000011\t wd 0.0100\ttime 0.0378 (0.0378)\tloss 0.2252 (0.2252)\tgrad_norm 1.8965 (1.8965)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][10/625]\teta 0:00:23 lr 0.000011\t wd 0.0100\ttime 0.0365 (0.0376)\tloss 0.2964 (0.3842)\tgrad_norm 1.9966 (2.1694)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][20/625]\teta 0:00:22 lr 0.000011\t wd 0.0100\ttime 0.0327 (0.0369)\tloss 0.3372 (0.3591)\tgrad_norm 1.9645 (2.1086)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][30/625]\teta 0:00:22 lr 0.000011\t wd 0.0100\ttime 0.0335 (0.0370)\tloss 0.2206 (0.3783)\tgrad_norm 1.5512 (2.2288)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][40/625]\teta 0:00:21 lr 0.000011\t wd 0.0100\ttime 0.0326 (0.0362)\tloss 0.3228 (0.3893)\tgrad_norm 1.8879 (2.2643)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][50/625]\teta 0:00:20 lr 0.000011\t wd 0.0100\ttime 0.0328 (0.0357)\tloss 0.4944 (0.3838)\tgrad_norm 3.2735 (2.2562)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][60/625]\teta 0:00:20 lr 0.000011\t wd 0.0100\ttime 0.0334 (0.0354)\tloss 0.3247 (0.3790)\tgrad_norm 2.0672 (2.2066)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][70/625]\teta 0:00:19 lr 0.000011\t wd 0.0100\ttime 0.0331 (0.0353)\tloss 0.3052 (0.3741)\tgrad_norm 1.9733 (2.2084)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][80/625]\teta 0:00:19 lr 0.000011\t wd 0.0100\ttime 0.0342 (0.0354)\tloss 0.2610 (0.3719)\tgrad_norm 1.5563 (2.2077)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][90/625]\teta 0:00:18 lr 0.000011\t wd 0.0100\ttime 0.0352 (0.0355)\tloss 0.2455 (0.3745)\tgrad_norm 1.6709 (2.2153)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][100/625]\teta 0:00:18 lr 0.000011\t wd 0.0100\ttime 0.0370 (0.0357)\tloss 0.3557 (0.3771)\tgrad_norm 2.1150 (2.2214)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][110/625]\teta 0:00:18 lr 0.000011\t wd 0.0100\ttime 0.0327 (0.0355)\tloss 0.2861 (0.3698)\tgrad_norm 1.6613 (2.2029)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][120/625]\teta 0:00:17 lr 0.000011\t wd 0.0100\ttime 0.0327 (0.0354)\tloss 0.3364 (0.3680)\tgrad_norm 2.1322 (2.2096)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][130/625]\teta 0:00:17 lr 0.000011\t wd 0.0100\ttime 0.0366 (0.0353)\tloss 0.4419 (0.3672)\tgrad_norm 2.7844 (2.2202)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][140/625]\teta 0:00:17 lr 0.000011\t wd 0.0100\ttime 0.0368 (0.0353)\tloss 0.4185 (0.3657)\tgrad_norm 2.3101 (2.2136)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][150/625]\teta 0:00:16 lr 0.000011\t wd 0.0100\ttime 0.0350 (0.0353)\tloss 0.4141 (0.3636)\tgrad_norm 2.5166 (2.2106)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][160/625]\teta 0:00:16 lr 0.000011\t wd 0.0100\ttime 0.0363 (0.0352)\tloss 0.2617 (0.3633)\tgrad_norm 2.0701 (2.2101)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][170/625]\teta 0:00:15 lr 0.000011\t wd 0.0100\ttime 0.0365 (0.0351)\tloss 0.4087 (0.3645)\tgrad_norm 2.3706 (2.2130)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][180/625]\teta 0:00:15 lr 0.000011\t wd 0.0100\ttime 0.0323 (0.0351)\tloss 0.3054 (0.3680)\tgrad_norm 2.1151 (2.2189)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][190/625]\teta 0:00:15 lr 0.000011\t wd 0.0100\ttime 0.0332 (0.0350)\tloss 0.2717 (0.3662)\tgrad_norm 1.8621 (2.2133)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][200/625]\teta 0:00:14 lr 0.000011\t wd 0.0100\ttime 0.0323 (0.0349)\tloss 0.3188 (0.3656)\tgrad_norm 3.5865 (2.2200)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][210/625]\teta 0:00:14 lr 0.000011\t wd 0.0100\ttime 0.0331 (0.0349)\tloss 0.5972 (0.3656)\tgrad_norm 2.1563 (2.2261)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][220/625]\teta 0:00:14 lr 0.000011\t wd 0.0100\ttime 0.0357 (0.0348)\tloss 0.4729 (0.3669)\tgrad_norm 3.3559 (2.2406)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][230/625]\teta 0:00:13 lr 0.000011\t wd 0.0100\ttime 0.0360 (0.0348)\tloss 0.3494 (0.3670)\tgrad_norm 2.8827 (2.2491)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][240/625]\teta 0:00:13 lr 0.000011\t wd 0.0100\ttime 0.0352 (0.0348)\tloss 0.5781 (0.3668)\tgrad_norm 3.3741 (2.2440)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][250/625]\teta 0:00:13 lr 0.000011\t wd 0.0100\ttime 0.0325 (0.0348)\tloss 0.3948 (0.3673)\tgrad_norm 2.3163 (2.2462)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][260/625]\teta 0:00:12 lr 0.000011\t wd 0.0100\ttime 0.0324 (0.0349)\tloss 0.4512 (0.3687)\tgrad_norm 2.3475 (2.2498)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][270/625]\teta 0:00:12 lr 0.000011\t wd 0.0100\ttime 0.0324 (0.0348)\tloss 0.3232 (0.3710)\tgrad_norm 2.3309 (2.2576)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][280/625]\teta 0:00:12 lr 0.000011\t wd 0.0100\ttime 0.0324 (0.0348)\tloss 0.2323 (0.3707)\tgrad_norm 1.5000 (2.2605)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][290/625]\teta 0:00:11 lr 0.000011\t wd 0.0100\ttime 0.0321 (0.0348)\tloss 0.5107 (0.3711)\tgrad_norm 2.8532 (2.2648)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][300/625]\teta 0:00:11 lr 0.000011\t wd 0.0100\ttime 0.0365 (0.0348)\tloss 0.5176 (0.3725)\tgrad_norm 2.0646 (2.2651)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][310/625]\teta 0:00:10 lr 0.000011\t wd 0.0100\ttime 0.0351 (0.0348)\tloss 0.3835 (0.3728)\tgrad_norm 1.5660 (2.2635)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][320/625]\teta 0:00:10 lr 0.000011\t wd 0.0100\ttime 0.0325 (0.0348)\tloss 0.5957 (0.3731)\tgrad_norm 2.5279 (2.2635)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][330/625]\teta 0:00:10 lr 0.000011\t wd 0.0100\ttime 0.0397 (0.0348)\tloss 0.2544 (0.3724)\tgrad_norm 1.7913 (2.2561)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][340/625]\teta 0:00:09 lr 0.000011\t wd 0.0100\ttime 0.0389 (0.0349)\tloss 0.3877 (0.3740)\tgrad_norm 2.1667 (2.2597)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][350/625]\teta 0:00:09 lr 0.000011\t wd 0.0100\ttime 0.0365 (0.0349)\tloss 0.4070 (0.3730)\tgrad_norm 1.8938 (2.2613)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][360/625]\teta 0:00:09 lr 0.000011\t wd 0.0100\ttime 0.0327 (0.0350)\tloss 0.3994 (0.3730)\tgrad_norm 2.1966 (2.2609)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][370/625]\teta 0:00:08 lr 0.000011\t wd 0.0100\ttime 0.0329 (0.0350)\tloss 0.2380 (0.3720)\tgrad_norm 1.8745 (2.2609)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][380/625]\teta 0:00:08 lr 0.000011\t wd 0.0100\ttime 0.0323 (0.0350)\tloss 0.4192 (0.3715)\tgrad_norm 2.2552 (2.2551)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][390/625]\teta 0:00:08 lr 0.000010\t wd 0.0100\ttime 0.0326 (0.0350)\tloss 0.3389 (0.3716)\tgrad_norm 2.4784 (2.2575)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][400/625]\teta 0:00:07 lr 0.000010\t wd 0.0100\ttime 0.0322 (0.0350)\tloss 0.3589 (0.3721)\tgrad_norm 1.9252 (2.2576)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][410/625]\teta 0:00:07 lr 0.000010\t wd 0.0100\ttime 0.0326 (0.0350)\tloss 0.3467 (0.3720)\tgrad_norm 2.2044 (2.2557)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][420/625]\teta 0:00:07 lr 0.000010\t wd 0.0100\ttime 0.0325 (0.0350)\tloss 0.4812 (0.3724)\tgrad_norm 2.4131 (2.2563)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][430/625]\teta 0:00:06 lr 0.000010\t wd 0.0100\ttime 0.0356 (0.0351)\tloss 0.3171 (0.3716)\tgrad_norm 1.6327 (2.2508)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][440/625]\teta 0:00:06 lr 0.000010\t wd 0.0100\ttime 0.0362 (0.0351)\tloss 0.3928 (0.3719)\tgrad_norm 2.7942 (2.2490)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][450/625]\teta 0:00:06 lr 0.000010\t wd 0.0100\ttime 0.0325 (0.0351)\tloss 0.1614 (0.3713)\tgrad_norm 1.5125 (2.2445)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][460/625]\teta 0:00:05 lr 0.000010\t wd 0.0100\ttime 0.0328 (0.0351)\tloss 0.3599 (0.3700)\tgrad_norm 1.9116 (2.2384)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][470/625]\teta 0:00:05 lr 0.000010\t wd 0.0100\ttime 0.0357 (0.0351)\tloss 0.2832 (0.3700)\tgrad_norm 1.9894 (2.2365)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][480/625]\teta 0:00:05 lr 0.000010\t wd 0.0100\ttime 0.0377 (0.0351)\tloss 0.4558 (0.3704)\tgrad_norm 2.2287 (2.2432)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][490/625]\teta 0:00:04 lr 0.000010\t wd 0.0100\ttime 0.0323 (0.0351)\tloss 0.6846 (0.3716)\tgrad_norm 2.9172 (2.2434)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][500/625]\teta 0:00:04 lr 0.000010\t wd 0.0100\ttime 0.0327 (0.0351)\tloss 0.3821 (0.3716)\tgrad_norm 1.9143 (2.2438)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][510/625]\teta 0:00:04 lr 0.000010\t wd 0.0100\ttime 0.0325 (0.0351)\tloss 0.3044 (0.3716)\tgrad_norm 1.9057 (2.2408)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][520/625]\teta 0:00:03 lr 0.000010\t wd 0.0100\ttime 0.0369 (0.0351)\tloss 0.2249 (0.3716)\tgrad_norm 1.6534 (2.2456)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][530/625]\teta 0:00:03 lr 0.000010\t wd 0.0100\ttime 0.0385 (0.0352)\tloss 0.5732 (0.3714)\tgrad_norm 2.2762 (2.2426)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][540/625]\teta 0:00:02 lr 0.000010\t wd 0.0100\ttime 0.0396 (0.0353)\tloss 0.2360 (0.3712)\tgrad_norm 1.5873 (2.2416)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][550/625]\teta 0:00:02 lr 0.000010\t wd 0.0100\ttime 0.0355 (0.0353)\tloss 0.5400 (0.3714)\tgrad_norm 2.3083 (2.2384)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][560/625]\teta 0:00:02 lr 0.000010\t wd 0.0100\ttime 0.0364 (0.0353)\tloss 0.3113 (0.3713)\tgrad_norm 2.1151 (2.2384)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][570/625]\teta 0:00:01 lr 0.000010\t wd 0.0100\ttime 0.0331 (0.0353)\tloss 0.4001 (0.3716)\tgrad_norm 2.6764 (2.2399)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][580/625]\teta 0:00:01 lr 0.000010\t wd 0.0100\ttime 0.0358 (0.0353)\tloss 0.2788 (0.3714)\tgrad_norm 2.7508 (2.2407)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][590/625]\teta 0:00:01 lr 0.000010\t wd 0.0100\ttime 0.0333 (0.0354)\tloss 0.2441 (0.3716)\tgrad_norm 1.6078 (2.2421)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][600/625]\teta 0:00:00 lr 0.000010\t wd 0.0100\ttime 0.0359 (0.0354)\tloss 0.4731 (0.3714)\tgrad_norm 2.3279 (2.2443)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][610/625]\teta 0:00:00 lr 0.000010\t wd 0.0100\ttime 0.0365 (0.0354)\tloss 0.3865 (0.3718)\tgrad_norm 2.0923 (2.2451)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [98/100][620/625]\teta 0:00:00 lr 0.000010\t wd 0.0100\ttime 0.0329 (0.0354)\tloss 0.3735 (0.3720)\tgrad_norm 2.3853 (2.2483)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 98 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_98.pth saving......\n",
      "./model_save/ckpt_epoch_98.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.4036 (0.4036)\tAcc@1 81.250 (81.250)\tAcc@5 100.000 (100.000)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.4382 (0.5578)\tAcc@1 84.375 (81.818)\tAcc@5 100.000 (99.148)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.5132 (0.5852)\tAcc@1 82.812 (80.804)\tAcc@5 98.438 (99.330)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.016 (0.015)\tLoss 0.8442 (0.5894)\tAcc@1 71.875 (80.444)\tAcc@5 98.438 (99.143)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.016 (0.016)\tLoss 0.7334 (0.5879)\tAcc@1 76.562 (79.916)\tAcc@5 98.438 (99.200)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.016 (0.016)\tLoss 0.7026 (0.5795)\tAcc@1 75.000 (80.392)\tAcc@5 100.000 (99.203)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.016 (0.016)\tLoss 0.5337 (0.5702)\tAcc@1 87.500 (80.917)\tAcc@5 96.875 (99.129)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.016 (0.016)\tLoss 0.4280 (0.5640)\tAcc@1 85.938 (81.074)\tAcc@5 100.000 (99.142)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.016 (0.016)\tLoss 0.5972 (0.5635)\tAcc@1 76.562 (80.903)\tAcc@5 100.000 (99.074)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.016)\tLoss 0.5361 (0.5705)\tAcc@1 82.812 (80.855)\tAcc@5 98.438 (99.038)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.016 (0.016)\tLoss 0.6157 (0.5778)\tAcc@1 76.562 (80.739)\tAcc@5 100.000 (98.994)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.016 (0.016)\tLoss 0.6929 (0.5865)\tAcc@1 75.000 (80.560)\tAcc@5 98.438 (99.001)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.016 (0.016)\tLoss 0.5400 (0.5880)\tAcc@1 79.688 (80.643)\tAcc@5 98.438 (98.941)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.016 (0.016)\tLoss 0.4248 (0.5793)\tAcc@1 81.250 (80.749)\tAcc@5 100.000 (99.010)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.016 (0.016)\tLoss 0.5703 (0.5755)\tAcc@1 81.250 (80.929)\tAcc@5 98.438 (99.025)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.016 (0.016)\tLoss 0.3218 (0.5763)\tAcc@1 89.062 (80.867)\tAcc@5 100.000 (99.038)\tMem 455MB\n",
      " * Acc@1 80.920 Acc@5 99.030\n",
      "Accuracy of the network on the 10000 test images: 80.9%\n",
      "Max accuracy: 81.55%\n",
      "Train: [99/100][0/625]\teta 0:00:23 lr 0.000010\t wd 0.0100\ttime 0.0375 (0.0375)\tloss 0.3442 (0.3442)\tgrad_norm 1.9148 (1.9148)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][10/625]\teta 0:00:22 lr 0.000010\t wd 0.0100\ttime 0.0388 (0.0366)\tloss 0.4172 (0.3698)\tgrad_norm 2.8864 (2.4026)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][20/625]\teta 0:00:21 lr 0.000010\t wd 0.0100\ttime 0.0353 (0.0361)\tloss 0.4390 (0.4084)\tgrad_norm 2.3235 (2.4209)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][30/625]\teta 0:00:21 lr 0.000010\t wd 0.0100\ttime 0.0331 (0.0362)\tloss 0.3059 (0.3930)\tgrad_norm 1.6704 (2.4018)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][40/625]\teta 0:00:21 lr 0.000010\t wd 0.0100\ttime 0.0327 (0.0359)\tloss 0.3767 (0.3887)\tgrad_norm 2.3299 (2.4075)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][50/625]\teta 0:00:20 lr 0.000010\t wd 0.0100\ttime 0.0380 (0.0359)\tloss 0.2544 (0.3911)\tgrad_norm 2.2650 (2.4121)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][60/625]\teta 0:00:20 lr 0.000010\t wd 0.0100\ttime 0.0392 (0.0359)\tloss 0.2435 (0.3791)\tgrad_norm 1.5728 (2.3648)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][70/625]\teta 0:00:19 lr 0.000010\t wd 0.0100\ttime 0.0352 (0.0359)\tloss 0.4629 (0.3745)\tgrad_norm 2.6976 (2.3492)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][80/625]\teta 0:00:19 lr 0.000010\t wd 0.0100\ttime 0.0328 (0.0359)\tloss 0.2544 (0.3701)\tgrad_norm 1.6933 (2.3386)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][90/625]\teta 0:00:19 lr 0.000010\t wd 0.0100\ttime 0.0353 (0.0361)\tloss 0.4253 (0.3688)\tgrad_norm 2.6770 (2.3171)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][100/625]\teta 0:00:18 lr 0.000010\t wd 0.0100\ttime 0.0359 (0.0360)\tloss 0.2686 (0.3681)\tgrad_norm 1.9996 (2.3115)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][110/625]\teta 0:00:18 lr 0.000010\t wd 0.0100\ttime 0.0352 (0.0359)\tloss 0.5024 (0.3721)\tgrad_norm 2.5323 (2.3258)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][120/625]\teta 0:00:18 lr 0.000010\t wd 0.0100\ttime 0.0389 (0.0360)\tloss 0.3181 (0.3691)\tgrad_norm 2.0154 (2.3089)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][130/625]\teta 0:00:17 lr 0.000010\t wd 0.0100\ttime 0.0330 (0.0358)\tloss 0.4866 (0.3697)\tgrad_norm 3.2857 (2.2904)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][140/625]\teta 0:00:17 lr 0.000010\t wd 0.0100\ttime 0.0364 (0.0359)\tloss 0.3813 (0.3710)\tgrad_norm 2.3592 (2.2872)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][150/625]\teta 0:00:17 lr 0.000010\t wd 0.0100\ttime 0.0391 (0.0360)\tloss 0.2283 (0.3740)\tgrad_norm 2.0051 (2.2683)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][160/625]\teta 0:00:16 lr 0.000010\t wd 0.0100\ttime 0.0330 (0.0361)\tloss 0.4485 (0.3756)\tgrad_norm 1.6192 (2.2562)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][170/625]\teta 0:00:16 lr 0.000010\t wd 0.0100\ttime 0.0350 (0.0360)\tloss 0.4148 (0.3752)\tgrad_norm 2.2279 (2.2598)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][180/625]\teta 0:00:16 lr 0.000010\t wd 0.0100\ttime 0.0334 (0.0360)\tloss 0.3367 (0.3758)\tgrad_norm 1.9328 (2.2565)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][190/625]\teta 0:00:15 lr 0.000010\t wd 0.0100\ttime 0.0360 (0.0361)\tloss 0.5273 (0.3768)\tgrad_norm 2.2426 (2.2589)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][200/625]\teta 0:00:15 lr 0.000010\t wd 0.0100\ttime 0.0337 (0.0361)\tloss 0.4324 (0.3770)\tgrad_norm 2.1615 (2.2573)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][210/625]\teta 0:00:14 lr 0.000010\t wd 0.0100\ttime 0.0324 (0.0361)\tloss 0.3550 (0.3775)\tgrad_norm 1.6333 (2.2521)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][220/625]\teta 0:00:14 lr 0.000010\t wd 0.0100\ttime 0.0326 (0.0360)\tloss 0.2092 (0.3771)\tgrad_norm 1.6989 (2.2437)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][230/625]\teta 0:00:14 lr 0.000010\t wd 0.0100\ttime 0.0386 (0.0359)\tloss 0.5239 (0.3777)\tgrad_norm 2.7959 (2.2520)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][240/625]\teta 0:00:13 lr 0.000010\t wd 0.0100\ttime 0.0328 (0.0360)\tloss 0.3652 (0.3772)\tgrad_norm 2.3127 (2.2556)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][250/625]\teta 0:00:13 lr 0.000010\t wd 0.0100\ttime 0.0395 (0.0360)\tloss 0.4697 (0.3760)\tgrad_norm 2.0720 (2.2536)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][260/625]\teta 0:00:13 lr 0.000010\t wd 0.0100\ttime 0.0323 (0.0360)\tloss 0.4973 (0.3777)\tgrad_norm 2.9355 (2.2574)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][270/625]\teta 0:00:12 lr 0.000010\t wd 0.0100\ttime 0.0399 (0.0360)\tloss 0.5063 (0.3788)\tgrad_norm 3.4807 (2.2648)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][280/625]\teta 0:00:12 lr 0.000010\t wd 0.0100\ttime 0.0325 (0.0360)\tloss 0.2805 (0.3783)\tgrad_norm 1.5212 (2.2561)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][290/625]\teta 0:00:12 lr 0.000010\t wd 0.0100\ttime 0.0327 (0.0360)\tloss 0.3315 (0.3775)\tgrad_norm 2.9069 (2.2564)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][300/625]\teta 0:00:11 lr 0.000010\t wd 0.0100\ttime 0.0350 (0.0360)\tloss 0.3665 (0.3765)\tgrad_norm 2.4235 (2.2519)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][310/625]\teta 0:00:11 lr 0.000010\t wd 0.0100\ttime 0.0326 (0.0359)\tloss 0.3652 (0.3762)\tgrad_norm 2.2142 (2.2477)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][320/625]\teta 0:00:10 lr 0.000010\t wd 0.0100\ttime 0.0358 (0.0360)\tloss 0.3008 (0.3757)\tgrad_norm 1.8522 (2.2498)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][330/625]\teta 0:00:10 lr 0.000010\t wd 0.0100\ttime 0.0364 (0.0359)\tloss 0.4734 (0.3751)\tgrad_norm 2.0777 (2.2469)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][340/625]\teta 0:00:10 lr 0.000010\t wd 0.0100\ttime 0.0364 (0.0359)\tloss 0.3047 (0.3759)\tgrad_norm 2.3604 (2.2521)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][350/625]\teta 0:00:09 lr 0.000010\t wd 0.0100\ttime 0.0326 (0.0359)\tloss 0.1989 (0.3753)\tgrad_norm 1.5440 (2.2549)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][360/625]\teta 0:00:09 lr 0.000010\t wd 0.0100\ttime 0.0389 (0.0359)\tloss 0.1619 (0.3737)\tgrad_norm 1.9670 (2.2551)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][370/625]\teta 0:00:09 lr 0.000010\t wd 0.0100\ttime 0.0358 (0.0359)\tloss 0.3511 (0.3751)\tgrad_norm 1.7391 (2.2603)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][380/625]\teta 0:00:08 lr 0.000010\t wd 0.0100\ttime 0.0390 (0.0359)\tloss 0.4248 (0.3757)\tgrad_norm 3.0108 (2.2603)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][390/625]\teta 0:00:08 lr 0.000010\t wd 0.0100\ttime 0.0332 (0.0359)\tloss 0.3909 (0.3766)\tgrad_norm 2.5709 (2.2706)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][400/625]\teta 0:00:08 lr 0.000010\t wd 0.0100\ttime 0.0349 (0.0359)\tloss 0.5049 (0.3761)\tgrad_norm 3.3778 (2.2705)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][410/625]\teta 0:00:07 lr 0.000010\t wd 0.0100\ttime 0.0398 (0.0360)\tloss 0.4546 (0.3749)\tgrad_norm 2.4122 (2.2663)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][420/625]\teta 0:00:07 lr 0.000010\t wd 0.0100\ttime 0.0401 (0.0360)\tloss 0.4365 (0.3754)\tgrad_norm 2.5095 (2.2664)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][430/625]\teta 0:00:07 lr 0.000010\t wd 0.0100\ttime 0.0351 (0.0360)\tloss 0.5181 (0.3751)\tgrad_norm 2.4804 (2.2627)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][440/625]\teta 0:00:06 lr 0.000010\t wd 0.0100\ttime 0.0401 (0.0360)\tloss 0.3328 (0.3748)\tgrad_norm 2.9438 (2.2626)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][450/625]\teta 0:00:06 lr 0.000010\t wd 0.0100\ttime 0.0337 (0.0361)\tloss 0.4648 (0.3746)\tgrad_norm 2.5801 (2.2613)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][460/625]\teta 0:00:05 lr 0.000010\t wd 0.0100\ttime 0.0400 (0.0361)\tloss 0.3389 (0.3746)\tgrad_norm 2.3607 (2.2642)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][470/625]\teta 0:00:05 lr 0.000010\t wd 0.0100\ttime 0.0325 (0.0361)\tloss 0.3433 (0.3744)\tgrad_norm 1.8731 (2.2611)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][480/625]\teta 0:00:05 lr 0.000010\t wd 0.0100\ttime 0.0329 (0.0361)\tloss 0.2466 (0.3747)\tgrad_norm 1.3072 (2.2603)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][490/625]\teta 0:00:04 lr 0.000010\t wd 0.0100\ttime 0.0349 (0.0360)\tloss 0.3303 (0.3747)\tgrad_norm 1.7693 (2.2601)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][500/625]\teta 0:00:04 lr 0.000010\t wd 0.0100\ttime 0.0326 (0.0360)\tloss 0.5815 (0.3767)\tgrad_norm 2.9749 (2.2671)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][510/625]\teta 0:00:04 lr 0.000010\t wd 0.0100\ttime 0.0354 (0.0360)\tloss 0.4790 (0.3772)\tgrad_norm 2.2625 (2.2666)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][520/625]\teta 0:00:03 lr 0.000010\t wd 0.0100\ttime 0.0381 (0.0360)\tloss 0.3303 (0.3770)\tgrad_norm 2.1939 (2.2662)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][530/625]\teta 0:00:03 lr 0.000010\t wd 0.0100\ttime 0.0352 (0.0360)\tloss 0.3840 (0.3767)\tgrad_norm 1.7496 (2.2655)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][540/625]\teta 0:00:03 lr 0.000010\t wd 0.0100\ttime 0.0395 (0.0360)\tloss 0.3867 (0.3760)\tgrad_norm 2.1838 (2.2613)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][550/625]\teta 0:00:02 lr 0.000010\t wd 0.0100\ttime 0.0327 (0.0360)\tloss 0.4736 (0.3764)\tgrad_norm 2.3629 (2.2599)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][560/625]\teta 0:00:02 lr 0.000010\t wd 0.0100\ttime 0.0389 (0.0360)\tloss 0.3457 (0.3764)\tgrad_norm 2.4281 (2.2606)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][570/625]\teta 0:00:01 lr 0.000010\t wd 0.0100\ttime 0.0377 (0.0360)\tloss 0.2106 (0.3758)\tgrad_norm 1.3116 (2.2581)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][580/625]\teta 0:00:01 lr 0.000010\t wd 0.0100\ttime 0.0356 (0.0360)\tloss 0.3721 (0.3753)\tgrad_norm 2.5581 (2.2609)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][590/625]\teta 0:00:01 lr 0.000010\t wd 0.0100\ttime 0.0347 (0.0360)\tloss 0.3752 (0.3750)\tgrad_norm 3.2665 (2.2629)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][600/625]\teta 0:00:00 lr 0.000010\t wd 0.0100\ttime 0.0329 (0.0360)\tloss 0.2539 (0.3748)\tgrad_norm 1.8564 (2.2616)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][610/625]\teta 0:00:00 lr 0.000010\t wd 0.0100\ttime 0.0331 (0.0359)\tloss 0.2808 (0.3746)\tgrad_norm 2.2226 (2.2585)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "Train: [99/100][620/625]\teta 0:00:00 lr 0.000010\t wd 0.0100\ttime 0.0327 (0.0359)\tloss 0.5181 (0.3743)\tgrad_norm 3.2641 (2.2588)\tloss_scale 32768.0000 (32768.0000)\tmem 455MB\n",
      "EPOCH 99 training takes 0:00:22\n",
      "./model_save/ckpt_epoch_99.pth saving......\n",
      "./model_save/ckpt_epoch_99.pth saved !!!\n",
      "Test: [0/157]\tTime 0.016 (0.016)\tLoss 0.4421 (0.4421)\tAcc@1 85.938 (85.938)\tAcc@5 100.000 (100.000)\tMem 455MB\n",
      "Test: [10/157]\tTime 0.015 (0.015)\tLoss 0.6963 (0.5771)\tAcc@1 78.125 (80.682)\tAcc@5 96.875 (98.580)\tMem 455MB\n",
      "Test: [20/157]\tTime 0.015 (0.015)\tLoss 0.4719 (0.5467)\tAcc@1 82.812 (82.292)\tAcc@5 98.438 (99.033)\tMem 455MB\n",
      "Test: [30/157]\tTime 0.015 (0.015)\tLoss 0.4167 (0.5331)\tAcc@1 82.812 (82.006)\tAcc@5 100.000 (99.294)\tMem 455MB\n",
      "Test: [40/157]\tTime 0.015 (0.015)\tLoss 0.4067 (0.5357)\tAcc@1 89.062 (81.822)\tAcc@5 98.438 (99.352)\tMem 455MB\n",
      "Test: [50/157]\tTime 0.015 (0.015)\tLoss 0.4949 (0.5575)\tAcc@1 84.375 (81.526)\tAcc@5 100.000 (99.326)\tMem 455MB\n",
      "Test: [60/157]\tTime 0.015 (0.015)\tLoss 0.3574 (0.5603)\tAcc@1 82.812 (81.378)\tAcc@5 100.000 (99.206)\tMem 455MB\n",
      "Test: [70/157]\tTime 0.015 (0.015)\tLoss 0.7041 (0.5677)\tAcc@1 75.000 (81.228)\tAcc@5 98.438 (99.208)\tMem 455MB\n",
      "Test: [80/157]\tTime 0.016 (0.015)\tLoss 0.4294 (0.5680)\tAcc@1 87.500 (81.096)\tAcc@5 100.000 (99.190)\tMem 455MB\n",
      "Test: [90/157]\tTime 0.015 (0.015)\tLoss 0.7305 (0.5677)\tAcc@1 81.250 (81.284)\tAcc@5 96.875 (99.176)\tMem 455MB\n",
      "Test: [100/157]\tTime 0.015 (0.015)\tLoss 0.5640 (0.5721)\tAcc@1 84.375 (81.080)\tAcc@5 100.000 (99.118)\tMem 455MB\n",
      "Test: [110/157]\tTime 0.015 (0.015)\tLoss 0.3667 (0.5705)\tAcc@1 87.500 (81.109)\tAcc@5 100.000 (99.099)\tMem 455MB\n",
      "Test: [120/157]\tTime 0.015 (0.015)\tLoss 0.4636 (0.5729)\tAcc@1 79.688 (81.173)\tAcc@5 100.000 (99.044)\tMem 455MB\n",
      "Test: [130/157]\tTime 0.015 (0.015)\tLoss 0.6313 (0.5700)\tAcc@1 76.562 (81.274)\tAcc@5 98.438 (99.070)\tMem 455MB\n",
      "Test: [140/157]\tTime 0.015 (0.015)\tLoss 0.7622 (0.5690)\tAcc@1 76.562 (81.283)\tAcc@5 98.438 (99.058)\tMem 455MB\n",
      "Test: [150/157]\tTime 0.015 (0.015)\tLoss 0.5703 (0.5713)\tAcc@1 82.812 (81.240)\tAcc@5 96.875 (99.027)\tMem 455MB\n",
      " * Acc@1 81.330 Acc@5 99.040\n",
      "Accuracy of the network on the 10000 test images: 81.3%\n",
      "Max accuracy: 81.55%\n",
      "Training time 0:41:17\n"
     ]
    }
   ],
   "source": [
    "max_accuracy = 0.0\n",
    "\n",
    "print(\"Start training\")\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    # train_iterator.sampler.set_epoch(epoch) # 분산 학습 시에만!\n",
    "\n",
    "    train_one_epoch(epochs, model, criterion, train_iterator, optimizer, epoch, lr_scheduler, loss_scaler)\n",
    "    \n",
    "    if epoch % 1 == 0 or epoch == (epochs - 1): # config.SAVE_FREQ / dist.get_rank() == 0 and (epoch % 1 == 0 or epoch == (epochs - 1))\n",
    "        save_checkpoint(epoch, model, max_accuracy, optimizer, lr_scheduler, loss_scaler)\n",
    "\n",
    "        acc1, acc5, loss = validate(val_iterator, model)\n",
    "        print(f\"Accuracy of the network on the {len(val_subset)} test images: {acc1:.1f}%\")\n",
    "        max_accuracy = max(max_accuracy, acc1)\n",
    "        print(f'Max accuracy: {max_accuracy:.2f}%')\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "print('Training time {}'.format(total_time_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
